<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[文章标题]]></title>
      <url>/sre/2020/05/11/%E6%96%87%E6%A1%A3%E6%A8%A1%E7%89%88/</url>
      <content type="text"><![CDATA[  前言内容前言    code]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第一篇blog]]></title>
      <url>/something/2020/03/11/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E6%96%87/</url>
      <content type="text"><![CDATA[  如何搭建该网站！.准备工作  github pages  jekyll具体过程      github pages 创建  首先新建仓库， 需要以username.github.io作为仓库名。        jekyll  选择模版，可以在Jekyll Themes选择自己喜欢的模版。我选择的是 Next模版，之所以选择该模版，是因为可以按照Next 使用文档一步一步进行操作，对于小白来说比较友好。  遇到问题jekyll安装， ps：mac os  ruby版本过低  解决方案，安装rvm更新ruby，Rvm是一个命令行工具，可以管理多个版本的Ruby。Mac使用RVM更新Ruby  权限问题  使用gem遇到 write permissions for the /usr/bin directory；      sudo gem install -n /usr/local/bin jekyll      I]]></content>
      <categories>
        
          <category> something </category>
        
      </categories>
      <tags>
        
          <tag> something </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十六章 灰度部署 (金丝雀部署)]]></title>
      <url>/sre/2020/01/16/%E7%81%B0%E5%BA%A6%E9%83%A8%E7%BD%B2/</url>
      <content type="text"><![CDATA[  发布工程是一个术语，用来描述从存储库中获取代码发布到生产环境中，之间相关的全部过程和所有组件。自动化发布可以帮助避免许多发布工程的传统缺陷: 重复性和手工任务的辛苦、手动流程的不一致性、无法了解上线的确切状态以及回滚困难。发布工程的自动化已经在其他文献中得到了很好的介绍——例如，关于持续集成和持续交付的书籍(CI/CD)。  我们将灰度发布定义为：对服务进行部分且有时间限制的变更部署，并同时进行评估。该评估将帮助我们决定是否继续上线。变更的服务部分是the canary，服务的其余部分是the control。支持这种方法的逻辑是，灰度发布通常在线上进行小流量发布，或者影响比the control部分少得多的用户上。灰度发布是一个有效的A/B测试过程。  我们将首先介绍发布工程的基础知识，以及通过自动化发布来建立共享词汇的益处。发布工程原理发布工程的基本原理如下:可再生构建构建系统应该能够接受构建输入(源代码、资产等)并生成相同结果。与上周相同的输入(构建代码)应该在本周产生相同的输出。自动化构建一旦代码上传之后，能够自动化生成构建组件并将其上传到存储系统。自动化测试一旦自动构建系统构建了组件，某种类型的测试套件应该确保它们正常工作。自动化部署部署应该由计算机执行，而不是人。小型部署构建系统应该支持小的、自包含的更改。这些原则为运维人员带来直接收益:  通过消除手工和重复的任务来减轻工程师的操作负担。  强制同行评审和版本控制，因为自动化通常是基于代码的。  建立一致的、可重复的、自动化的流程，从而减少错误。  添加对发布管道的监控，通过解决以下问题进行测量和持续改进:          –发布版本需要多长时间生产环境才生效?      –发布成功的频率是多少?一个成功的版本是一个没有严重缺陷或SLO违规的、客户可用的版本。      –可以做哪些更改来尽早的捕获管道中的缺陷?      –哪些步骤可以并行化或进一步优化?      CI/CD与发布自动化相结合可以持续改进开发周期，如图16-1所示。当发布自动化时，你可以更频繁地发布。对于变更率很高的软件来说，更频繁地发布意味着在任何给定的发布工件中捆绑更少的更改。而更小的、自包含的发布工件使得在出现bug时回滚任何给定的发布工件变得成本更低、更容易。更快的发布节奏意味着可以更快地修复bug。平衡发布速度和可靠性快速发布(以下称为发布)和可靠性常常被视为相反的目标。企业希望以100%的可靠性尽快发布新特性和产品改进!然而这个目标是不可能实现的(因为100%从来不是可靠性的正确目标;参见第2章)，但可以在满足特定产品的特定可靠性目标的同时，尽可能快地进行交付。实现这个目标的第一步是了解发布对软件可靠性的影响。在谷歌的经验,大多数事件都是由二进制或配置推送导致的(见附录C)。许多类型的软件更改都可能导致系统故障 - 例如，底层组件的行为更改，依赖关系（例如API）的更改，或DNS等配置更改。尽管对软件进行变更存在固有的风险，但是这些变更(bug修复、安全补丁和新特性)对业务的成功是必需的。你可以使用SLOs和错误预算的概念来衡量发布新版本对可靠性的影响，而不是提倡反对变更。你的目标应该是在满足用户期望的可靠性目标的同时尽快发布软件。下一节将讨论如何使用canary流程来实现这些目标。分离变更频率不同的组件服务由具有不同变更频率的多个组件组成:二进制文件或代码、基础环境(如JVM、内核/OS)、库、服务配置或标志、特性/测试配置和用户配置。如果只有一种发布变更的方法，那么这些组件单独变更会比较困难。特性标志或测试框架(如Gertrude、Feature和PlanOut)允许你将特性启动从二进制版本中分离出来。如果二进制版本包含多个特性，你可以通过更改测试配置一次启用一个特性。这样，就没有必要将这些小的变更集合为一个大的变更，或者为每个特性执行单独的版本。更重要的是，如果只有一些新特性的行为不像预期的那样，你可以选择性地禁用这些特性，直到下一个构建/发布周期可以部署新的二进制文件为止。你可以将特性标志/试验原则应用于服务的任何类型的更改，而不仅仅是软件版本。Canarying是什么？Canarying一词是指将金丝雀带入煤矿以确定该矿是否对人类安全的做法。 由于鸟类比人类更小，呼吸更快，因此它们被危险气体毒害的速度比人类更快。即使你的发布管道是完全自动化的，在真正的流量到达服务之前，你依然无法检测到所有与发布相关的缺陷。当一个发布版本准备好部署到生产环境中时，你的测试策略应该充分保证该版本是安全的，并且按预期工作。然而，测试环境与生产环境并不是100%相同的，并且测试不可能会涵盖100％的场景。依然会存在一些会影响生产缺陷。如果一个版本立即部署到系统的全部地方，那么可能存在的缺陷亦将到达系统的全部地方。如果你能够快速地检测和解决缺陷，则可以接受此方案。但是，更安全的选择是:首先使用灰度发布向新版本导入一些生产流量。灰度发布允许部署管道在尽可能少地影响你的服务的前提下，更快地检测出问题。发布工程和灰度发布在部署系统的新版本或其关键组件(如配置或数据)时，我们将变更(通常未公开给真实输入的更改，如面向用户的流量、或用户提供的批处理数据)打包。变更会带来新的特性和功能，但也存在部署之后出现问题的风险。我们的目标是通过测试一小部分流量来降低风险，以确保没有任何不良影响。我们将在本章后面讨论评估过程。灰度过程还让我们对变更充满信心，因为我们将其暴露给越来越大的流量。为变更引入实际生产流量还使我们能够识别在单元测试或负载测试等测试框架中可能不可见的问题，这些问题通常更为人为。我们将使用一个实际的示例来检查灰度过程及其评估，同时避免深入研究统计数据。相反，我们关注点是整个过程和典型的实际考虑。我们使用App Engine上的一个简单应用程序来说明发布的各个方面。灰度发布流程的需求针对特定服务的灰度发布需要特定功能：将变更通过灰度发布部署到服务全部子集的方法。      一个评估过程，用来评估变更是好还是坏。将评估集成到发布过程中。最后，当灰度检测到有问题的发布版本，并在没有误报的情况下识别出好的发布版本时，灰度发布展示了它的价值。我们的示例环境我们将使用一个简单的前端web服务应用程序来演示一些灰度发布的概念。该应用程序提供了一个基于http的API，消费者可以使用它来操作各种数据(如产品价格等简单信息)。示例应用程序有一些可调参数，我们可以使用这些参数来模拟各种生产环境，由灰度发布流程进行评估。例如，可以让应用程序为20%的请求返回错误，或者规定5%的请求至少需要两秒钟。我们使用部署在谷歌应用程序引擎上的应用程序来演示灰度发布流程，这些原则同样适用于其他环境。虽然示例应用程序是经过设计的，但是在实际场景中，类似的应用程序与我们的示例可以共享灰度发展中使用的指标。我们的示例服务有两个可能的版本:当前版本和候选版本。当前版本是当前部署在生产环境中的版本，而候选版本是新构建的版本。使用这两个版本来说明发布概念，以及如何实现灰度发布以使发布过程更安全。回滚部署与简单的Canary部署比较我们将在发生中断时根据错误预算节省和一般影响，来对没有灰度发布的部署流程和灰度发布流程进行比较。我们的部署过程以开发环境为基础。一旦我们感觉代码在开发环境中正常工作，我们就将该版本部署到生产环境中。在部署之后不久，监视开始报高错误率(参见图16-2，在图16-2中，为了模拟示例服务中的缺陷，对示例应用程序进行配置以使20％的请求失败)。对于示例，假设部署流程不支持回滚到以前已知的配置正常的版本时。修复这些错误的最佳选择就只有在生产版本中查找缺陷，对其进行补救，并在停机期间重新部署一个新版本。这种做法肯定会延长错误对用户的影响。                                            图 16-2 部署之后错误率增加为了改进这个初始部署过程，我们可以在使用灰度发布来减少推送错误代码所造成的影响。 我们需要一种方法来在小部分生产环境中运行候选版本，而不是一次性部署到生产环境。 然后将一小部分流量发送到该生产环境（the canary金丝雀）并将其与其他部分（the control 主控）进行比较。 使用此方法，我们可以在所有生产受到影响之前发现候选版本中的缺陷。我们在示例应用程序中的进行简单灰度发布，在应用程序的特定版本之间分配流量。 您可以使用App Engine或其他任何方法来分割流量（例如负载均衡器上的后端权重，代理配置或循环DNS记录）。图16-3显示了当我们使用灰度发布，变更的影响会大大降低;事实上，这些错误几乎不可见!这提出了一个有趣的问题:与总体流量趋势相比，灰度发布的流量趋势很难看到和跟踪。图 16-3 部署之后错误率增canary部署错误率； 因为进行canary部署的只是系统的一小部分，因此总体错误率降低为了更清楚地了解需要在合理范围内跟踪的错误，我们可以通过App Engine应用程序版本查看关键指标(HTTP响应代码)，如图16-4所示。当我们查看每个版本的分解趋势图时，我们可以清楚地看到新版本引入的错误。我们还可以从图16-4中观察到当前版本提供的错误非常少。现在，我们可以根据应用程序版本的HTTP错误率对部署进行调优。如果灰度发布的错误率大于全部系统的错误率，这表明canary部署是糟糕的。我们应该暂停并回滚部署，或者联系他人来帮助解决问题。如果错误率相似，我们可以正常地进行部署。在图16-4中，我们的canary部署显然很糟糕，我们应该回滚它。图 16-4 应用程序HTTP响应码； 新版本产生多数错误、当前版本产生小数错误（图中显示10%的log）Canary实施现在我们已经看到了一个相当简单的canary部署实现，接下来让我们更深入地了解成功的canary流程所需的参数。最小化SLOs和错误预算的风险第2章讨论了SLOs如何反映设计服务可用性的业务需求。这些需求也可以通过canary实现。canary进程的风险仅仅是我们错误预算的一小部分，它受到时间和canary规模大小的限制。全局部署会很快将SLO置于危险之中。如果实例中为系统全面部署候选版本，我们将面临20%的请求失败的风险。如果我们使用5%的canary规模，我们将为5%的流量提供20%错误，导致1%的总体错误率(如图16-3所示)。这个策略允许我们保留我们的错误预算—预算的影响与暴露于缺陷的流量的数量成正比。我们可以假设，对于全局部署和灰度部署，检测和回滚花费的时间差不多，但是当我们将灰度发布集成到部署过程中时，我们会以更低的成本获得有关新版本的有价值信息。这是一个假设负载均匀的极简模型。它还假设我们可以将整个错误预算用于灰度发布。这里我们只考虑新版本引入的不可用性，而不是实际可用性。我们的模型还假设新版本具有100%的失败率，这是最坏的情况。而进行灰度的部分不会导致线上系统100%不可用。我们还允许在灰度部署期间，整个系统的可用性低于SLO。这个模型有明显的缺陷，但它是一个可靠的起点，你可以根据业务需求进行调整。我们建议使用最简单的模型来满足你的技术和业务目标。根据我们的经验，专注于使模型在技术上尽可能正确，常常会导致在建模上的过度投资。对于具有高复杂性的服务，过于复杂的模型可能导致持续的模型调优，而没有真正的好处。选择灰度规模和持续时间选择合适的灰度持续时间，需要考虑发布频率。 如果需要每天发布，那么在一次只运行一个灰度的情况下，无法使灰度保持一周,如果每周部署一次，就可以执行较长的灰度发布。 如果持续部署（例如，一天20次），灰度的持续时间必须明显缩短。 在一些说明里，虽然可以同时运行多个灰度，但这样做会增加大量精力来跟踪系统状态。 在任何情况下，需要快速推断系统状态时，同时运行多个灰度会成为问题。如果灰度重叠，同时运行多个灰度也会增加信号污染的风险。我们强烈建议一次只运行一个灰度。对于基本的评估，不需要大规模的灰度来检测关键条件。然而，一个有代表性的灰度发布流程需要跨多个维度进行决策:规模和持续时间它的规模应够大，持续时间应够长，足以代表整个部署。仅在接收到少量查询后终止canary部署，对于以具有不同功能的不同查询为特征的系统来说，这无法提供有用的信号。处理率越高，获取代表性样本所需的时间就越少，以确保所观察到的行为实际上是由变更引起的，而不仅仅是随机因素。流量我们需要在系统上接收足够的流量，以确保它是一个具有代表性的示例，并且系统有机会对输入做出负面反应。通常，请求越均匀，所需要的流量就越少。时间点性能缺陷通常只在高负载下出现，因此在非高峰时间部署可能不会触发性能相关的缺陷。度量指标灰度的代表性与我们选择评估的指标密切相关(我们将在本章后面讨论)。我们可以快速评估诸如查询成功之类的琐碎指标，但是其他指标(如队列深度)可能需要更多的时间或较大规模的灰度来提供清晰的信号。但问题是，这些要求可能相互冲突。Canarying是一种平衡行为，它通过对最坏情况的冷静分析和系统过去的实际记录来实现。一旦您从过去的灰度中收集了指标，您就可以根据典型的canary评估失败率而不是假想的最坏情况来选择canary参数。选择和评估度量标准到目前为止，我们一直在研究成功率，这是评估灰度发布的一个非常清晰和明显的指标。但是直觉上，我们知道这个单一的指标对于有意义的canary流程来说是不够的。如果我们以10倍的延迟为所有请求提供服务，或者在这样做时使用10倍的内存，那么我们可能也会遇到问题。并不是所有的指标都适合评估灰度发布。哪些指标最适合评估灰度发布版本是好是坏?度量标准应指出问题首先，指标需要能够指出服务中的问题。这很棘手，因为构成问题的并不总是客观的。我们可能会认为用户请求失败是有问题的。但是如果一个请求的响应时间增加了10%，或者系统内存增加了10%?，这该如何判断？我们通常建议使用sla作为开始考虑canary指标的地方。良好的服务质量指数往往与服务健康状况密切相关。如果已经使用SLIs来度量SLO是否符合，那么我们可以重用这些工作。几乎任何指标在极端情况下都可能出现问题，但是向灰度流程中添加太多的指标也会产生成本。我们需要为每个指标正确定义可接受行为。如果可接受行为定义过于严格，我们会得到大量的误报;也就是说，我们会认为灰度很糟糕，即使实际不是这样。相反，如果对可接受行为的定义过于宽松，我们更有可能忽略掉有问题的灰度部署。正确选择什么是可接受的行为可能会成本较大——既耗时又需要分析。然而，如果做得不好，错误的结果会完全误导你。此外，随着服务、其特性集和行为的发展，您需要定期重新评估期望。我们应该根据这些指标多大程度上能够表明系统中实际用户的体验来进行排名，选择排名靠前的几个指标(可能不超过12个)。太多的度量标准会带来递减的回报，并且在某种程度上，收益会被维护它们的成本所抵消，或者在发布过程中如果不维护它们，会对发布结果无法保证100%的信任。为了使这个指导原则更加具体，让我们回头再来看示例。它有许多我们可以评估的指标:CPU使用量、内存占用、HTTP返回码(2xx、3xx等等)、响应延迟、正确性等等。在这种情况下，我们最好的度量标准可能是HTTP返回码和响应延迟，因为它们的降级最接近于实际用户影响。在这个场景中，CPU使用率并没有那么有用:资源使用的增加不一定会影响服务，并且可能导致不稳定或嘈杂的canary进程。这会导致操作人员禁用或忽略canary进程，这会首先破坏使用canary进程的目的。对于前端服务，我们直观地知道，响应较慢或响应失败通常会真实反映服务中存在的问题。HTTP返回码包含一些有趣的复杂情况，例如状态码404，它告诉我们没有找到资源。这可能是因为用户获得了错误的URL(想象一下在一个流行的论坛上分享了一个错误的URL)，或者因为服务器错误地停止了对资源的服务。通常，我们可以通过排除canary评估中的400级状态码，并添加黑盒监控来测试特定URL的存在，从而解决此类问题。然后，我们可以将黑盒数据作为canary分析的一部分，以帮助将canary流程与奇怪的用户行为隔离开来。度量标准应该具有代表性和可归属性观察到的指标变化其来源，应该清楚地归因于正在进行的变更，并且不应该受到外部因素的影响。在一个大的系统中(例如，许多服务器或许多容器)，我们可能会有外部性——超过连接的机器、运行具有不同性能特征的不同内核的机器，或者网络中过载的机器。此时金丝雀部分和主系统部分之间的差异，既是我们所部署的两个基础设施之间的差异，也会是我们变更导致的差异。管理金丝雀是多种力量之间的平衡。增加金丝雀的规模是减少这个问题影响的方法(如前所述)。当我们的系统达到我们认为的合理的金丝雀规模时，我们需要考虑我们选择的指标是否会显示出很大的差异。我们还应该知道canary和control环境之间共享的失败域;坏金丝雀会对控制产生负面影响，而系统中的坏行为可能会导致我们错误地评估金丝雀。同样，确保您的度量标准是良好隔离的。考虑一个同时运行我们的应用程序和其他进程的系统。整个系统的CPU使用量的急剧增加会导致糟糕的度量，因为系统中的其他进程(数据库负载、日志轮转等)可能会导致这种增加。更好的度量标准是在处理请求时所花费的CPU时间。更好的度量标准是在服务进程实际计划在CPU上的时间窗口上为处理请求服务所花费的CPU时间。虽然与我们的进程相关的严重超额的机器显然是一个问题(监控应该捕捉到它!)，但它不是由我们正在进行的更改引起的，因此不应该将其标记为金丝雀部署失败。金丝雀也需要是可归属的;也就是说，您还应该能够将canary度量与SLIs联系起来。如果一个度量可以在不影响服务的情况下发生巨大变化，那么它不适合用来评估灰度发布。评估前/评估后依然是有风险的canary过程的前后是归因问题的延伸。在这个过程中，旧系统被新系统完全替代，你的canary评估将在一段时间内比较变更之前和之后的系统行为。你可以将此过程称为时空中的canary部署，在此过程中，您通过分割时间来选择A/B组，而不是通过机器、cookie或其他方法来分割总体。由于时间是观察到的指标变化的最大来源之一，因此很难在评估之前/之后来判断性能是否下降。虽然canary部署可能导致降级，但原有系统本身也可能会降级。如果需要长时间运行canary部署，就会变得更加复杂。例如，如果在周一进行发布，可能会将工作日的行为与周末的行为进行比较，从而引入大量噪音。在该示例中，用户可能在周末以不同的方式访问该服务。从而在canary进程中引入噪音。评估前/后过程本身引入了一个问题，即大而短的错误率(由前/后评估引入)是否优于小而长的错误率(由一个小金丝雀引入)。如果新版本完全被破坏，我们能多快地检测和恢复? 大规模的金丝雀之前/之后可以更快地检测到问题，但恢复的总体时间可能仍然相当长，与较小的金丝雀类似。在此期间，用户会一直受到影响。使用渐进的灰度会更好选择的度量标准即使不符合我们理想中的属性，但仍然很有价值。我们可以通过使用更细微的灰度过程来介绍这些指标。我们可以使用包含多个阶段的canary来反映我们对度量的推理能力，而不是简单地评估单个canary阶段。在第一阶段，我们对这个版本没有信心或不了解。因此，我们希望使用一个小的阶段，以尽量减少负面影响。在小型灰度中，我们更喜欢能够最清晰地显示问题的指标——应用程序崩溃、请求失败等等。一旦这一阶段成功地过去，下一阶段将增加灰度规模，从而增强我们分析变化影响的信心。依赖和隔离正在测试的系统不会在完全真空中运行。出于实际原因，灰度和主系统可以共享后端、前端、网络、数据存储和其他基础设施。甚至可能与客户端有非常不明显的交互。例如，假设一个客户端发送了两个连续的请求。第一个请求可以由灰度部分来处理。其响应可能会改变第二个请求的内容，第二个请求可能会落在主系统部分，从而改变主系统的行为。不完美的隔离会带来几个后果。最重要的是，我们需要知道，如果灰度过程的结果表明我们应该停止生产变更并调查情况，那么灰度并不一定是错误的。这一事实对于一般的canarying来说是正确的，但是在实践中，它经常由于隔离问题而导致被强制执行。此外，不完美的隔离意味着灰度部署的错误行为也会对原始系统产生负面影响。Canarying是A/B比较，A和B有可能同时改变;这可能会导致评估灰度变得混乱。还必须使用绝对度量，例如定义的SLOs，以确保系统正确运行。在非交互系统中进行Canarying本章重点讨论了交互式请求/响应系统，它在许多方面是最简单和最常讨论的系统设计。其他系统，如异步处理管道，也同样重要，但有不同的canarying注意事项，我们将简要列举。有关数据处理管道的canarying的更多信息，请参见第13章。首先，canary的持续时间和部署本质上依赖于工作单元处理的持续时间。当涉及到交互系统时，我们忽略了这个因素，假设工作单元处理的时间不会超过几秒钟，这比canary的持续时间要短。非交互式系统中的工作单元处理(如呈现管道或视频编码)可能需要更长的时间。因此，确保canary持续时间至少跨越单个工作单元的持续时间。对于非交互式系统，隔离可能变得更加复杂。许多管道系统只有一个工作分配程序和一组使用应用程序代码的工作人员。在多阶段管道中，工作单元由工作人员处理，然后返回到池中，由同一工作人员或另一个工作人员执行下一阶段的处理。金丝雀分析有助于确保处理特定工作单元的工人总是从相同的工人池中提取——要么是金丝雀池，要么是控制池。否则，信号就会变得越来越混杂(有关理清信号的需要的更多信息，请参见349页的监视数据的要求)。最后，度量标准的选择可能更加复杂。我们可能感兴趣的是端到端处理工作单元的时间(类似于交互系统中的延迟)，以及处理本身的质量(当然，这是完全特定于应用程序的)。考虑到这些警告，canarying的一般概念仍然是可行的，并且适用相同的高级原则。监控要求在评估灰度部署时，您必须能够将部署了灰度的系统与未部署灰度的系统进行比较。通常，这需要在构造监视系统时多加注意—有效的比较非常简单，并且能够产生有意义的结果。考虑之前的例子，在5%的规模中进行灰度，错误率为20%。因为监视很可能将系统作为一个整体来观察，所以它只能检测到1%的总体错误率。根据系统的不同，这个信号可能与其他错误源无法区分(参见图16-3)。如果我们通过按照服务请求的对象来（金丝雀与主系统）分解指标，(参见图16-4)我们可以清楚地看到主系统与canary之间的错误率，这清楚地说明了全局部署将带来什么。在这里，我们看到，对整个服务的监控不足以分析灰度是否ok。在收集监视数据时，能够执行细粒度的分解非常重要，这些分解使得能够区分金丝雀和主系统的指标。收集指标的另一个难点是金丝雀的部署受到设计的时间限制。当度量指标在特定时期内进行聚合时，这可能会导致问题。考虑每小时的度量误差。我们可以通过对过去一小时的请求求和来计算这个度量。如果我们使用这个度量来评估我们的canary，我们可能会遇到问题，如下面的时间表所述:  某些事件会导致一些错误发生。  一只金丝雀被部署在5%的人口中;金丝雀的持续时间是30分钟。  canary系统开始监视每小时的错误度量，以确定部署是好是坏。  部署被检测为错误，因为每小时的错误度量与控制总体的每小时的错误显著不同。此场景是使用每小时计算一次的度量来评估仅30分钟长的部署的结果。因此，canary进程提供了一个非常模糊的信号。当使用度量来评估canary的成功时，确保度量的间隔与canary的持续时间相同或小于持续时间。相关概念通常，与客户的对话涉及到在生产中使用蓝/绿部署、人工负载生成和/或流量测试。这些概念类似于canarying，因此虽然它们不是严格意义上的金丝雀流程，但亦可使用。蓝/绿部署蓝/绿部署维护系统的两个实例：一个提供流量（绿色），另一个准备提供流量（蓝色）。 在蓝色环境中部署新版本后，将流量切换到其中。切换过程不需要停机，并且回滚只是简单逆转路由器而已。 一个缺点是该设置使用的资源是传统部署的两倍。在该设置中，您正在有效地执行前/后金丝雀（前面已讨论过）。通过同时(而不是分开地)使用蓝/绿部署，您可以或多或少地将蓝色/绿色部署用作常规的金丝雀。在此策略中，您可以将canary部署到blue(备用)实例，并在绿色和蓝色环境之间缓慢地分配流量。您的评估和比较蓝色环境和绿色环境的指标都应该与流量控制相关。这种设置类似于A/B金丝雀，此时绿色环境是主系统，蓝色环境是金丝雀部署，金丝雀数量由发送到每个金丝雀的流量控制。人工负载生成与其将实时用户流量暴露给canary部署，还不如在安全性方面犯点错误，使用人工负载。通常，您可以在多个部署阶段(QA、预生产，甚至在生产中)运行负载测试。虽然根据我们的定义，这些操作不符合canarying，但是它们仍然是找到缺陷的可行方法，但需要注意一些事项。使用人工负载进行测试可以很好地最大化代码覆盖率，但不能提供良好的状态覆盖率。在可变系统(具有缓存、cookie、请求关联等的系统)中人工模拟负载尤其困难。人工负载也可能无法准确地模拟真实系统中流量变化。有些问题可能只在无人工负载的情况下出现，从而导致覆盖率有所差距。人工负载在可变系统中也很难工作。例如，试图在计费系统上生成人工负载可能非常危险:系统可能开始向信用卡供应商发送呼叫，然后信用卡供应商将开始主动向客户收费。虽然我们可以避免测试危险的代码逻辑，但是在这些逻辑上缺乏测试会降低我们的测试覆盖率。流量测试如果人工流量不具有代表性，我们可以复制流量并将其发送到生产系统和测试环境。这种技术被称为流量镜像。生产系统服务于实际流量并响应请求，canary部署服务于副本流量并丢弃响应。您甚至可以将canary响应与实际响应进行比较，并运行进一步的分析。这种策略可以提供有代表性的流量，但通常比更直接的canary流程更复杂。在有状态系统中，流量测试也不能充分识别风险;流量副本可能会在看似独立的部署之间引入意外的影响。例如，如果canary部署和生产系统共享一个缓存，人为导致的缓存命中率增加将使canary指标的性能度量无效。结论您可以使用许多工具和方法来自动化版本发布，并将canarying引入到发布管道中。没有一种测试方法是万能的，测试策略应该由系统的需求和行为决定。Canarying可以作为一种简单、健壮且易于集成的方法来补充测试。当您及早发现系统缺陷时，用户受到的影响最小。Canarying还可以为频繁发布提供信心，并提高开发速度。正如测试方法必须随着系统需求和设计而发展一样，canarying也必须如此。前言]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第六章 减少琐事]]></title>
      <url>/sre/2020/01/06/%E5%87%8F%E5%B0%91%E7%90%90%E4%BA%8B/</url>
      <content type="text"><![CDATA[前言Google SRE的大量时间用于系统优化，通过工程化的方法，与开发一起协同努力，追求卓越。哪怕是很少的性能收益也是值得的。但优化范围不仅局限于服务器资源，SRE的工作耗时也是优化的范畴。首先，SRE的工作不是琐事（关于琐事请参阅《SRE：Google运维解密》第5章内容）。本章我们将琐事定义为：与维护服务相关的，重复的、可预测的、持续的任务流。对于产品运维团队来说，琐事不可避免。运维不可避免地需要处理部署、升级、重启、告警等工作。如果没有系统的方法，这些工作很快将耗尽整个团队精力。Google将SRE团队日常操作的耗时占比限制在50%以内（包括琐事和非劳动密集型工作。这样做的原因，请参阅《SRE：Google运维解密》书中第5章内容）。虽然这个目标可能不适合所有团队，但花费在琐事上的时间上限仍然很重要，因为识别和量化琐事是团队时间优化的第一步。琐事的定义琐事往往具有如下特征：这在我们的上一本书中有所阐述（《SRE：Google运维解密》译者注）。在这里，我们列举出琐事的特征，并给出了一个具体的例子加以解释：  手动性: 当web服务器上的/tmp目录磁盘占用率达到95%时，工程师Anne登录到服务器，在文件系统中查找并删除了无用的日志文件。  重复性: 写满/tmp目录的事情不太可能只发生一次，因此我们需要反复处理。  可以被自动化: 假设修复文件的工作包括如下几个步骤：“X登录，执行此命令，检查输出，执行命令，并通过命令的输出来判断是否需要重启Y”。这些指令流本质上就是伪代码！在上面的例子中，解决方案实际上已经可以部分自动化了。如果不需要人来运行脚本，可以自动化的检测故障并修复是再好不过了。更进一步，我们可以提交一个补丁使软件不再因为文档损坏的问题而中断。  非技术性: “磁盘写满”和“服务宕机”之类的告警会分散工程师的注意力，从而忽略高价值的事情，并可能掩盖其他更严重的告警。大量类似的告警造成的后果会波及到服务的健康状况。  没有持续的价值: 完成一项任务会带来一种令人满意的成就感。但长远来看，这种重复的满足感不能给工程师带来持续的价值。比如，处理告警能够确保用户查询持续进行；确保HTTP请求状态码小于400，以便可以让应用提供持续的服务，这些固然很好。然而，今天解决的问题并不能防止将来不再出现类似的问题，所以这样做的回报只是短期的。  与服务同步增长: 许多业务工作量的增长速度与基础设施规模的增长速度一样快(或许更快)。例如，你花费在修复硬件故障的时间会随着服务器集群规模的增加而增加。但请注意，相关的辅助任务(例如，软件/配置更改)不一定是这个趋势。我们并不能将带来琐事的原因规范化和标准化，但是我们需要知道琐事的一些的特征。除上述特征外，还要考虑某项工作对团队士气的影响。人们是乐于完成一项觉得会有回报的任务？还是会处理无益的琐碎和无聊的任务？答案显而易见，琐事会慢慢地降低团队士气——时间往往花在琐事上而不是花在批判性思考或者是表达创造力上了；只有减少琐事，工程师才能更好地将时间用于思考和进行创造的领域。  案例：人工处理琐事作者：John Looney，Facebook资深 SRE  哪些工作内容是琐事，通常是模糊的。一个“创造性”的解决方案，可能使问题得到最优解决，因此，SRE团队应奖励那些分析根因并解决问题的人，而不是那些掩盖问题的人。  我加入Google后的第一个任务（2005年4月）是追查一批机器死机原因并修复。如果确认是硬件原因，则转交给硬件技术人员维修。这个任务并没有看似那样的简单，因为我需在截止日期前处理超过20,000台机器。  第一台机器死机原因是：Google网络驱动补丁不断打印毫无意义的日志，导致文件系统的根目录写满，类似的一千台机器都是同样的问题。  我和同事沟通了解决这个问题的方案：编写一个脚本，ssh到所有异常机器，如果根目录已满，则清空/var/log中大文件日志，并重启syslog。我的同事对此方案不认可，他说最好找到根因并修复。如果掩盖了问题，在后续一段时间内，可能会引起更多严重性问题。  理论上，每台机器每小时的成本约为1美元。我的想法是，成本是运维工作很重要的衡量指标，应该高优让机器提供服务，利用起来。但我没有考虑的是：如果只是解决了这个表象，就没有机会去追查根因。  在高级工程师指导下，我翻阅了内核源码，找到导致此问题的可疑代码，并且记录了bug，帮助内核团队完善了他们的测试用例。从成本来看，解决这个网络补丁问题，每花费一小时，Google将为此付出1,000美元。  那天晚上就发布了新的内核版本，第二天我就把它升级到所有受影响的机器，内核团队在第二周更新了他们的测试用例。这个问题的处理，我很满意，因为找到了根因并成功修复，而不是每天上班后清理日志。琐事的度量运维工作是辛苦的。如果你做了一些工作减少了琐事，如何知道你的努力是成功的？许多SRE团队是结合经验和直觉来回答这个问题。经验和直觉会产生好的效果，但是我们还可以将方法上升到一个理论的维度。经验和直觉是因人而异、非客观的。根据场景的不同，琐事的定义也不同。比如，同一团队的不同成员会根据工作的投入产出比来判断一件事情是否可以定义为琐事。此外，为了减少琐事所做的工作可能会持续几个季度甚至几年的时间(本章的一些案例研究就证明了这一点)，在此期间团队的人员主要任务可能会发生改变。所以，为了保证减少琐事的工作能够长期进行，一般的，团队必须从几个确定的琐事中选择一个琐事来消灭它。我们应当将这件事上升为一个项目，并且需要建立起这个项目的长期的客观的度量机制以保证投入得到回报。在启动项目之前，重要的是分析成本与收益，并确认通过减少琐事所节省的时间(至少)与第一次开发和维护自动化解决方案所投入的时间成正比(图6-1)。从节省的时间与投入的时间的简单比较来看，那些看起来“无利可图”的项目可能仍然值得进行，因为自动化有许多间接或无形的好处。潜在的好处包括：  随着业务规模扩大，收益越明显  提高团队士气，减少团队流失和成员的厌倦情绪  更少的中断性工作，从而提高团队工作效率  提高流程清晰度和标准化  增强团队成员的技术技能和拥有更全面的职业发展  缩短新成员的培训时间  减少人为错误导致的问题  提高安全性  缩短用户投诉的响应时间 图 6-1 预测在减少琐事工作上花费的时间，并确保其收益大于投入 琐事的度量方法      识别它。第一本SRE书的第5章提供了如何识别琐事。最能够识别琐事的人取决于团队本身。理想情况下，SRE团队既是利益相关方，也是实际操作方。        选择适当的计量单位来量化人力成本。我们可以选择“分钟”或者“小时”这么一个客观和普遍能够理解的计量单位。务必还要考虑琐事转自动化的成本。有些人力成本具有分散性和碎片化的特征，所以我们从成员工作的内容来衡量更为合适。度量单位应该要能够很好的度量如下工作：为应用增加的补丁，完成的票证，手动生产环境的变更，电子邮件交换或者是一些对硬件的操作。总的来说，只要度量单位客观，一致且易于理解，它就可以作为工作的衡量标准。        在项目的整个周期内我们需要连续跟踪并记录度量的指标。我们可以使用工具或脚本来简化度量指标的测量过程，使得收集这些测量值不会产生额外的工作。  琐事分类法琐事，就像一座摇摇欲坠的桥梁或一座漏水的大坝，日复一日地隐藏在广阔无垠的大地之中。本节中的分类并不能够详尽无遗，但代表了一些常见的琐事类别。这些类别中有许多类似“正常”的工作，但是它们实际上就属于琐事。商业流程这可能是最常见的琐事来源。也许你的团队管理一些计算机资源——计算、存储、网络、负载平衡器、数据库等，以及为该资源提供支持的硬件资源。你需要处理用户登录、配置修改和计算机安全维护、软件更新以及扩缩容。你还需要最大限度地降低成本避免计算机资源的浪费。你的团队是计算机的人机界面，通常与为其需求提交票证的内部客户进行交互。你的组织甚至可能拥有多个票务系统和工作系统。票务系统属于“隐藏”一类的琐事，因为其驱动的业务流程通常是我们需要完成的目标。用户得到了他们想要的东西，并且因为琐事往往分散在整个团队中，所以琐事并不能明显地显现出来。在以票据驱动的任何地方，都有可能悄悄地积累这琐事。即使你没有明确的自动化流程，仍然需要执行流程的改进工作，例如简化流程，使其未来更容易做到自动化，同时更加容易管理。工作中断中断是一类为了保证系统运行的时间敏感类任务，简单理解为被其他紧急事情打断。例如，你可能需要通过手动释放磁盘空间或重新启动泄漏内存的应用程序来解决某些资源（磁盘，内存，I/O）的严重短缺。你可能正在提交更换硬盘驱动器，“踢”出无响应的系统或手动调整容量以满足当前或预期的负载请求。通常，中断会将注意力从更重要的工作上移开。流程监督在许多组织中，部署工具从发布到生产需要SRE进行监督。即使有自动化，全面的代码覆盖，代码审查和多种形式的自动化测试，这个过程并不总是顺利进行。根据工具和发布节奏，发布请求、回滚、紧急补丁以及重复或手动配置更改，发布仍产生琐事。服务迁移服务迁移也是我们经常要处理的一类事情。你可以手动或使用有限的脚本来执行此工作，而且希望只迁移一次。迁移有多种形式，包括有数据存储、云供应商、源代码控制系统、应用程序库和工具的更改。如果你手动迁移大规模的工程，迁移很可能涉及到“琐事”。对于大规模的迁移，你可能倾向于手动执行迁移，因为这是一次性的工作。并且我们甚至会将其视为“项目”的一部分而非“琐事”，但迁移工作的很多特征与“琐事”的特征是吻合的。从技术上讲，修改一个数据库的备份工具以便与另一个数据库可以协同工作是软件开发的范畴，但这项工作本质上只是重构代码，用一个接口替换另一个接口。这项工作是重复的，并且在很大程度上，备份工具的业务价值与之前是相同的。压缩成本和容量规划无论是拥有硬件还是使用基础架构提供商（云），压缩成本和容量规划通常是一些劳动密集型的工作。例如：  在计算、内存或IOPS（每秒输入/输出操作）等资源的未来规划中要确保成本效益和突发情况的扩容能力。这可能转化为采购订单，AWS预留实例或云/基础设施即服务合同协商。  应对（并从中恢复）关键的高流量事件，如产品发布或者遇到假期。  排查下游和上游服务水平和容量情况。  根据专有云服务产品的计费细节优化应用程序（适用于AWS的DynamoDB或适用于GCP的Cloud Datastore）。  重构工具以便更好地利用现有资源。  处理超预算的资源，无论是基础设施提供商的上游还是与下游客户之间。黑盒系统故障排除分布式微服务架构现在很常见。随着系统更加分散，出现了新的故障模式。团队可能没有能力来构建复杂的分布式跟踪，高可靠监控或详细的仪表盘。即使企业确实拥有这些工具，它们也可能不适用于所有系统。故障排除甚至可能需要登录到各个系统并使用脚本工具来对日志进行实时地查询分析。故障排除本身并不是坏事，但你应该把精力集中在新的故障模式上，而不是每周都发生的由脆弱系统架构导致的故障。随着可用度为“P”的新关键上游依赖性服务的上线，系统可用性将下降（1-P）倍。一个可用度为4个9的服务增加了9个关键的4个9的核心组件，现在就变为了是一个三个9的服务。琐事管理战略任何规模的生产系统，琐事管理都是至关重要的。一旦确定并量化了琐事，消除琐事的计划就要提上日程。这个工作可能需要数周才能完成，因此制定一个完善的计划是至关重要。首先，从源头上消除琐事是最佳的解决方案，但是对于源头上无法消除的琐事，则需要通过其他方式来消除。在我们深入研究两个案例之前，本节提供了此方面工作的通用性准则。正如下文的两个案例中提到的，琐事的细微差别是因团队而异。但无论如何，一些常见的准则是适用于任何规模或风格的组织。在后续案例中将以具体方式诠释每种策略。琐事的识别与度量采用数据驱动的方法来识别琐事，并配合客观的成本控制策略，获得此类项目最优的投入产出比。如果你的团队正在被琐事缠身，并将减少琐事作为了一个长期的项目。Google SRE团队根据多年的经验，在控制项目投入产出比方面是一个不错的借鉴。有关技术和指导，请参见第96页的“量化琐事”一节。让SRE从琐事中解脱出来减少琐事的最佳策略是从源头杜绝琐事。在进行系统设计和为生产环境制定流程之前，工程师要优化产品和系统来减少甚至消除琐事。真正了解生产环境痛点和知道导致系统出现琐事原因的那部分人正是SRE，因为只有他们和生产环境紧密联系。SRE应该在与产品开发团队合作的过程中，将自己的运维经验与产品开发团队共享从而开发出人机交互友好型的软件，从源头减少琐事，并且使产品具有更好的扩展性和弹性。拒绝琐事一个被琐事缠身的团队应该尽早的做出“消除琐事”决策。第一种策略是对琐事说“不”！对于每个琐事，量化它并以此为原则决定是否要做，但是根据Google的经验，这一种策略可能会适得其反。另一种策略是故意拖延这些琐事，直到我们可以通过批处理或并行处理来解决它。将琐事集中在一起一并处理它们，这种方式可以减少工作中的中断，并帮助你们识别琐事的特征，并将它们作为下一个消除目标。使用SLO减少琐事如第2章所述，服务系统应具有文档化的SLO。明确定义SLO才能使工程师做出明智的决策。例如，如果某项工作即使做也不会减少服务的错误预算，你就可以考虑忽略某项工作。随着服务的增长，专注于整体服务的可用性而不是单个设备的SLO，这样做是非常有利的，也是可持续的。有关编写有效SLO的指导，请参阅第2章。从部分自动化开始如果你的业务特别复杂，请将“部分自动化”方法视为实现“完全自动化”的临时步骤。在这种方法中，你的服务通常可以通过定义的API接收结构化数据。工程师也可以进行一些操作从而得到想要的结果。虽然这样做需要一些手动的操作，但是这种“幕后工程师”方法是逐步实现全自动化的前提。使用“客户端输入”来统一收集数据；通过确定的请求格式，你可以更容易的以编程的方式对请求进行处理。这种方法让客户也能够明白你需要的信息和指标，并在你完全理解系统服务之前避免使用大型的解决方案而产生的未知问题。提供一种自助的服务方法一旦你们提供了交互型界面的服务产品，请进一步的为用户提供自助式的服务方法。你可以提供Web表单、二进制、脚本、API，甚至只是告诉用户如何向服务的配置文件发出拉取请求的文档。例如，软件开发工程师要求SRE工程师为其开发工作配置新虚拟机，我们为他们提供一个简单的Web表单或脚本来触发配置，而不是让他们提交相关票证来进行这件事。如果发生了特殊的情况，我们也允许使用“票证”的方式替代自助的服务，这是可接受的。部分自动化是一个良好的开端，但服务SRE工程师应该始终要致力于尽可能让服务自动化起来。获得管理层和同事的支持在短期内，减少琐事的项目需要投入人力成本，反之会减少处理其他日常任务的人员数量。但长远来看，如果项目达到了减少琐事的目标，团队将更加健康，并有更多的时间进行更重要的工程改进。对于团队中的每个人来说，“减少琐事”作为一个共同的价值目标是很重要的。管理层的支持对于减少工程师的干扰是至关重要。制定琐事评估的客观指标来说明项目的推进情况可以让管理层更加支持项目的进行。减少琐事作为提高服务稳定性一部分要为减少琐事的项目创建一个强大的业务案例支持，将你的目标与其他业务目标相结合。如果有一个补充性的目标，例如，安全性、可扩展性或可靠性——这对客户来说是具有吸引力的，他们会更愿意放弃当前充满琐事的系统，转向更加亮眼的新系统。这样来看，减少琐事也可以提高用户服务的质量，这也是另一个角度来看待琐事的认识。从简单的琐事开始并持续改善，不要试图设计没有琐事的系统。面对一个充满琐事的系统，首先自动化一些高优先级的项目，然后通过评估这个项目所花费的时间来改进你的解决方案，总结获得的经验和教训。在项目开始之前，选择一个明确的指标，如MTTR（平均修复时间）来评估你的项目的进展和效果。提高系统的一致性从规模上看，多样化的生产环境是难以管理的。特殊的生产环境容易出错，管理能力会降低，事故的处理能力也会降低。你可以使用“宠物与牛”方法（https://www.engineyard.com/blog/pets-vs-cattle，译者注）来添加系统冗余并在你的生产环境中实施增加一致性的策略。是否选择“牛”取决于组织的需求和规模。将网络链路、交换机、机器、机架，甚至整个集群评估为可互换单元也是合理的。将设备转换为“牛”的理念可能会带来较高的初始成本，但会减少中长期的维护成本，增强灾难恢复能力和提高资源利用能力。为多个设备配置相同的接口意味着它们具有相同的配置，是可互换的，维护成本也就降低了。各种设备的界面一致（转移流量，恢复流量，执行关机等）使系统更加灵活和更加可扩展。Google鼓励各团队将不断发展的内部技术和工具进行统一，并有相应的鼓励机制。无论团队用什么样的方法，但他们不得不承认一些不受支持的工具或遗留的系统是产生琐事的根源。评估自动化带来的风险自动化可以节省人力成本，但是也会出现未知的错误，严重时会造成停机。一般情况下，防御性软件可以控制这类事情的发生。当管理级别的行为被自动化之后，防御性软件会显得至关重要。在执行前应对每项行为的安全性进行评估。在实施自动化时，我们建议采用以下做法：  防御性地处理用户输入，即使这个输入来自于上游的系统 ——换句话说，要对上下游的输入进行仔细的校验。  构建告警机制，使得工程师可以接收到相关告警以进行处理。安全措施可能与命令超时一样简单，也可能是对当前系统指标或当前中断次数的更复杂检查。因此，监控，报警和仪表系统应由机器和操作人员共同使用。  请注意，即使是简单的读取操作也可能会导致设备负载过高和触发服务中断。随着自动化的扩展，这些安全检查的工作量是可控的。  最大限度地减少因自动化安全检查不完整导致服务中断的影响。如果操作员遇到不安全的情况，自动化操作应该默认为人工操作。琐事自动化之后要做什么一旦你可以将一个工作自动化后，这个自动化的工作就值得更深层次的被发掘。进一步的将自动化的任务按照人工处理的流程优化下去。但请注意，自动化不应该让工程师认为任务不会出错。在完成上述优化后，你还可以尝试将自动化的工作分解为可单独实现的组件，并用于创建可组合的软件库，其他自动化项目可在以后重复使用。正如下文中的“数据中心维修案例”研究所示，自动化提供重新评估和简化人工工作流程的机会。使用开源和第三方工具有时你不必做所有的工作来减少琐事。像一次性迁移这样的工作可能自己无法建立定制型的工具，但你可能并不是第一个遇到这个任务的工程师。寻找第三方或开源库以降低开发成本，或者说，至少可以帮助你过渡到部分自动化。反馈并改进积极寻求反馈，这些反馈可以来自于工具、工作流程和自动化交互相关的其他人，这是非常重要的。你的用户将根据他们对底层系统的理解将你的工具在不同使用情景下进行使用。你的用户对这些工具越不熟悉，就越要积极地寻求用户的反馈。利用用户调查，用户体验（UX）和其他机制来了解你的工具被如何使用，并整合这些反馈，以便在未来实现更有效的兼容性。人的输入只是你应该考虑反馈中的一个方面。我们还可以根据延迟，错误率，返工率和节省的人工时间等指标（跨过流程中涉及的所有组）来衡量自动化任务的有效性。能够获得在自动化工作部署之前和之后两种状态的对比是最明确的衡量方式。  扩展：历史遗留系统  大多数SRE工程师在他们的工作中都会遇到过历史遗留系统。这些旧系统经常在用户体验，安全性、可靠性或可伸缩性方面有问题。他们倾向于将遗留系统看作一个神奇的黑匣子，因为系统“大部分组件是在工作中的”，但很少有人了解它们是如何工作的。贸然的调整它们是可怕的，也是昂贵的，并且保持它们的运行通常需要大量繁琐操作步骤。远离遗留系统通常遵循以下路径：      避免：我们可以为不去解决这个问题找到许多理由：可能是没有资源来替换这个系统；判断业务成本和风险发现不值得替换；可能没有找到商业上更好的解决方案。避免选择的是接受风险并从SRE转向系统管理。    封装/扩充：你可以使用SRE来构建一个抽象API的外壳，自动化，配置管理，监视和测试这些遗留系统，这些系统将卸载SA的工作。遗留系统仍然很难改变，但现在你至少可以识别它并在适当时有回滚策略。这种策略仍然可以避免，但这是将风险引入到的更好的系统中。这通常是准备增量替换的权宜之计。    替换/重构：替换遗留系统可能需要大量的决心、耐心、沟通成本和文档，最好是逐步进行。一种方法是定义遗留系统公共接口。此策略可帮助你使用发布的工程手段，将用户缓慢、安全地迁移到其他安全的架构中。通常，遗留系统的“规范”实际上只是通过其历史用途来定义，因此有助于构建生产大小的历史预期输入和输出数据集，以建立新系统不会偏离预期行为的信心（或正在以预期的方式发散）。    退出/保管所有权：最终，大多数客户或功能被迁移到一个或多个系统。这个迁移需要有激励措施，没有迁移的用户让他们自行维护历史遗留系统，并承担相应责任。  案例研究案例研究1：利用自动化减少数据中心的工作量  案例研究1中所应用的减少琐事的战略：      SRE工程师从琐事中解脱出来    从部分自动化开始    提高系统的一致性    使用SLO减少琐事    评估自动化带来的风险    反馈并改进    提供一种自助的服务方法  背景此案例来源于Google数据中心。与其他的数据中心类似，Google的计算机连接到交换机，交换机连接到路由器。流量通过链路流入和流出这些路由器，而链路又连接到互联网上的其他路由器。随着谷歌对互联网流量的要求越来越高，服务该流量所需的交换机数量也急剧增加。为了能够应对大流量的情况，我们的数据中心在规模和复杂性方面都有所增长。这种增长迫使数据中心改变了手动维修的旧方法。（从偶尔和有趣到频繁和沉闷的转变。）早期，谷歌在运行数据中心时，每个数据中心的网络拓扑都只有少量的网络设备，可以管理大量服务器的流量。单个网络设备故障可能会显著影响网络性能，但是一个小规模的工程师团队就可以处理设备的故障。早期，工程师调试故障设备并手动将流量切换到其他正常组件。而我们下一代的数据中心拥有更多的机器，并引入了折叠Clos拓扑结构的软件定义网络（SDN），交换机数量显著增加。图6-2展示的是一个小型数据中心Clos交换机网络的流量复杂情况。如果将这个比例放大，意味着设备数量更多，发生故障的组件也更多。虽然可以说，每个单独的故障对网络性能的影响比以前更小，但是大量的问题同时并发也会压倒工程师们。调试问题的过程同时也会引入大量新的问题，复杂的布局也让工程师感到困惑：需要检查哪些链接？需要更换哪个线卡？为什么是Stage 2开关，而不是Stage 1或Stage 3开关？关闭交换机会给用户带来哪些问题？图6-2. 一个小型Clos网络，Stage1 支持480台机器连接 修复故障的线卡是一个随着系统网络增长而任务量不断增长的琐事，因此我们将此作为“数据中心网络修复自动化”项目的第一阶段的目标。本案例阐述了我们如何在第一代线卡（名为Saturn）系统上开始自动化修复的过程，并以此为基础，我们讨论了如何对自动化工作进行改进以适应下一代线卡(Jupiter光纤网络)。如图6-3所示，在自动化项目开始之前，数据中心线卡修复工作需要工程师执行如下几个操作：  确定从故障交换机切走流量是否是安全的。  切走流量至其他交换机（“drain”操作）。  执行重启或修复（例如更换线卡）。  将流量切回至该交换机（“undrain”操作）。Drain，更换线卡，undrain的工作是不变和重复性质的，是“琐事”的典型范例。这些重复性的工作本身就会带来一些问题——例如，工程师在处理此类故障时会并行处理其他更有挑战性的工作，分心的工程师可能会意外地将未配置的交换机加入网络。  图6-3. 自动化之前的数据中心（Saturn）线卡修复工作流程：所有步骤都需要手动工作 问题陈述数据中心修复线卡问题具有以下几个维度：  团队规模增长的速度跟不上系统增长的速度（故障数量也在增长），使得我们无法快速解决问题以防止对系统带来负面影响。  人为错误一定会在重复执行的步骤中发生。  并非所有线卡故障的影响都是一致的。我们没办法对线卡故障划分优先级。  一些故障是暂时的，这时我们会选择直接重新启动线卡或重新安装交换机作为修复过程的第一步。并且，我们可以用编程方式捕获这些问题，如果它再次发生，则进行设备替换。  新的拓扑环境要求我们在采取行动之前手动评估隔离容量的风险。每次的人工风险评估都有可能带来人为错误，并可能带来严重影响。系统工程师和技术人员也没有好的方法来判断有多少设备和链接会受到修复过程的影响。我们要如何解决这个问题？为达到最好的效果，我们决定创建一个与现场技术人员配合使用的自动化框架，而不是把每个问题分配给工程师，让其进行风险评估，流量切换，维修和验证等人工操作。自动化的第一步：Jupiter光纤网络的修复自动化我们的最终目标是构建一个能够代替工程师分析和处理故障的网络设备故障检测系统。我们的程序是直接切换流量并告知工程师，而不是向工程师发送“线卡”故障的告警。新系统有一些值得注意的特点：  我们最好是利用现有工具。如图6-3所示，我们的告警已经可以检测到线卡上的问题; 所以我们可以配置告警以触发自动修复。新的工作流程还应改变工单系统，以便支持自动提交的维修请求。  我们建立自动风险评估的机制，以防止在流量切换期间意外的隔离设备，并在需要时触发安全机制。此机制可以杜绝人为错误。  我们编写程序用于跟踪告警以便作出不同的处理操作：第一次告警仅重启该线卡并重装了软件；第二次出现告警则直接请求更换线卡并告知供应商。执行自动化操作新的自动化工作流程（如图6-4所示）进行如下：  检测到有问题的线卡，并将故障特征添加到数据库中。  维修服务组件会解决问题并对交换机进行维修。该服务还会执行风险评估以确认操作不会隔离任何容量，然后：  a. 从故障交换机中切出流量。 b. 关闭线卡。 c. 如果这是第一次告警，则重新启动线卡，将流量恢复到此交换机。此时，工作流程已完成。 d．如果这是第二次失败，则工作流程进行到步骤3。  流程管理器检测到新案例并将其发送到故障维修池，供系统工程师处理。  系统工程师对故障做出响应，在UI界面中看到红色的“停止”（表示在开始修理之前需要切走流量），并分三步执行修复步骤： a. 系统工程师通过UI界面中的“准备组件”按钮启动流量切换。 b. 流量切换完成后表示交换机可操作。 c. 关闭交换机并维修线卡。  自动修复系统再次启动线卡。完成修复后，启动交换机，待初始化后，流程管理器会触发恢复操作，切回交换机流量并结算故障工单。 图6-4.具有自动化功能的Saturn线卡维修工作流程：只需按下按钮即可完成更换线卡等全部手动工作 新的自动化系统将团队从大量的琐事中解放出来，使他们有更多时间在其他地方开展更高效的项目：使用下一代Clos拓扑结构Jupiter。自动化项目的第二步：Saturn线卡修复与Jupiter线卡修复数据中心的容量需求几乎每12个月翻一番。因此，我们的下一代数据中心结构Jupiter比Google以前的任何数据中心的六倍还要大，所以故障的数量也会增加六倍多。Jupiter提出了自动化故障修复的挑战目标，这个目标的难度在于每层的数千个光纤链路和数百个线路卡都可能出现故障。幸运的是，随着潜在故障点的增加系统也会伴随增加更多的冗余，这有利于我们完成自动化任务。如图6-5所示，我们保留了系统的一些常规工作流程，并添加了一些重要的修改：  在自动切流量和关闭交换机之后，确定我们要更换的硬件，将硬件故障单发送给系统工程师。在这个过程中，切流量的行为是自动的，不需要系统工程师手动按下“预备按钮切流量开关”来完成。  我们添加了自动化，用于安装和推送组件更换后的配置。  我们启用自动化功能，以便在切回流量之前验证修复是否成功。  除非绝对必要，否则我们更关注的是如何恢复流量而不用人为介入。 图6-5.左图为Saturn线卡宕机自动化流程，右图为Jupiter线卡宕机自动化流程项目实现我们为Jupiter交换机上的所有的线卡故障采用了简单而统一的工作流程：操作通报，流量切换，开始修复。自动化执行如下：  检测到交换机故障，并将故障特征写到数据库。  维修程序开始修复交换机：停止使用交换机，并将停止原因写到数据库中。 a. 如果这是六个月内的第二次故障，请执行步骤4。 b. 否则，请执行步骤3。  尝试（通过两种不同的方法）重启交换机。  a. 如果重启成功，用自动化服务检查健康状态，然后安装并配置交换机使其投入使用；删除修复原因，删除数据库中的故障记录。 b. 如果健康检查失败，请升级给技术人员。  如果这是第二次故障告警，请将故障案例直接升级给技术人员，向其申请新的硬件设备。硬件更新后，用自动化服务检查健康状态，然后安装并配置交换机使其投入使用。删除修复原因，删除数据库中的故障记录。这种新的工作流程管理完全重写了以前的修复系统。同样的，我们要尽可能利用现有工具：  配置新交换机（安装和验证）的操作与验证已更换的交换机所需的操作相同。  快速部署新的硬件需要以编程的方式进行BERT和cable-audit的能力。在恢复使用之前，我们可以使用该程序在已经修复的链路上运行功能测试。这些测试需要能够识别错误链接以进一步提高修复的效果。下一步要提升的是自动缓解并修复Jupiter交换机线卡的内存错误。如图6-6所示，在开始自动化修复之前，此工作流程在很大程度上取决于工程师来判定故障是硬件导致还是软件导致，然后再停止使用，重启交换机等工作，并适时地安排修复。 图6-6. 自动化之前的Jupiter内存错误修复工作流程 我们的自动化过程不再尝试对内存错误进行故障排除从而达到简化修复工作流程的目的（请参阅第119页的“有时不完美的自动化就足够了”，了解为什么这样做是有意义的）。相反，我们处理内存错误的方式与处理线卡故障的方式相同。为了将自动化覆盖到内存错误引起的故障，我们只需在配置文件中添加一个特征，使其对新的故障类型起作用。 图6-7描述了内存错误的自动化工作流程。经验教训在我们致力于实现网络故障自愈的这些年里，我们学会了如何有效减少琐事。UIs 不该引入开销和复杂度替换一块Saturn-based线卡需要切走整个交换机的流量。等待备件更换以及工程师支持的时候，过早地执行全部切换操作意味着失去所有线卡的工作能力。我们在UI中增加一个“准备组件”的按钮，以允许技术人员在更换线卡前执行整个交换机的切换流量操作，从而消除了交换机不必要的停机时间（请参阅“按下准备按钮” 切出流量的开关“见图6-5）UI和维修工作的流程引入了许多非预期的问题  按下切走流量的按钮后，技术人员无法得到流量切换进度的反馈，只能在结果返回后才能进行下一步操作。  该按钮可能无法反馈真实的状态。造成的结果是，有时切流量开关出问题但并没有被维修，或者技术人员可能通过其他方式中断了进程但是并没有告知系统。  问题出现时，非自动化的组件反馈了一个通用的‘contact engineering’信息。经验不丰富的技术人员无法快速找到可以提供帮助的人，而联系上的工程师并不总能够立即解决问题。为快速对用户反馈以及因功能复杂性带来的回归问题进行响应，我们设计了更完善的工作流程，来保证按钮的安全性和可用性。不要依赖人的经验我们过分依赖有经验的数据中心技术人员来识别系统中的错误（例如，当程序认为可以安全地进行维修，但实际上交换机并没有完成流量切换的动作）。这些技术人员在没有自动化提示的情况下，还必须手动执行多项工作。经验是难以复制的。在一个复杂的情节中，技术人员在等待数据中心维修时，决定启动并发切换来快速进行“按下按钮并等待结果”的操作，从而导致了网络拥塞和用户可见的数据包丢失。我们的软件无法预测并阻止这种行为，因为我们并没有测试过这种自动化。设计可重复使用的组件尽可能避免采用集成化设计。使用组件来构建复杂的自动化工作流，每个组件处理一个独特且定义明确的任务。我们可以轻松地重复使用或调整早期Jupiter自动化的关键组件来用于下一代的软件设计，并且很容易针对已经存在的自动化项目增加新的功能。Jupiter类结构的连续变体可以采用早期已经完成的工作。不要过分分析问题我们过度分析了Jupiter线卡内存错误问题。我们试图进行精确的问题诊断，我们想区分软件错误（可通过重新启动修复）与硬件错误（需要更换卡），并识别影响流量的错误与未发生的错误。我们花费将近三年（2012-2015）的时间来收集超过650个离散内存错误的数据，然后才意识到这个分析是过头了，或者至少不应该阻塞我们自动化项目的开展。一旦我们决定对检测到的任何错误都采取必要的措施，就可以直接使用我们现有的自动化修复技术来实现简单的切换策略、重启以及为修复内存错误而重置交换机。如果问题再次出现，我们可以认为，故障很可能是基于硬件的，并立即要求更换组件。我们花费了整个项目四分之一的时间来收集数据，发现大多数的错误是暂时的 ——大多数交换机在重新启动和重新安装后都恢复了。我们不需要额外的数据来执行修复，因此为了实现这种自动化花费了三年是没有必要的。有时不完美的自动化就已经足够解除链路之前，通过BERT很容易确认链路状况，但BERT工具不支持网络管理链路。我们将这些链路添加到现有的链路修复自动化中，并允许跳过验证。我们很愿意绕过验证，因为链路并没有承载客户流量，如果验证结果很重要，我们可以稍后添加此功能。保证维修自动化项目的持续性和可继承性自动化项目可以有很长的生命周期，需要确保人员的流动不会干扰项目的连续性。 新人工程师应该接受现有系统的培训，以便他们能够修复错误。由于Jupiter线卡部件的短缺，Saturn-based系统在其目标寿命结束后很长一段时间内还是存在的，这要求我们日后在Saturn的生命周期中进行一些改进。自动化一旦被采用，在很长的一段时间内将会被依赖使用，并伴随着一些积极和消极的后果。如果可能，以灵活的方式设计你的自动化程序。不灵活的自动化会使系统变更变得难以实现。使用基于策略的自动化可以明确地将意图与通用实现引擎分离，从而使自动化更加可持续的发展。深入开展风险评估和防御措施为Jupiter构建新工具以评估执行切流操作前的风险，而后由于问题的复杂性，我们需要在更深层次的防御上引入二次检查。二次检查设定了受影响链路数量的上限，以及受影响设备的额外限制。一旦超过任一限定值，便会自动触发追踪bug以请求更进一步的检查。我们不断地调整这些限制，以减少误报。最初我们认为二次检查只是一项临时措施，但是在主要风险评估平稳后，该措施已被证明可用于识别由于停电和软件错误导致的维修问题（如请参阅SRE中“自动化：在规模上实现失效”）。失败预算和管理者支持修复自动化有时会失败，尤其是在首次使用时。管理者的支持对于保护项目，并鼓励团队坚持不懈是至关重要的。我们建议为通过自动化技术消除琐事项目设置错误预算。你还需要向外部的其他利益方解释：尽管存在故障风险，但自动化极其重要，并可以持续提高可靠性和效率。总结最终，复杂场景的自动化是真正需要解决的问题。在引入自动化系统之前要反复对系统进行评审——是否可以先简化系统和工作流？要关注自动化工作流程的各个方面，而不仅仅是造成琐事的那部分。和直接参与项目的人员共同开展测试工作，并积极寻求他们的反馈和帮助。如果他们在使用过程中出现操作问题，要想办法使工作界面更清晰，或者增加额外的安全检查。确保自动化不会带来额外的琐事——例如开启了不必要的工单以引起人的注意。给其他团队创造问题将增加自动化推进的难度。案例研究2：淘汰以文件为后端的Home directories  案例研究2中强调了减少琐事的方法：      考虑淘汰旧系统    将减少琐事作为一项工程    获得管理层和同事的支持    拒绝琐事    从部分自动化开始    提供一种自助的服务方法    从细微处开始然后改进    反馈并改进  背景在谷歌的早期，公司数据存储（CDS）SRE团队为所有Google员工提供home目录服务。与企业IT中常见的Active Directory漫游配置文件类似，Google员工可以跨工作站和平台使用相同的home目录。CDS团队还为共享存储空间中的跨团队协作提供“团队共享”服务。我们通过NFS / CIFS（或“文件管理器”）上的Netapp存储设备提供home目录和团队共享。这种存储系统是很昂贵的，但Google员工对此类服务的需求是必须的。问题陈述随着时间的推移，这些文件管理系统解决方案的优势被其他更好的存储解决方案所超越：我们的版本控制系统（Piper / Git-on-borg），Google Drive，Google Team Drive，Google云存储以及全球内部共享分布式ilesystem（x20）。这些替代方案的优越性体验在如下方面：  NFS / CIFS协议并不适用于在WAN上运行，这造成即使有几十毫秒的延迟，用户体验也会迅速降低。这也为远程工作人员或全球分布的团队带来了问题——因为数据只能存在于一个地方。  与替代品相比，原系统的设备运行和规模都是昂贵的。  要使NFS / CIFS协议与Google的Beyond Corp11网络安全模型兼容，需要做大量的工作。与本章最相关的是，home目录和团队共享会频繁的使用。存储配置的许多方面都是ticket驱动的。虽然这些工作流程通常是研发人员编写的，但它们代表了相当数量的CDS团队的工作成果。我们花了很多时间创建和配置共享，修改访问权限，解决最终用户问题，以及执行启动和调整以管理容量。除了配置、更新和备份之外，CDS还需要管理专用硬件的配置，机架和布线过程。由于延迟要求，我们经常不得不部署在远程办公室而不是在Google数据中心 – 这有时需要花费团队成员相当长的时间。我们决定做什么首先，收集数据：CDS团队开发了一个名为“Moonwalk”的工具来分析员工使用此的服务的场景。我们确定收集如下通用的指标，如每日活跃用户（DAU）和月活跃用户（MAU），并询问了诸如“哪些用户实际使用他们的home目录？”和“哪些人每天使用此系统？他们最常访问的文件是什么？“Moonwalk与用户调查相结合，验证了文件管理器当前服务的业务需求可以通过低运营开销和成本的可替代方案代替。另一个引人注目的原因促使我们放弃现有的文件系统：如果我们可以将大多数文件管理器用例迁移到G Suite / GCP，那么我们可以利用我们学到的经验来改进这些产品，从而为其他大型企业迁移到GSuite/ GCP提供支持。没有一种替代方案可以满足所有当前的文件管理器用例。然而，通过将问题转化为若干小的需求来寻找可替代系统，我们发现少数备选方案可以涵盖我们所有的使用场景。替代解决方案更专业，并且每个解决方案都带来比旧的解决方案更好的用户体验。例如：  x20  全局共享静态文件对于团队来说是很好的方式，比如二进制文件。  G Suite Team Drive  适用于办公文档协作，与NFS相比，用户更能容忍此延迟。  谷歌的巨像Colossus文件系统  比NFS更安全，更可靠地共享大型数据文件  Piper/Git-on-Borg  可以更好地同步dotfiles（工程师的个性化工具首选项）  一种新的“历史服务”工具  可以托管跨工作站命令行的历史记录在我们编制用例并找到替代方案时，旧文件系统的下线计划也已经开展设计与实施下线旧的文件管理系统是一项持续的、迭代的、需要多年的进行的工作。需要伴随多个子项目的开展：  Moira  home目录下线  Tekmor  迁移home目录用户的历史遗留数据  Migra  团队共享下线  Azog  下线home目录/共享基础架构和相关硬件 图6-8。Moira项目的四个阶段 本案例研究重点关注第一个项目Moira。后续项目的开展是在Moira的学习和开展的基础上开始的。如图6-8所示，Moira由四个阶段组成。关键组件Moonwalk虽然我们有关于用户共享（例如共享大小）的基本统计数据，但我们仍需要了解用户的工作流程，以帮助用户即使在一片反对声中仍然可以做出有利于业务发展的决策。我们建立了一个名为“Moonwalk”的系统来收集和反馈这些信息。Moonwalk存储了谁正在访问哪些文件以及何时使用BigQuery的数据，这使我们能够做出统计报告以便更好地了解用户。在BigQuery的帮助下，我们汇总了25亿个文件，共计300 TB的数据的用户访问模式。该数据来自于全球60个地理站点的124个NAS设备，共计600,000个磁盘卷，共收集了60,000名POSIX用户的使用信息。Moira Portal通过工单处理来完成home目录下线的想法，在我们庞大的用户基数面前看起来不太现实。我们需要在整个过程中（调查用户，告知项目下线原因，归档数据或迁移到替代系统）尽可能提供低接触服务（低接触服务是指这样的服务模式：销售服务人员在向顾客提供服务时，保持较少的面对面的接触机会。相对于高接触服务而言，低接触服务需要更多的机器和固定资产。因为通常需要由它们来自动完成顾客服务，如自动售货机、自动柜员机、自动加油机等，译者注）。我们的最终要求是：  描述项目的登录页面  不断更新对常见问题的解答  与当前用户共享关联状态和使用信息  提供请求，停用，存档，删除，扩展或重新激活共享的选项至此，我们的业务逻辑变得相当复杂——因为我们必须考虑许多用户场景。例如，用户可能会从Google离职，短暂离职，或者在诉讼状态（需要保留其拥有的数据）。图6-9提供了一个示例图，说明了其复杂性。 图6-9。基于用户场景的业务逻辑 为主门户网站提供支持的技术相对简单。基于Flask框架下用Python语言编写，它读取并写入Bigtable，并使用大量后台作业和调度程序来管理其工作。归档和迁移自动化我们需要大量的辅助工具来将门户网站和配置管理组合在一起，并与用户进行通信来进行用户查询。我们还需要使用沟通技巧来鉴别出适合进行数据迁移的用户。误报（错误地报告所需行动）或漏报（未通知用户您正在取走某些东西）都是不可接受的，这里发生错误将意味着失去用户可信度和带来客户服务的额外工作。我们与其他存储系统所有者合作——为新系统添加我们需要的功能。因此，随着项目的进展，不太成熟的替代品变得更适合了。我们还可以使用和扩展其他团队的工具。例如，我们使用其他团队内部开发的工具将数据从Google云端存储迁移到Google云端硬盘，作为门户网站自动存档功能的一部分。这项工作需要在整个项目期间进行长期的软件开发。我们构建并迭代了每个组件–Moonwalk报告管道，门户和自动化，以便更好地管理下线和归档共享，以响应下一阶段的要求和用户反馈。我们在第三阶段（差不多两年）才接近达到一个功能健全的系统。即便如此，我们还需要额外的工具来处理大约800名用户的“长尾”。这种低速和慢速的方法有一定的好处。因为它允许我们：  维持一个精炼的团队（平均三名CDS团队成员）  减少对用户工作流程的干扰  减少Techstop的琐事（谷歌内部技术支持组织）  根据需要构建工具，以避免将时间浪费在工程工作中与所有工程决策一样，存在如下权衡：项目将长期存在，因此团队在设计解决方案时必须忍受与文件管理器相关的琐事。该计划于2016年正式完成。在撰写本文时，我们已将home目录从65,000个减少到约50个（目前的Azog项目旨在淘汰这些最后用户并彻底下线文件管理系统的硬件。）我们的用户体验有所改善，CDS已停止运营成本高昂的硬件。经验教训虽然没有任何替代方案可以替代Google员工已使用14年之久的文件管理系统，但我们并非没必要进行批量更换。通过有效地将堆栈从通用但有限的文件系统解决方案升级到多个应用程序共同组成的解决方案，我们增加了系统的灵活性，以提高可扩展性、延迟包容度和安全性。Moira团队不得不预测各种用户的行为，并考虑不同阶段的可替代方案。我们必须围绕这些替代方案来调整我们的期望：总的来说，它们可以提供更好的用户体验，但实现这一目标并非是毫无痛苦的。我们学到了以下关于有效减少琐事的策略。发现旧系统的不足并下线昂贵的业务流程业务需求不断变化，新的解决方案不断涌现，因此定期评估旧的业务流程是值得的。正如我们在第101页的“琐事管理策略”中所讨论的那样，拒绝琐事（决定不执行）通常是消除它的最简单方法，即使这种方法并不总是快速或简单的。通过用户分析和业务理由来调整你的业务工作内容，而不仅仅是减少琐事。文件管理系统下线的主要业务理由归结为Beyond Corp安全模型的优势。因此，虽然Moira是减少CDS团队琐事的好方法，但强调下线系统的原因如果是考虑到了新系统诸多的安全优势，这些优势将带来更具吸引力的业务需求。构建自助服务接口我们为Moira建立了一个自定义门户（相对昂贵），但通常有更便宜的选择。Google的许多团队使用版本控制来管理和配置他们的服务，以拉取请求（称为更改列表或CL）的形式处理请求。这种方法几乎不需要服务团队的参与，但为我们提供了代码审查和持续部署的优势，便于验证、测试和部署内部服务配置更改。从人工支持的界面开始在几个方面，Moira团队采用了“幕后工程师”的方法，将自动化与工程师的人工操作相结合。共享请求在路由过程中出现bug，我们的自动化在处理请求时会及时更新。系统还会通知到终端用户，提醒他们解决类似的共性问题。工单可以作为自动化系统的应急的GUI：它们保存工作日志，更新利益相关者的数据，并在自动化出错时提供简单的人工干预机制。在我们的示例中，如果用户需要获得数据迁移工作的帮助，或者如果自动化无法处理其请求，则该错误会自动路由到SRE手动处理的队列中。零接触的自动化自动化系统要求请求合规。Moira的工程师选择重新调整我们的自动化，以专门处理共享的边缘场景请求，或者删除/修改不合格的共享以符合系统的期望。这使我们能够在大多数迁移过程中实现零接触的自动化。  有趣的事实：在谷歌，通过改变现实去适应代码而不是通过修改代码去适应现实的方式被称为“购买侏儒”。这句话源自一个关于Froogle的故事，Froogle是一个很早就开展的购物搜索引擎服务。在Froogle的早期阶段，发生过精确匹配搜索“跑鞋”关键字导致返回了garden gnome(花园侏儒, 穿着跑鞋）的严重错误。在几次尝试修复错误失败之后，有人注意到gnome不是批量生产的商品，而是一个带有“一口价”选项的eBay商品。他们购买了这个“花园侏儒”商品后，解决了这个返回错误搜索结果的问题（译者注：相比起修改代码，以更低的成本解决了问题）。（图6-10）。 图6-10. 不会消失的花园侏儒 推动新系统的使用寻找方法来推动新用户采用更好的替代方案。在这种情况下，Moira需要升级系统配置以便应对新的请求和下线旧的系统。在服务设置中，新系统使用最佳实践和用户如何配置系统也很重要。Google团队经常使用codelabs或cookbook为用户提供常见用例设置和指导如何使用他们的服务。因此，大多数用户入手都不需要额外的团队的指导。结论与生产服务运行相关的琐事会随着系统复杂性和规模的增长而线性增长。自动化通常是消除琐事的黄金法则，并且可以与其他策略相结合。即使一些琐事没必要完全自动化，你也可以通过部分自动化或改变业务流程等策略来减少操作的负担。本章中描述的消除琐事的模式和方法可以推广到其他各种大规模生产服务中。消除琐事可以节省工作时间，以便工程师专注于服务的更重要的方面，并允许团队将手动任务保持在最低限度。随着现代服务架构的复杂性和规模不断增加，此策略尤其重要。但是要注意，消除琐事并不总是最好的解决方案。如本章所述，你应该考虑成本，设计、改造和实施自动化解决方案都需要投入成本。一旦决定减少琐事，就必确立目标，进行投资回报率（ROI）分析，风险评估和迭代开发来确定是否减少了工作量。琐事通常是从小事开始积累的，并且可以迅速成长最终消耗整个团队的人力资源。SRE团队必须坚持不懈地消除琐事——因为即使减少琐事的项目看起来令人生畏，但其好处通常也是会超过成本的。我们所描述的每个项目都需要各自团队的坚持不懈和奉献精神，他们有时会面对质疑或者需要与制度进行斗争，并且总是面临竞争这种高优先级的任务。我们希望这些案例鼓励你识别工作中的琐事，量化它，然后努力消除它。即使今天不能开展一个大项目，你也可以从一个小概念开始，这可以帮助改变你的团队处理琐事的方式。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第三章 SLO工程案例学习]]></title>
      <url>/sre/2020/01/03/SLO%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0/</url>
      <content type="text"><![CDATA[  名次解释：      SLI：服务质量指标、该服务的某项服务质量的一个具体量化指标。例如：延迟、可用性    SLO：服务质量目标、服务的某个SLI的目标值/范围。例如：搜索请求的平均延迟 &lt; 100ms。    SLA：服务质量协议、服务与用户之间的一个明确的协议，描述达到/未达到SLO之后的后果。    错误预算： 1 - 可靠性目标  尽管SRE的许多原则都是在Google内部形成的，但它的原则早已存在于Google之外。许多Google SRE的标准已被业内多个组织实践应用。SLO是SRE模型的基础。自从我们组建了客户可靠性工程（CRE）团队——这是一组帮助Google Cloud Platform（GCP）客户构建更可靠的服务的经验丰富的SRE——几乎与每个客户交互都以SLO开始以SLO结束。我们在这里介绍了两个不同行业的公司事迹，概述了他们在与Google CRE团队合作时采纳SLO和基于错误预算的方法的过程。有关SLO和错误预算的讨论，请参阅本书的第2章和第一本书的第3章。Evernote的SLO故事Evernote是一款跨平台的APP，可帮助个人和团队创建、整合和共享信息。在全球拥有超过2.2亿用户，我们在平台内存储了超过120亿条信息——包括文本笔记、文件和附件/图像。在后台，Evernote服务由750个以上的MySQL实例支持。我们向Evernote引入了SLO的概念，并将其作为更广泛的技术改造的一部分，旨在提高工程速度，同时保持服务质量。我们的目标包括：将工程重点从数据中心中冗余的繁重工作转移到客户实际关心的产品工程工作上。为此，我们停止运行物理数据中心并转移到公有云。调整运维和软件工程师的工作模式，旨在保持整体服务质量的同时提高变更速度。改进我们对SLA的看法，以确保我们更加关注故障对庞大的客户群所造成的的影响。这些目标对许多行业的组织而言可能都很熟悉。虽然没有一种方法可以全面实现这些类型的变更，但希望我们分享的经验可以为面临类似挑战的人提供有价值的参考意见。为什么Evernote采用SRE模型？过渡开始阶段的Evernote的特点是传统的运维和开发分离：运维团队维护生产环境的稳定性，而开发团队的任务是为客户开发新的产品功能。这些目标通常是冲突的：开发团队 感觉被繁琐的流程所束缚，而运维团队又会因新代码在生产环境中引入新的问题变得不满。 当我们在这两个目标之间不断动摇时，运维和开发团队之间蔓延了一种不满和紧张的关系。我们希望达到一个双方都满意的节点，更好地平衡所涉及团队的不同需求。在五年多的时间里，我们尝试了各种方式解决这种传统二分法中的差距。在尝试了“你编码，你运行”的开发模式，以及“你编码，我们为你运行”的运维模式之后，我们转向了以SLO为中心的SRE方法。那么是什么促使Evernote向这个方向发展呢？在Evernote，我们将运维和开发的核心目标视为工程师专业化的独立发展方向。一个方向关注的是近乎7*24小时地持续为客户提供服务。另一个关注的是服务的扩展和发展，以满足客户未来的需求。近年来，这两个方向已经越来越接近，例如SRE和DevOps强调将软件开发应用于运维。（数据中心自动化和公有云的发展进一步推动了这种融合，这两者都为我们提供了一个可以完全由软件控制的数据中心。）另一方面，全栈所有权和持续部署也越来越多地应用于软件开发。SRE模型完全接受并包容了运维和开发间的差异，同时鼓励团队朝着共同的目标努力。它并不试图将运维工程师转变为应用程序开发人员，反之亦然。相反，它给出了一个共同的参考框架。根据我们的经验，由于使用错误预算/SLO方法的两个团队在交流时很少带着主观感情，所以在面对同样的情况时通常会做出类似的决定。SLO简介：正在进行的旅程旅程的第一步是从物理数据中心迁移到Google云平台。当Evernote服务在GCP上稳定运行后，我们就引入了SLO。我们的目标有两个：确保所有团队都在Evernote SLO的新框架内工作。将Evernote的SLO纳入我们与Google 云团队的合作中，他们现在负责我们的底层基础架构。由于在整体模型中加入了新的合作伙伴，因此我们需要确保迁移到GCP不会影响我们对用户的承诺。在使用SLO约9个月后，Evernote已经开始实践使用其SLO的第3版了！在深入了解SLO的技术细节之前，要先从客户的角度开始提问： 你可以提供哪些承诺？与大多数服务类似，Evernote具有许多功能和选项，用户可以通过各种创造性方式使用这些功能和选项。我们希望在一开始就关注最重要和最常见的客户需求：Evernote服务的可用性，以便用户能够访问和同步多个客户端的内容。我们的SLO之旅从这个目标开始。通过关注服务正常运行时间， 我们完成了接入SLO的第一步。使用这种方法，我们可以清楚地表达我们衡量的内容以及衡量方法。我们的第一份SLO文件包含以下内容：SLO的定义这是一个（服务、系统）可用时间的计算方法：为某些服务或者是方法，在月级别的统计周期内设定了99.95%的可用性。这个数据是我们基于内部客户支持团队、产品团队，尤其重要的是用户共同讨论得来的。我们特意选择将SLO和日历月而不是与滚动的时期进行关联，就是为了使我们在进行服务复查时保持专注有序。衡量什么，以及如何衡量它衡量度量    我们指定了一个服务终点，我们可以调用它来测试服务是否按预期运行。在我们的例子中，我们在服务中内置了一个状态页面，它可以运行我们的大部分堆栈并返回200状态代码（如果一切正常）。如何度量    我们想要一个定期调用状态页面的探测器。我们希望探测器完全位于我们的环境之外并独立于我们的环境，因此我们可以测试所有组件，包括负载均衡。我们的目标是确保我们可以统计到GCP服务以及evernote应用任何、所有异常。但是，我们不希望随机网络问题触发误报。我们选择使用专门建立和运行此类探测器的第三方公司。我们选择了Pingdom，但市场上还有很多其他产品。我们按如下方式进行衡量：   如何从监控数据计算SLO最后，我们仔细记录了我们如何根据从Pingdom收到的原始数据计算SLO。例如，我们指定了如何考虑维护窗口：我们无法假设我们所有的数亿用户都知道我们发布的维护窗口。因此，不知情的用户会将这些窗口视为通用和无法解释的停机时间，因此我们的SLO计算将维护视为停机时间。一旦我们定义了SLO，我们就必须使它发挥最大的价值。 我们希望SLO能够推动软件和运维方面的变革，让我们的客户更快乐并让他们满意。 怎么做到最好？探测频率：我们每分钟轮询一次前端节点。探测器的位置：此设置是可配置的; 我们目前在北美和欧洲使用多个探测器“down”的定义：如果一个探测器检测结果为失败，那么这个节点会被标记为疑似宕机，然后第二个基于不同地理位置独立部署的探测机会进行第二次确认。如果第二次检查同样也失败了，出于计算SLO的目的这个节点会被标记为宕机。只要探测请求持续显示错误，那么这个节点会被持续标记为宕机。我们用SLO中有关错误预算的思维为方法来分配下一步工作的需要的资源。举例来说，如果我们没有达成上个月的SLO，这会促使我们高优（对系统、服务）进行目标明确的加固、改进和修复。我们制定最简原则：evernote团队以及google团队共同进行月级别 的SLO目标复查。在这个会议上，我们复核SLO的表现并对所有服务中断行为进行深入研究。基于针对上个月的上述分析而不是根因分析，我们制定了一些改进措施。在整个过程中，我们的指导原则是“过犹不及”。即使在SLO还没有达到完美的时候，它也足以在此期间指导我们进行改进。一个“完美”的SLO应该可以衡量每一个与我们服务有关的潜在用户交互设计并且解释所有的边界行为。虽然字面上看起来这是个好主意，但是如果要实现起来却要花费数月的时间去改进服务（如果真的可以这到完美）。相反，我们选择了一个初始SLO，涵盖了大多数（但不是全部）用户交互，这是服务质量的良好代理。自从我们开始执行SLO以来，根据从服务复盘以及响应客户有感的宕机事件中得到的启示，我们对SLO做了两次修改。因为我们一开始就没有追求完美SLO，为了适应业务的发展我们乐于做出改变。除了evernote团队与google进行月级别SLO复盘之外，我们也设定了一个6个月的SLO复盘周期，这个周期可以使SLO的维护达到一个平衡：既不会频繁更新，也不会使之过时。在不断修订SLO的过程中，我们也意识到了，期望的衡量标准和可以达到的衡量标准之间的平衡是很重要的。自引入SLO以来，我们的运维和开发团队之间的关系有了微妙但显著的改善。现在团队对成功有了共同的衡量标准，那就是：取消对服务质量的人为解释使两个团队达成了共同的观点和标准。在此我们试着举一个例子，2017年当我们不得不在短期内推动多个版本的发布任务时，SLO为我们提供了共同基础。当我们发现一个复杂的bug时，产品开发团队要求我们将常规的周级别发布任务分配到多个独立的发布窗口，每个发布窗口都会对客户产生潜在的影响。通过对问题进行有针对性的SLO计算以及消除方案中的人为主观因素，我们可以更好的量化客户感受并且通过把发布窗口由5个降为2个从而达到了减少了客户痛点的目的。打破客户与云服务商之间的隔阂介于客户和云服务商之间的隔阂看起来是在所难免的。虽然google已经为运行evernote的GCP平台设定了SLO和SLA（服务等级协议），但是evernote有自己的SLO和SLA。期望两个技术团队会将彼此的SLA告知对方看起来是不现实的。evernote不希望存在这样的隔阂。当然我们也可以基于自己的SLO和底层的GCP平台的SLA建立起隔离域，相反从一开始我们就希望google可以理解性能表现对我们来说是多重要以及为什么这么重要。我们期望google和我们在目标上达成一致，让两家公司把evernote在可靠性方向的成败当作共同的职责。为了实现这一目标，我们需要一种方法可以：达成一致的目标确保我们的合作伙伴（在此指google）真正清楚我们最关心哪些指标共担成败大多数服务商都为自己的云服务发布了SLO/SLA。虽然服务运行在此框架下很重要，但这并不能全面的反映我们的服务在云服务商的环境中运行的状况。例如，一个给定的云服务商可能在全球运行了数十万台虚拟机，他们为这些虚机的正常运行和可靠性负责。GCP承诺计算引擎（也就是虚机）可以达到99.95%的可靠性。即使当GCP SLO指标显示为绿色的时候（即可靠性高于99.95%），evernote的监控视图的表现可能完全不同：因为我们的虚机在GCP全球总量虚机中仅占有很小的比例，会使导致我们（服务所在）区域成为孤岛（或由于其他原因导致成为孤岛）的故障最终在全球级别的汇总中被忽略。为了修正这样的情况，我们将我们的SLO和未达成SLO的实时性能与goolge进行共享。因此，Google CRE团队和Evernote团队基于同样的性能仪表盘展开合作。这看起来似乎是一个很简单的观点，但最终被证明是一种相当有效的、可以形成真正以客户为中心的工作方法。因此，google会向我们提供更明确的环境运行情况通知，而不是那种泛泛的“x服务当前运行缓慢”的通知。举例来说，除了那种泛泛的“今天GCP负载均衡环境运行缓慢”之外，我们还会被告知这个问题已经对evernote的SLO造成了5%的影响。这种关系也有助于google内部团队了解他们的行为和决策是如何影响用户的。这种双向关系也为我们提供了一个非常有效的框架来应对重大事件。大多数情况下，P1-P5级别的工单和常规的支持渠道配合使用，产生了很好的效果，使我们能够提供稳定的服务，并与谷歌保持良好的合作关系。但众所周知，当你整个在线服务面临着拓展业务增长的压力的时候，P1级别的工单是不能满足要求的。这时，我们与CRE团队共享的SLO和（合作）关系得以实现。我们达成共识，如果SLO影响足够高，双方都会将该问题视为P1级别进行特殊处理。这就意味着evernote和google的cre团队经常要快速组织起一个可以共享的沟通渠道。Google CRE团队监控（管理）我们共同定义和商定的SLO，使我们在优先级和恰当响应方面保持同步。当前状态协调目标确保我们的合作伙伴（在本例中为Google）真正了解对我们重要的内容分享成功和失败在积极使用SLO大约九个月之后，Evernote已经在使用SLO实践的第三版了。下一个版本的SLO会以我们当前简单正常运行时间的SLO为基础进行改进。我们将关注单个API调用和客户端的指标/性能视图，以便更好地表示用户QoS。通过提供标准定义的QoS测量方法，SLO使Evernote更关注我们的服务是如何运行的。我们内部或者和谷歌进行以数据为驱动的对话，了解服务中断的影响，这能够推动服务改进，最终建立更强大的支持团队，使客户更满意。Home Depot的SLO故事Home Depot（THD）是全球最大的家居装饰零售商：我们在北美拥有2,200多家商店，每家商店都拥有超过35,000种产品（网站上有超过150万种产品）。 我们的基础架构托管各种软件应用程序，支持了近400,000名员工每年处理超过15亿的客户交易。这些商店由全球供应链和每年访问量超过20亿次电子商务网站紧密组成。最近为了提高我们软件开发的速度和质量，THD转向敏捷软件开发并改变了我们设计和管理软件的方式。我们从支持大型软件包开发的团队转变为小型独立的微服务架构开发团队。因此，我们的系统现在由一系列不断变更的微服务组成，这些微服务也是通过堆栈整合而成。我们向微服务转变的过程中，全栈所有权获得了新的“自由和责任文化”的补充。这种方法使开发人员可以自由地在需要时推送代码，同时也使他们为他们对服务的操作负责。对于这种共同所有权工作模式，运维和开发团队需要达成一种共识，即促进责任制和减少复杂性：SLO。相互依赖的服务需要知道如下信息：如果每项服务都能为这些问题提供明确的和一致的答案，那么团队就可以清楚地了解服务的依赖关系，从而达到更好地沟通，增强团队之间的信任和责任感。SLO文化项目在我们的服务模式开始转变之前，Home Depot没有SLO文化。监控工具和仪表盘特别多，但都分布在各处，并且不会随着时间的推移记录数据。我们并不总能查出服务中断的根因。我们通常从遇到的服务问题开始排查，直到我们发现问题为止，这浪费了无数个小时。如果服务需要计划停机时间，其依赖服务就会受不了。如果一个团队需要构建一个99.95%的服务，他们不确定有严格依赖的服务能否达到99.99%的标准。这些未知导致我们的软件开发团队和运维团队之间的疑惑和失望。我们需要通过建立SLO的共同文化来解决这些问题。因此，需要一个影响人员、流程和技术的总体战略。 我们的努力跨越了四个方面：内部名词规定：在THD（Home Depot）公司内部定义SLOs。 来说明如何以一致的方式来进行度量。福音主义在整个公司传播这个词。通过给销售提供培训资料，在公司进行路演、内部博客、宣传资料比如T恤和贴纸等方式，传播为什么SLO很重要。争取一些早期采用者来实施SLO并向其他人展示其价值。建立一个感兴趣的首字母缩略词（VALET;稍后讨论）以帮助传播这个想法。创建培训计划（FiRE学院：可靠性工程基础），对开发人员进行培训使其了解SLO和其他可靠性概念。自动化为了降低指标收集的难度，用一个指标收集平台去自动收集生产环境中的服务的服务等级指标。这些SLI以后可以更容易地转换为SLO。激励为所有开发经理制定年度目标，为其服务设置和衡量SLO。每个人达成共识很重要。我们还希望保持这个框架尽可能简单，以帮助这个想法更快地传播。为了开始，我们仔细研究了我们在各种服务中监控的指标，并发现了一些模式。每项服务都会监控某种形式的流量、延迟、错误和利用率指标，这些指标与Google SRE的四个黄金指标密切相关。此外，许多服务都可以从错误中明显监控正常运行时间或可用性。很遗憾，整体来看，并不是所有类型的采集项都统一添加了监控、统一了命名、或者有足够的监控数据。我们的服务都没有SLO。我们的生产系统与面向客户的SLO最接近的指标是（用户）支持数据。通过跟踪商店内咨询台接收到的支持电话数量，是我们评价部署在我们商店的应用可靠性的主要（大多数时候是唯一）方法。我们的第一套SLO我们不能对一个可度量系统的每个方面都创建SLOs，因此我们必须确定系统的哪些指标或SLIS应该具有SLOs。API调用的可用性和延迟我们决定对微服务之间的API调用设置可用性和延迟SLOs。例如，Cart微服务调用Inventory微服务。针对那些API调用，Inventory微服务发布了SLOs，Cart微服务（以及需要Inventory的其他微服务）可以获取这些SLOs并以此决定Inventory微服务是否能满足可靠性要求 基础设施利用/基础设施利用率。基础设施利用率THD团队通过不同的方式来衡量基础设施利用率，而最典型的衡量标准是分钟级别的实时基础设施利用率。我们基于某些原因并不会设置这种利用率SLOs。首先，微服务并非十分关注这个指标-只要服务可以承载流量，服务器正常运行、响应速度很快、不抛错误，且并不会耗尽容量，那么你的用户就不会真正关心利用率。此外，计划迁移服务到云端意味着资源利用率不是重点，这时我们要关注的是成本规划，而不是容量规划。（我们仍然需要监控利用率并执行容量规划，但不需要将其包括在我们的SLO框架内。）流量由于THD没有进行容量规划的传统，因此我们需要一种机制，该机制能让开发和运维团队就其服务可以承载的流量进行沟通。流量通常被定义为对服务的请求，但我们需要确定是否应该跟踪平均每秒请求数，每秒峰值请求数或报告时间段内的请求数。最终我们决定跟踪这三项，并给每项服务选择最合适的指标。我们讨论是否为流量设置SLO的原因在于这个指标是由用户行为决定的，而非我们可控的内部因素决定。我们要讨论是否为流量设置SLO，因为流量的衡量跟用户行为密切相关，我们可控的内部因素无法发挥决定作用。 最终我们认为，作为零售商，我们需要为应对黑色星期五这样的活动流量峰值增加服务的规模，并根据预期的峰值流量设置SLO。延迟我们给每个服务定义了延迟SLO并确定其最佳的衡量方式。这里我们只要求服务应该通过黑盒监控来补充我们常见的白盒性能监控，以捕获由网络或诸如缓存以及微服务外部代理失效等层面的问题。并且，我们认为，采用百分位数比算术平均值更合适。服务最少需要达到90％的目标，而面向用户的服务则最好达到95%或99%的目标。错误错误解释起来有点复杂。由于我们主要处理Web服务，因此我们必须将错误内容以及返回结果标准化。如果Web服务发生错误，我们自然会对HTTP响应代码进行标准化：. 在服务的返回内容中，不应该用2xx来标记错误; 相反，一个错误应该抛出4xx或5xx。 . 由服务端问题（如内存不足）引起的错误应该抛出5xx错误。 . 客户端错误（如发送错误格式的请求）应该抛出4xx错误.一番考虑后，我们决定跟踪4xx和5xx错误，但仅使用5xx错误来设置SLOs。与定义其他相关SLO的方法类似，我们采用通用形式来定义错误SLO，以便不同环境中的不同应用都可以使用该SLO。例如，除HTTP错误外，定义一个批处理服务的错误，可能是该服务无法处理记录的个数。工单正如前面提到的，工单最初是我们评估大多数生产软件的主要方式。由于历史原因，在我们其他的SLOs中，我们决定继续跟踪工单。你可以将该指标视为类似于“软件操作级别”的指标。VALET我们将新的SLOs概括为一个更简易的缩略词：VALET。容量（流量）服务可以处理多少业务量？可用性需要的时候服务是否正在运行？延迟使用时服务是否快速响应？错误使用时服务是否会抛出错误？工单服务是否需要人为干预才能完成请求？推广SLOs凭借这样一个易于记忆的缩略词，我们开始在企业内部推广SLOs：. 为何SLOs如此重要. SLOs是怎样与我们的“自由和责任”文化相契合的. 应该衡量什么. 如何处理结果因为开发人员现在要负责维护他们自己的软件，因此他们需要建立SLOs以体现他们开发和维护软件可靠性的能力，针对面向用户的服务，他们需要同服务使用者和产品经理进行交流。然而，他们中多数人并不熟悉诸如SLAs和SLOs这样的概念，因此他们需要接受VALET框架方面的培训。由于我们需要获得强有力的支持来推广SLOs，因此一开始我们可以面向高级领导者进行SLOs的推广讲解。然后逐个向开发团队讲述SLOs的价值观。我们鼓励团队从他们自定义的度量跟踪机制（通常是人为制定）转向VALET框架。为了保持这种推广态势，我们每周发送一份VALET格式的SLO报告给高层领导，这份报告结合了可靠性理念和从内部事件中吸取的经验。这也有助于构建业务指标，例如在VALET框架下，创建的采购订单（流量）或支付订单失败（错误）。我们还以多种方式扩展了我们的推广渠道：. 我们建立了一个内部WordPress网站来托管有关VALET和可靠性的博客，并将其链接到相关资源。. 我们组织内部技术讲座（包括Google SRE演讲嘉宾），讨论了通用可靠性概念以及如何使用VALET进行度量。. 我们开展了一系列VALET培训研讨会（之后将演变为FiRE学院），并向所有想参加的人开放，这些研讨会持续了好几个月。. 我们甚至制作了VALET笔记本电脑贴纸和文化衫，用来支持全面的内部推广活动。很快，公司里的每个人都知道了VALET这一概念，并且我们的SLOs新文化开始在公司占据主流。对开发负责人来讲，实施SLO甚至已正式成为其年度绩效评估指标。虽然大约有50项服务正在按周级别获取并报告其SLOs，但我们会将这些指标存储在电子表格中。虽然VALET的思想已经非常流行，但为了让其更广泛地被接纳，我们仍然需要自动化技术来进行数据的收集。自动化VALET数据收集虽然我们的SLO文化现在有了强大的立足点，但自动化VALET数据收集将加速SLO的应用。TPS报告我们构建了一个框架来自动捕获部署到新GCP环境的任何服务的VALET数据。我们将此框架称为TPS报告，这是我们用于数量和性能测试的术语（每秒交易次数），当然，也是为了满足多个管理者想要查看这些数据的想法。 我们在GCP的BigQuery数据库平台之上构建了TPS Reports框架。我们的Web服务前端生成的所有日志都被输入BigQuery以供TPS Reports处理。当然也包括来自各种监控系统的指标，例如Stackdriver的可用性指标。TPS报告将这些数据转换为任何人都可以查询的每小时VALET指标。新创建的服务自动注册到TPS报告中，因此可以立即查询。由于数据全部存储在BigQuery中，因此我们可以跨时间帧有效地报告VALET指标。我们使用此数据构建了各种自动报告和警报。 最有趣的集成是一个聊天机器人，让我们直接在商业聊天平台上报告服务的VALET。例如，任何服务都可以显示过去一小时的VALET，前一周的VALET，未达成SLO的服务以及聊天频道内的各种其他值得引起关注的数据。VALET服务我们的下一步是创建一个VALET应用程序来存储和报告SLO数据。因为SLO最适合用作趋势工具，所以该服务以每日、每周和每月粒度跟踪SLO。请注意，我们的SLO是一种趋势工具，我们可以将其用于错误预估，但不直接连接到我们的监控系统。相反，我们有各种不同的监控平台，每个平台都有自己的警报。这些监控系统每天汇总其SLO并发布到VALET服务以进行趋势分析。此设置的缺点是监控系统中设置的警报阈值未与SLO集成。 但是，我们可以根据需要灵活地更换监控系统。预计需要将VALET与未在GCP中运行的其他应用程序集成，我们创建了一个VALET集成层，该层提供API来收集聚合的VALET数据以生成服务日报。TPS Reports是第一个与VALET服务集成的系统，我们最终集成了各种本地应用程序平台（占在VALET中注册的服务的一半以上）。VALTE 仪表盘VALET仪表板（如图3-1所示）是我们用于可视化和报告此数据的UI，并且相对简单。 它允许用户：图3-1  VALET仪表盘注册新服务。 这通常意味着将服务分配给一个或多个URL，这些URL可能已经收集了VALET数据。为五个VALET类别中的任何一个设置SLO目标。在每个VALET类别下添加新的指标类型。 例如，一个服务采集99%的请求所用的延迟，而另一个服务采集90%的请求所用（或两者）的延迟。或者，后端处理系统可以跟踪每日总量（一天内创建的采购订单），而客户服务的前端可以跟踪每秒交易的峰值。VALET仪表盘允许用户一次报告许多服务的SLO，并以多种方式对数据进行切片和切块。例如，团队可以查看过去一周未达到SLO的所有服务的统计信息。负责复盘服务性能的团队可以查看其所有服务及其所依赖的服务的延迟。VALET仪表盘将数据存储在一个简单的Cloud SQL数据库中，开发人员使用流行的商业报告工具来构建报告。这些报告成为开发人员新的最佳实践的基础：定期对其服务进行SLO审核（通常是每周或每月）。基于这些，开发人员可以创建操作项以使服务回归SLO，或者可能按照需要调整不符合实际的SLO。SLOs的扩散一旦SLOs融入到组织的集体思想中，并且具备了有效的自动化技术和报表，那么新的SLOs就可以快速实施。在年初跟踪了约50项服务的SLOs之后，到今年年底我们正在跟踪800项服务的SLOs，每月约有50项新服务在VALET注册。由于VALET允许我们在THD中推广SLO的应用，因此自动化开发这项工作是非常有意义的。但是，不具备这种自动化开发能力的公司也不用担心采用SLO会带来的麻烦。虽然自动化为THD提供了额外的收益，但一开始就编写SLO也收益颇多。将VALET应用于批处理应用程序当我们围绕SLO开发强大的报表时，我们发现了VALET的一些其他用途。 经过一些调整，批处理应用程序可以适用此框架，如下所示：数量已处理的记录数量可用性在一定时间内完成工作的频率（百分比） 等待时间作业运行所需的时间 错误程序运行失败的记录 工单操作员必须手动修复数据和重新处理作业的次数在测试中使用VALET由于在发展SRE文化的同时，我们发现在临时环境中，VALET可以支持我们的破坏性测试（混沌工程）自动化。有了TPS Reports框架，我们就可以自动进行破坏性测试并记录对service’s VALET data造成的影响（希望没有影响）。未来展望通过800个（并且不断增长）服务来收集VALET数据，我们可以拥有大量有用的运营数据。我们对未来有几个期望。既然我们正在有效地收集SLO，我们希望使用这些数据来采取行动。我们的下一步是类似于Google的错误预算文化，当服务不在SLO时，团队停止推送新功能（除了提高可靠性相关的）。为了满足业务增长的需求，需要平衡SLO报告的生成频率（周级别或月级别）和SLO标准的更新频率。和许多采用错误预算的公司一样，我们正在权衡滚动窗口与固定窗口的优缺点。我们希望进一步优化VALET以跟踪详细的节点和服务的使用者。目前，即使特定服务具有多个节点，我们也只在整个服务中跟踪VALET。因此，很难区分不同的操作（例如，对目录的写入与对目录的读取；虽然我们对这些操作添加了单独的监控和报警，但不跟踪SLO）。同样，我们也很乐意为服务的不同消费者提供对应的VALET结果。虽然我们目前在Web服务层跟踪延迟SLO，但我们还希望跟踪最终用户的延迟SLO。此度量将捕获网络延迟和CDN缓存等因素如何影响页面开始呈现和完成呈现所需的时间。我们还想将VALET数据扩展到应用程序部署。具体来说，在将更改推广到下一个服务器、域或区域之前，我们希望自动化验证VALET是否在容差范围内。我们已经开始收集有关服务依赖性的信息，并且制作了一个可视化图表原型，该图表显示了我们在调用树中未触及到VALET指标的位置。 新兴的网格服务平台将简化这种分析。最后，我们坚信服务的SLO应该由服务的业务所有者（通常称为产品经理）根据其业务的重要性来设置。至少，我们希望业务所有者设置服务正常运行时间的最低要求，并将SLO用作产品管理和开发之间的共享目标。虽然技术人员发现VALET很直观，但对于产品经理来说，这个概念并不那么直观。我们正在努力使用与它们相关的术语来简化VALET的概念：我们既简化了正常运行时间的选择数量又提供了示例指标。我们还强调从一个级别转移到另一个级别所需的大量投入。以下是我们可能提供的简化VALET指标的示例：. 99.5％：商店员工使用次数很少的应用程序或新服务。    . 99.9％：适用于THD的大多数非销售系统 . 99.95％：销售系统（或支持销售系统的服务） . 99.99％：共享的基础设施服务以业务术语来衡量指标并在产品和开发之间共享可见目标（SLO！），这种行为将大量减少公司常见的对可靠性的错误预期。概要向大公司介绍一个新流程，都需要一个好的策略、高管的支持、强大的传播、简单的采用模式以及最重要的耐心，更不用说是一个新文化了。像SLO这样的重大变革可能需要数年才能在公司中牢固地建立起来。我们想强调的是，Home Depot是一家传统企业;如果我们能够成功地引入这么大的变化，那么你也可以。你也不必一次完成这个任务。虽然我们逐步实施SLO，但制定全面的传播策略和明确的激励结构促进了快速转型：我们在不到一年的时间内获得了从0到800的SLO服务支持。结论SLO和错误预算为解决许多不同问题提供了强大的理论支持。这些来自Evernote和Home Depot的案例研究提供了非常真实的例子，说明如何实施SLO文化可以使产品开发和运维更紧密地结合在一起。这样做可以促进沟通并更好地为制定决策提供信息。它最终将为你的客户带来更好的体验 - 无论这些客户是内部、外部、人类还是其他服务。这两个案例研究强调实现SLO文化是一个持续的过程，而不是一次性修复或解决方案。虽然它们共享哲学基础，但THD和Evernote的度量风格、SLIs、SLOs和实现细节明显不同。这两个案例都补充了谷歌对SLOs的看法，说明了SLO实现不一定是Google所特有的。正如这些公司为自己独特的环境量身定制SLO一样，其他公司和组织也可以这样做。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第二章 实施SLO]]></title>
      <url>/sre/2020/01/02/%E5%AE%9E%E6%96%BDSLO/</url>
      <content type="text"><![CDATA[  名次解释：      SLI：服务质量指标、该服务的某项服务质量的一个具体量化指标。例如：延迟、可用性    SLO：服务质量目标、服务的某个SLI的目标值/范围。例如：搜索请求的平均延迟 &lt; 100ms。    SLA：服务质量协议、服务与用户之间的一个明确的协议，描述达到/未达到SLO之后的后果。    错误预算： 1 - 可靠性目标  SLO为服务可靠性设定了一个目标级别。它是可靠性决策的关键因素，所以是SRE实践的核心。无论从哪个角度来看，这都将是本书中最重要的一章。我们只有具备了一定的理论，设置初始的SLO并细化它们，这个过程才会变得简单。在第一本书第四章中介绍了有关SLO和SLI的相关理论，并对如何使用它们给出了一些建议。了解了SLO和错误预算这个概念之后，本章提供了一种方法让你开始SLO之旅，以及一些如何进一步迭代的建议。然后，我们将介绍如何使用SLO做出有效的业务决策，并探索一些更高级的使用场景。最后，我们介绍了一些不同场景下开展SLO的案例，以及在特定情况下开展更复杂SLO的指导方案。SRE需要SLO的原因即使在大型研发团队中，工程师也是稀缺资源，工程师的时间应投入到重要服务的核心问题上。工程师应该花时间在功能研发上以便赢得新的客户，还是花时间在提高服务可靠性和可伸缩性上以便让客户满意，这是很难找到平衡点的。谷歌认为一个深思熟虑的SLO是做出决策的关键，这些决策包括了可靠性相关工作，和确定工作优先级排序等内容。SRE的核心职责不仅仅是将“所有的事情”自动化并随时待命处理故障，他们的日常工作都将按照SLO来开展。确保SLO在短期内是合理的，并且可根据情况适时地调整。甚至可以说，如果没有SLO，就没有SRE。SLO更像一种工具，可以帮助工程师确定哪个工作优先级更高。 例如，考虑如下两个工作的优先级：将服务自动回滚和切换到备份站点。 通过计算这两个工作的“错误预算”值，我们可以确定哪个工作对用户更有利。有关详细信息，请参阅第37页上的“使用SLO和错误预算进行决策”部分，以及《Site Reliability Engineering》中的“拥抱风险”一章。入门作为建立基本SLO指标的起点，让我们来假设你的服务是某种形式的代码，它已经被编译和发布，并且运行在用户可以web访问的网络基础设施上。你的系统可能处于如下某个阶段：  起步阶段——尚未部署任何内容  在生产环境中，当出现问题时，系统的监控会通知您，但是没有正式的目标和没有错误预算的概念，也没有一个明确的正常运行时间  有SLO指标，但对其重要性理解不到位，或者不知道如何利用它来进行持续改进。  为了采用基于错误预算的站点可靠性工程方法，您需要达到以下状态：  服务的利益相关方认可此SLO  服务正常状态下可以达到SLO的要求  管理者认可此错误预算并在实际决策中发挥作用  有一个完善的SLO过程制定SLO的第一步是讨论SLO是什么，以及它应该包含哪些内容。SLO为服务客户设定了目标可靠性级别。 超过此阈值，几乎所有用户都应对你的服务感到满意（假设他们对服务的效用感到满意）。低于此阈值，用户可能会开始抱怨或停止使用该服务。最终，用户的快乐才是最重要的 - 快乐的用户使用服务，为您的组织创造收入，减少对您的客户支持团队的抱怨，并向他们的朋友推荐该服务。我们以可靠的服务让客户满意。顾客满意度是一个相当模糊的概念；我们无法精确衡量它。通常我们对它的了解很少，那么该如何开始呢?我们的经验表明，100％的可靠性是错误的目标：  服务即使使用冗余组件、自动健康检查和快速故障转移，也存在一个或多个组件同时失败的场景，服务的可靠性将低于100%。如果制定的SLO是100%，这件事将不可能实现。（运小白说：泰坦尼克号，有“”永不沉没“”的美誉，底仓有16个水密舱， 任何4个水密舱进水的情况下都不会沉没）  即使服务实现了100%的可靠性，但客户也不会体验到100％的可靠性。服务和客户之间的链路长且复杂，链路中的任何一个组件故障都会造成失败败。这也意味着当您的可靠性从99％提高到99.9％到99.99％时，每增加一个9都会增加额外的成本，但客户几乎感受不到。 （运小白说：搜索引擎搜索“运营商故障”即可感受到）  如果服务的可靠性是100%的，并希望保持这种可靠性，那么你永远无法更新或改进服务。最大的故障原因就是变化：推出新功能、应用安全补丁、部署新硬件以及扩大规模以满足客户需求都将影响100％的目标。 最终，服务将停滞不前，你的客户将转移到其他地方。（运小白说：对于节日期间没有促销活动的业务来讲，除去偶尔的硬件故障外，那是难得的平静期）  SLO为100％意味着你只有被动应对。除了对&lt;100％可用性做出反应之外，你实际上无法做任何事情，这是一定会发生的。 100％的可靠性不是工程师要追求的——它应该是运营团队的目标。（运小白说：运维和救火类似，如果消防人员的目标定位不能有任何小火苗，那消防人员估计就会疲于奔命了）一旦SLO目标低于100%，它就需要由组织中的某个人有权在迭代速率和可靠性之间进行权衡。在小型组织中，这可能是CTO；在更大的组织中，通常是产品所有者（或产品经理）。衡量标准:使用SLI一旦你认同100％是错误目标，多少才是正确的？ 在这里，服务质量指标发挥作用：我们引入SLI的概念，SLI是指服务的质量指标。虽然计算SLI有多种方法，我们建议SLI为：好的事件数量除以总事件数量。例如：  成功的HTTP请求数/总HTTP请求数（成功率）  在请求延迟小于100 ms 的成功请求数/总请求数  搜索结果数/搜索结果总数，包括那些正常降级的搜索结果  使用10分钟以上库存数据的产品搜索的“库存检查计数” 请求的数目/库存检查请求的总数  “良好用户分钟数” /“用户分钟数”这种形式的SLI有一些特别有用的属性。 SLI的范围从0％到100％，其中0％表示无效，100％表示无损。 我们发现这个比例是很直观的，这种风格很容易引入错误预算的概念：SLO是一个目标百分比，错误预算是100％减去SLO。 例如，如果您有99.9％的SLO成功率，且在四周内收到的300万个服务的请求，那么在此期间的错误预算为3,000（0.1％）。 如果单个中断导致1,500个错误，则该错误将占错误预算的50％。此外，使所有的SLI遵循一致的风格以便更好地利用工具：你可以编写报警逻辑、SLO分析工具、错误预算计算和报告，以期望得到相同的输入: 分子、分母和阈值。简化是一个额外的好处。在尝试首次制定SLI时，将SLI进一步划分为SLI规范和SLI实现是必要的：SLI规范：你认为对用户重要的服务结果的评估，与其测量方式无关。例如：加载小于100毫秒的主页请求比SLI实现：SLI规范及其测量方法。例如：  加载小于100毫秒的主页请求比，由服务器日志的延迟列进行测量，这种度量方式将遗漏未能到达后端的请求。 （运小白说：遗留有很多个地方都会发生，从用户侧到运营商，从运营商到IDC，从接入层到后端）  加载小于100毫秒的主页请求比，由在虚拟机中运行的浏览器中执行JavaScript的探测器测量。 当请求无法到达我们的网络时，此度量将捕获错误，但可能会遗漏仅影响用户子集的问题。（运小白说：例如部分地域/运营商的网络异常，仅通过该方案就无法发现）  加载小于100毫秒的主页请求比，通过在主页本身上使用JavaScript进行测量，并将其报告给专门的遥测记录服务。这个度量将更准确地捕获用户体验，尽管我们现在需要修改代码来捕获这些信息，并构建基础设施来进行记录 —— 但这是一个具有自身可靠性要求的规范。 （运小白说：俗称埋点，BAT均有使用，对访问速度优化，可用性监控，地址库优化等均能起到较好的效果）如你所见，单个SLI规范可能具有多个SLI实现，每个SLI实现在质量（它们如何准确地捕获用户体验），覆盖范围（它们如何捕获所有用户体验）和成本方面都具有自己的优缺点。您对SLI和SLO的第一次尝试不需要完全正确; 最重要的目标是获得适当的位置并加以测量，并建立反馈机制以便改进。 （我们将在本章的“持续改进SLO目标”中深入探讨这个主题。）在我们的第一本书中，我们建议不要根据当前的性能选择SLO，因为这可能会导致你执行不必要的严格SLO。虽然这个建议是正确的，但是如果你没有任何其他信息，并且有一个好的迭代过程(我们将在后面介绍)，那么你当前的性能是一个很好的起点。但是，当你优化SLO时，不要让当前性能被限制：客户也会期望服务在其SLO上执行，因此如果服务在不到10毫秒的时间内请求成功率为99.999％，任何基于该基线的退化可能让他们不开心。 （运小白说：当前的实际情况是一个参考，而非说目标制定必须以当前值为基础并高于当前值。而且，很多时候，单一目标是能上不能下的，你让用户习惯了这个响应速度，他就无法接受比这个基础值低的服务，这既是门槛也是压力。另外，对单一目标的不断追求，还需要考虑投入产出比。因此这个时候，可以参考下面的建议，从多个维度制定一组SLO。）要创建第一组SLO，您需要确定对您的服务至关重要的几个关键SLI规范。 可用性和延迟SLO非常常见; 新鲜度，耐用性，正确性，质量和覆盖范围SLO也有它们的位置（我们稍后会详细讨论它们）。（运小白说：大牛们对搜索服务的SLO总结为全，新，快，稳，准）如果你不知道从哪类SLI开始学习，那么从简单的开始:  选择一个要定义SLO的应用程序。如果产品包含许多应用程序，则可以在此之后添加这些应用程序。  在这种情况下，明确“用户”是谁。  考虑用户与系统交互的常见方式 - 常见任务和关键活动。  绘制系统的高级架构图; 显示关键组件、请求流、数据流和关键依赖项。将这些组件分组到下一节中列出的类别中(可能存在一些重叠和歧义; 运用你的直觉，不要让完美成为善意的敌人。） 你应该仔细考虑你选择什么作为你的SLI，但你也不应该过分复杂化。 特别是如果您刚刚开始SLI之旅，请选择相关但易于衡量的系统方面 ，以便可以随时进行迭代和优化。组件类型开始设置SLI的最简单方法是将系统抽象为几种常见的组件类型。然后，您可以使用我们为每个组件提供的SLI建议列表，来选择与您服务最相关的SLI:请求驱动用户创建某种类型的事件并期望响应。 例如: 这可以是HTTP服务，其中用户与浏览器或移动应用程序的API交互。管道一种系统，它将记录作为输入，对其进行转变，并将输出放在其他位置。 这可能是一个在单个实例上实时运行的简单过程，也可能是需要花费数小时的多阶段批处理过程。 例子包括：  一种定期从关系数据库中读取数据并将其写入分布式哈希表以优化服务的系统  一种将视频从一种格式转换为另一种格式的视频处理服务  一种从多个源读取日志文件以生成报告的系统  一种从远程服务器提取指标并生成时间序列和报警的监控系统    存储    接收数据(例如字节、记录、文件、视频)并使其在以后可以被检索的系统。  ##案例一个简化过的手机游戏架构，如图2-1所示。在用户手机上运行应用程序与云中运行的HTTP API交互。API将状态更改并写入永久存储系统。一个管道定期运行这些数据，来生成今天、本周和所有时间的高分排行。这些数据被写入一个单独的排行榜数据存储，可以通过移动应用程序和网站获得结果。用户可以通过API和网站将游戏中使用的自定义头像上传到用户数据表。鉴于此设置，我们可以开始考虑用户如何与系统交互，以及采用哪种SLI衡量用户体验。这些SLI中有些可能存在重叠：请求服务具有正确性SLI，管道具有可用性SLI，并且持久性SLI可能被视为正确性SLI的变体。 我们建议选择少数（五个或更少）SLI类型，这些类型代表了客户最关键的功能。。为了捕获典型的用户体验和长尾，我们还建议使用多个等级的SLO。例如，如果90％的用户请求在100毫秒内返回，但剩下的10％用户需要10秒，这部分用户将不满意。 延迟SLO可以通过设置多个阈值来捕获此用户群：90％的请求快于100毫秒，99％的请求快于400毫秒。 这个原则适用于所有的SLI – 这些SLI的参数用来衡量用户的满意程度。表2-1为不同类型的服务提供了一些常用的SLI。                          表2-1 不同类型组件常用的SLI            服务类型      SLI类型      描述                  请求驱动      可用性      成功响应的请求比例。              请求驱动      延迟      比某些阈值快的请求比例。              请求驱动      质量      如果服务在过载或后端不可用时正常降级，则需要测量在未降级状态下提供服务的响应比例。 例如，如果用户数据存储不可用，但使用通用图像游戏仍可玩。              管道      新鲜度      最近更新的数据比例超过某个时间阈值。 理想情况下，此指标会计算用户访问数据的次数，以便最准确地反映用户体验。              管道      正确性      正确输出值的比例。              管道      覆盖范围      对于批处理，处理超过某个目标数据量的作业比例。对于流处理，在某个时间窗口内成功处理的传入记录比例。              存储      耐用性      可以成功读取的记录所占的比例。特别注意持久性SLI:用户想要的数据可能只是存储数据的一小部分。例如，如果你在过去10年里有10亿个记录，但是用户只需要今天的记录(但这些记录不可用)，那么即使他们的数据几乎都是可读的，他们也会不高兴。      从SLI理论到SLI实践第一次SLI实践可以考虑选择一个资源需求相对较少的项目。比如有如下几个项目可供选择：web日志服务器的SLI项目，这个项目我们不需要准备什么；对监控系统进行SLI项目实践，但是这需要几周的时间准备，而JavaScript的项目则会需要几个月的时间。在这种情况下请使用web服务器的日志来作为第一个SLI实践的工程。衡量SLI需要足够指标：可用性指标（成功率和失败率）; 慢请求延迟（请求的响应时间）。 这些指标可能需要你重新对Web服务器进行配置才能获得。 如果是基于云服务的Web，这些指标可以在监控仪表盘中看到。在这个案例中我可选择的SLI指标有很多，每个指标都有自己的优缺点。 以下部分详细介绍三种典型的SLI指标的应用。API和HTTP服务的可用性指标和慢请求延迟指标请求是否成功可以基于HTTP的返回码。5XX就代表请求失败，会降低服务的SLO，其他响应码代表成功。 可用性的SLI是指请求成功率；慢请求延迟的SLI是指在给定请求响应时间阈值下的请求成功率。SLI应该是具体明确并可测量的。总结“衡量标准:使用SLI”中的提供的潜在候选列表，SLI可以使用以下的一个或多个数据来源:  应用服务器日志  负载均衡监控  黑盒监控  客户端插件我们的例子采用负载均衡监控，因为这些指标已经是可用的，并且数据信息比采用“应用服务器日志”更真实反应用户体验的SLI。（运小白说：采用负载均衡的数据，是因为接入层记录的耗时，是一个用户请求在整套系统所有模块处理耗时和所有网络传输耗时的总和，因此更加真实的反应用户的体验，且和客户端插件相比，实施成本相对较低。但该部分耗时，并不包含从用户端到IDC这段的耗时）管道数据延迟率，范围覆盖率和准确率使用管道系统管理一个排行榜时，它会记录一个包含有数据更新的时间戳标签。下面是我们进行SLI实践的例子：  在排行榜上周期性的运行一个进程用于查询有多少次记录被更新和总共有多少个记录。这两个指标同样重要。  在用户请求数据时默认为请求增加一个时间标签，排行榜服务收到客户端请求后会检查这个标签并将请求计数器+1， 如果数据超出了预定义的阈值，则将配置另一个用于记录超时的计数器数字+1。（运小白说：在一个数据流中各个环节或者关键环节中添加时间戳后，可以在监控，性能优化，故障定位等多种场景中使用）以上两个步骤的数据要求都在客户端实现 。这个指标与用户体验密切相关。为了计算我们覆盖率的SLI，我们的管道输出了它应该处理的记录数和它成功处理的记录数。此度量标准可能会遗漏由于管道配置错误而未记录的数据。我们采用如下方法来评估准确率：  将已知的数据作为输入写入系统，计算输出与期望值匹配率。  基于默认管道的输入输出结果作为基准，计算此管道在相同输入下的输出与前者匹配的程度（这个方法可能并不适合所有的管道系统）。我们的案例是为一个需要人工管理的数据库建立指标为准确率的SLI。所有的数据的输入都是合法的，通过管道系统输出结果， 计算输出的准确率。为了使指标能够很好的反应用户体验，我们需要确保人工输入的数据和用户真实数据是一致的。（运小白说：这段看似简单，却是经验的分享。举一个具体的例子来让大家更深刻的理解，以计算服务为例，将已知的数据作为输入写入系统，你可以每分钟输入一个不变的数，然后让系统去计算一定时间的和值，从而度量计算服务的SLI。进阶的话，就是每分钟输入的是变化的数，从而计算和值，均值，最大值，最小值，那变化的数用什么呢，一般就是当前的分钟数）SLI的计算                    图2-2展示的是用白盒监控系从示例程序的各个组件中收集指标的过程。给出一个示例来说明我们是如何使用监控系统中的指标来计算启动器的SLO指标的，以便读者可以更好的理解。虽然我们在案例中只使用了可用性和慢查询延迟指标，但是同样的思路也适用于其他潜在的SLO指标的计算。系统使用度量标准的完整列表，请参阅附录a。我们的案例都使用普罗米修斯监控系统进行数据采集（Prometheus notation）。####负载均衡指标后端的请求返回码为500的数量（“api” or “web”）：http_requests_total{host=”api”, status=”500”}总延迟，作为累积直方图；每个柱状图（bucket）表示计算花费少于或等于该时间的请求数量:http_request_duration_seconds{host="api", le="0.1"}http_request_duration_seconds{host="api", le="0.2"}http_request_duration_seconds{host="api", le="0.4"}一般来说，计算得到慢请求数要比用直方图估计得到的慢请求数更加精准。但是，由于有些信息是拿不到的，所以最终使用监测系统提供的直方图。另一种方法是根据负载均衡配置中的各种慢请求阈值(例如，阈值为100毫秒和500毫秒)来计算慢请求数量。这种方式需要对监控的配置进行修改，所以会更复杂但是会更准确。http_request_duration_seconds{host="api", le="0.1"}http_request_duration_seconds{host="api", le="0.5"}计算SLI使用前面的指标，我们可以计算前七天的当前SLI，如表2-2所示。                                            表2-2   过去七天的SLI计算            指标      计算方式                  可靠性      sum(rate(http_requests_total{host=”api”, status!~”5..”}[7d]))  /  sum(rate(http_requests_total{host=”api”}[7d])              延迟      histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[7d]))  histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[7d]))      利用SLI计算初始 SLO我们可以将这些SLI划分为可管理的数字（例如，两个重要的可用性数据，或最多50 ms的延迟）来获得我们的起始SLO。例如，超过四周，API指标显示：  总请求数：3663253  总成功请求数:3,557,865 (97.123%)  90%的延迟: &lt; 432 ms      99%的延迟: &lt; 891 ms我们为其他SLI重复此过程，并为API创建一个SLO，如表2-3所示。                              表2-3  API的建 SLO                    SLO类型      目标                  可靠性      97%              延迟      90%的请求 &lt; 450ms              延迟      99%的请求 &lt; 900ms      附录A提供了SLO文档的完整示例。 本文档包含SLI实现，为简洁起见，我们在此省略。根据所提出的SLI，我们可以计算这四周的错误预算，如表2-4所示。                            表2-4    过去四周错误预算            SLO      允许失败数                  97%的可用性      09,897              90％的请求快于450ms      366,325              99％的请求快于900ms      36,632      选择合适的时间窗口可以在不同的时间间隔上定义SLO，并且可以使用滚动窗口或周期对齐窗口（例如，一个月）。选择时间窗口时需要考虑几个因素。滚动窗口与用户体验更紧密地联系在一起：如果你在一个月的最后一天发生大量中断，则你的用户在下个月的第一天不会突然忘记它。 我们建议将这段时间定义为整数周，以便它始终包含相同数量的周末。 例如，如果你使用30天的窗口，则某些时段可能包括四个周末，而其他时段包括五个周末。 如果周末流量与工作日流量明显不同，你的SLI可能会因为无趣的原因而有所不同。周期窗口与业务规划和项目工作更紧密地结合在一起。例如，你可以每个季度评估SLO，以确定下一个季度项目人员的重点工作。周期窗口还引入了一些不确定性因素:在季度中期，你不可能知道在本季度余下的时间里会收到多少请求。因此，在季度中期做出的决定必须推测系统将在本季度剩余时间内花费多少错误预算。更短的时间窗口可以让你更快地做出决策：如果你错过了前一周的SLO，那么小的更正 - 例如优先考虑相关错误 - 可以帮助避免未来几周的SLO违规。对于更具战略性的决策，更长的时间周期更好：例如，如果你只能选择三个大型项目中的一个，那么你最好转移到高可用性分布式数据库，自动执行部署和回滚过程，或者在另一个部署重复堆栈区。你需要超过一周的数据来评估大型多季度项目; 所需的数据量与建议修复它的工程量大致相当。我们发现为期四周的滚动窗口是一个很好的通用间隔。我们每周任务优先级总结和每季度的项目规划总结报告刚好补充这一时间段。如果数据源允许，则可以使用这个建议的SLO来计算在此期间的实际SLO性能：如果根据实际测量设置初始SLO，则按此设计。但我们也可以收集关于分布的有趣信息。在过去的四个星期内，有哪天我们的服务没有达到标准? 这些天与实际事件有关联吗? 在那些日子里，有没有(或者应该)采取一些行动来应对这些事件?如果没有日志、度量或任何其他历史性能来源，则需要配置数据源。例如，作为HTTP服务的基本解决方案，你可以设置远程监视服务，对HTTP服务定期的执行某种健康检查（ping或HTTP GET），并报告请求成功的数量。许多在线服务可以轻松实现这一解决方案。获得所有利益相关者同意为了使提议的SLO有用和有效，你需要让所有利益相关者同意它：  产品经理必须同意这个阈值 ——低于这个值的性能无法令人接受，需要花费时间来修复。  产品开发人员需要同意，如果错误预算已用尽，他们将采取一些措施来降低用户的风险，直到服务重新回到错误预算中（如第31页的“建立错误预算策略”中所述）。  负责维护这个SLO生产环境的团队已经同意并一致认为，不需要付出巨大的努力、过度的辛劳——这对团队和服务都是不利的。 一旦所有这些观点都达成一致，最难的部分就完成了。你已经开始了SLO之旅，剩下的步骤需要从这个起点迭代。你需要设置监控和报警来监控SLO，（请参阅第5章），以便工程师发现问题。建立错误预算策略获得SLO后，你可以使用SLO来获取错误预算。 要使用此错误预算，你需要一个策略，描述当你的服务超出预算时要执行的操作。获得所有关键的利益相关者(产品经理、开发团队和SRE)批准的错误预算策略，是对SLO是否适合目的良好测试:  如果SRE认为需要付出更多的工作才能保证SLO，那么他们可以提出放宽SLO的要求。  如果开发团队和产品经理认为，他们必须投入更多的资源来修复系统，这将导致特性发布速度低于可接受的水平，那么他们也可以争取放宽目标值。记住，降低SLO也会降低SRE响应的情况数量；产品经理需要对此做权衡。  如果产品经理认为，在错误预算策略提示任何人解决某个问题之前，SLO将给大量用户带来糟糕的体验，那么SLO可能不够紧凑。  如果所有三方都不同意执行错误预算策略，那么你需要迭代SLI和SLO，直到所有利益相关者都满意为止。决定如何前进，以及做出决定需要什么：更多的数据？更多的资源？还是对SLI或者SLO进行修改？当我们讨论强制执行错误预算时，我们的意思是一旦你耗尽了错误预算(或者接近于耗尽它)，你应该采取措施来恢复系统的稳定性要制定错误预算执行决策，你需要从书面策略开始。 此策略应涵盖服务在给定时间段内消耗全部的错误预算时必须采取的具体操作，并指定谁将采取这些操作。 共同所有者和行动包括：  开发团队将过去四周内与可靠性问题相关的bug放在了首位。  开发团队专注于可靠性问题，直到系统处于SLO范围内。 功能迭代可以推迟。  为了降低更多停机导致的风险，冻结生产系统的变更，直到有足够的错误预算来恢复变更。有时候，服务会消耗掉整个错误预算，但并不是所有利益相关者都同意制定错误预算策略是合适的。如果发生这种情况，你需要返回到错误预算策略审批阶段。记录SLO和错误预算策略一个SLO应记录在一个突出的位置，其他团队和利益相关者可以审查它。该文件应包括以下信息：  SLO的作者，审核人（检查技术准确性）和审批人（谁做出了关于它是否是正确的SLO的商业决策）。  批准的日期，以及下次审核的日期。  为读者了解相关背景的简要说明。  SLO的细节：目标和SLI实现。  关于如何计算和使用错误预算的详细信息。  这些数字背后的基本原理，以及它们是否来自实验或观察数据。 即使SLO完全是临时的，也应记录这一事实，以便未来阅读文档的工程师不会根据临时数据做出错误的决定。 你查看SLO文档的频率取决于SLO文化的成熟度。 在开始时，你应该经常审查SLO （例如每个月）。 一旦SLO变得更加符合实际，你可以降低评审频率为每季度或更低。制定错误预算策略，还应包括以下信息：  策略的制定人、审核人和审批人  批准的日期，以及下次审核的日期  编写说明文档  应对错误预算耗尽时采取的行动  如果在某种情况下商定的策略发生分歧，则将问题升级  让有经验的工程师对错误预算进行审核有关SLO文档和错误预算策略的示例，请参阅附录A。仪表盘和报表除了已发布的SLO和错误预算，及说明文档之外，还应有一个报表和仪表盘进行展示。（运小白说：通过仪表盘/大屏以及背后的存储系统，记录，展示和分析长期的SLO，从而才能帮助团队更好的发展，减少犯同样的错误）图2-3中的报表显示了几种服务的总体合规性：它们是否满足前一年的所有季度的SLO（括号中的数字表示满足的目标数量，以及目标总数），以及他们的SLI相对于上一季度和去年同一季度是否呈上升趋势或下降趋势。使用仪表盘来显示SLI的趋势也是很有用的。 这些仪表盘显示你是否以高于平常的速率消费预算，或者是否存在需要特别关注趋势。图2-4中的仪表盘显示了一个季度的错误预算，在该季度的中间部分，我们看到单个事件在两天内消耗了大约15%的错误预算。错误预算对于量化这些事件很有用——例如，“这次宕机消耗了我季度错误预算的30%”，或者“这是本季度排名前三的事件，根据它们消耗了多少错误预算来排序”。##持续改进SLO目标每项服务都可以从持续改进中受益。 这是ITIL的核心服务目标之一。 例如： 在你提高SLO目标之前，你需要拥有用户对服务满意度的信息来源。 有很多选择：  人工发现的服务不可用次数、公共论坛上的帖子、故障单和投诉电话  社交媒体上的用户反馈  用插件定期对用户的满意度进行采样  调查问卷进行用户调查和采样最佳的方法取决于你的服务，我们建议从成本较低的渠道开始。让你的产品经理把可靠性纳入到他们与客户关于定价和功能的讨论中，这会是一个很好的开始。提高SLO质量记录人工检测到的服务不可用次数， 其他相关网站支持票数也可以计算在内，检查这些数据是否与错误预算的变化趋势相关。 同时检查这短时间内SLI和SLO的变化趋势。如果你擅长统计分析，Spearman相关系数是量化这种关系的有效方法。图2-5显示了每天增加的支持票的数量与当天错误预算的关系。虽然不是所有的支持票都与可靠性问题相关，但支持票与错误预算之间是存在相关性。我们看到两个异常值：一天只有5张票，损失了10%的错误预算；一天有40张票，没有损失任何错误预算。这两个异常值都需要进一步追查。如果支持票未在SLI或SLO中体现，或者用户关注的问题并没有在指标中体现，说明指标覆盖率存在问题。 这种情况完全正常，符合预期。 你的SLI和SLO应随着时间的推移而发生变化，因为服务的实际情况会发生变化， 不要畏惧对它们进行改进！如果你的SLO或SLI覆盖率不高，你可以采取多种方案：修正SLO如果你的SLI显示现在出问题了，但是你的SLO没有异常，你可能需要更加严格的SLO。  如果该时间段内发生的问题比较严重，通过SLI计算SLO应该出现异常的时间段。调整SLO之后，把这个新的SLO应用到SLI的历史数据上，看看这个调整会发现什么问题。如果发现严格的SLO会不断地对不重要的事件作出响应，那么这个修正毫无意义。  同样地，对于SLO误报的情况，考虑放宽SLO。如果在任一方向上修正SLO会导致误报或漏报，那么你还需要修正SLI实现。修正SLI实现有两种方法可以修正SLI实现: 要么将采集点更靠近用户以提高度量精准度；要么提高覆盖率，从而获得更高的用户交互比例。例如:  在负载均衡或客户端上测量成功率/延迟，而不是在服务器上测量。  更多的功能检测任务，或者在所有客户端通过JavaScript探测，而不仅仅是使用简单的HTTP GET请求来衡量可用性。制定一个高标准的SLO有时你需要更严格的SLO才能让用户满意，但改进产品以满足SLO需要一些时间。 如果你实施更严格的SLO，你将永久地脱离SLO并受到错误预算政策的约束。 在这种情况下，你可以将高标准的SLO作为期望值，与当前SLO一起进行追踪和对比。 通过这种方式，你可以掌握与高标准SLO之间的差距，却不会一直处于高压状态。迭代有许多不同的迭代方法，评审会议可以帮你找到许多潜在改进点。选择成本最低的方法，特别是在最初的几次迭代中，错误常常出现在贪图更快，更便宜方面;  这样做可以减少指标的不确定性，并帮助你确定是否需要更昂贵的指标。 根据需要进行多次迭代。使用SLO和错误预算进行决策一旦你制定了SLO，你就可以使用它们进行决策。当你没有达到SLO，也就是说已经用尽了错误预算，这时面对的首要问题是要做什么？如前所述，错误预算策略会告诉你应该做什么。 常见策略包括降级，直到服务再次处于SLO中；或者花费时间去处理问题以提高服务的可靠性。在特殊情况下，团队可以对外宣布处于紧急状态，取消所有外部需求，直到服务满足退出条件 （退出条件通常指服务处于SLO中，并且短时间内SLO不会出现问题）。我们可以使用改进监控，改进测试，消除系统的依赖关系，或重新调整架构以排除已知的故障类型等方法。你可以根据消耗错误预算的比例来确定事件的规模，并使用这些数据来识别最关键的故障，这些故障需要更深入的追查。例如，假设新版本API的发布导致100％  NullPointerExceptions，系统直到四小时后才可以恢复。检查服务的原始日志表明该问题导致了14,066个错误。 使用制定的97%的SLO和109,897个错误预算的标准来计算，这个故障使用了13%的错误预算。或者，数据库出现问题，而从备份数据恢复需要20小时。基于历史流量估算中断导致了72,000个错误，占错误预算的65%。想象一下，假设五年内只有一次服务器故障导致数据库异常，但通常每年会有两到三个版本被回退。 可以估计发布新版本导致的错误预算是数据库故障的两倍。 这些数字表明，投入资源来解决版本问题比调查服务器故障更有益处。如果服务运行完美且几乎不需要任何监督，并且做到了服务的故障管理和高级别的监督，那么你可以减少对此服务的SLO实施。因此，你可以将精力集中在其他需要更多SRE支持的系统上。表2-5  提供了基于三个关键维度决策矩阵:  SLO指标  维护服务所需要的工作量      客户对服务的满意程度                                             表2-5   SLO决策矩阵      SLO进阶一旦你拥有成熟的SLO和错误预算的氛围，下一步要做的就是继续改进和完善如何度量服务的可靠性。模拟用户SLO最终应该以改善用户体验为中心。 因此，你应该以用户为中心制定SLO。你可以仿照用户典型流程来评估用户的体验 （典型流程是指一系列任务的集合，包括了用户体验核心部分，也是服务的重要方面）。 例如，对于在线购物体验，用户典型流程包括：（运小白说：大牛总结的电商典型流程是首页-搜索-商详-购物车-下单-支付）  搜索产品  添加购物车  完成购买这些肯定不能很好地映射到现有的SLI；每个任务都需要多个复杂的步骤，这些步骤可能在任何时候都会失败，并且从日志中推断这些操作的成功（或失败）非常困难。 （例如，如何确定用户在第三步失败了？可能他们只是被分散了注意力）。然而，你需要定位到故障发生的原因是什么，因为这是服务可靠性的一部分。一旦确定了用户最关心的问题，就可以通过监测典型流程来解决上述问题。 你可以通过将不同的日志事件连接在一起，使用高级JavaScript探测，使用客户端检测或使用其他一些过程来度量它们。 一旦你可以定位一个问题，它就变成了另一个SLI。你可以和现有的SLI和SLO一起追踪。 用户关键流程可以在不影响精度的情况下提高你的召回。###分级的重要性并不是所有的请求都是平等的。虽然来自app的HTTP请求——检查帐户通知(其中通知是由每日的管道生成的)对用户很重要，但广告客户与账单相关的请求更重要。我们需要一种方法来对请求进行分类，可以使用“bucketing”来完成此操作 - 也就是说，为SLI添加更多标签，然后对不通的标签制定不同的SLO指标。 表2-6显示了一个示例。                              表2-6  分级分配SLO你还可以按照响应对请求进行分类，如表2-7所示。                              表2-7    按照响应进行分类如果你可以为每个用户制定SLO，那么你就可以在任何时间内得到处于SLO合理范围内的用户数量。请注意，这个数字是有大量噪音——请求数量非常少的客户要么拥有100%的可用性（因为他们足够幸运地没有遇到故障）要么拥有非常低的可用性（因为他们经历的一个失败会是相当大的百分比，因为请求基数少 )。单个客户可能会因为一些低级的原因而无法满足他们的SLO。但是总的来说，跟踪这个指标是非常有用的。（运小白说：关于分级，我记忆中最深刻的是以前一个同事的总结，30%的资源，支持了10%的流量，提供了5%的收入，因此这类资源必须要优化）依赖关系建模大型系统有许多组件。单个系统可能有表示层、应用层、业务逻辑层和数据持久层。每一层都可能包含许多服务或微服务。虽然你最关心的是系统的SLO实现，但SLO也可以作为提高系统各组件间可靠度的有用方法。例如，系统某个组件被过度依赖，那么它的可靠性保障应尽可能放到最高级。相应组件的团队也应有SLO。如果某些组件可靠性存在客观限制，则SLO应该可以将该限制表现出来。如果这个组件不能满足系统的可靠性要求，要么改进它，要么使用其他组件代替他或进行主动防御（比如：添加缓存，预存储和计算，优雅降级等）。你也可以尝试用数学方法解决这些问题。例如：如果在单个区域内有一个可用性为99.90%的服务，但你需要99.95%的可用性，则在两个区域中部署该服务就可以解决这个需求。两个服务同时发生故障的概率非常低，此时服务的可用性为99.9999%。然而，这种情况的假设前提是两区域服务完全独立，但这几乎不可能。应用程序的两个实例将具有共同的依赖和故障模式，无论如何精心设计和管理，都可能会导致两个服务同时异常。除非将这些依赖项和故障模式都被枚举出来，否则任何此类计算都具有欺骗性。当故障是由其他团队负责的组件引起的，以下两种思路可以用于解决SLO的问题：  你的团队还应该继续开展发布新版本，不要把过多时间用于可靠性相关工作，因为不是你系统引起的问题  你应该制定故障隔离策略，以便最大程度地降低未来可能由此组件引起的服务故障的可能性，无论此组件故障的原因是什么第二种方法将使你的用户更快乐。你可以灵活地运用这个原则。根据停机和依赖关系的性质，冻结更改可能不实际。确定最适合你服务及其依赖项的决定，并将此决定记录在你的错误预算策略中。有关如何在实践中工作的示例，请参阅附录B中的错误预算策略示例。（运小白说：这个问题非常典型，大家都可能会碰到，我使用你的服务，你应该保障你服务承诺的可用性，而不应该是我来解决这个问题；本文给出了另外的一种思路，添加缓存，预存储和计算，优雅降级，多活，多机房部署等来保障自身服务的稳定性，因此下次遇到这类问题，希望大家可以尝试一下这些方式。另外，高内聚低耦合固然重要，但是也不要太过极端，觉得别人的东西都不靠谱，只有全部自己做才放心，很多时候，把一些依赖的服务放到手里独立部署，你觉得稳定性提升很多，其实，那只是集群拆分压力减小后的一种表象，平时很少出问题，因此你也会放松警惕，另外，加之业务众多，每个业务投入的精力也较为有限，一旦出现问题，通常难以应对）放宽SLO，进行试验如果你想对服务进行可靠性的相关试验以便了解指标（例如，增加页面加载时间的延迟）的变化对用户体验的影响程度(例如，完成购买的用户百分比)。我们建议，只有当你确信自己有足够的错误预算时，才进行这类操作和分析。由于延迟、可用性、客户、业务领域和竞争(或缺乏竞争)这些因素之间有许多微妙的相互作用。故意影响顾客体验的决策需要深思熟虑。虽然这种方法的影响听起来十分可怕，因为没有人想失去用户。但通过这种方法，你可以将得到的结论用于服务的改进，从而在未来让服务拥有更好的性能，从而获得更多的用户。这种方法还可以让你在统计学上获得关键业务度量(例如，销售额)和可靠性指标(例如，延迟)之间的关系。如果是这样，你就获得了非常有价值的数据，这些数据可以帮助你做成做出重大决策。这个尝试不应该是一次性的。随着你的服务的发展，你的客户的期望也会随之改变，确保它们之间的关系是实时有效的。这种尝试获得的关系也可能存在风险，因为你可能会误解你得到的数据。例如，如果你人为地将页面加载时间增加了50毫秒的延迟，但是并没有发现相应的损失，那么你可能会得出这样的结论: 延迟的SLO太严格了。然而，你的用户可能是不满意，只是缺乏可替代的产品，用户别无选择。一旦出现竞争对手，你的用户就会流失。一定要保数据的正确性，并采取适当的预防措施。结论本书的每个案例都有SLO理论的影子。既然你已经阅读了这一章，我们希望能够意识到，即使是形式化的SLO(它清楚地向用户传达了你的承诺)也提供了一个清晰的框架来分析你系统表现。在服务未能满足期望时，你还可以用此SLO确定可采取的补救措施。总结：  SLO是衡量服务可靠性的工具  错误预算是一种工具，它可以帮助你平衡可靠性和其他日常工作的精力，同时也是判定工作优先级的好方法  你应该立即使用SLO和错误预算有关SLO文档和错误预算策略的示例，请参阅附录 A和B。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第一章 SRE与DevOps之间的联系]]></title>
      <url>/sre/2020/01/01/SRE%E4%B8%8EDevops%E4%B9%8B%E9%97%B4%E7%9A%84%E8%81%94%E7%B3%BB/</url>
      <content type="text"><![CDATA[  《The Site Reliability Workbook — Practical Ways to Implement SRE》 中文版运维是一门很难的学科。 不但没有解决如何很好地运行系统，即便那些已经在使用的最佳实践也是高度依赖环境且未被广泛采纳的。 并且最重要的，没有解决如何良好地管理运维团队这一问题。人们普遍认为，对这些问题的详细分析源于二战期间致力于改善盟军军事进程和产出的作战研究，但事实上，长期以来我们一直都在思考如何更好地实践。尽管有这么多的努力和想法，可靠的生产运维仍然是难以保障的,特别是在信息技术和软件可操作性领域， 例如: 企业通常将运维视为成本中心， 这使得对结果进行有意义的改进变得困难甚至不可能。 这种短视的方法还没有被广泛理解， 但对它的不满却已经引发了IT领域对如何组织工作方面的一场革命。这场革命源于试图解决一系列普遍问题， 并诞生了两个不同的解决方案: DevOps 和 SRE(Site Reli‐ability Engineering)。 尽管单从描述上看，他们是企业完全不同的两个方面，需要单独讨论，但事实上，它们的相似之处，要远比我们想象的多。但首先，我们需要来了解一下每种原则的背景。DevOps产生的背景DevOps是一套松散的实践，指南和文化，旨在打破IT开发，运维，网络和安全方面的孤立。 是由John Willis，Damon Edwards和Jez Humble提出，使用CA(L)MS表示：文化（Culture），自动化（Automation），精益（Lean， 如精益管理;也包含持续交付），测量（Measurement,）和分享（Sharing） – 这是一个记住DevOps哲学要点很有用的缩写。 而分享和合作是这一运动的重中之重。 在DevOps方法中，您可以改进某些内容（通常通过自动化实现）、测量结果，并与同事分享这些结果，以便整个组织得到改进。 所有CALMS原则都是由支持文化促进的。DevOps，Agile以及各种其他业务和软件工程技术，都是关于如何在现代世界中进行最佳实践的示例。DevOps哲学中的任何元素彼此都不能轻易分离，这是由基本设计来决定的。 但是，有一些关键的想法可以相对分开地讨论。不再孤岛关键一：不再孤岛 。有以下两种观点：  曾经流行将运维和开发团队独立分开，但现在却越来越过时。  在许多情况下，极端的知识孤岛化、纯粹的对内部优化的激励以及缺乏协作对商业是十分不利的。事故是正常的关键二：事故不仅仅是由个人的孤立行动造成的，更是当问题不可避免地发生时，缺乏防范措施的结果。例如，一个糟糕的接口在不经意间助长了压力下的错误行为；如果出现（未知的）错误，系统缺陷将不可避免地导致失败；监控失效使得人们不可能知道是否出了问题，更不用说出了什么问题。一些传统观念更强的企业，拥有开除犯错者并惩罚他们的文化。但这样做有其自身的恶果： 他会诱使人们混淆问题、掩盖真相和指责他人， 而所有这些最终没有任何价值，专注于恢复服务比阻止事故发生要更有价值。变更应该是循序渐进的第三个关键点是， 小而频繁的变更是最佳的。 一个比较激进的示例，是变更委员会每月开会讨论彻底修改大型机配置的计划，然而这种做法并不鲜见，所有变更必须由经验丰富的人员进行有效的规划，结果或多或少与最佳实践相悖。变更是有风险的，没错，但是正确的做法是将变更尽可能拆分成更小的组件或单元。然后，根据产品、设计和基础架构的变更，构建稳定的低风险变更管道。（Then you build a steady pipeline of low-risk change out of regular output from product, design, and infrastructure changes）这种策略，增加对小变更的自动化测试和异常变更的可靠回滚，就形成了管理变更的方法：持续集成(CI)和持续交付或部署(CD)。工具和文化是相互关联的工具是DevOps的一个重要组成部分，特别是强调正确管理变更的今天，变更管理依赖于高度定制化的工具。 但总的来说，DevOps的支持者十分强调组织文化 - 而不是工具 - 这是成功采用新工作方式的关键。 一个好的文化可以解决破碎的工具，但相反的情况很少适用。 俗话说， 文化能把战略当早餐吃(意味着文化的影响力远胜过策略)。 与运维一样，变更本身也很难。度量是至关重要的最后，度量在整个业务环境中尤为重要，例如，打破孤立和故障处理。 在上述的每种场景中，你可以通过客观的度量来确定正在发生事情的真实性，验证改变是否符合预期，并为不同职能部门达成一致的对话创建客观基础。 （这适用于商业和其他环境，例如On-call。）##SRE产生的背景SRE是由Google的工程副总裁Ben Treynor Sloss提出的术语（和相关的工作角色）。正如我们在上一节中所看到的，DevOps是运维和产品开发之间在整个生命周期互相协作的一系列广泛原则。SRE是一个工作角色，也是我们发现的一组实践（稍后介绍），以及一些激励这些实践的信念。如果您将DevOps看作一种哲学和工作方法，则可以认为SRE实现了DevOps描述的一些哲学，并且比“DevOps工程师”更接近于这个工作或角色的具体定义。因此，在某种程度上，SRE类实现了DevOps接口。与DevOps运动不同，DevOps运动起源于多家公司的领导者和从业者之间的合作，而SRE在整个行业广泛普及之前，则是由Google的SRE继承周围公司的大部分文化。 考虑到这一轨迹，整个SRE学科目前并没有像DevOps那样在文化上突然增长。 （当然，这并不能说明文化变革对在任意组织中进行SRE是否是必要的）SRE由以下具体原则定义。运维是一个软件问题SRE的基本原则是：做好运维是一个软件问题。 因此，SRE应使用软件工程来解决这一问题。 这涉及广泛的领域，涵盖了从流程和业务变更到同样复杂但更传统的软件问题的所有内容，例如重写堆栈以消除业务逻辑中的单点故障。通过SLOs进行管理SRE不会尝试提供100％的可用性。 正如我们的第一本书 《Site Reliability Engineering》中所讨论的，这是错误的目标， 原因有很多。 相反，产品团队和SRE团队为服务及其用户群选择适当的可用性目标，并管理服务达到该目标，选定这样的目标需要业务部门的强大协作。 SLOs也具有文化内涵：作为利益相关者之间的协作决策，SLO违规行为将团队无可厚非地带回到原点。###减少琐事对于SRE来说，任何手动的， 重复性的的运维任务都是令人憎恶的。 （这并不意味着我们没有任何此类任务：我们有很多这样的操作。我们只是不喜欢它们。）我们相信，如果机器可以执行所需的操作，那么通常应该让机器来执行。 这是一种区别(也是一种价值)，在其他组织中并不常见。在那里，琐事就是工作，而这就是你付钱让一个人去做的事情。而对于在谷歌环境下的SRE来说，琐事不是工作——它不可能是。任何在操作任务上花费的时间都意味着无法再投入到项目工作上——项目工作才能使我们的服务可靠和可扩展。然而，通过“the wisdom of production”，执行运维任务确实为决策提供了重要的参考。这项工作通过提供来自给定系统的实时反馈信息来保持稳定。（This work keeps us grounded by providing real-time feedback from a given system.）琐事的来源需要明确，这样可以最小化或消除它们。然而，如果你发现自己处于操作不足的状态，那么你可能需要更频繁地推动新特性和更改，以便工程师依旧熟悉你所支持的服务的工作方式。                                         The Wisdom of Production A note on “the wisdom of production”: by this phrase, we mean the wisdom you get from something running in production—the messy details of how it actually behaves, and how software should actually be designed, rather than a whiteboarded view of a service isolated from the facts on the ground. All of the pages you get, the tickets the team gets, and so on, are a direct connection with reality that should inform better system design and behavior.把今年的工作自动化在这个领域真正要做是，确定哪些工作基于什么样的条件，以什么样的方式要完成自动化。（The real work in this area is determining what to automate, under what conditions, and how to automate it.）在Google，经验丰富的SRE严格限制团队成员花费在琐事上的时间，与之相反的是他们会在产生持续价值的工程类工作中花费50%的时间。许多人认为这个限制是一个上限。 事实上，将它视为一种保证更为有用，一种明确的声明和启用机制，采用基于工程的方法来解决问题，而不是一遍又一遍地辛劳的解决问题。当我们考虑自动化和琐事时，基线和其如何发挥作用并不直观。（There is an unintuitive and interesting interaction between this benchmark and how it plays out when we think about automation and toil.） 随着时间的推移，一个SRE团队最终会将服务的大部分操作自动化，只留下无法自动化的（Murphy-Beyer效应）。 在其他条件相同的情况下，除非采取其他行动，否则SRE团队所做的事情就会受到影响。 在google你更倾向于通过不断新增服务来达到填满50%的工程设计时间的限制，或者你在自动化方向做的非常成功，以至于你可以去做一些完全不同的事情。通过降低故障成本来快速行动日益提高的可靠性只是SRE带来的众多收益中的一种，事实的确如此，它实际上提高了开发的产出。为什么呢？对于常见故障，减少故障平均修复时间（ Mean Time To Repair）会提高产品开发人员的速度，因为工程师不必在这些故障问题之后耗费时间和精力进行处理。这源于一个众所周知的事实，在一个产品的生命周期里，问题发现的越晚，修复它所付出的代价越高。SREs专门负责改善异常问题的过晚发现，为公司整体带来收益。与开发分享权限“应用程序开发”和“生产”（有时被称为Dev和Ops）之间的严格界限会适得其反。 如果项目事务处的职责划分和作为成本中心的分类，导致权力不平衡、尊重或薪酬方面的差异，则尤其如此。SREs往往倾向于关注生产而不是业务逻辑问题，但随着问题被他们用软件工程工具所解决，他们与产品开发团队分享技术栈。 通常，SREs在他们正在关注的服务的可用性，延迟，性能，效率，变更管理，监控，应急响应和容量规划方面具有特殊的专业知识。 那些特定的（通常定义明确的）能力是SRE对产品和产品的开发团队所做的贡献。理想情况下，产品开发和SRE团队应该对技术栈有一个整体的看法 - 前端，后端，库，存储，内核和物理机器 - 没有团队应该令人嫉妒的拥有着单个组件。事实证明，如果你“模糊线条”并使用SREs共苦JavaScript，或者产品开发人员对内核进行限定，你可以做得更多：知识如何进行更改，权限更加广泛，而激励小心翼翼地保护任何特定的功能这一想法都应摒弃。在《Site Reliability Engineering》这本书里,，我们没有明确表明Google中的产品开发团队默认拥有自己的服务。 SRE既不可用也不保证大部分服务，尽管如此，SRE原则仍然可以告知整个Google如何管理服务。 SRE团队与产品开发团队合作时的所有权模式最终也是一个共享模型。使用相同的工具，无论功能或职位工具是一个非常重要的行为决定因素，  在Google的环境中，SRE如果没有统一的代码库、软件和系统的各种工具、高度优化和专有的生产堆栈等是非常天真的。我们与DevOps分享这个绝对的假设：团队服务应该使用相同的工具，无论他们在组织中的角色如何。 没有好的方法来管理一个服务，当该服务具有一个用于SRE的工具，一个用于产品开发人员的工具，在不同情况下表现不同（并且可能具有灾难性）。 当拥有的分歧越多，公司从改进每个工具努力中的获益就越少。比较和对比从上面聊到的原则中，我们可以立即看到他们之间有很多共性：  DevOps和SRE都接受一种理念，即为了改进，变更是必要的（都接受对于提高而言，变更是必要的）。否则，就没有多少可操作的空间。  协作是DevOps工作的前沿和中心。 有效的分享所有权模式和合作伙伴关系是SRE发挥作用所必需的。 与DevOps一样， SRE也具有跨组织分享的强大价值，这样更容易打破团队之间的孤立。  变更的最佳实践是: 持续小而频繁的变更，大多数操作理想情况下应该是：自动化测试和部署。变更和可靠性之间的关键交互使得这对于SRE尤为重要。  正确的工具至关重要，工具在一定程度上决定了你的行为范围。然而，我们决不能过于关注是否使用某些特定工具实现某种操作；归根结底，面向系统管理的API是更为重要的哲学，它将比任何特定的实现都持久。  度量绝对是DevOps和SRE如何工作的关键。对于SRE, SLOs (服务质量目标) 决定着是否改善和优化服务。当然，如果没有度量( 以及在产品、基础设施/SRE和业务之间的跨团队合作)，就不可能有SLOs。对于DevOps，度量行为通常用于理解流程的输出是什么，反馈周期的持续时间是什么，等等。DevOps和SRE都是面向数据的东西， 无论是从专业角度还是从哲学角度。  管理生产服务的残酷现实意味着故障时有发生，您必须说明原因。SRE和DevOps都进行了无可厚非的故障复盘，以抵消争议。  最终，实施DevOps或SRE是一种整体行为; 两者都希望通过高度特定的方式共同合作，使整个团队（或单位或组织）更好。 对于DevOps和SRE，更好的速度就是产出。如你所见，DevOps和SRE之间有许多的共同点。然而，也存在着显著的差异。DevOps在某种意义上是一个更广泛的哲学和文化。因为它影响的变化范围比SRE更广，所以DevOps对上下文更敏感。 DevOps对于如何在一个具体层面上执行操作没有更详细的说明。例如，它不是关于服务的精确管理的规定。相反，它选择专注于在更广泛的组织中打破壁垒。这就很有价值。另一方面，SRE的职责定义相对狭窄，其职权范围通常是面向服务（面向最终用户）而非整体业务。 因此，它为如何有效运行系统的问题带来了自以为是的知识框架（包括错误预算等概念）。 虽然作为一个职业，SRE非常清楚激励措施及其影响，但它反过来却对孤立化和信息壁垒等主题保持沉默。 它将支持CI和CD，不一定是因为业务需要，而是因为所涉及的操作实践得到了改进。 或者，换句话说，SRE相信和DevOps一样的东西，但原因略有不同。组织环境与成功采纳的培养DevOps和SRE在其运行方式上存在非常大的概念重叠。 正如您所料，他们也有一组类似的条件必须在组织内成立，以便他们  a)首先可以实现，并且  b)从该实现中获得最大的好处。 正如托尔斯泰几乎从未说过的：有效的操作方法都是相似的，而失败的方法都有各自的失败之处。 激励机制可以部分解释这一点。如果组织的文化重视DevOps方法的好处并且愿意承担这些成本 - 通常表现为招聘困难，维持团队和责任，流动性所需的能量，以及用于补偿必要技能所增加的财务资源，这更为罕见 。然后该组织还必须确保激励措施是正确的，以实现这种方法的全部好处。具体而言，以下内容应在DevOps和SRE的环境中都应成立。教条，刚性的激励措施限制了你的成功许多公司无意中定义了破坏集体绩效的激励措施。为了避免这种错误，不要将激励机制局限于与发布相关或可靠性相关的结果。正如任何一位经济学家都能告诉你的那样，如果有一个数字衡量标准，人们总会找到一种方法，让它产生不好的效果，有时甚至是以一种完全出于善意的方式。相反，你应该允许其他人自由地找到正确的选择。正如前面所讨论的，DevOps或SRE通常可以作为产品团队的催化剂，允许其他软件组织以连续可靠的方式向客户提供功能。这种动态机制还解决了传统和分散的系统/软件组方法的一个持久性问题：设计和生产之间缺乏循环反馈。具有早期SRE参与的系统（理想情况下，在设计时）通常在部署后的生产中工作得更好，而不用管是谁负责管理服务。 （没有什么比丢失用户数据更能阻碍功能开发的进展。）最好自己解决这个问题; 不要责怪别人此外，要避免把生产事故或系统故障的责任推给其他组。在许多方面，推卸责任的动力是传统工程操作模型的核心问题，因为运维和软件团队允许出现单独的激励机制。不管怎样，考虑采用以下做法来反驳组织层面的指责:不仅仅只是允许，而是积极鼓励工程师在产品需要时改变代码和配置。还应允许这些团队在其任务范围内采取激进行动，从而消除采取缓慢行动的想法。支持事后总结。这样做排除了淡化或掩盖问题的动机。这一步骤对于充分理解产品并实际优化其性能和功能至关重要，并且依赖于前面提到的生产经验。允许对“运行困难并且不可挽救的”产品不进行支持。 支持暂停这种产品，直到产品开发在支持准备阶段和产品本身得到支持之后再修复该问题，从而节省每个人的时间。 根据您的背景，“运行困难并且不可挽救的”的含义可能会有所不同 - 这里的动态应该是相互理解的责任之一。 对其他组织的推迟可能会更为温和，“我们认为使用这种技能的人有更多的时间”，或者限制在“这些人员将会因为过多的操作工作而没有机会使用他们的工程技能。“在Google，直接撤销此类产品支持的做法已成为一种制度。将可靠性工作视为一个专门的角色在谷歌，SRE和产品开发是独立的组织。每个小组都有自己的重点、优先级和管理，而不需要对另一个小组发号施令。然而，当产品成功时，产品开发团队将有效地资助新员工SRE的提升。这样，产品开发与SRE团队的成功息息相关，就像SREs与产品开发团队的成功息息相关一样。SRE也很幸运地得到了管理层的大力支持，这使得工程师团队认可了“SRE”这一角色。尽管如此，你不需要有一个组织结构图来做不同的事情，但是你需要一个不同的实践社区。不管你是使用组织结构图还是使用非正式的机制，重要的是要认识到专业化会带来挑战。DevOps和SRE的实践者可以从一个同伴社区中获得支持和职业发展，以及一个用来奖励他们独特的技能和观点的职业阶梯。值得注意的是，Google采用的组织结构以及上述一些激励措施在某种程度上依赖于规模庞大的组织。 例如，如果您的20人创业公司只有一个（相对较小的）产品，那么允许运维退出支持没有多大意义。 仍然可以采用DevOps风格的方法，但是，如果您能做的仅仅只是帮助它成长，那么改善操作性差的产品的能力就会受到损害。不过，对于如何满足这些增长需求，与技术债务累积的速度相比，人们通常有比想象中更多的选择。何时可以替代但是，当您的组织或产品增长超过一定规模时，您可以在支持哪些产品或如何确定支持优先级方面行使更大的自由度。 如果很明显，对系统X的支持将比支持系统Y更快地发生，那么隐式条件可以发挥同样的作用,选择不支持服务的行为。在谷歌，SRE与产品开发的强大合作关系已被证明至关重要：如果您的组织存在这种关系，那么撤回（或提供）支持的决定可以基于有关的客观数据来比较运营特征，从而避免非生产性的交涉。SRE与产品开发之间的富有成效的关系也有助于避免产品开发团队在产品或功能准备就绪之前必须交付的组织反模式。相反，SRE可以与开发团队合作，在维护负担转移到具有最多专业知识的人员之前改进产品。争取平等的尊重：职业与薪酬最后，确保正确的职业激励措施到位：我们希望我们的DevOps/SRE组织能够像他们的产品开发伙伴一样受到尊重。因此，每个团队的成员应按大致相同的方法进行评级，并具有相同的薪酬激励。结论在IT运维整体领域的许多方面，DevOps和SRE在实践和理念上都非常接近。DevOps和SRE都需要讨论、管理支持、并从实际工作人员那里来获得重大进展。 实施其中任何一个都是一段旅程，而不是一个快速解决方案：rename-and-shame（重命名和羞耻的）做法是空洞的，不太可能带来收益。 鉴于它是对如何执行操作的更具见解性的实现，SRE对于如何在此过程中更早地更改您的工作实践有更具体的建议，尽管需要进行特定的调整。DevOps关注的范围更广了，因此很难对其进行推理并将其转化为具体的步骤，但恰恰是因为更广泛的关注，可能会遇到较弱的初始阻力。但是，每种方法的实践者都使用许多相同的工具、相同的方法来改变管理，以及相同的基于数据的决策思维方式。最终，我们都面临着同样的问题:生产，让它变得更好——不管我们被称为什么。对于那些有兴趣进一步阅读的人，以下建议可以帮助您更广泛地了解目前正在进行的运维革命的文化，业务和技术基础：  Site Reliability Engineering  Effective DevOps  The Phoenix Project  The Practice of Cloud System Administration: DevOps and SRE Practices for Web Services, Volume 2  Accelerate: The Science of Lean Software and DevOps]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[《SRE Google运维实践》介绍]]></title>
      <url>/sre/2020/01/01/SRE-Google%E8%BF%90%E7%BB%B4%E5%AE%9E%E8%B7%B5/</url>
      <content type="text"><![CDATA[  《The Site Reliability Workbook — Practical Ways to Implement SRE》 中文版Edited by:    Betsy Beyer, Niall Richard Murphy, David K. Rensin, Kent Kawahara and Stephen Thorne前言    The Site Reliability Workbook is the hands-on companion to the bestselling Site Reliability Engineeringbook and uses concrete examples to show how to put SRE principles and practices to work. This book contains practical examples from Google’s experiences and case studies from Google’s Cloud Platform customers. Evernote, The Home Depot, The New York Times, and other companies outline hard-won experiences of what worked for them and what didn’t.《The Site Reliability Workbook》操作手册 具体的用途来展示如何在工作中实践SRE。 本书包含了Google自身经历或是从Google’s Cloud Platform的客户案例，Evernote、The Home Depot、The New York Times。本书目录结构：第一章  SRE与DevOps之间的联系第一部分：基本原理第二章  SLO实施第三章  SLO工程案例学习第四章第五章 第六章  减少琐事第七章  第八章第二部分： 实践第九章第十章     第十一章第十二章第十三章第十四章第十五章第十六章   灰度发布（金丝雀部署）第三部分： 进程第十七章第十八章第十九章第二十章第二十一章  相关资料英文原版：the-site-reliability-workbook-next18.pdf]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
