<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[kafka相关运维案例]]></title>
      <url>/%E5%A4%A7%E6%95%B0%E6%8D%AE/2020/05/26/kafka%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E6%A1%88%E4%BE%8B/</url>
      <content type="text"><![CDATA[  版本：kafka_2.11-0.10.1.1数据：1P+规模：20+节点__consumer_offsets topic占用空间过大现象：一日kafka集群单节点磁盘报警，上服务器排查发现三个实例的三块盘均已使用85%，其余磁盘均使用40%左右，再次排查发现这三块盘中均是__consumer_offsets_43 这个partition占用将尽3T。  线上集群未做raid，单实例上有12块盘，__consumer_offsets 共有3副本，因此3台机器均受到影响__consumer_offsets 有什么用？0.9.0版本之后，kafka默认将consumer的offset信息记录在该系统topic里面。格式：[consumer group, topic name, partition] :: [offsetmetadata [offset value,  metadata],    committime value,         expiratintime value]   示例：[test_consumer,  test_topic, 90]        :: [OffsetMetadata [68248895952,   NO_METADATA], CommitTime 1590481622713, ExpirationTime 1590568022713]        [消费者组,        topic名称,   分区]      :: [ offset元数据    [offset ,      nometadata ],  提交时间,                  过期时间 ]   通过该命令可以查看最近100条__consumer_offsets数据./kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server x.x.x.x:9092 --formatter "kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter"   --max-message 100 定位突增的数据？通过消费具体的partition来定位具体是哪个消费者组在提交offset。0.9.0.0之后版本(含)/kafka-simple-consumer-shell.sh  --partition 20 --formatter "kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter" --broker-list x.x.x.x:9092 --topic __consumer_offsets --max-message 3000为什么会出现该现象？  线上kafka集群默认配置了数据清楚策略，因此其余topic均按照保留时间进行删除，但 __consumer_offsets 是用来保存 kafka 其余topic消费offset信息的topic，如果log.cleaner.enable设置为false，是不进行数据清除的。  研发提交consumer offset方式不对总结__connsumer_offsets部分分区数据量异常的问题是由于以下两方面原因共同造成:  __connsumer_offsets默认清理策略设置不当，导致过期历史数据无法正常清理。  部分应用消费方式不当，导致产生大量commit信息。]]></content>
      <categories>
        
          <category> 大数据 </category>
        
      </categories>
      <tags>
        
          <tag> ELK </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第一篇blog]]></title>
      <url>/something/2020/03/11/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E6%96%87/</url>
      <content type="text"><![CDATA[  如何搭建该网站！.准备工作  github pages  jekyll具体过程      github pages 创建  首先新建仓库， 需要以username.github.io作为仓库名。        jekyll  选择模版，可以在Jekyll Themes选择自己喜欢的模版。我选择的是 Next模版，之所以选择该模版，是因为可以按照Next 使用文档一步一步进行操作，对于小白来说比较友好。  遇到问题jekyll安装， ps：mac os  ruby版本过低  解决方案，安装rvm更新ruby，Rvm是一个命令行工具，可以管理多个版本的Ruby。Mac使用RVM更新Ruby  权限问题  使用gem遇到 write permissions for the /usr/bin directory；      sudo gem install -n /usr/local/bin jekyll      I]]></content>
      <categories>
        
          <category> something </category>
        
      </categories>
      <tags>
        
          <tag> something </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第二十一章 组织变更管理]]></title>
      <url>/sre/2020/01/21/SRE-%E7%BB%84%E7%BB%87%E5%8F%98%E6%9B%B4%E7%AE%A1%E7%90%86/</url>
      <content type="text"><![CDATA[在第一本SRE手册的介绍中，Ben Treynor Sloss将SRE团队描述为“以快速创新和大量接受变革为特征”，并将组织变革管理作为SRE团队的核心职责。本章探讨理论如何在实践中应用于SRE团队。在回顾了一些关键的变革管理理论之后，我们探索了两个案例研究，它们展示了在Google中不同的变更管理风格是如何以具体的方式表现出来的。请注意，变更管理一词有两种解释：组织变更管理和变更控制。本章将变更管理作为所有方法的集合术语，用于准备和支持个人，团队和业务单位进行组织变革。我们不会在项目管理环境中讨论这个术语，它可以用来指代变更控制流程，例如变更审核或版本控制。SRE拥抱变化2000多年前，希腊哲学家Heraclitus宣称变化是唯一不变的。这个公理今天仍然适用——特别是在技术方面，尤其是在快速发展的互联网和云计算领域。产品团队的存在是为了构建产品、发布功能和满足客户需求。在Google，大多数变化是快节奏的，遵循“启动和迭代”的方法。执行此类更改通常需要跨系统、产品和全球分布的团队进行协调。网站可靠性工程师经常处于这个复杂且快速变化的环境中，负责平衡变更中固有的风险与产品可靠性和可用性。错误预算（参见第2章）是实现这种平衡的主要机制。变更管理简介自上世纪40年代Kurt Lewin在该领域的基础性工作以来，变更管理作为一个研究和实践领域不断发展。理论主要侧重于开发管理组织变革的框架。对特定理论的深入分析超出了本书的范围，但是为了在SRE领域内对它们进行语境化，我们简要介绍了一些常见理论以及每种理论如何适用于SRE类型的组织。虽然这些理论框架中隐含的正式流程尚未被SRE应用于Google，但通过这些框架的镜头考虑SRE活动有助于我们改进管理变革的方法。在讨论之后，我们将介绍一些案例研究，展示其中一些理论的元素如何适用于Google SRE领导的变更管理活动。Lewin的三阶段模型Kurt Lewin用于管理变革的“不冻结—改变—冻结”模型是该领域中最古老的相关理论。这个简单的三阶段模型是一个管理过程审查的工具，以及由此产生的群体动态变化。阶段1需要说服一个需要改变的团体。一旦他们接受了改变的想法，第2阶段就会执行这一改变。最后，当变化大致完成时，第3阶段将新的行为和思想模式制度化。该模型的核心原则将该群体作为主要的动态工具，认为当群体计划、执行和完成任何变革期时，应将个人和群体互动作为一个系统来进行检验。因此，Lewin的工作对于在宏观层面规划组织变革最有用。McKinsey的7-S模型McKinsey的七个S代表结构、战略、系统、技能、风格、员工和共同价值观。 与Lewin的工作类似，该框架也是计划组织变革的工具集。 虽然Lewin的框架是通用的，但7-S的明确目标是提高组织效率。 两种理论的应用始于对当前目的和过程的分析。 但是，7-S还明确涵盖了业务要素（结构、战略、系统）和人员管理要素（共享价值观、技能、风格、员工）。 对于考虑从传统系统管理重点转向更全面的网络可靠性工程方法的团队，此模型可能非常有用。Kotter领导变革的八步流程《时代》杂志将John P. Kotter于1996年出版的《引领变革》（Leading Change, Harvard Business School Press）一书评为有史以来最具影响力的25大商业管理书籍之一。 图21-1描述了Kotter变更管理流程中的八个步骤。 图21-1：Kotter的变更管理模型 [来源：](https://www.kotterinc.com/ 8-steps-process-for-leading-change/） Kotter的流程尤其与SRE团队和组织相关，只有一个小例外：在许多情况下（例如，即将推出的Waze案例研究），没有必要产生紧迫感。支持快速增长的产品和系统的SRE团队经常面临紧急的扩展、可靠性和运维挑战。组件系统通常由多个开发团队拥有，可能跨越多个组织单元; 扩展问题可能还需要与从物理基础架构到产品管理的团队进行协调。 由于SRE通常在出现问题时处于第一线，因此他们具有独特的动机来领导所需的更改，以确保产品24/7/365全天候可用。大部分SRE工作（隐含地）都采用了Kotter的流程来确保支持产品的持续可用性。Prosci ADKAR模型Prosci ADKAR模型侧重于平衡变更管理的业务和人员两个方面。 ADKAR是个人为成功组织变革必须达到的目标的首字母缩写：意识、愿望、知识、能力和强化。原则上，ADKAR提供了一个有用的，深思熟虑的，以人为中心的框架。但是，它对SRE的适用性是有限的，因为业务责任通常会带来相当大的时间限制。通过ADKAR的阶段反复进行并提供必要的培训或指导需要在通信方面进行调整和投资，这在全球分布的，以业务为重点的团队的背景下难以实施。也就是说，Google已成功使用ADKAR风格的流程来引入和构建对高级别更改的支持——例如，将全局组织变更引入SRE管理团队，同时保留本地实现细节的自主权。基于情感的模型桥梁过渡模型描述了人们对变化的情感反应。虽然它是人员管理者的有用管理工具，但它不是变更管理的框架或流程。同样，Kübler-Ross变化曲线描述了人们在面对变化时可能会感受到的情感范围。根据Elisabeth Kübler-Ross关于死亡和垂死的研究，它已被用于理解和预测员工对组织变革的反应。这两种模型都可以在变更期间保持高员工生产率，因为不快乐的人很少有生产力。戴明循环也称为Plan-Do-Check-Act（或PDCA）循环，统计学家Edward W. Deming的这一过程通常用于DevOps环境中以改进流程——例如，采用持续集成/持续交付技术。它不适合组织变革管理，因为它不包括变革的人性方面，包括动机和领导风格。戴明的重点是采用现有流程（机械的，自动化的或工作流的）并循环应用持续改进。我们在本章中提到的案例研究涉及更大的组织变革，其中迭代会适得其反：频繁、痛苦的组织结构变化会削弱员工的信心并对公司文化产生负面影响。这些理论如何应用于SRE没有一种变更管理模式适用于所有情况，因此Google SRE并未专门针对一种模式进行标准化也就不足为奇了。也就是说，这就是我们如何考虑将这些模型应用于SRE中的常见变更管理方案：  Kotter的八步流程是SRE团队的变革管理模式，他们必须将变革视为核心责任  Prosci ADKAR模型是SRE管理层可能需要考虑的框架，用于协调全球分布式团队的变更。  所有单独的SRE经理都将受益于熟悉Bridges Transition Model和 Kübler-Ross Change Curve，它们提供了在组织变革时为员工提供支持的工具。既然我们已经介绍了这些理论，让我们看看两个案例研究，它们展示了变革管理在Google上的表现。案例研究1：从临时变更到计划变更的缓和规模背景Waze是Google于2013年收购的基于社区的导航应用程序。收购完成后，Waze进入了活跃用户、工程人员和计算基础架构的显著增长期，但在Google内部继续相对独立的运行。这种增长带来了许多技术和组织方面的挑战。Waze的自主权和创新精神使他们通过小组工程师的基层技术响应来应对这些挑战，而不是前一节讨论的正式模型所暗示的管理性，结构化的组织变革。然而，他们在整个组织和基础设施中传播变更的方法与Kotter的变更管理模型非常相似。本案例研究探讨了Kotter的流程（我们追溯应用）如何恰当地描述了Waze在收购后增长所面临的一系列技术和组织挑战。消息队列：在保持可靠性的同时更换系统Kotter的模型以一种紧迫感开始了变革的周期。Waze的SRE团队需要在Waze的消息队列系统的可靠性严重退化，导致日益频繁和严重的停机时迅速而果断地采取行动。如图21-2所示，消息队列系统对于操作至关重要，因为Waze的每个组件（实时、地理编码、路由等）都使用它来与内部的其他组件进行通信。 图21-2：Waze组件之间的通信路径 随着消息队列上的吞吐量显着增长，系统根本无法应对不断增长的需求。SRE需要手动干预以在越来越短的时间间隔内保持系统稳定性。在最糟糕的情况下，整个Waze SRE团队每周7天，每天24小时大部分时间在进行排障，最终每小时重新启动消息队列的一些组件，以保持消息流动，数千万用户满意。由于SRE还负责构建和发布所有Waze软件，因此这种操作负载对特性速度有明显影响——当SRE花费所有时间处理故障时，他们几乎没有时间支持新功能推出。通过强调情况的严重性，工程师说服Waze领导重新评估优先级并将一些工程师的时间用于可靠性工作。两个SRE和一名高级工程师的指导联盟聚集在一起形成了一个未来的战略愿景，SRE辛劳不再是保持信息流动所必需的。这个小团队评估了现成的消息队列产品，但很快就决定他们只能通过定制解决方案满足Waze的扩展和可靠性要求。如果没有某种方法在此期间维持操作，在内部开发此消息队列是不可能的。联盟从使用当前消息传递队列的团队中招募了一批志愿者开发人员，从而消除了这一障碍。每个团队都检查了他们的服务代码库，以确定减少他们发布的消息数量的方法。删除不必要的消息，并在旧队列的顶部扩展压缩层，可以减少系统上的一些负载。该团队还通过为一个特定组件构建专用消息队列来获得更多的操作空间，该组件负责超过30％的系统流量。这些措施产生了足够的临时操作缓冲，允许在两个月内组装和测试新消息传递系统的原型。即使没有迫在眉睫的服务崩溃的压力，迁移每秒处理数万条消息的消息队列系统也是一项艰巨的任务。但逐渐减少旧系统的负载可以减轻一些压力，为团队提供更长的时间窗口来完成迁移。为此，Waze SRE重建了消息队列的客户端库，以便他们可以使用其中一个或两个系统发布和接收消息，使用集中控制界面来切换流量。一旦新系统被证明有效，SRE就开始了迁移的第一阶段：他们发现了一些低流量，高重要性的消息流，消息传递中断对这些消息流来说是灾难性的。对于这些流，向两个消息传递系统写入将提供一个备份路径。有几次差点失败，当旧系统摇摇欲坠时，备用路径保持核心Waze服务的运行，提供了短期的胜利，证明了最初的投资是合理的。大规模迁移到新系统需要SRE与使用它的团队密切合作。该团队需要弄清楚如何最好地支持他们的用例以及如何协调流量切换。由于SRE团队自动化了迁移流量的过程，并且新系统默认支持更多用例，因此迁移率显著加快。Kotter的变革管理流程以实施变革而告终。最终，在采用新系统背后有足够的动力，SRE团队可以声明旧系统已弃用且不再受支持。几个季度后他们迁移了最后的一批消息队列。如今，新系统处理的负载超过前一个系统的1000倍，并且几乎不需要SRE的人工干预即可持续提供支持和维护。下一个变更周期：改进部署过程作为一个周期的变化过程是Kotter的关键见解之一。当涉及到SRE面临的技术变化类型时，有意义变化的周期性特征尤其明显。消除系统中的一个瓶颈常常会突出显示另一个瓶颈。随着每个变更周期的完成，由此产生的改进、标准化和自动化可以节省工程时间。工程团队现在有空间更仔细地检查他们的系统并识别更多的痛点，从而触发下一个变化周期。当Waze SRE最终能够从与消息传递系统相关的问题中退出时，一个新的瓶颈出现了，随之而来的是一种新的紧迫感：SRE对发行版本的唯一所有权明显地、严重地阻碍了开发速度。发布的手动性质需要大量的SRE投入时间。为了加剧已经不理想的情况，系统组件很大，而且由于发布成本很高，它们的频率相对较低。因此，每个版本都代表一个大的增量，这大大增加了一个重大缺陷需要回滚的可能性。由于Waze SRE没有一个方案的总体规划，因此逐步改进为更好的发布流程。为了精简系统组件，以便团队能够更快地迭代每个组件，Waze的一位高级开发人员创建了一个构建微服务的框架。这提供了一个标准的“电池包含”平台，使得工程组织可以很容易地将其组件分开。SRE与该开发人员一起工作，以包含一些重点关注可靠性的特性——例如，一个通用的控制界面和一组易于自动化的行为。因此，SRE可以开发一套工具来管理发布过程中以前昂贵的部分。其中一种工具通过将创建一个新的微服务所需的所有步骤与框架捆绑在一起来鼓励采用。这些工具一开始很简单，最初的原型是由一个SRE在几天内完成的。随着团队从它们的父组件中分离出更多的微服务，SRE开发的工具的价值在更广泛的组织中很快变得明显起来。SRE将精简后的组件投入生产的时间减少了，而单独发布新的微服务的成本要低得多。虽然发布过程已经有了很大的改进，但新微服务的激增意味着SRE的总体负担仍然令人担忧。工程领导不愿意承担发布过程的责任，直到发布不再那么繁重。作为回应，一个由SREs和开发人员组成的小联盟勾勒出了一个战略愿景，使用Spinnaker(一个开源、多云、持续交付平台，用于构建和执行部署工作流)转向持续部署策略。通过引导工具节省的时间，团队现在能够设计这个新系统，以支持一键构建和部署成百上千的微服务。新系统在各个方面都优于以前的系统，但是SRE仍然无法说服开发团队进行转换。这种不情愿是由两个因素驱动的：必须将自己的发行版推向生产的明显的抑制因素，加上对发布过程的可见性不强所导致的变更厌恶。Waze SRE通过展示新流程如何增加价值来消除这些采用障碍。该团队构建了一个集中式仪表盘，显示二进制文件的发布状态以及微服务框架导出的一些标准指标。开发团队可以很轻松地将他们的发布与这些指标中的变化联系起来，这使他们相信部署是成功的。SRE与一些面向系统的志愿者开发团队密切合作，将服务转移到Spinnaker。这些胜利证明了新的系统不仅能够满足它的需求，而且能够在原有的发布过程之外增加价值。此时，工程领导为所有团队设定了一个目标，即使用新的Spinnaker部署管道来执行发布。为了促进迁移，Waze SRE为具有复杂需求的团队提供了组织范围内的Spinnaker培训和咨询会议。当早期采用者熟悉新系统后，他们的积极经历引发了加速采用的连锁反应。他们发现，与等待SRE推送他们的版本相比，这个新的流程更快，痛苦也更少。现在，工程师开始对没有移动的依赖项施加压力，因为他们是加快开发速度的障碍——而不是SRE团队!如今，超过95%的Waze的服务使用Spinnaker进行持续部署，并且可以在极少人工参与的情况下将更改推到生产环境中。虽然Spinnaker并不是一种万能的解决方案，但是如果使用微服务框架构建了一个新的服务，那么配置一个发布管道是很简单的，因此新的服务有强烈的动机对这个解决方案进行标准化。经验总结Waze在消除技术变更瓶颈方面的经验，对于其他尝试工程主导技术或组织变更的团队来说，包含了许多有用的经验。首先，改变管理理论不是浪费时间！通过Kotter过程的镜头来观察这个开发和迁移过程可以证明模型的适用性。当时，Kotter模型更正式的应用可能有助于简化和指导变更的过程。从基层发起的变更需要SRE和研发团队之间的密切合作，以及行政领导的支持。创建一个小的、集中的团队，成员来自组织的各个部分——sre、开发人员和管理人员——是团队成功的关键。类似的合作对实现这一变更至关重要。随着时间的推移，这些特设小组能够而且应该发展成更正式和更结构化的合作，在这种合作中，SREs自动参与设计讨论，并能够就在整个产品生命周期中在生产环境中构建和部署健壮的应用程序的最佳实践提供建议。增量更改更容易管理。直接跳到“完美”的解决方案是一个非常大的步骤，不能一下子全部执行（如果你的系统即将崩溃，更不用说可能是不可行的），而且“完美”的概念可能会随着更改过程中新信息的出现而演进。迭代方法可以演示早期的胜利，帮助组织接受变更的远景 并证明进一步的投资是合理的。另一方面，如果早期的迭代没有显示出价值，那么当你不可避免地放弃变更时，你将浪费更少的时间和资源。因为增量式的改变不是一下子就能发生的，所以有一个总体计划是非常宝贵的。用宽泛的术语描述目标，要灵活，并确保每次迭代都朝着目标前进。最后，有时你当前的解决方案不能支持你的战略远景的需求。构建新事物需要大量的工程成本，但如果项目将你推离了局部的最大值，并且能够实现长期的增长，那么这是值得的。作为一个思想实验，随着业务和组织在未来几年的增长，找出系统和工具中可能出现的瓶颈。如果你怀疑任何元素没有横向扩展，或者对于核心业务度量（如每日活跃用户）具有超线性（或者更糟，是指数增长），那么你可能需要考虑重新设计或替换它们。Waze开发的一种新的内部消息队列系统表明，一小群有决心的工程师有可能进行变革，从而提高服务可靠性。将Kotter的模型映射到变更上表明，对变更管理策略的一些考虑可以帮助提供成功的公式，即使是在小型的、工程主导的组织中。而且，正如下一个案例研究也表明的那样，当变革促进标准化技术和过程时，整个组织可以获得相当大的效率收益。案例研究2：SRE中的通用工具采用背景SREs对于他们可以用来管理生产的软件持有不同的看法。多年的经验，观察什么做得好，什么做得不好，以及通过事后分析的视角来审视过去，让SREs有了深刻的背景和强烈的直觉。在SRE中，指定、构建和试实施软件以自动化今年的工作是核心价值。特别是，Google SRE最近将我们的工作重点放在了横向软件上。大量用户和开发人员采用了相同的解决方案，这就形成了一个良性循环，减少了重新开发。否则可能不进行交互的团队将共享使用相同软件自动化的实践和策略。这个案例研究基于组织的发展，而不是对系统扩展或可靠性问题的响应（如Waze案例研究中所讨论的）。因此，Prosci ADKAR模型（如图21-3所示）比Kotter的模型更适合，因为它识别了在变更期间显式的组织/人员管理特征和技术考虑。 图21-3：变更管理的Prosci ADKAR模型 问题陈述几年前，Google SRE发现自己使用了多个独立的软件解决方案，可以在多个问题空间中解决大致相同的问题：监控、发布和部署、事件响应、容量管理等等。这种最终状态出现的部分原因是为SRE构建工具的人员与他们的用户及其需求是分离的。工具开发人员并不总是对问题陈述或整个生产环境有一个当前的视图——生产环境以新的方式以非常快的速度变化，因为新的软件、硬件和用例几乎每天都被引入到生活中。此外，工具的使用者是多种多样的，有时还存在正交需求（“这种推出必须是快速的；近似是正确的，相对而言，这个展示必须是100%正确的；可以慢慢进行”）。因此，这些长期项目都没有完全满足任何人的需求，每个项目的特点都是不同级别的开发工作、功能完整性和持续的支持。那些等待大用例的人——一个非特定的、全能的未来解决方案——等了很长时间，感到沮丧，并使用他们自己的软件工程技术来创建他们自己的利基解决方案。那些有更小、更具体需求的人不愿意采用一种更广泛的、不适合他们的解决方案。更通用的解决方案的长期、技术和组织效益是显而易见的，但是客户、服务和团队并没有因为等待而得到人员配备或奖励。为了是这种情况更加复杂，大客户团队和小客户团队的需求会随着时间而改变。我们决定做什么为了将此场景扩展为一个具体的问题空间，我们问自己：如果所有Google SREs都可以使用一个通用的监控引擎和一组仪表盘，这些仪表盘易于使用，并且支持各种各样的用例，而不需要自定义，那会怎么样?同样，我们可以将这种思维模型扩展到发布和推广、事件响应、容量管理等等。如果一个产品的初始配置捕获了大量的方法来满足我们的大部分功能需求，那么随着时间的推移，我们一般的和高深的解决方案将变得不可避免。在某种程度上，与生产交互的工程师的临界数量将超过他们使用的任何解决方案，并自行选择迁移到一组通用的、受良好支持的工具和自动化中，放弃他们定制的工具和相关的维护成本。Google的SRE很幸运，它的许多工程师都有软件工程背景和经验。他们是专家，对具体问题有自己的看法——从负载均衡到发布工具到事件管理和响应——以虚拟团队的形式工作，由共同的长期愿景自行选择。这些工程师将把他们的愿景转化为实际的软件，最终被所有的SRE和所有的Google所采用，作为生产的基本功能。为了回到ADKAR的变更管理模型，到目前为止所讨论的步骤——识别问题和确认机会——是ADKAR启动意识步骤的典型例子。Google SRE领导团队同意需求（愿望），并有足够的知识和能力来快速设计解决方案。设计我们的首要任务是集中讨论一些我们认为是核心的主题，这将极大地受益于一致的愿景：交付适合大多数用例的解决方案和采用计划。从65个以上的项目列表开始，我们花了几个月的时间收集客户需求，验证路线图，进行市场分析，最终将我们的工作范围确定在少数经过审查的主题。我们最初的设计围绕这些主题创建了一个虚拟的SRE专家团队。这个虚拟团队将为这些横向项目贡献很大比例的时间，大约80%。80%的时间和一个虚拟团队背后的想法是，确保我们在没有与生产持续接触的情况下，不设计或构建解决方案。然而，我们（也许可以预见）发现了这种方法的一些痛点:  协调一个虚拟团队是非常困难的，这个团队的重点是在多个时间区域内定期随叫随到。在运行一个服务和构建一个软件之间，有很多状态需要交换。  从收集共识到代码审查的所有内容都受到缺乏中心位置和公共时间的影响。  横向项目的人员最初必须来自现有的团队，他们现在处理自己项目的工程资源更少了。即使在Google，委派员工来支持系统与委派员工来构建面向未来的基础设施之间也存在矛盾。有了足够的数据，我们意识到我们需要重新设计我们的方法，并选择更熟悉的集中式模型。最重要的是，我们取消了团队成员在项目工作和值班职责之间分配80/20时间的要求。大多数SRE软件开发现在都是由拥有大量on-call经验的高级工程师组成的小组来完成的，但他们都是专注于基于这些经验构建软件的。我们也通过招募或调动工程师来集中这些团队。小组（6-10人）的开发在一个房间内更有效率（然而，这个论点并不适用于所有的小组——例如，远程SRE团队）。我们仍然可以通过视频会议、电子邮件和传统的出差来达到收集整个Google工程组织的需求和观点的目标。所以我们的设计演变实际上出现在一个熟悉的地方——小型、灵活、大多是本地、快速发展的团队——但更加强调选择和构建自动化和工具，以供60%的Google工程师采用（我们确定这个数字是对“几乎每个人都在Google”的目标）。成功意味着Google大部分人都在使用SRE为管理其生产环境而构建的工具。ADKAR模型在以人为中心的知识和能力阶段之间映射了变更项目的实现阶段。这个案例研究证实了这种映射。我们有许多敬业、才华横溢、知识渊博的工程师，但我们通过关注客户需求，产品路线图和交付承诺，要求那些专注于SRE问题的人员像产品软件开发工程师一样行事。我们需要重新考虑这个更改的实现，以使工程师能够展示他们关于这些新属性的能力。实现：监控为了回到上一节中提到的监控空间，第一本SRE手册中的第31章描述了Viceroy-Google SRE如何创建一个适合所有人的监控仪表盘解决方案，解决了完全不同的定制解决方案的问题。几个SRE团队一起创建并运行最初的迭代，随着Viceroy成长为Google的实际监控和仪表盘解决方案，一个专门的集中式SRE开发团队承担了项目的所有权。但是，即使Viceroy框架将SRE统一在一个共同的框架下，由于团队构建了特定于其服务的复杂自定义仪表盘，因此需要进行大量重复工作。虽然Viceroy提供了一种标准的托管方法来设计和构建数据的可视化显示，但仍然需要每个团队决定显示哪些数据以及如何组织这些数据。现在集中化的软件开发团队开始了第二个并行工作，提供通用仪表板，在较低级别的“自定义”系统之上构建了一个固定的零配置系统。这个零配置系统提供了一套标准的综合监控显示，它基于一个给定的服务被组织为少数流行的样式之一的假设。随着时间的推移，大多数服务都迁移到使用这些标准仪表板，而不是投资于自定义布局。如果需要，非常大的、独特的或其他特殊的服务仍然可以在托管系统中部署自定义视图。回到ADKAR模型，Google监控工具的整合始于基层工作，由此带来的运营效率提升提供了可量化的基础（意识和愿望），以启动更广泛的努力：SRE自筹资金的软件开发团队为所有Google构建生产管理工具。经验总结设计相互依赖的部件的迁移通常比空白页设计更复杂。但在现实生活中，最困难的工程工作最终是将许多小型/受限系统演变成更少、更通用的系统——而不会干扰许多客户所依赖的已经在运行的服务。与此同时，除了现有的系统之外，新的小型系统也在不断增加——其中一些系统最终发展成为大型系统而让我们感到惊讶。大型设计重新开始，只有支持真正必要的约束，才有吸引力，但系统和团队的迁移是迄今为止最困难的工作。设计横向软件需要大量听取潜在最终用户的意见，在许多方面，构建和采用的任务看起来很像产品经理的角色。为了使这一努力取得成功，我们必须确保我们吸收并优先考虑优先事项。满足客户需求——SREs和其他生产用户的需求——也是成功的关键因素。必须承认，向通用工具的转移仍然是一项正在进行的工作。我们对构建共享技术的团队的结构和人员进行了迭代，以更好地满足客户需求，我们还增加了产品管理和用户体验人才(解决了缺失的知识)。在过去的一两年里，我们在Google的许多团队中看到了这些SRE设计和构建的产品。我们已经了解到，要想取得成功，迁移（从旧的、碎片化的、专门的解决方案）的成本相对于新的通用解决方案的净收益而言较小。否则，迁移本身就会成为采用的障碍。我们继续与构建这些产品的单个团队合作，以加强团队交付的通用解决方案满足客户所需的行为。我们在横向软件开发项目中发现的一个共同主题是，无论新软件和产品有多好，从已经在工作的东西迁移到新东西的迁移成本总是被认为非常高。尽管有更容易管理和不太具体的深入知识的诱惑，从熟悉的地方迁移（尽管有缺点和辛苦）的成本通常是一个障碍。此外，个别工程师也经常有类似的内部独白：“我没有改进或改变系统；我把一个工件换成另一个工件。ADKAR将这种阻力描述为“知识——能力差距”。在人性方面，为了认识和接受变革，人们需要时间、指导和新工具和技能方面的培训。在技术方面，实现变更需要理解采用成本，并包括将这些成本最小化的工作作为启动过程的一部分。因此，对于团队、个人和公司来说，迁移成本必须接近于零（“只需重新编译，您就可以获得新的东西”），而好处也必须明确（“现在你可以免受$foo漏洞的伤害”）。SRE通常用于以“尽力而为”的方式构建我们承诺的产品，这意味着我们给产品的时间量适合我们正在做的其他事情之间的裂缝（管理主要服务，容量规划，处理中断，等等）。因此，我们的执行不是很可靠；无法预测什么时候可以使用某个特性或服务。延伸开来，我们产品的消费者对最终结果的信任度就降低了，因为我们的产品总是会被推迟，并且有一个轮流的产品经理和个体工程师组成。当各个SREs或SRE团队为自己的使用构建工具时，重点是解决个别问题，以降低为支持的系统维护SLOs的成本。为了在Google中为大多数用例构建通用工具，我们需要将重点转移到衡量这项工作在产品采用方面的成功与否。由于我们的组织文化和丰富的资源，我们以自下而上而不是自上而下的方式来处理这个项目。我们没有强制用户迁移到我们的新监控系统，而是通过证明我们的新产品比现有的解决方案更好来赢得用户。随着时间的推移，我们了解到我们如何执行我们的开发过程将告知潜在的内部用户如何感知最终结果。只有当生产经验丰富的工程师100%致力于构建软件时，这些项目才能获得真正的吸引力，其计划和支持与Google的其他软件开发相同。透明地构建通用软件，像clockwork一样，具有良好的通信（“我们将在Y 日期之前完成X”），极大地提高了迁移到新系统的速度。人们已经信任这个新系统，因为他们可以观察到它是如何从早期发展起来的。从一开始，人们对香肠制作过程的理解就比我们预想的更加重要。我们最初的想法是“如果你创造出伟大的东西，人们会自然而然地涌向它”，但这并不是真的。相反，这些项目必须明确定义，事先做好宣传，针对大量的用户案例（首先针对最暴躁的采用者）进行评估，比现有的选择有更好的跳跃式发展，并且可以毫不费力地采用。普通工具采用的消费者越多，除了编写代码之外，你实际花费的时间就越多。回想起来，这听起来可能很明显，但是清晰的最终目标、可信的日期、定期的更新以及与消费者的持续接触是至关重要的。通常持怀疑态度的消费者会问：“如果我当前的一次性shell脚本运行良好，我真的需要这个吗?”采用通用软件或流程类似于可靠性作为一项特性——你可以构建世界上最好的东西，但是如果人们不采用它（或者如果它不可靠就不能使用它），那么它对任何人都没有用处。当涉及到构建和采用通用工具和实践时，制定一个采用计划——从拥护者到beta测试人员，从执行发起人到专门的工程师，他们都明白最小化采用障碍的重要性——既是最终目标，也是起点。这是因为采用会带来网络效应：随着普通软件工具的规模和范围的扩大，对这些工具的逐步改进对组织来说更有价值。随着工具价值的增加，致力于它们的开发工作也会增加。这些开发工作中的一部分自然用于进一步降低迁移成本，鼓励更多的采用。广泛采用鼓励以一致的、类似于产品的方式构建组织范围内的改进，并证明配备完整的团队以支持长期的工具是合理的。这些工具应该具有快速开发、特性稳定性、通用控制界面和可自动化api的特点。在衡量此类工作的影响时，我们可以提出类似以下问题：  新产品开发人员能够以多快的速度构建和管理世界级服务？  通过常见的工具和实践启用，一个领域中的SRE可以多容易地转移到另一个领域?  使用相同的原语可以管理多少服务，如端到端用户体验与单独服务？这些都是度量影响的可能且非常有价值的方法，但是我们的第一个度量必须是采用。结论正如Waze和横向软件案例研究所展示的那样，即使在一家公司内，SRE变更管理也可能需要处理各种问题空间和组织环境。因此，可能没有任何一种正式的变更管理模型可以巧妙地应用于任何给定组织可能处理的变更范围。然而，这些框架，特别是Kotter的八步过程和Prosci ADKAR模型，可以为即将发生的变化提供有用的见解。在像SRE这样动态的环境中，任何必要的更改都有一个共同点，那就是不断的重新评估和迭代。虽然许多变化可能以基层的方式有机地开始，但随着变化的成熟，大多数变化可以从结构化的协调和计划中获益。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第二十章 SRE：团队生命周期]]></title>
      <url>/sre/2020/01/20/SRE-%E5%9B%A2%E9%98%9F%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
      <content type="text"><![CDATA[本书的前言就设定了一个目标，即“消除SRE只能在谷歌场景中实现”。本章给出了一个从无人值守到成熟SRE组织的路线图。无论你的SRE团队中处于什么阶段或位置，本章都将帮助你如何发展SRE团队。针对SRE的不同阶段，本章讨论了SRE理论。虽然SRE根据自己团队的规模、性质和地理分布而有所不同，但我们描述的SRE理论和实践适用于许多不同类型的团队。没有SRE的SRE实践即使没有SRE，也可以使用SLO。如第2章所述，SLO是SRE实践的基础。因此，SRE的第一条理论：  理论1：SRE需要SLO评估影响。用SLO来评估服务性能，将会引导你的业务决策。即使没有SRE，如下SRE的实践也可以实现。  承认你不需要100%的可靠。  设置合理的SLO目标，此SLO应衡量对用户最重要的可靠性。  同意有助于保护用户体验的错误预算政策，使用错误预算来帮助指导：–减少停机等之类的管理措施以此来保障你的系统达到可靠状态。–更长期的工作优先顺序，使系统更可靠，使用更少的错误预算。  测量SLO并承诺遵循错误预算策略。这一承诺需要得到公司领导层的同意。即使团队没有SRE，为关键客户服务设置SLO并实施错误预算是应该的，只是因为隐含的100％SLO意味着团队只能被动反应。此SRE理论允许你就如何确保应用程序的可靠性做出数据知情决策。开始一个SRE角色找到你的第一个SRE有可能你的第一个SRE员工不会有明确的SRE经验。我们发现以下几个方面与SRE的角色有关，因此适合在面试中进行交谈：运维  在生产中运行应用程序提供了非常宝贵的见解，否则很难获得。软件工程SRE需要了解他们支持的软件，并有权改进它。监控系统SRE原则要求可以衡量和解释的SLO，生产自动化扩展操作需要自动化。生产自动化扩展操作需要自动化。系统架构扩展应用程序需要良好的架构。你的第一个SRE可能会在速度和可靠性目标之间处于一个困难和模糊的位置。他们需要有弹性和灵活性，以便在实现产品开发和维护客户体验之间提供适当的平衡。安排你的第一个SRE一旦雇佣了你的第一个SRE，你现在需要决定将他们嵌入到你的团队中。你有三个主要的选择:  在产品开发团队中  在运维团队中  在一个横向角色中，跨多个团队进行咨询在阅读本章之后，我们建议你评估这三个选项的利弊，考虑：你自己的角色和影响范围。如果你能够有效地影响产品开发团队，那么在运维或横向工作中嵌入一个SRE可以帮助尽早解决生产问题。你面临的直接挑战。如果挑战需要实际工作来减轻技术问题或业务风险，那么将SRE嵌入到运维或产品团队中可能是有利的。这样做可以消除团队孤岛，便于团队成员之间的沟通。你期望在未来12个月内面临的挑战。例如，如果你关注的是发布，那么将SRE嵌入到产品开发团队中可能是有意义的。如果你关注的是基础架构的更改，那么将SRE嵌入到运维团队中可能更有意义。你计划如何改变你的团队。如果你计划转向集中式的SRE团队，那么你可能不希望在产品开发团队中首先嵌入SRE——以后可能很难将他们从这些团队中删除。你已确定为第一个SRE的人。  根据他们的背景和技能来决定第一个SRE在哪里最有生产力。在确定哪种方法最适合你时，尝试使用不同的模型可能是有意义的。但是，我们强烈建议长期坚持使用一个稳定且连贯的模型；否则，不稳定性将破坏SRE的有效性。引导你的第一个SRE你的第一个SRE的首要任务是加快服务速度。为了产生积极影响，SRE需要了解服务的当前问题、所需的工作（参见第6章）以及将系统保持在SLO中所需的工程。如果你的组织尚未按照理论1拥有SLO和错误预算，那么你的第一个SRE需要执行设计和实现这些工具所需的工程。基于这点，第二条SRE理论：  理论2：SRE必须有时间做明天比今天更好的事情。如果没有这个原则，辛劳只会随着服务使用的增加而增加，系统也会相应地变得更大、更复杂。运维责任和项目工作之间的健康平衡是非常重要的——如果繁重的工作变得过于繁重，有才华的工程师就会离开团队。有关SRE团队如何获得这种平衡的更多指导，请参阅第17章。最初的项目工作可能集中于以下之一:  改进监控，以便在出现问题时更好地了解系统。  解决在最近的事后调查中发现的任何高优先级的行动（见第10章）。  实现自动化，以减少运行服务所需的特定工作。至关重要的是，SRE有一个独特的角色，他们的项目有利于整个团队。留意SRE工作进展不顺利的迹象：  S他们的工作组合与其他工程工作难以区分。  S如果你的第一个SRE是在一个产品开发团队中，那么他们所做的工作超出了他们的职责范围，或者他们是唯一一个在服务配置更改方面工作的人。  SLO没有受到重视，SRE也没有在衡量和维护客户体验方面取得进展。分布式SRE如果你没有离散的SRE团队，那么为分布式SRE构建一个社区是很重要的。这个社区应该提倡SRE的独特作用，并在团队之间推动以可靠性为中心的技术或实践的一致变化。如果没有社交分组，个体SRE可能会感到非常孤立。你的第一个SRE团队你可以通过多种方式组建一个SRE团队。我们在Google中使用的方法，从最小到最复杂，包括：  S创建一个新团队作为主要项目的一部分  建立横向SRE团队  转换现有团队（例如，运维团队）最适合你的方法是因地制宜。一个团队需要足够的SRE来处理运行服务所需的运维任务。处理这种工作量使我们想到我们的第三个理论：  理论3：SRE团队有能力调节工作负载。在大型SRE团队之外，团队可能无法从第一天起就接受这个概念。这一原则易于解释，但很难有组织地付诸实施。它也是我们三个原则中最微妙的一条，也需要一些梳理。下面的部分将介绍如何构建团队，使用Tuckman的表现模型：形成、攻坚、规范和表演四个阶段。形成你组建的团队应该具备以下经验和专业知识：  修改应用软件以提高可靠性和性能。  编写软件，来达到如下目的：  –产品中问题的的发现和快速解决  –自动化手动操作  建立并使用强大的软件实践和标准来促进长期的可维护性。  采用有条不紊和谨慎的方法进行操作。  了解系统架构（分布式系统设计和操作）。理想情况下，你的团队将准备采用一种新的工作方式，并在技能上与其他团队建立的个人关系之间取得平衡。如果可能的话，我们建议你通过内部转移为团队提供支持。这可以减少团队的启动和运行所需的时间。创建一个新的团队作为主要项目的一部分你可以为一个大的项目创建一个新的SRE团队，这个团队大到足以证明新的人员编制是合理的，并且已经将可靠性和操作能力确定为项目风险。示例可能包括新服务的创建或技术的重大更改（例如，服务迁移到公共云）。组建横向SRE团队在这种方法中（在我们第一本书的第27章中有详细的记录），一个SRE小组在多个团队之间进行咨询。这个团队还可能建立配置管理、监视和警报的最佳实践和工具。正确地转换团队角色你可以将现有的团队转换为SRE团队。现有的团队可能不是产品开发团队；典型的候选人包括：操作团队、使用流行开源组件的团队。如果没有首先应用SRE实践和原则，要小心避免将团队从“运维”重新命名为“SRE”！如果你的重命名工作失败了，你的组织将来可能会对整个SRE概念造成毒害。攻坚新组建的团队一开始就需要考虑协作的问题：团队成员需要互相配合，也需要与其他团队合作。你可以使用任何策略来促进这种凝聚力。在Google，我们已经成功地提供了一个定期论坛来学习和讨论SRE实践，并反思团队的表现。例如，你可能会定期举办一场电视午餐，在那里你会播放一段来自SREcon的视频，或者是一个读书俱乐部，在那里你可以提前阅读一些相关内容，然后讨论如何应用它。在此阶段，鼓励你的新SRE团队进行扩展。你的新SRE应该乐于说出不适合你的组织的SRE实践，以及是否值得进行更改以使它们适合你的组织。风险和缓解在SRE旅程的初期阶段，团队可能会以多种方式失败。接下来，我们将介绍一些风险和可能的缓解策略，这些策略根据新团队的组成进行了细分。你可以针对每种风险使用一个或多个缓解策略。新团队作为重大项目的一部分风险  团队:          一次承担太多服务的责任，会让自己过于分散。——一个经常处理报警的团队没有时间以更持久的方式处理风险。      试图理解SRE原则和如何实现它们变得过于内省。结果，它未能实现预期目标。——例如，团队可能会忙于开发完美的SLO定义，同时忽略了服务的需求。      没有彻底检查其工作。因此，服务管理恢复到以前的行为。——团队每天有100个工单。由于这些工单并不需要立即干预，因此被忽略。      放弃SRE原则和实践，以满足产品里程碑。——保护SLO的可靠性改进（例如架构更改）可能永远不会实施，因为它们会推迟开发时间。      由于与新SRE团队失去影响力或权力而与现有团队发生冲突而分散注意力。      没有必要的技能广度，所以只提供了必要的部分改进。——例如，如果不能进行编程，SREs可能无法测量产品的可靠性。      缓解措施  团队：          从事单一重要服务开始。      尽可能早地参与项目，最好是在设计阶段。      对设计有投入，特别关注于定义SLO和分析设计中固有的可靠性风险。      与产品开发团队合作，致力于可靠性和与现有操作平台集成的特性。      在第一天不需要承担运维责任。相反，这种责任最初由产品开发团队或项目团队承担。这可能是一个需要管理层支持的重大文化变革。      就服务必须满足的条件与SRE达成明确的协议(参见《现场可靠性工程》第32章)。  此外：      如果项目涉及到迁移，团队应该对当前和未来的环境有充分的了解。如果你的团队成员需要从外部招聘，请考虑具有软件工程和未来环境知识的候选人。      继续将新员工的数量控制在团队的三分之一以下，这样培训工作就不会压倒现有的团队成员。      横向SRE团队风险    团队被视为一个新的“门控”组织，不做真正的工作，也不增加真正的价值。缓解措施  团队：          由具有相关专业知识的受人尊敬的工程师组成。      进行项目工作，集中于交付工具(用于监视、警报、推出、最佳实践、检查列表)。这些工具应该至少对另外两个团队有短期的有益影响。      传达成功和利益。应该庆祝一个能够实现效率突破，自动化工作，或永久消除系统不可靠性的来源的SRE团队。      将自己视为推动者，而非看门人。专注于解决方案，而不仅仅是问题。      一个团队转换到位风险  团队：          认识到转换过程是自动取代人类的失业之旅的开始。      不支持对SRE团队的更改。      他们没有足够的能力来改变团队的日常活动。      几个月后，他们的日常工作毫无益处。      适用于不支持脚本或自动化的系统。      没有软件工程技能来自动化他们当前的工作量。      不具备向SRE发展所需的技能，或者对获得技能的兴趣。缓解措施        团队：          确保高层领导对变革的支持。      重新协商责任，以创建实现变革所需的空间。      非常谨慎地管理变更的沟通。      在整个过渡过程中能够获得强大的个人和技术支持。      直面对失业的担忧。在许多环境中，自动化消除了部分工作，但不包括整个工作；虽然这可能是走向失业的一步，但它至少有一个优点，那就是腾出时间去做一些比非自动化劳动更好的事情(也更适合未来的雇主)。      可以避免运维过载，并具有更大的影响。如果工程师减少了繁重的工作量，需要一个更小的团队，那么他们的经验应该在组织的其他地方得到高度重用。如果他们的经验不能在公司内部使用，那么在其他地方找工作应该会有优势。      接受培训以获得SRE需要的技能。你的产品开发团队可以提供产品培训，而SRE定位可以利用这本书和其他外部资源。      改变绩效评估的方式——评估团队和个人的指标。前者应与SLO和采用其他SRE做法相一致；后者应该与SRE技能的证据相一致。      向团队中添加一个有经验的SRE或开发人员。      具有识别和引入新的开源或基于云的监控和警报系统以实现自动化的自由度（预算或时间）。确定现有系统是否足够是早期的优先事项。      定期审查内部和利益相关方的进展情况。      规范化规范化需要克服405页“风险和缓解”中提出的问题，并就组织的SRE团队的最佳实践达成广泛一致。团队需要就可接受的工作量水平、适当的警报阈值以及重要的和相关的SRE实践达成一致。团队还需要充分主动地识别服务前的挑战，并制定中长期目标来改进服务。团队应该在规范化成熟度达到以下水平：  SLO和错误预算已经到位，错误预算政策在重大事件发生后执行。领导对SLO测量感兴趣。  值班的轮换是建立和可持续的(参见第8章)。on-call工程师可以对他们待命时间进行补偿。在重大事件中，有足够的工具，文档，和培训来支持任何团队成员。  有文档记录，有禁止事项，有管理。因此，SRE完成了有影响力的项目，提高了可靠性和效率。  事后分析文化已经确立。(参见第十章)。  团队展示了第一章列出的大部分原则。  当团队解决了405页“攻坚”中列出的初始问题时，他们会抓住他们所学到的知识并防止重复的问题。该团队定期进行演练，如不幸之轮或DiRT(灾难恢复测试)。(有关on-call培训的更多信息，请参阅我们第一本书的第11章和本书的第18章。)  产品开发团队从持续参与值班循环中获益。  团队为他们的利益相关者制作定期报告(例如，季度报告)，涵盖了报告期间的重点、亮点和关键指标。与产品开发团队建立健康的关系是许多缓解策略的基础。团队应该根据组织的计划周期一起计划工作。在继续下一步之前:停下来庆祝这一成功，写一篇回顾你到目前为止的经历。执行SRE团队的经验应该赢得更广泛的尊重和关注，并为战略的制定奠定基础。在Tuckman的performance model的最后阶段你应该期望:成为架构设计和变更的顾问    从最初的设计阶段开始，SRE应该为软件的构建和结构可靠性定义模式。主观能动性    团队应始终如一地应用原则3，以实现系统的整体健康。产品架构方面所有重大服务的变更，产品开发团队应该向SRE团队寻求意见。例如，SRE团队会在新服务体系结构设计早期介入以减少日后进行高成本改造的几率。产品开发和SRE团队需要认识到他们在架构决策方面上观点的不同，但是目的都是要达到良好的产品设计。SRE的参与在如下方面可以为产品增加价值:  提高可靠性、可伸缩性和可操作性  更好地重用现有模式  更简单的迁移(如果需要的话)自动调节工作负载尽管随着时间的推移，产品架构负责人应该以某种有机的方式出现，但是SRE团队必须明确地向其伙伴维护原则3。要做到这一点，需要强有力的团队领导能力和高层管理人员的明确承诺。管理自己的工作负载的能力确保了SRE团队作为一个工程团队的地位，该工程团队与产品开发团队一样，在组织最重要的服务上工作。在实践中，SRE团队如何确定自己的工作负载取决于与SRE接口的团队。在谷歌中，SRE团队通常与不同的产品开发团队进行交互。在这种情况下，关系具有以下特点:  SRE团队选择是否和何时上线服务(参见站点可靠性工程第32章)。  在运维超负荷的情况下，团队可以通过以下方式减少工作量:  –降低SLO  –将运营工作转移到另一个团队(如产品开发团队)  如果在约定的辛劳限制下无法在SLO上运行服务，SRE团队可以将服务交还给产品开发团队。  SRE参与不是永久的——它通过系统问题的解决和服务可靠性的提升来满足自身发展的需要。如果一个SRE团队已经解决了一个服务稳定性的问题，那么你需要:  –有意识地为SRE团队寻求其他靠性挑战。  –有意识地决定将服务交还给产品开发团队。  否则，随着SRE转向其他领域，团队可能会面临人员流失的风险。造成的缓慢流血可能会危及生产。并不是所有的SRE团队都有合作的产品开发团队。一些SRE团队还负责开发他们运行的系统。一些SRE团队将第三方软件、硬件或服务打包(例如，开源包、网络设备等)，并将这些资产转换为内部服务。在这种情况下，您没有将工作转移回另一个团队的选项。相反，考虑以下策略:  如果服务不符合其SLO，停止与特性相关的项目工作，转而支持以可靠性为中心的项目工作。  如果在约定的工作量限制下无法在SLO上运行服务，请减少懒惰——除非管理层提供更多的能力(人员或基础设施)来处理这种情况。组建更多的SRE团队一旦你的第一个SRE团队开始步入正轨，基于如下的原因我们可能还要建设另一个SRE团队：服务的复杂性随着服务复杂度的提升，单个SRE团队无法有效的支持服务的运维工作。你可能希望将团队分成专门处理服务部分的子团队。SRE上线如果你的第一个SRE团队取得了成功并有明显的不同，那么在更多的服务中采用这种方法是必要的。在地理上分离你想要在不同的时区将团队分成两部分，并改为12小时on-call的轮班制。当创建一个新的SRE团队时，我们建议执行以下操作：  阅读其他团队成立后的总结报告。找出重复做得好的事情，修复并探索那些做得不好的事情。  将现有的SEE团队成员加入到新的团队中，这些SRE新团队的骨干，以便应对挑战和风险。根据我们的经验，要找到合格的SRE候选人是很困难的，所以在新员工的帮助下快速发展团队通常是不现实的。  标准化建立团队和入职服务的框架(见第18章)。  慢慢改变值班的职责。例如：  –为了避免核心on-call工程师离职，让团队成员在一个过渡时期内为他们以前的团队系统值班。  –在团队分离后，等待三到六个月的时间来分离值班轮换。服务复杂性如何分割如果一个服务对于单个团队来说过于复杂而难以管理，那么有很多方法可以将工作分开。考虑以下选项来简化团队成员的认知负荷：结构分割例如，计算、存储和网络；前端和后端；前端和数据库；客户端和服务器；前端和管道。代码分割SRE原则不依赖于编程语言。但是，如果你的SRE深入到源代码中，那么沿着这些代码进行拆分可能会有一些好处。管理分割如果你所领导组织的工程跨越多个办公室，你可能希望将SRE团队的布置与应用程序开发联系起来。隐患当一个团队分裂时，有时新的团队中不会为原来团队所拥有的组件承担责任。为了减轻这种风险，你可以：  指定一个团队对第二团队章程之外的所有事情负责。  任命一个高级SRE在两个团队中担任一个全面的技术领导角色。SRE上线如果你最初的SRE团队成功了，那你的组织可能需要更多的SRE团队。我们建议对获得SRE支持的服务进行仔细的优先排序。考虑以下几点：  优先考虑可靠性对财务或声誉有很大影响的服务。影响越大，优先级越高。  定义最小可行的服务集，这些服务集是为了使产品能够正常工作而需要提供的。对这些服务进行优先级排序，并确保其他服务优雅地降级。  服务不应该成为SRE的优先级，因为它不可靠。在与业务最相关的领域，SRE应该在战术上得到应用。你也不希望在SREs投入使用之前让开发人员忽略可靠性。地理分割正如我们第一本书的第11章所述，Google通常在不同大洲的姐妹SRE团队中工作。我们这样做有很多原因：服务可靠性如果一个重大事件(如自然灾害)阻止一个团队工作运维服务，另一个团队可以继续支持服务。值班压力将值班轮班分成12小时轮班，为值班的工程师提供了适当的休息时间。招聘和留住人才与正常工作日重叠的值班轮班，扩大了我们可以招募到SRE工程师的基础，并强调了我们角色中的工程部分。生产期限随着文档、培训和标准化的需求变得越来越重要，跨两个办公室划分服务职责通常会促进成熟度的提高。如果你的组织足够幸运，已经在多个大洲拥有了工程团队，我们建议配备多站点SRE团队。在不同于开发团队的办公室中有一个SRE团队是可行的，但是根据我们的经验，主机托管为健康和健壮的团队间对话提供了好处。否则，SREs就很难理解服务如何发展或技术基础设施如何使用，产品开发人员也就很难对基础设施的改进感到乐观。位置：团队之间应该跨多少时区?假设你有一些选择，时区分隔是决定两支队伍位置时的一个重要考虑因素。不幸的是，目标是相互排斥的：  尽量减少值班人员在正常办公时间以外的工作时间  最大化两个团队在线时的重叠时间，这样他们就可以定期互动根据我们的经验，在相隔6至8个小时的时区工作的员工团队工作得很好，避免了12点到6点的值班轮班。你可以使用https://www.timeanddate.com/worldclock/meeting.html等在线资源来可视化不同位置来减少重叠。人员和项目：建立团队当你在地理上划分团队时，新办公室中的第一个SRE团队将为未来的SRE团队设置规范。如果你能识别出一个或多个愿意在临时或长期的基础上从原来的站点迁移来建立SRE实践、招募和培训新团队的SRE人员，你成功的可能性就会大大提高。新团队还应该承担一个高价值的项目，促进团队内部的协作，并需要与姐妹团队进行交互。平均：在办公室之间分配工作，避免“夜班”通常，两个姐妹的SRE团队中的一个与产品开发团队(我们将其称为“Office 1”)相关联(或者至少在同一个时区)。如果是这种情况，要保持警惕，以确保没有被配置的团队(“office2”)不会变成一个与产品开发团队几乎没有联系的夜班，承担过多的工作量，或者只分配给不太有趣或影响不大的项目。这两个办公室的工作量会有一些自然的差异：  你的服务可能每天都有高峰，在高峰期间会有一个办公室内的人员随时待命。因此，这两个站点的on-call体验将有所不同。  开发过程将以特定的节奏生成新版本。一个办公室人员可能会承担更多的与推出和回滚相关的负担。  Office 1在工作日更容易被产品开发团队的问题打断。  Office 1更容易承担与主要版本相关的项目工作。相反，Office 2更容易承担与即时产品目标脱钩的项目工作。你可以使用以下方法来维持平衡：  平衡办公室之间值班的工作量。分配较大比例的报警及较小比例的工单到办公室。  将开发区域与特定办公室的SRE团队联系起来，这可以是短期(例如，根据项目)或长期(例如，根据服务)的。否则，产品开发团队很可能会依赖于Office 1，而无法有效地与Office 2中的SREs打交道。  将更高比例的内部服务改进项目(这些项目可能需要较少的产品开发团队参与)分配给Office 2。  在两个办公室之间公平地传播最有趣、最有影响力的项目。  在两个办公室之间保持相似的团队规模和资历组合。  将项目分散到两个站点，有意促进两个办公室SREs之间的交互。虽然从一个办公室运行一个主要项目可能会获得一些效率，但是将两个站点的项目分开有助于传播知识并在办公室之间建立信任。  允许工程师定期去其他办公室。这可以创造更好的和谐关系，从而，愿意与对方合作。工作地点：三个地点怎么样?我们试图将SRE团队分成三个站点，结果导致了各种问题：  不可能有一个所有SREs都能参加的跨办公室生产会议(见我们第一本书的第31章)。  很难在三个办公室之间确保知识、能力和操作响应的一致性。  如果所有on-call的工作都是在办公时间内完成的，那么自动化低级工作和低价值页面的动机就会减少。在工作时间做一个解决简单问题的英雄是很有趣的。但如果它有一定的个人成本，确保它不再发生的动机是尖锐和直接的。工时机：两队应该同时首发吗?你可以使用以下任何一种模型来组建姐妹团队：  两半同时开始。  首先建立与产品开发团队合作的网站。这允许SREs更早地参与到产品生命周期中。  首先建立一个不与产品开发团队合作的站点，或者，如果一个服务已经投入生产一段时间，SRE团队和产品开发团队可以共享on-call。  根据合适的人选在合适的时间开始做出改变。财务：差旅预算为团队两部分之间的高质量交互创造机会是非常重要的。尽管视频会议对日常会议很有效，但我们发现，定期面对面的交流有助于促进健康的人际关系和信任。我们建议：  每个SRE，产品开发经理，和技术领导在站点1访问站点2每年(至少)，反之亦然。  在站点1中担任管理或技术领导角色的每个SRE每年至少访问站点2两次，反之亦然。  所有SREs至少每年召开一次会议。领导能力：共同拥有一项服务如果你有多个SRE站点，那么可能每个办公室都有决策者。这些聚会应该定期面对面和通过视频会议。只有建立牢固的个人关系，他们才能：  讨论团队面临的挑战的解决方案。  解决意见分歧，同意共同前进的道路。  为对方的团队辩护(防止“我们与他们对抗”的心态)。  支持彼此团队的健康发展。运行多个团队的实践建议当你的组织积累了更多的SREs和SRE团队时，新的挑战就会出现。例如，你必须:  确保你为SREs提供他们需要的职业机会。  鼓励操作和工具的一致性。  处理那些不适合完全参与SRE的服务。本节描述了我们在Google中为处理这些问题而采用的一些实践。根据你的组织的具体情况，有些或许多组织可能也为你工作。任务控制Google的任务控制计划使产品开发团队的工程师有机会在SRE团队中工作六个月。我们通常会将这些工程师与他们专业领域截然不同的SRE团队进行匹配。软件工程师接受生产系统和实践方面的培训，并最终随叫随到。6个月后，一些工程师决定留在SRE；其他人返回到他们的老团队，对生产环境和SRE实践有了更好的认识。SRE团队从额外的工程资源中获益，并对培训材料和文档中的漏洞和错误获得有价值的见解。SRE交换Google的SRE交换计划让SRE与不同的SRE团队一起工作一周。来访的SRE将观察主队的工作方式，并与主队分享可能对主队有用的来自主队的实践。在交流结束时，来访的SRE会写一份旅行报告，描述他们的一周，他们的观察，以及他们对两个团队的建议。这个程序在Google很有用，因为我们的SRE团队是高度专业化的。培训培训对于SRE操作系统的能力至关重要。虽然大多数培训是在团队中进行的(参见第8章第150页的“培训路线图”)，但是考虑为所有SREs建立一个标准的培训课程。在Google，所有新的SREs参加SRE EDU，一个沉浸式的为期一周的培训，介绍了几乎所有SREs工作的关键概念，工具和平台。这提供了所有新SREs的基本知识水平，并简化了特定于团队和特定于服务的培训目标。几个月后，SRE EDU团队还运行了第二系列课程，介绍了用于管理重大事件的常用工具和流程。我们的绩效管理流程特别认可为本次培训提供便利的SREs人员。横向项目因为SRE团队与一组服务紧密结合，所以对于团队来说，构建专有的解决方案来应对他们遇到的挑战是一种诱惑——例如，监控、软件推出和配置工具。这可能导致跨团队工作的重大重复。虽然允许许多解决方案竞争“市场”采用是有价值的，但在某些时候，将标准的解决方案聚合在一起是有意义的：  满足大多数团队的需求  提供一个稳定的、可扩展的平台，在此基础上构建下一层创新Google通过使用横向团队来完成这些工作，横向团队通常由经验丰富的SREs人员组成。这些横向团队构建并运行标准解决方案，并与其他SRE团队合作以确保顺利采用。(有关横向软件开发的更多信息，请参阅第21章第432页的“案例研究2：SRE中的通用工具采用”。)SRE流动性Google尽最大努力确保工程师积极地想成为各自团队的一员。为此，我们确保SREs能够（并意识到他们能够）在团队之间进行转移。假设没有性能问题，SREs可以自由地转移到其他人员开放的SRE团队。SREs也通过了我们软件工程师职位的招聘标准，他们可以自由地转到产品开发团队(参见http://bit.ly/2xyQ4aD)。这种流动性水平对于个人和团队来说是非常健康的，原因有很多：  工程师能够识别并占据感兴趣的角色。  如果个人情况发生变化，on-call的职责变得不切实际，SREs可以在要求较少on-call职责的团队中探索机会。他们可以通过与其他团队交谈和查看团队值班的统计数据来获得这些信息。  在团队之间移动的SREs扩大了他们加入的团队的经验。  SREs在办公室之间流动有助于建立或保持不同办公室之间的文化一致性。  SREs不会被强迫去做不健康的服务，或者为那些不支持个人发展的经理工作。这个策略还有一个副作用，就是让你的SRE经理专注于健康快乐的服务和团队。团建除了保持地理上分散的团队健康所需的旅行（见第417页的“财务：旅行预算”一节），考虑以下方面的资金：  建立公司内部感兴趣的社区，包括来自多个办公室的SREs。这类团体可以通过电子邮件和视频会议进行广泛的合作，但至少每年面对面交流一次。  参加并出席全行业的SRE和与SRE相关的会议，以拓宽知识，了解其他组织如何处理类似问题，并希望得到启发和激励。启动协调工程小组正如我们第一本书的第27章所描述的，启动协调工程(LCE)团队可以将SRE原则应用到更广泛的产品开发团队中——这些团队构建的服务不需要引起值得SRE参与的注意级别。就像其他的SRE团队一样，LCE团队应该积极地参与日常操作的自动化。例如，开发标准工具和框架使产品开发团队能够在生产环境中设计、构建和启动他们的服务。卓越生产随着组织中SRE团队数量的增长，将出现许多最佳实践。每个SRE团队的发展都是不同的，因此评估它们需要深入了解多个团队的高级SREs。在Google，我们定期进行名为Production Excellence的服务评估。高级SRE领导定期检查每个SRE团队，评估他们的一些标准度量(例如，工单负载、错误预算使用、项目完成、bug关闭率)。该评论既赞扬出色的表现，也为表现不佳的团队提供建议。经验丰富的SRE可用于评估细微差别。例如，将团队合并或拆分导致的项目完成率下降与真正的团队性能问题相比，是一项具有挑战性的工作。如果一个团队有被淹没的风险，评审员可以也应该利用他们的组织地位来支持团队的领导来纠正这种情况。SRE资金和招聘在Google，我们使用两种做法来确保每个SRE都贡献了显著的价值：  大部分SRE资金来源于产品开发团队的资金来源。与测试或安全类似，可靠性是产品开发的核心支柱，并为此提供资金支持。  根据我们的经验，SREs的供应总是小于需求。这一动态确保我们定期审查和优先考虑得到SRE支持的服务。简而言之，你应该有比组织想要的更少的SREs，并且只有足够的SREs来完成他们的专业工作。在Google中，产品开发团队中SREs与工程师的比例从1:5左右(例如，低级基础设施服务)到1:50左右(例如，使用标准框架构建大量微服务的面向消费者的应用程序)。许多服务在这一范围的中间，比率约为1:10。结论我们相信任何规模的组织都可以通过以下三个原则来实施SRE实践：  SRE需要带有结果的SLOs。  SRE必须有时间让明天比今天好。  SRE团队有能力调整他们的工作量。自从Google开始公开谈论SRE，它已经从Google特有的生产实践发展成为许多公司的专业实践。这些原则经常被证明是正确的——无论是在我们多年的大规模直接经验中，还是在我们最近与客户一起采用SRE实践的经验中。因为我们已经看到这些实践在Google内部和外部都起作用，我们认为这些建议应该在不同类型和规模的组织中被证明是有用的。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十九章 SRE：超出界限]]></title>
      <url>/sre/2020/01/19/SRE-%E8%B6%85%E5%87%BA%E7%95%8C%E9%99%90/</url>
      <content type="text"><![CDATA[距离我们开始在Google上练习SRE已有14年了。 回想起来，当时的一些成果似乎是显而易见的，而其他发展则令人震惊。 我们出版第一本SRE书的两年以来特别有趣。 现在正在实施SRE的公司数量以及我们在会议和客户的谈论中关于它的时间已经超出了我们之前的想象。特别是这种变化 – 围绕SRE的非谷歌生态系统的快速扩张 - 是最令人兴奋的，但它使得预测SRE行业的未来变得更加困难。 尽管如此，我们自己在谷歌的SRE工作中，开始看到一些可能为行业未来提供概述信息的趋势。 本章代表了我们分享 自己以及全球SRE同事所看到的，以及迄今为止所努力得出的结论。真理不言而喻对未来有任何意义的唯一方法就是从基本的原则开始，然后继续前进。接下来的事情应该是没有争议的。其他的就没那么多了。然而，在任何情况下，这些原则都是基于我们在世界上看到的真实事物。可靠性是最重要的特征当我们断言“可靠性是任何系统最重要的特征”时，人们通常不会进行反驳，只要我们小心地指出“可靠性”通常覆盖很广的领域。很容易找出充足的证据：  如果一个系统不可靠，用户就不会信任它。  如果用户不信任一个系统，当有其他的选择时，他们不会使用它。  由于所有软件系统都受网络效应控制，如果一个系统没有任何用户，那么它就一文不值。  你就是衡量标准，因此请仔细选择您的指标。决定你的可靠性是用户，而不是监控，系统的价值与它的用户息息相关，因此可靠性的唯一衡量标准的关键就是用户体验的可靠性。如果你的用户怀疑是你的平台造成了他们的故障，在这时告诉他们“我们的监控一切正常，因此问题一定出现在你们那边”，不会让用户的情绪好转，用户体验到你的系统不稳定，当你和你的竞争对手之间做出选择时，客户会想起这一点。（这种现象被称为峰值规则）你的监控，日志和报警只有帮助你赶在客户之前发现问题的情况下才有价值。如果你运行一个平台，那么可靠性就是合伙人如果其他人使用你系统的唯一方式是通过可视化用户界面（例如，网页），并且你的系统仅由真人（而不是机器）使用，那么你用户体验的可靠性几乎只与你作为一名SRE所从事的保障系统可靠性的工作有关。但是，一旦你添加了一个API，并且你的一些“用户”实际上是其他机器，那么你的运行平台的规则就已经改变了。当您的产品充当平台时，用户体验的可靠性并不局限于您的选择。 可靠性就成为一种合作关系。 如果您的用户在您的平台上构建或运行的系统永远不会达到99％以上的可靠性 - 即使您以99.999％的可靠性运行您的平台 - 那么他们的最佳案例体验是98.99901％。这些用户的选择直接影响他们的体验，并与您的服务相关联。你可能不会喜欢，但他们会让你对他们所经历的一切负责，即使这不是你的错。任何重要的东西最终都会成为一个平台由于系统的价值随着使用它的人数的增加而增加，因此你需要找到访问其他大型已建立的用户池的方法。当您吸引更多的用户时，其他软件系统也想要接触您的用户。这是其他公司开始让他们的机器通过API与您的机器通信的时候。如果您的系统非常流行，那么集成是您的发展中不可避免的一步。即使您决定不关心其他用户社区，并决定永远不会创建机器可使用的API，您仍然无法避免这种未来。 其他人会简单地把您的UI包装到机器API中并使用它。 唯一的区别是你无法控制结果。一旦您的系统成为大量用户的网关，它就变得很有价值。 APIs – 官方或非官方的 – 将成为您未来的一部分。当你的客户遇到困难时，你必须放慢速度当你的客户遇到困难时，他们的挫败会变成对你的摩擦。即使您没有传统的支持模式(故障工单、电子邮件、电话等)，您仍然会花时间通过StackOverflow，甚至Twitter、Facebook和其他社交平台来处理问题和回复投诉。无论你投入到帮助用户度过难关的精力有多少，你都不能投入于改进你的系统。我们已经看到许多团队(和公司)允许他们的时间慢慢地被中断/修复客户问题所占用——留下一个不断减少的创新预算。这些团队被辛劳所消耗。一旦进入这种状态，就很难发现(见第6章)。你可能在读这篇文章的时候会想，哎呀，我只是内部平台团队的一员。这对我不适用!我们很抱歉地通知您，这对您来说是加倍适用的!在您的案例中，您的客户是您公司系统的消费者。这就引出了下一个结论。你需要和你的客户一起练习SRE如果你想让你的客户使用你的平台来设计和运行可靠的系统，你必须教会他们如何操作。是的，这也包括你的内部客户。仅仅因为您在内部平台团队工作并不意味着您可以逃离这个动态过程——事实上，您最有可能首先遇到它。即使您可以将这些信息完美地提炼成高度伸缩的一对多表单(书籍、博客帖子、架构图、视频等)，您仍然需要一种方法来确定要包含哪些内容和培训。随着你平台的成长和完善，这些经验教训将会改变。您总是需要一种方法来防止这些资源变得陈旧。学习这些经验的最好方法就是和你的用户一起“do SRE”。这并不一定意味着您需要为用户的系统创建页面调度程序，但您确实需要承担通常导致页面调度程序切换的大部分工作（意味着系统已满足某些最低可行的可靠性要求）， 至少是您用户的代表性样本。怎样:  和你的用户一起实践SRE与用户一起实践SRE的想法似乎有点令人生畏，你读这本书的原因可能是你自己都不知道该如何去做。不过不同担心，两者可以同时进行，实际上，前者可以帮助你加速后者。下面是我们要遵循的步骤，它对我们很有帮助，并且我们认为也同样会对你有所帮助。步骤一: SLOs and SLIs Are How You Speak你希望你的用户认为你的系统是可靠的。否则，你就有可能失去他们。因此，你应该非常关心他们是如何形成这些观点的。它们度量什么？它们是如何度量？最重要的是，这些度量对用户做出了什么承诺？如果您的用户度量SLIs并对SLOs保持警惕，并且与你共享这些度量值，您的生活会好得多。否则，你会花费很多的精力在这样的对话中:  用户：API调用X通常需要时间T，但现在需要时间U.我认为你们出现了一些问题。 请仔细研究并立即回复我。  你：这种表现符合我们的预期，一切看起来都很正常。 如果API调用X确实需要这么长时间，这有问题吗？  用户：我不清楚。 这个过程通常不需要这么长时间，所以中间发生了一些变化，我们对这种变化感到担忧。这场对话将会循环下去，并且永远不会有一个满意的结果。你要么花费大量时间去说服你的用户这不是他们应该关心的，要么您将花费大量时间在这个变化产生的根本原因上，以便你可以说服你的用户他们没必要关心。在任何一种情况下，你都花费了很多精力，而这些精力本可以用在其他地方。这个问题的根本原因是用户没有使用SLO来确定他们是否应该关心他们所看到的性能。 他们只是注意到一个无法解决的问题，你的用户将不可避免地发明一个而不会告诉你，直到你不满足它！ 你更喜欢这个对话：  用户: 我们对应用程序FOO的SLO消耗得太快，应用程序处于危险之中。SLIs的 X和Y都呈现断崖式下跌，它们都依赖于你的API X。  你：好的。让我看一下API X是如何在我的系统中执行的/或它的具体表现。这是一个更有效的对话，因为：（a）它只会在SLO受到威胁时才会发生。（b）它依赖于相互理解的度量（SLIs）和目标（SLOs）。如果你使用SRE实践来运行你的系统，那么你在内部说的是SLOs。如果你的用户也讲SLO，你的日子会更好过，你的用户也会更舒心，因为这会让你们更容易对话。我们建议你做一个简单的练习，让你与用户的工作关系变得更好: 与用户坐下来，解释一下SLOs、SLIs和错误预算——尤其是如何在团队中实践它们。然后帮助他们用这些术语描述他们在你的平台上构建的关键应用程序。步骤二: 审核监控和构建共享仪表板一旦您的用户为他们的应用程序选择了一些基本的SLOs，下一个问题就是他们是否度量了正确的东西来确认他们是否达到了这些目标。您应该帮助他们确定他们使用的度量是否合适。根据我们的经验，您的用户度量（和报警）的事物中有多达一半对他们的SLOs没有任何影响。 当你向他们指出这一点时，你的生活将变得更好，他们会关闭令人讨厌的报警。 这对他们来说意味着更少的页面，对你而言也是如此！其余的度量是有用的候选SLIs。帮助您的用户聚合这些度量数据，以计算他们的SLOs。一旦开始这个练习，您很快就会很快知道SLOs的一部分已经被发现——没有相关的度量方法来说明这些维度的任何有用之处。您还应该帮助客户覆盖他们SLOs的这些部分。现在，你的客户可以开始在你的平台上谈论他们的应用程序的SLO性能了。最后，与客户构建一组共享的SLO仪表板。您应该能够看到他们的应用程序SLOs，并且应该共享您所拥有的任何与他们体验您的系统性能相关的信息。您的目标是，当您的客户因为他们的SLO似乎受到威胁而联系您时，您都不必交换太多额外的信息。所有这些信息都应该在共享的监控中。步骤三: 测量和协商一旦你把测量数据整理出来，你应该收集一两个月的数据。准备好面对你的客户可能会突然觉醒的可能性。他们认为应用程序运行在“五个9”(99.999%;每个人都认为他们得到了五个9)的情况下，如果与他们闪亮的新SLOs相比，可能只有99.5%-99.9%。在最初的震撼消失之后，是指出他们的用户并不是一直在大喊大叫的好时机，所以他们可能从来不需要他们真正没有得到的5个9。问题的关键在于，他们的用户对应用程序的性能有多满意?如果他们的用户满意，并且没有证据表明提高性能或可靠性会增加用户的采用/保留/使用，那么您的目的就达到了。你应该定期问自己这个问题，以确保你的预算和优先事项是正确的。(有关此主题的更深入的讨论，请参阅第2章。)如果客户认为他们仍然需要做得更好，那就继续下一步。步骤四: 设计评审和风险分析与客户坐下来，真正了解他们的应用程序是如何设计和操作的。他们是否有隐藏的单点故障（SPOFs）？他们有部署和回滚的预案吗？基本上，对你自己的内部应用再进行同样的练习。接下来，根据每个项目消耗的错误预算的大小对您找到的问题进行排名。(阅读更多关于如何在Google云平台博客上执行此操作的信息。)，注意客户选择修复哪些项目以“赚取他们想要的9”(例如，从99.5%调整到99.9%)。您从这些评论中所学到的知识将告诉您：  您的客户如何使用您的平台  这样做会造成什么样的可靠性错误？  当他们试图改进时，会如何进行权衡。此练习还将帮助您的客户围绕他们当前应用程序应该具有的可靠性来设定切合实际的期望。 他们的期望会影响他们的看法，因此恰当地设定期望只会有助于赢得和保持他们的信任。步骤五: 练习,练习,再练习最后一步是为您的客户创建一些操作严谨性。 模拟故障（不幸之轮练习，故障与恢复测试，纸质游戏日等）。在团队之间建立健康的肌肉记忆，以便在危机期间进行有效的沟通。 这是建立信任，降低MTTR以及了解一些奇怪操作极少cases好方法，您可以将其作为增强功能集成到平台功能中。当故障发生后，不要只与您的客户分享您的结论。 实际上进行一些故障复盘。 这样做也将建立信任并教给你一些宝贵的经验教训。需要考虑和训练的在一小部分客户之外，很快就不可能执行以上这些步骤。请不要尝试将此模型扩展到每个人身上。相反，你应该做一些有原则的决定来决定如何做出选择。以下是一些常见的方法:收入范围选择占你收入XX%的最小客户数量。如果你的收入主要集中在几个大客户身上，那么这可能是你的正确选择。功能范围选择覆盖平台特性XX%以上的最小客户数量。如果你运行一个高度多样化的平台，有很多客户做着不同的事情，那么这种方法将帮助你避免意外。工作范围您的平台的使用可能由几个不同的用例或客户类型主导。 也许这些类型的客户中没有一个是占主导地位的，但您可以轻松地将他们分类成不同的群组。 在这种情况下，从每个群组中抽取一个或两个客户是获得平台覆盖率并发现用例之间的操作差异的好方法。无论你选择什么方法，坚持下去。 混合和匹配使用会使您的利益相关者感到困惑，并迅速压垮您的团队结论在过去的几年里，SRE的职业和角色已广泛传播到谷歌之外。 尽管我们从未预料到这一点，但我们仍然为之激动不已。 我们或许可以说一些关于我们如何认为该学科将在谷歌内部发展的值得信赖的话，但在外界，这是一个“令人不安又刺激”的主张。我们非常确定的一点是，当您将SRE原则应用到您的组织中时，您将跨越许多与我们相同的拐点(有些我们没有!)—包括需要在您客户的终点和您的起点之间模糊界限。在这样的操作深度下与个别客户打交道，对我们来说是一个很有价值的新领域，我们仍在这条道路上走得很远。(你可以在线关注谷歌云平台博客。)然而，我们走得越远，我们就越确信这是你们也需要经历的。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十八章 SRE：参与模式]]></title>
      <url>/sre/2020/01/18/SRE-%E5%8F%82%E4%B8%8E%E6%A8%A1%E5%BC%8F/</url>
      <content type="text"><![CDATA[我们的第一本书的第32章，描述了SRE团队分析和提高服务可靠性的技术和方法。其中包括：生产成熟度评审（PRR）、早期参与和持续改进。简而言之，SRE的目标是在保证产品可靠性的前提下，最大限度的提高开发团队的项目进度。这对用户和公司而言都是有益的。但是，即使最好的SRE团队所能完成的工作也是有限的，并且当范围太大且过于复杂时，SRE模型就不那么的有效了。当前，小公司拥有微服务的个数通常比单个SRE团队能处理的要多。鉴于生产环境较大，并且无法涵盖所有服务，SRE团队必须将注意力集中在能够获得最佳效果的地方。产品开发和SRE团队可以一起确定正确的关注目标。本章采用某SRE团队的视角，该团队准备为新服务提供支持。我们着眼于如何与负责该服务的开发和产品团队一起有效地提供服务。虽然SRE通常“参与”一个或多个服务，但“参与”所涉及的内容远不止服务本身——它侧重于理解开发和产品团队的目标，并找到支持他们的正确方法。以下的大多数讨论适用各种组织规模。虽然我们经常使用团队这个词，但理论上“团队”也可以从单人开始（尽管会很忙）。无论团队规模如何，主动定义SRE的角色以及管理与产品开发的沟通和协作十分重要。服务生命周期正如《Google SRE运维解密》的前言所述，SRE团队对服务可靠性的贡献贯穿于服务生命周期的所有阶段。在任何SRE为服务提供on-call之前，他们对于生产知识和经验的应用，都可以大大提高服务的可靠性。图18-1显示了服务生命周期中SRE参与的理想情况。但是，SRE团队可能在服务生命周期的任何阶段参与服务。例如，如果开发团队计划将SRE所支持的服务进行替换，则SRE可能很早就会参与新服务。又或者，服务可用数月或数年，且现在面临可靠性或可伸缩性的挑战时，SRE团队可能会正式参与该服务。本节提供有关SRE团队如何在每个阶段实现自身价值的方针。 图18-1: 服务生命周期中SRE的参与程度 阶段1：架构和设计SRE可以以多种方式影响软件系统的体系结构和设计：  提供开发团队在构建新产品时可以采用的最佳实践，例如单点故障自我恢复的能力。  (基于经验）记录特定基础设施系统的注意事项，以便开发人员可以正确的选择并使用构建模块，避免已知陷阱。  参与前期讨论，详细讨论具体架构和设计选择，并在目标原型的帮助下验证假设。  加入开发团队参与开发工作。  协调部分服务。到了开发周期的后期，是很难修复由架构选型导致的错误的。SRE在早期参与有助于避免在系统与实际用户交互时需要进行高成本的重新设计，或根据服务增长进行扩展。阶段2：积极发展随着产品在积极开发过程中完成，SRE便可以开始“生产化”服务——使其成型并投入生产。生产化通常包括容量规划，为冗余设置额外资源，规划尖峰和过载处理，实施负载均衡，以及实施可持续运维实践，如监控，报警和性能调优。阶段3：有限的可用性随着服务向Beta发展，用户数量，用例的多样性，使用强度以及可用性和性能需求都会增加。在此阶段，SRE可以帮助衡量和评估可靠性。我们建议在常见可用性（GA）之前先定义SLO，以便服务团队客观的衡量服务的可靠性。产品团队可以选择撤回无法达到目标可靠性的产品。在此阶段，SRE团队还可以通过构建容量模型，为即将到来的启动阶段获取资源以及自动化调整和弹性调整扩展系统。SRE需要确保合适的监控范围，帮助即将到来的的服务创建与其SLO相匹配的报警配置。服务使用情况一直在变化，且SRE团队仍需要了解服务如何工作以及如何管理其故障模式，所以团队在事件响应和运维操作期间的工作量仍是增加的。我们建议开发人员和SRE团队能共同承担此项工作。这样，开发团队就可以获得服务的运维操作经验，且SRE可以获得常见的服务经验。运维工作和事件管理将在GA之前告知系统变更并发布服务所有者需要进行的变更。第4阶段：一般可用性在此阶段，该服务已通过生产准备审核（详细信息请参阅《Google SRE运维解密》中的第32章），并被所有用户接受。虽然SRE通常执行大部分的操作工作，但为了保险起见，开发人员团队需要继续完成所有操作和事件响应工作的小部分内容。可以在on-call轮值中安排一名开发人员，帮助开发人员持续跟踪业务负载。在GA的早期阶段，由于开发人员专注于服务的成熟以及发布第一批新功能，因此需要进行轮值来了解实际负载下的系统属性。在GA的后期阶段，开发人员主要提供小的新增功能以及一些bug修复，其中的一些功能和bug恢复需求来源于操作需求和已发生的生产事件。第5阶段：弃用没有系统能一直运行。如果有更好的替代系统，那么现有系统将对新用户关闭，所有工作都侧重于将用户从现有系统转换到新系统中。在没有开发团队参与的情况下，SRE将运维现有系统，并支持开发和运维工作的过渡。虽然减少了现有系统所需的SRE工作量，但SRE实际上是同时支持两个完整系统，所以需要适当调整人员以及人员配置。第6阶段：被遗弃一旦服务被遗弃，通常，开发团队将接手运维工作。在此过程中，SRE会尽力提供支持。对于具有内部用户的服务，SRE将服务管理权限移交给这些用户。本章提供了两个案例研究，说明SRE如何将服务归还给开发团队。第7阶段：停止支持没有用户且服务已关闭时。SRE会帮助删除生产配置和文档中引用服务的部分。建立联系服务不是凭空存在的：需要SRE团队与构建服务的开发团队以及确定发展方向的产品团队合作。本节介绍了与这些团队建立和维持良好工作关系的方法和策略。交流业务和生产优先事项你在帮助别人之前肯定需要了解其需求。同理，SRE也需要了解产品开发人员期望SRE参与实现的目标。在与开发团队合作时，SRE应深入了解产品和业务目标，了解自身角色以及如何参与帮助开发人员实现这些目标。团队需要定期就业务和生产优先事项进行沟通。理想情况下，SRE和开发领导团队应该作为一个整体进行工作，定期开会交流技术和优先级问题。SRE领导甚至可以加入产品开发领导团队。识别风险由于SRE团队专注于系统可靠性，能很好的识别潜在风险。由于中断开发的成本和功能流对产品和工程师很重要，因此要尽可能准确的衡量这些风险的可能性和潜在影响。目标一致开发人员和SRE团队都很关注可靠性、可用性、性能、可扩展性、效率、功能和发布速度。然而，SRE的主要目标和动力是为了支持服务在新功能发布后的长期可靠性。根据我们的经验，开发人员和SRE团队既可以通过维护自身团队的目标来达到平衡，也可以通过支持对方团队的目标实现平衡。SRE可以设立明确的目标来支持开发团队的发布上线，并确保所有已审批通过的版本上线成功。例如，SRE可能会表明：“我们将尽可能快的支持你安全发布上线”，其中“安全”通常意味着保持在错误预算范围内。开发人员应该投入一定的时间去修复或预防一些有损可靠性的事情上：解决设计和实施层面的在线服务问题，解决遗留技术问题，尽早在新功能开发时让SRE参与设计。   共同目标：纽约时报的SRE   作者：Surya Prashanth Sanagavarapu (New York Times)  当涉及到云迁移，生产过渡期或向容器部署应用时，我们对SRE资源的需求会很大。此外，SRE团队还有自身积压的工作要解决。面对有限的资源，SRE团队的成功在于合理的安排互不兼容的事务的优先级。虽然雇佣SRE是解决SRE时间需求的一种方式，但并非每个团队都有额外的成本、足够的经验或时间。  “纽约时报”SRE职能的核心使命是为产品开发团队提供工具和流程,最大程度的支持新闻编辑室的应用的可靠性和弹性，从而为读者提供高质量的新闻报道。我们采用了共享目标模型，在减少自身工作积压和团队合作之间获取平衡。  在与团队合作之前，我们会审核当前季度/年度的总体积压，明确定义工作项目和类别。例如，我们的待办事项可能包括：      通过点击应用的服务状态按钮，添加自动化设置基础监控和报警。    实施更可靠和/或更快的构建管道。    当有团队向SRE寻求帮助时，我们确定请求优先级时考虑的因素之一是参与进去是否有助于减少我们的工作积压。  定义参与度  我们的SRE根据两种不同的模型与产品开发团队合作：      全职模型    相对简短和受限制项目的兼职模型    我们根据SRE团队的参与度定义参与模型。对于全职参与，我们更愿意将SRE嵌入产品开发团队，这样有助于提供时间和精力来减轻产品开发团队的负担。随着开发人员SRE技能和能力提高的同时，SRE和产品团队有更多的时间来了解彼此。对于长期合作，我们优先考虑最适合我们公司战略的应用  在定义参与范围时，我们尝试衡量团队或应用与SRE实践相关的成熟度。我们发现，在考虑SRE实践和原则时，每个团队处于不同的水平。我们正努力使用应用成熟度模型来提供帮助。  设定共同的目标和期望  对于任务的最后期限和完成度而言设定正确的目标十分重要。为此，我们按照以下原则工作：      我们强调，应用所有者（非SRE）直接负责对应用进行更改。    SRE参与是为了公司范围的利益。任何新的自动化或工具都应该同时改进整个公司使用的常用工具和自动化，避免一次性的脚本开发。    SRE应该让开发人员团队提前了解可能会引入的新流程（例如，负载测试）。    参与应用准备评审（ARR）和生产就绪程度评审（PRR），如《Google SRE运维解密》第32章所述。ARR和PRR的拟议变更必须优先由开发人员和SRE共同考虑。    SRE不是传统的运维工程师。他们不支持手动工作，例如运行部署作业。    我们会与开发团队一起明确目标，并将目标划分为一个个里程碑。如果你是一家基于敏捷开发的公司，你可以撰写描述或综述。SRE团队可以将这些目标映射到他们的待办事项中。  设定目标时我们的共同模式是：      确定参与范围。   示例1：在下一季度，我希望团队的所有成员都能够处理GKE/GAE部署，熟悉生产环境，并能够处理生产故障。   示例2：在下一季度，我希望SRE与开发团队合作，在扩展和监控方面保证应用稳定性，针对故障有运行手册和自动化任务。    确定并明确标出最终结果成功案例。   示例：参与后，产品开发团队可以在不升级的情况下处理Google Kubernetes Engine的服务故障。    冲刺和沟通  任何与产品开发团队的合作都始于发布和计划会议。在发布之前，我们的SRE团队会审核应用架构和我们的共同目标，验证在给定时间范围内预期结果是否切合实际。相互参与可以从创建描述和综述的联合计划会议开始。  这种参与的流程可能是：      查看应用架构。    定义共享目标。    举行启动和计划会议。    进入开发周期以达到里程碑。    进行回顾来获得参与方的反馈。    进行生产就绪程度评审。    进入开发周期以达到里程碑。    计划、执行发布。    我们要求团队定义反馈方法并就反馈频率达成一致。SRE和开发团队都需要有关工作和非工作的反馈。为了让这一举措获得成功，我们发现通过协商提供持续的循环反馈是有效的——例如，每两周一次进行审查或与团队经理确认。如果相互参与不起作用，我们也不希望团队回避并减少接触。  衡量影响力  为了确保SRE从事高价值的工作，对SRE参与工作的影响力进行衡量十分重要。为了方便SRE确定最有效的方法，我们还衡量每个合作团队的成熟度级别。我们与Google客户可靠性团队（CRE）团队合作，并在开始参与之前与产品工程团队的负责人进行时间点评估。  时间点评估包括遍历成熟度矩阵，衡量服务的成熟度，依据SRE关注的各个方面开展（如《Google SRE运维解密》第32章所述），并就功能区域的各个方面达成一致，如可观察性、容量规划、变更管理和事件响应处理。在进一步了解团队的优劣和盲点之后，有助于更好的确定SRE参与度。  在SRE完成工作且开发团队可以自行发布之后，我们会再次评估衡量SRE参与的价值。如果我们有一个成熟度模型，我们会根据模型进行衡量，看看参与度是否会带来更高的成熟度。设定基本规则在Google，每个SRE团队都有两个主要目标：短期   通过提供可用、可按需扩展、操作稳定的系统来满足产品的业务需求，立足于系统的可维护性。长期   将服务的运维操作优化到不需要持续人工投入的水平，这样SRE团队可以继续开展下一个高价值的工作。为此，各小组就某些合作原则达成一致，例如：  业务工作的定义（和硬性限制）。  通过商定和衡量服务SLO来明确开发人员和SRE团队工程工作的优先级。你可以在没有SLO的情况下工作，但我们的经验，项目开始时还未确定SLO及工作优先级意味着在后面的工作中将回溯到此步骤。有关如何在没有SLO的情况下理想地进行工程工作，请参阅第427页的“案例研究1：将Waze从AdHoc扩展到计划变更”。  商定季度错误预算，确定发布速度和其他安全系数，例如处理意外使用增长的超额服务容量。  为确保持续存在的问题得到关注并确定修复根本原因的优先级，开发人员需要参与日常运维中。计划与执行为确保SRE团队在优化和降低运维成本的同时达到预期和产品目标，需要主动规划和协调执行。我们建议在两个（相邻）阶段进行规划：  在开发人员的领导下，确定产品和服务的优先级，并发布年度企划图。  定期审查和更新路线图，并得出与路线图一致的目标（季度或其他）。路线图确保每个团队拥有清晰、高效工作的长期时间线。可能会有充分的理由（例如，开发组织变化太快）来放弃路线图。但在稳定的环境下，缺乏路线图可能是SRE团队与其他团队合并，将服务管理工作移交回开发团队，甚至是解散的信号。与开发领导层保持持续的战略对话有助于快速确定工作重点，讨论SRE为业务增加价值的新机会，或停止对产品而言没有成本效益的工作。路线图可以专注于改进产品，还可以解决如何应用和改进常见的SRE技术和流程以降低运维成本。保持持续有效的关系健康有效的关系需要不断的努力，本节简述了对我们而言效果非常好的策略。投入时间共同努力投入时间相互协作这种简单的行为有助于SRE和开发人员更有效的协作。我们建议SRE定期与开发人员当面沟通确保其运维的服务稳定性。SRE还可以定期与其他SRE团队沟通，这些团队运维的服务可以向本团队负责的服务提供流量或提供服务使用的通用基础架构。因为团队已经彼此了解并且设定了如何启动和管理升级的期望目标，这样，在故障或意见分歧期间，SRE团队可以自信且迅速的升级事件。保持开放的沟通渠道除了之前提到的团队日常沟通之外，我们还发现了一些更加正式的信息交换方法，这些方法在参与过程中十分有效。SRE可以与产品领导进行季度“生产状态”谈话，帮助他们了解应该在何处投入资源以及SRE如何帮助他的产品或服务。类似的，开发人员可以定期向SRE团队提供“产品状态”，或者让SRE参与开发团队的执行演示。向SRE团队概述了开发团队在上季度所取得的成就（并让SRE了解他们自己的工作要如何实现）。还提供了产品未来几个季度的最新信息，以及让产品负责人了解SRE在哪些方面发挥了作用。定期执行服务评估作为服务的未来决策者，SRE和负责该服务的开发团队每年至少应该见面一次。也许很难更频繁的开会-例如，可能涉及洲际旅行。在会议期间，我们通常会分享未来12-18个月的路线图，并讨论新项目和发布会。SRE团队有时会进行回顾讨论团队想要停止做什么，继续做什么以及开始做什么。项目可以出现在多个区域且这些意见都是有效的。最好的结果通常是全团队都参与的，所以需要积极促进这些会议。这些会议产生的细节可以推动重大的服务变更，因而被评为服务会议中最有用的会议。当规则开始变化时要重新评估如果之前协商的部分（参见379页的“设置基本规则”）开始回滚，开发人员和SRE都需要更改优先级以使服务恢复正常。我们发现，根据紧急程度，意味着可能发生以下任何一种情况：  团队指定的工程师必须放弃低优先级任务，专注于回滚。  两个团队都号称“可靠性黑客马拉松”，但通常团队的优先级是在黑客马拉松之上的。  停止功能开发，两个团队的多数成员都专注于解决回滚问题。  技术领导层确定产品的可靠性存在严重风险，团队要“全力以赴”的响应。根据你的SLO和错误预算调整优先级指定明确的SLO有助于团队安排工作优先级。如果服务存在丢失SLO或存在用完错误预算的风险，那么两个团队的高优先级工作应该是使服务恢复安全。他们可以通过战术措施（例如，超额配置以解决与流量相关的性能回滚）和更具战略性的软件修复（例如优化，缓存和优雅降级）来降级此类情况。如果服务在SLO内且剩余错误预算充足，我们建议使用备用错误预算来提高功能迭代速度，而不是在服务改进上花费过多的精力。妥善处理错误人总会犯错。和我们的事后文化一致，我们不会责怪某个人，而是专注于系统行为。你的情况可能和我们不一样，但以下策略也可以作为参考。三思而后行如果可能，请勿在疲惫或情绪高涨时进行后续对话。在高压力时，人们很容易误解书面交流如电子邮件中的语气。读者会记住这些词语让他们产生何种感受的，当你在异地进行通信时，通常应该进行视频聊天，这样你可以看面部表情，听到的词语语调也可以帮忙消除原本可能产生的歧义。当面（或尽可能近的）解决问题仅通过代码审查或文档交互很难让人集中注意力。当另一个团队的行为或决定与我们预期的不一致时，我们会和他们讨论并询问为何没有达到预期。要乐观要感谢别人积极主动的行为。做起来可能很简单-例如，在代码审查，设计审查和故障场景培训期间，我们要求工程师介绍出彩的内容。你可能注意到优秀的代码注释或感谢人们愿意花时间投入设计审核。了解沟通的差异不同的团队对如何传播信息有不同的预期，了解这些差异有助于加强团队的关系。将SRE扩展到更大的环境目前为止，我们讨论的场景涉及一个SRE团队，一个开发团队和一个服务。较大的公司，甚至是使用微服务模型的小公司，可能需要扩展部分或全部团队规模。单个SRE团队支持多项服务由于SRE需要专业技能并且是稀缺资源，因此Google通常将SRE与开发人员的比率保持在&lt;10%。因此，一个SRE团队通常与其产品领域（PA）中的多个开发团队合作。如果SRE的数量不足以支持需要面对的服务数，是，那么SRE团队可以将精力集中到一项服务，或者集中在开发人员较少的一些服务上。根据我们的经验，如果这些服务具有以下特征，你可以将有限的SRE资源应用到多个服务中：  服务是单一产品的一部分。提供了用户体验的端到端所有权以及与用户的一致性。  服务建立在相似的技术栈上。可以最大限度的减少认知负担，有效的重用技术技能。  服务由同一开发团队或少数相关开发团队构建。这样可以最大限度的减少关联数量，便于商定优先级。构建多个SRE团队环境如果你的公司足够大，拥有多个SRE团队，或许还有多个产品，那么你需要选择SRE和产品组相关联的合适的架构。在Google，我们支持复杂的开发人员组织。如图18-2所示，每个PA由多个产品组组成，每个产品组包含多个产品。SRE组织以层次结构的方式影响开发人员组织，每个级别都有共享的优先级和最佳实践。当一个组中的所有团队或PA中的所有组都共享相同或相似的特定业务目标，且每个产品组都有产品领导和SRE领导时，这个模型都是有效的。 图18-2. 大规模的开发者与SRE团队关系图（每个产品领域） 如果你的组织有多个SRE团队，你需要以某种方式对其进行分组。我们发现有两种主要的分组方式：  将团队分组到产品中，这样他们就不必与太多不同的开发团队协调。  将团队分组到技术栈中（例如，“存储”或“网络”）。为了防止在开发人员重新开发的期间SRE团队的流失，我们建议根据技术而不是开发人员PA报告架构来组织SRE团队。例如，许多支持存储系统的团队都以相同的方式构建和运行。即使是来自开发组织的不同部分，将技术型产品组中的存储系统分组可能会更有意义。使SRE团队结构适应不断变化的环境如果你需要调整SRE团队的结构来响应不断变化的PA需求，那么我们建议你根据服务需求以及工程和运维负载来创建，拆分（切分），合并和解散SRE团队。每个SRE团队都应该有一个清晰的章程来反映他们的服务，技术和运维。当一个SRE团队拥有太多服务时，我们宁愿将现有团队分成多个团队来传递企业文化并发展现有领导层，而不是从头开始建立新的团队。类似这种的变化不可避免会对现有团队造成破坏，因此我们建议你仅在必要时对团队进行重组。运行有凝聚力的分布式SRE团队如果你需要确保全天候保持业务连续性，并且拥有全球性的服务，那么可以通过在全球范围内建立你的SRE团队来提供均匀覆盖。如果你拥有多个全球分布的团队，我们建议根据邻接以及服务和共享技术的相似性来协调团队。独立的团队通常效率较低，且容易受到团队外部重组的影响-我们只有在业务明确需要他们并且考虑了其他所有选项后才会建立这样的团队。许多公司没有足够的全球覆盖资源，但即使你只是在建筑物之间分布（不考虑洲际），创建和维护两个地方的团队也是有必要的。通过创建、维护组织标准来推动规划和执行以及培养和维护共享的团队文化十分重要。为此，可以定期让整个团队聚在一起-例如，每12-18个月举办一次全员参与的峰会。有时，对团队的个人而言，拥有某些特定职责是没有意义的-例如，从备份中执行定期测试还原或实施跨公司技术任务。在团队分布式站点间平衡这些责任时，请记住以下策略：  将个人职责分配给单个站点，但要定期轮换（例如，每年）。  分担各站点之间的责任，积极努力的平衡参与度和工作量。  不要常年将责任锁定在某个站点。我们发现这种配置的成本最终会超过收益。虽然这个站点可以很好的履行职责，但会培养“我们与他们”的心态，有碍知识的分享，并给业务带来连续性的风险。所有这些策略都需要站点之间维持战术和策略沟通。关系结束SRE参与不一定是无限期的。SRE通过有影响力的工程工作提供价值，如果工作不再具有影响力（即，SRE参与的价值消失），或者大部分工作不再在工程（或运维）层面，你可能需要重新审视当前参与的SRE。一般而言，独立的SRE团队倾向从过度辛劳的团队转变成更有趣的工程工作团队。在团队级别，如果SRE不再提供足够的业务价值来抵偿成本的话，你可能会归还服务。例如：  如果服务已经优化到不再需要SRE持续参与的水平  服务的重要性或相关性已经降低  如果服务已达到使用寿命以下案例研究展示了两个Google SRE参与模式的结束方式。第一个结果基本上是积极的结果，而另一个的结果则比较微妙。案例研究1：AresGoogle的Abuse SRE和CommonAbuse Tool（CAT）团队为大多数Google产品提供了反滥用保护，并与面向客户的产品合作以确保用户安全。Abuse SRE团队应用工程工作来降低CAT的运维负担，以便开发人员能够直接支持其用户。这些用户是Google运维CAT所捍卫的资源，他们对CAT的功效及其对问题或新威胁的响应时间有着很高的预期。有效的反滥用战斗需要保持持续的关注，能快速的适应变化，面对新的威胁和攻击时具有灵活性。通常SRE的目标是可靠性和有计划的功能开发，这些要求是与之冲突的。CAT团队通常需要快速开发并为受到攻击的资源部署新的保护措施。但是，Abuse SRE推迟了所要求的的变更，针对每个变更都要求对整个生产系统的影响进行更深入的分析。团队和审查之间协商的时间限制加剧了这种紧张局势。为了改善这种状况，Abuse SRE和CAT领导层开展了一个持续全年度的项目，在CAT内部建立了一个专门的基础设施团队。新成立的“Ares”团队有权统一Google资源的反滥用基础设施。该团队由CAT工程师组成，他们拥有生产基础知识和构建运行大型服务的经验。团队启动了一项交换计划，将生产管理知识从Abuse SRE转移到CAT基础设施团队成员。Abuse SRE团队告诉Ares团队，在生产中启动新服务最简单的方法（当你已经运行大型分布式服务时）是最小化服务所带来的额外认知负荷。为减少这种认知负荷，系统应尽可能是同构的。一起部署和管理生产服务集合意味着可以共享相同的发布结构，容量规划，访问存储的子服务等。根据这一建议，Ares重新设计了整个反滥用堆栈，应用模块化概念转向了微服务模型。他们还构建了一个新层，为开发人员提供抽象化，这样就不必担心监控，日志记录和存储等较低级别的生产细节。现在，Ares团队开始管理新的反滥用基础设施，看上去更像是CAT的SRE团队。同时，Abuse SRE专注于整个反滥用基础设施的生产部署和高效的日常运维。Ares工程师和AbuseSRE之间的协作带来了以下改进：现在，Ares团队开始管理新的防滥用基础设施，看上去更像是CAT的SRE团队。同时，Abuse SRE专注于整个防滥用基础设施的生产部署和高效的日常运维。Ares工程师和Abuse SRE之间的协作带来了以下改进：  由于CAT团队现在拥有“内部”生产专家，他们本身也是反滥用战斗的专家，Abuse SRE不再需要审查新的功能变更。大大缩短了新功能的开发时间。与此同时，由于新的基础设施抽象了生产管理细节，CAT团队的开发人员的开发速度也有了提高。  由于大多数请求不需要更改基础架构，因此Abuse SRE团队对CAT团队提出的新需求也少了很多。又因为基础设施很少需要更改，该团队对新功能影响的评估也比之前简单。当需要更改基础架构时，Abuse SRE只需要清楚对基础架构的影响，而不用了解具体的功能。  由于现在产品集成相当于功能发布，所以需要与反滥用基础架构集成的产品有更快更加可预测的转变时间。在该项目结束时，Abuse SRE不再直接支持CAT，而是专注于底层基础设施。这并没有影响CAT的可靠性，也没有使CAT团队承担额外的运维工作；相反，这加快了CAT的整体发展速度。目前，Ares通过大量Google资源来保护用户。自团队成立以来，SRE和产品开发合作一起就基础设施如何在生产中发挥作用进行决策。正是由于Ares的努力才使得这样的伙伴关系成为可能，Ares创造了一种共同的使命感。案例研究2：数据分析通道有时维持SRE运维关系的成本高于SRE提供的价值。这种情况下，通过解散SRE团队来结束这种关系是可行的 。  注1：Google HR在这类转换中为员工提供新机会随着时间的推移这种关系的价值在减小，但很难确定终止合作的时间点。Google的两个支持重点收入数据分析通道的团队就面临这一挑战。在经过十年的合作之后，确定分离的方法是十分重要的。回想起来，我们能够确定团队互动的几种模式，这些模式是我们需要重新考虑SRE团队和产品团队间关系的重要指标。数据挖掘在衰退的前三年，所有相关方都认识到他们的主要数据分析通道正在遇到扩展的限制。当时，开发团队决定规划新系统，并让少数工程师专门投入此项工作。随着此项工作的融合合并，有必要为现有系统开发大型，复杂或有风险的特性来支持新系统的工作。随着时间的推移，产生了两个重要的影响：  对新项目采用了非正式规则：如果项目的复杂度或修改现有系统以适应项目涉及到的风险太高，那么最好在新系统中进行规划。  随着资源转向开发新系统，即使对现有系统进行相对保守的变更也变得十分困难。但此时对现有系统的使用量仍在快速增加。沟通失败在保持现有系统正常运行的同时设计，构建，启动替换系统对任何工程团队而言都是一项挑战。压力自然的落在同时关注着新、旧系统的人，以及需要做出优先级决策的团队身上。当团队在组织结构上是分离的，这些困难可能更加复杂-例如，一个专注于维护和运维现有系统的SRE团队和一个致力于下一代系统的开发团队。在整个周期中，为了维护和保持团队间良好的工作关系，定期，开放和合作的沟通十分重要。在这个例子中，沟通不畅导致了团队间工作关系的不和谐。解散花费了一段时间才意识到SRE和开发团队完全脱节是不可取的。最终，最简单的解决方案是消除组织障碍，让开发团队完全把控新旧系统的优先级工作。在旧系统完全淘汰之前，预计两个系统将同时存在18-24个月。将SRE和产品开发功能整合到一个团队中可以使高层管理人员最大限度的响应他们的问责领域。同时，团队可以决定如何平衡运维需求和速度。虽然解散两个SRE团队并不是件愉快的事，但这样做解决了在何处投入精力的问题。尽管开发团队不可避免会有额外的运维负担，但是重新调整旧系统的所有权给对服务更了解的人员有助于更快的解决运维问题。该团队可以更深入的了解故障的潜在原因，能更高效的排查故障和解决问题。但是，开发团队在短期内接手所支持服务的运维工作时，不可避免会产生一些负面影响。SRE团队的最后工作是尽可能的分享运维知识，帮助开发团队顺利承担这项工作。如果工作关系更健康-团队合作可以有效的解决问题-SRE能在短期内将生产工作交付给开发团队。在系统重新稳定并强健能够满足预期的增长需求后，SRE通常会重新承担系统运维的责任。SRE和开发团队要主动直接解决问题并找出需要重置的工作内容。SRE的一部分工作是在面对不断变化的业务需求时帮助开发进行优化开发，寻找解决挑战性问题的解决方案。结论SRE团队参与的模式会改变服务生命周期的各个阶段。本章对每个阶段都提供了具体建议。Google和纽约时报SRE团队的例子表明，有效管理参与度和指定出色的技术设计决策同样重要。有时SRE的参与应该达到一个自然的终止点。Ares和数据分析通道团队的案例研究提供了如何实现这点的示例，以及如何很好的结束参与关系。在谈及SRE和产品开发团队之间建立有效关系的最佳实践时，关键在于定期和开放式沟通共享目标和方向。你可以通过多种方式扩展SRE团队，但这些关系管理原则应该始终如一。为了保持SRE参与的长期成功，协调团队目标，理解彼此的目标与捍卫SLO同样重要。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十七章 从过载中识别和恢复]]></title>
      <url>/sre/2020/01/17/%E4%BB%8E%E8%BF%87%E8%BD%BD%E4%B8%AD%E8%AF%86%E5%88%AB%E5%92%8C%E6%81%A2%E5%A4%8D/</url>
      <content type="text"><![CDATA[当SRE团队顺利运行时，团队成员应该感觉他们可以轻松地处理所有工作。他们应该能够处理工单，并且还有时间处理长期项目，以便将来更容易地管理服务。但有时现实情况会妨碍团队的工作目标，比如，成员长期病假或转移到新的团队。组织为SRE制定了新的生产范围计划，对服务或更大系统的更改带来了新的技术挑战。随着工作量的增加，团队成员开始工作更长时间来处理工单和紧急警报，以至于减少了花在工程工作上的时间。整个团队开始感到压力并沮丧，因为他们努力工作却没有取得进步。反过来，压力会导致人们犯更多的错误，影响可靠性最终影响最终用户。简而言之，该团队失去了管理日常工作和有效管理服务的能力。因此，团队需要找到摆脱这种过载状态的方法。他们需要重新平衡工作量，以便团队成员可以专注于必要的工程工作。运维负载（或运维工作负载）是一个术语，描述的是使系统和服务以最佳性能运行的持续维护工作。有三种不同类型的运维负载：紧急警报、工单和日常运维任务。紧急警报通常需要立即关注，与紧急问题相关的工单可能会有紧迫的截止日期。报警和紧急工单都会中断SRE的工程工作来支持团队的运维工作。出于这个原因，我们将它们称为中断。SRE（Site Reliability Engineering）的第29章讨论了管理团队在维护复杂系统的运行状态时处理自然中断的技术。当运维负载超过团队管理能力时，团队最终将处于运维过载状态（也称为工作超负荷）。当团队无法在关键优先事项方面取得进展时，团队处于运营超负荷状态，因为紧急问题不断取代项目工作。除了降低团队的优先级和服务改进之外，过载还会增加工程师出错的可能性。运维过载的阈值因团队而异，Google SRE团队将工作量限制在工程师工作时间的50%。从长远来看，成功的SRE团队必须有信心他们将能够完成所需的工程项目，以减少他们所管理服务的运维负担。本章描述了Google的团队如何从一个以运维过载为特征的困难局面发展到管理良好的工作负载。两个案例研究显示了运维过载对团队健康的不利影响，以及团队如何改变他们的日常任务，以便可以专注于长期有影响力的项目。在案例研究1中，当身处于一个不断缩小的团队中的成员无法跟上工作负载时，便会导致过载。在案例研究2中，团队遭受他们所认为的过载——这是一种与运维过载具有相同效果的状态，但最初是对实际工作负荷的误解。虽然案例研究突出了两个Google SRE团队的具体行为，但“减轻过载的策略”一节第366页提供了适用于任何公司或组织辨别和减轻过载的实践。因此，本章应该对过载团队的管理者或任何关注过载的SRE团队有用。从负载到过载无论其起源如何，过载都是一种可能削弱生产力的职业压力。如果不加以控制，可能会导致严重的疾病。对于SRE团队而言，运维负载通常是认知上困难任务的组合（如调试内存泄漏或分段故障）和一些需要频繁环境切换的小任务（通过配额请求，启动二进制分发等）。当团队没有足够的时间来处理所有这些任务时，通常会发生工作超负荷——当分配给团队的任务数量无法在每个任务的给定截止日期内完成时，这是客观现实。感知过载更为主观，并且当团队中的个人觉得他们有太多工作时就会发生。这通常发生在短期内有多次组织或工作变更时，但团队几乎没有机会与领导层就变更进行沟通。当你值班时，你永远不会清楚会出现什么问题，或者你的工作量是什么。一方面，看似单一的磁盘空间不足问题可能会导致对重复的垃圾收集工作进行深入调查。另一方面，20次以上的紧急报警风暴可能会成为监控不良的情况。当很难估计或预测你的工作量时，很容易成为认知偏差的受害者并误判工作量——例如，你可能会任务在你on-call期间工单队列太大而无法完成，即使你可以快速完成所有工单并且实际工作负载较低，你在第一次查看工单队列时也会感到超载。这种感知过载本身是一种影响工作方式和态度的心理因素，如果你没有以一种有很多工作的预想开始一天的工作，你将很可能潜心的按照你自己的方式完成工单序列。也许你整天都在工作，但并没有完成你的工作量（因此面临工作超负荷），但是这将比一开始就感觉不堪重负更有进步。累积很多工作中断可能会导致工作超载，但也并非如此。但是，当频繁的中断与外部压力因素配对时，大的工作量（甚至是小的工作量）很容易变成感知的过载。这种压力可能源于担心其他团队成员失望，工作安全感，工作相关或个人矛盾，疾病或健康相关问题，如缺乏睡眠或运动。如果你的工作没有得到适当的优先排序，那么每项任务都会显得同样紧迫，从而导致实际和感知过载。在实际的过载情况下，工单和警报的紧急程度可能导致团队成员工作到知道解决问题，即使这样做意味着持续的长时间工作。当一个团队面临被认为的过载时，重新确定优先级可以帮助减少紧急工作量，为他们创造空间，通过项目工作来解决过载源。在分析具体情况时，不一定要假设工作量本身需要更改，相反，我们建议首先量化团队所面临的工作，以及它如何（或没有）随时间变化。例如，你可以根据团队处理的故障单和紧急警报数量来衡量工作负载。如果你的工作量实际上没有随着时间的推移而发生变化，那么团队可能会感到超载仅仅是因为他们认为工作是压倒性的。可以通过要求每个成员列出他们面临的所有的工作任务来收集一次性快照，以更全面的了解团队当前的工作负载。然后看看你的团队面临的心理压力因素，例如组织变化或重新优化排序。完成研究后，就可以就改变工作量做出决定。第366页的“减轻过载的策略”更多的讨论了如何识别真是和感知的过载。首先，我们提出两个认可的团队案例研究，他们处于超负荷状态并采取措施缓解它。案例研究1：当半数团队成员离开时工作超载背景Google的一个内部存储SRE团队负责多种服务的后端维护，包括Gmail，Google云端硬盘和Google网上论坛，以及许多其他内部或面向用户的服务。我们在2016年中期经历了一场危机，当时三分之二的团队成员，包括最高级工程师（经理），在相对较短的时间内因为完全不相干的原因而离职。这个时间显然导致了巨大的工作量管理问题：可用于处理日常工作和项目工作的SRE越来越少，导致团队过载。我们的工作也遇到了瓶颈，因为每个团队成员的专业知识都被划分到不同的生产领域。虽然增加新的团队成员和三名实习生可以改善我们的工作量，但增加这些工程师需要花费大量的时间和精力进行培训。问题陈述上述因素显著降低了团队生产力。我们的开始落后于项目工作，并且我们管理的许多服务相关的工单开始堆积。我们没有足够的时间来处理这个积压，因为我们的所有工作都被更高优先级的任务所消耗。过不了多久我们就无法完成所需要的所有重要且紧急的工作。与此同时，我们的团队很快将获得更多高优先级的工作。如果我们没有把一些工作从我们的主要版块上移开，那么我们只能放弃重要工作。然而，一旦我们开始放弃一些工作，我们就会遇到一些心理问题：  放弃任何正在进行的工作，感觉就像我们刚刚浪费了我们努力的时间。大多数积压工作似乎要么至关重要，要么值得我们付出努力，所以只有无限期地推迟或取消项目。我们没有意识到我们正处于一种沉没成本谬论的控制之中。  努力实现流程自动化或修复工作负载的根本原因并不像立即处理高优先级故障那样重要。当这项工作被添加到已经庞大的堆积工作的顶部时，所有的工作都感到压力很大。我们决定做什么我们将团队成员聚集在一个房间中，并列出了团队的所有职责，包括积压项目、运维工作和工单。然后我们队每个列表项进行了分类，查看我们的每一项工作任务，这有助于我们确定并重新定义我们的实际优先级。然后，我们找到了最小化、切换或消除低优先级工作的方法。实现我们将一些自动化低成本较低的工作自动化，可能这不会很多，但一旦部署，将大大降低运维负荷。我们还确定了可以实现自助服务的常见问题。编写客户所需的程序并不需要很长时间，并从队列中删除了一些重复的工作。我们合理地关闭了许多积压这的工单，这些工单中的大多数都是过时的、多余的，或者是紧急的（虽然他们声称是紧急的）。有些工单是监控那些不可操作的工作，所以我们修复了相关的监控。在某些情况下，我们积极解决不重要的问题。我们将这些问题放在一边处理更紧急的工单，但首先要记录我们的进度，以便在我们能够再次处理他们之前不会失去之前的环境。当有疑问时，我们放弃一项工作，但标记为第二阶段的分流。一旦我们的盘子（几乎）空了，我们将重新审视这个暂定列表，以决定恢复哪些任务。事实证明，这些任务几乎都不具有影响力或重要性，无法恢复。两天——一天的密集分流加上一天的记录流程和实施自动化——我们很小的团队解决了几个月的工单积压。然后我们可以处理剩余的几个故障，这些故障与生产中的活动问题有关。经验总结我们的团队了解到识别和确认过载是解决问题的第一步。在我们帮助我们团队恢复健康状态之前，我们需要让每个人都进入同一个房间并重新评估积压工作。为了避免新的中断性任务积累，我们开始每两周对中断性任务进行一次分类。我们的技术负责人会定期检查任务队列，并评估团队是否有过载风险。我们决定每个团队成员应该有10张或更少的开放工单，以避免过载。如果团队领导同志团队成员的工单数超过10张，他们可以执行以下一项或多项组合：  提醒团队关闭陈旧的工单。  与过载的团队成员同步并从他们那卸载工单。  提示各个团队成员解决他们的工单队列。  组织团队范围的一日工单修复工作。  分配工作以修复故障单来源或操作工作以减少将来的故障单。案例研究2：组织和工作量变化后的感知过载背景本案例研究中的Google SRE团队分处两个地方，每个站点有六到七名随叫随到的工程师（有关团队规模的更多讨论，请参阅第11章站点可靠性工程)。虽然悉尼团队健康运作，但苏黎世团队在超负荷运转。在苏黎世团队进入超负荷之前，我们很稳定且满足。我们管理的服务数量相对稳定，每个服务都多种多样，维护度也很高。虽然我们所支持服务的SLO与其外部依赖的SLO不匹配，但这种不匹配并未引起任何问题。我们正在开展一些项目来改进我们管理的服务（例如，改善负载均衡）。同时致使苏黎世团队陷入过载的诱因是：我们开始在谷歌的基础架构中加入噪音更大、整合程度更低的新服务，技术主管和另一名团队成员也离开了我们团队，导致团队缺少两个人。额外工作量和知识流失的结合引发了更多问题：  对新服务的未调优监控和与迁移相关的监控导致每个班次增加了更多的页面。这种积累是渐进的，所以当它出现时我们没有注意到它的增加。  SRE对新服务感到相对无助，我们对它们的了解还不够，无法做出适当的反应，而且经常需要询问开发团队问题。虽然过载可能保证将服务交还给开发人员，但我们的团队从未返回过服务，所以我们并不认为这是一个可行的选择。  5人值班小组轮班缩短了我们通常花在业务工作上的时间。  新的故障单报警出现了问题，这种问题在最近的团队变更之前就存在了。我们过去只是简单地忽略了这些问题，但我们现在需要将被忽略的电子邮件报警移至故障单。项目规划并没有考虑到这一新的技术债务来源。  新的票据SLO要求我们在三天内处理票据，这意味着值班人员必须更快地处理在他们值班期间产生的票据。SLO旨在减少添加到我们（大部分被忽略的）积压工单中的票据数量，但这可能产生了更糟糕的副作用。现在，SREs觉得他们在轮班后无法得到他们所需要的休息，因为他们必须立即解决后续工作。对这些工单的优先考虑也意味着SREs没有足够的时间进行其它操作。在此期间，我们团队被指派给一位新的经理，他同时管理另外两个团队。这位新上任的经理并不是值班轮值人员，因此没有直接感受到团队成员所面临的压力。当团队向经理解释情况时，没有任何改变。团队成员认为他们没有被听到，这让他们感到与管理团队的距离太远了。工单的超载持续了几个月，让团队成员变得脾气暴躁，直到一连串的不愉快情绪蔓延到整个团队。问题陈述在失去两个人并接受额外和各种各样的工作后，我们的团队感到超负荷。当我们试图将这种感觉传达给我们的直接经理时，经理不以为然。随着工作时间的延长，人们开始精疲力竭，生产力正在下降，任务增加的速度开始快于团队解决问题的速度。感知到的过载现在变成了客观过载，使情况变得更糟。超负荷造成的情绪压力降低了士气，导致一些团队成员倦怠。当个人处理工作过度对身体的影响（疾病和低生产力）时，团队中的其他人不得不承担更多的工作，在每周的团队会议上分配的工作没有完成。然后我们开始假设我们不能依赖其他人来完成他们的工作，这削弱了团队内部的信任和可靠性。因此，我们对人际风险承担感到不安全，这是心理安全的一个重要因素（见第11章网站可靠性工程）。团队成员感觉不被其他团队成员接受和尊重，因此他们之间没有自由地相互协作。随着团队心理安全的减弱，协作停止，信息共享速度减慢，导致效率进一步低下。团队调查还显示，他们的心理安全受损——团队成员表示，他们并不觉得自己属于团队。他们不再关心他们的职业发展，团队晋升率也降到了历史最低点。当高层管理人员为我们分配了新的强制性全公司项目时，我们终于达到了一个突破点，在这一点上，我们重新与管理层就过载问题进行了对话。一系列的讨论表明，我们不愉快的情况不仅仅是工作太多的结果——我们对团队安全的看法使我们不再相互信任和合作。我们决定做什么上层管理人员为我们团队指派了一位新经理，他不是供职于三个团队。新经理采用参与式管理方式来改善团队的心理安全，以便我们再次合作。该方法使团队成员能够积极参与解决团队问题。整个团队，包括我们的直接经理，都参与了一系列简单的团建活动，以提高我们的团队效率（其中一些活动就像一起喝茶一样简单）。最终，我们能够起草一套目标：短期：缓解压力，提高心理安全，营造健康的工作氛围。中期：通过培训建立团队成员的信心；找到导致过载问题的根本原因。长期：解决正在发生的导致级联的问题。为了设定这些目标，我们首先必须在团队中达到某种基本的心理安全。随着士气的提高，我们开始分享知识、并在彼此想法的基础上找到让我们的工作负荷得到控制的方法。实现短期行为长期压力，无论是过度工作还是对团队安全的看法，都会降低生产力并影响人们的健康。因此，我们最重要的短期行动是减轻压力，提高信任和心理安全。一旦缓解了一些压力，团队成员就可以更清晰地思考并参与推动整个团队向前发展。在确定过载的一个月内，我们实施了以下措施：  开始了一个非定期的圆桌会议来讨论问题。该团队释放了挫败感，并对可能导致超负荷的原因进行了头脑风暴。  找到更好的衡量负载的指标。我们决定改进我们原有的页数标准，我们自动给值班人员分配工单，即使在轮班结束后，值班人也要负责这些工单。我们的新指标衡量了一位值班人在轮班后处理工单所需的时间。  审核并删除垃圾邮件警报。我们审核了警报，并删除了那些不代表面向用户问题的警报。  屏蔽大量警报。这个团队故意不去寻找每一个警报的来源，而是专注于减轻压力，避免因为我们已经知道的问题而不断接到警报和提工单。我们使用了以下策略：      ——已知的警报在被修复之前一直处于屏蔽状态。      ——警报只能在有限的一段时间内被屏蔽（通常是一天，有时长达一周）。否则，他们可能会掩盖故障。     ——几分钟内无法修复的警报被分配到一个跟踪工单上。  增加了一个专门针对单个团队的直接经理。让一个受人尊敬的团队成员成为新经理重新建立了对管理的信任。新经理可以将更多时间集中在团队及其成员上，而不是管理三个团队。  重新平衡团队。我们通过添加技术经验丰富的SREs来引入新的视角并减轻值班人员的压力，这些SREs对团队或组织没有先入为主的观念。找到合适的人并不是一件容易的事，但值得付出努力。  举办团体活动，如午餐和棋盘游戏。谈论与工作无关的话题，一起大笑，缓解团队的紧张局势，提高心理安全性。中期行为单靠短期解决方案无法维持良好的氛围——例如，我们的短期策略之一就是在没有真正解决问题的情况下屏蔽报警。在三个月内，我们还采取了一下行动：  值班期间尽可能减少运维工作（参见SRE第29章），以便团队可以专注于永久性修复和项目工作。  将一项服务的责任归还给其开发团队。  相互培训（和新的团队成员）。虽然培训需要投入时间和精力，但传播知识意味着所有团队成员（以及未来的雇员）可以在未来更快地排除故障并解决问题。培训同时提高了我们的信心，因为我们意识到我们实际上对服务有很多了解。当他们获得知识时，团队成员开始寻找管理服务的新方法，提高可靠性和减少过载。  从其他团队中引入SREs来安排我们的一些值班工作并参与培训。他们注意到了团队的压力，并提供了一些有价值的新视角。  在团队中重新扮演了两个开放的角色。  在报警屏蔽过期解决每个报警。我们在周会中讨论了没有采取任何操作的重复报警，这让我们调整了报警或修复了潜在的问题。虽然这些是重要的（和明显的）行为，我们只有在报警被屏蔽情况下才有足够的空间进行分析和采取行动而不是制造持续的噪音。  有组织的聆听活动。管理层（包括跳级经理和团队领导）有意识地倾听团队的痛点并找到一个团队驱动的解决方案。  增加视角。希望不是一种策略，但它确实有助于提升团队士气。随着新成员加入on-call，转变为更清晰的优先事项，以及结束产生报警的项目，团队的情绪得到了改善。长期行为为了保持我们新发现的稳定，我们目前正在将我们的SLO与其服务后端的SLO保持一致，并努力使服务更加统一。统一具有双重好处：它降低了SRE的心理负荷，并使编写可以跨服务使用的自动化变得更加容易。我们还回顾了已经存在了很长时间的服务，并将它们更新到当前的生产标准。例如，一些服务在负载下运行很差，这些年来显著增加。某些服务更需要根据其后端服务策略的更改进行更新。其它服务几年来一直没有更新。成效我们在第一次头脑风暴会议后的几个月，结果开始浮出水面：on-call轮班期间变得更安静了，我们的团队成功地快速有效地处理了一个棘手的时间。不久，新的团队成员加入。当我们在圆桌会议上讨论心理安全时，新成员说他们无法想象团队会有这样的问题。事实上，他们认为我们的团队是一个温暖而安全的工作场所。在最初的升级后大约一年，最初的超负荷几乎没有，一项匿名调查显示，团队成员现在觉得这个团队是高效和安全的。经验总结工作场所的变化会对团队中的人产生心理影响——毕竟，你的队友不是机器。你需要关注团队的压力水平这样人们就会开始互相信任，一起工作；否则，团队可能会进入导致压力的过载中恶性循环，从而阻止你应对过载。事实上，感知过载是过载，并且对团队的影响与其他因素造成的工作过载一样大。在我们的案例中，我们在悉尼的姐妹团队没有遇到同样的问题，与前几年相比，我们解决的报警数量并没有太大的变化。相反，失去两名团队成员，感知过载增加，工单增加以及新的3天的工单让团队感觉超负荷了。最终，客观和感知超载之间的区别并不重要：一些团队成员的管制过载会很快导致整个团队的超负荷。减轻过载的策略外部视角有时可以很容易地识别团队何时超负荷。同样，回顾一下应该采取什么行动也很容易。但当你正在体验它时，你将如何识别过载？当你陷入过载困境时，通往健康、友好和快乐的工作氛围的道路很难想象。本节介绍了识别和减轻团队过载的实践。识别过载的症状如果你知道过载的症状，很容易识别出一个超负荷的团队：团队士气降低：过载可能表现为咆哮和抱怨。相关主题（工作条件、工作满意度、项目、同事和经理）的调查通常反映团队士气，并在团队超负荷时产生更多负面结果。与团队领导定期积极的聆听会议可以解决你不了解的问题。积极倾听的一个基本要素是不经过判断就倾听。团队成员长时间工作，或生病时工作：没有补偿的加班可能是心理压力源。领导者应该梳理一个好榜样：生病时待在家里。更频繁的疾病：过度工作的团队成员往往会经常沮丧和生病不健康的任务队列：我们建议定期查看团队的任务队列，已查看积压的工单，处理哪些问题以及可以延迟或删除那些任务。如果团队错过最后期限，或者紧急事件阻止你定期执行此审核，那么团队很可能会比他们所能处理的更快地累积中断。不平衡的指标：    一些关键的指标可能表明你的团队过载    * 长时间关闭某个问题    * 长时间花费在艰难进行的工作上    * 大量的时间来关闭来自于调用会话的问题团队应该共同决定使用哪些措施。没有一种适合所有人的方法；每个团队的超负荷都会以不同的方式放映出来。作为经理，在不了解每个人的工作量和工作习惯的情况下，不要对团队施加措施。如果坚持使用特定措施，团队成员可能会觉得你不理解工作。例如，如果你按照修复问题所需的天数来评估负载，那么一个人可能会整整一天解决问题，而另一个人可能会在几天内将工作分配到其他工作中。减少团队压力维持团队健康状态阅读完标准后，你可能会认为你的团队已经超负荷了。不要绝望！本节提供了一个让你的团队恢复健康状态的方法。通常，给团队成员更多的控制和权力可以减少感知到的压力。虽然有压力的情况下求助于微管理，但重要的是要让团队处于循环状态中，并将优先级放在一起，以提高绩效和工作满意度。这个模型假设一个团队成员之间有着健康的人际关系之中。识别并减轻心理压力源当要调整一个超负载的团队时，最重要的是团队成员需要重建心理安全。团队和每个成员都是息息相关的。你可以从识别每个人和整个团队的心理压力源开始。实际哪些因素影响团队的压力？你无法控制团队成员是否患有重大疾病，但你可以控制团队面临压力的大小（如案例研究1中所示）或屏蔽报警（如案例研究2）。与你的合作的产品开发人员团队沟通，让他们知道你的团队的压力。他们或许可以伸出援助之手，甚至接管整个项目。当你的团队成员相互依赖并达到一定程度的心理安全（这样他们能够承担人际风险）时，你可以让个别成员承担更多的责任，学习其他领域的专业知识，并将专业人员物尽其用，从而提高他们的自信心，使他们能够承担风险的重任。决策应该是透明的，如果可能的话，应该是民主的。每个团队成员都应该对面对的情况有一种控制感。例如，案例研究2中的头脑风暴会议帮助团队识别和讨论问题。在四分之一的范围内优先处理和分类健康的团队会首先处理重要的问题并对问题进行分类。案例研究1为这个观点提供了一个很好的例子：团队坐在一起并审查他们积压的问题。审查帮助他们意识到他们超载了。他们重新确定了工作优先级后，并完成了可以迅速减少负载的任务。案例研究2中的团队现在每个季度末召开会议，共同规划现有和未来工作并确定其优先顺序。如果可能，我们建议SRE在其日历上安排无中断时间（没有on-call），这样他们就有时间处理技术深度上很困难的任务，如开发自动化和调查中断你的根本原因。在案例研究2中，当外部团队给予on-call一些解脱时，团队成员则有宝贵的时间专注于他们的项目。如果绝对必要，放弃一些工作内容：在案例研究2中，团队通过将此职责交还给开发团队，放弃了对其中一项服务的on-call支持。在未来保护自己我们强烈建议制定指标来评估团队的工作量。定期查看指标，确保他们正在衡量正确的事情。一旦你的团队出现过载，你可以通过采取措施监控或解决潜在问题来防止过载进一步恶化。例如，案例研究1中的团队现在维护一个轻量级的分类流程，以检测不断增加的积压任务。案例研究2中的团队目前正在制定一项长期计划，以协调后端和服务SLO。当你的团队处于超负荷状态时，优先考虑工程工作，即使你没有超负荷工作，也会比重复工作更重要，在将来你会获得利益。最后，团队中的每个人都应对预警信号负责（请参见第366也的“识别过载症状”），以指示可能出现的过载情况。如果管理人员认为团队正在走向过载，他们应该坐下来与团队成员交谈。结论在完美的世界中，SRE团队始终能够使用我们的第一本书中描述的策略来管理中断。但我们只是人类，我们的团队没有达到那个理想状态。本章研究了过载情况下如何建立团队健康的方法，并讨论了如何在它发生时检测和响应。特别实在运营工作方面，过度的中断很容易导致团队从正常工作负载滑落到过载。频繁的中断可能导致过载，过载会对健康和生产力产生负面影响。超载会给团队成员带来心理社会压力因素，进一步影响工作，导致自我强制循环。感知过载是一种特殊的过载形式，无法通过劳动量或操作量来衡量。很难确定和消除。为了使团队的工作量保持平衡，持续监控（感知的或为感知的）过载非常重要。为了更好地为用户服务并做好工作，你需要首先尊重自己和团队。在日常工作中保持健康的平衡对于帮助你和你的团队实现这一目标有很大帮助。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十六章 灰度部署 (金丝雀部署)]]></title>
      <url>/sre/2020/01/16/%E7%81%B0%E5%BA%A6%E9%83%A8%E7%BD%B2/</url>
      <content type="text"><![CDATA[  发布工程是一个术语，用来描述从存储库中获取代码发布到生产环境中，之间相关的全部过程和所有组件。自动化发布可以帮助避免许多发布工程的传统缺陷: 重复性和手工任务的辛苦、手动流程的不一致性、无法了解上线的确切状态以及回滚困难。发布工程的自动化已经在其他文献中得到了很好的介绍——例如，关于持续集成和持续交付的书籍(CI/CD)。  我们将灰度发布定义为：对服务进行部分且有时间限制的变更部署，并同时进行评估。该评估将帮助我们决定是否继续上线。变更的服务部分是the canary，服务的其余部分是the control。支持这种方法的逻辑是，灰度发布通常在线上进行小流量发布，或者影响比the control部分少得多的用户上。灰度发布是一个有效的A/B测试过程。  我们将首先介绍发布工程的基础知识，以及通过自动化发布来建立共享词汇的益处。发布工程原理发布工程的基本原理如下:可再生构建构建系统应该能够接受构建输入(源代码、资产等)并生成相同结果。与上周相同的输入(构建代码)应该在本周产生相同的输出。自动化构建一旦代码上传之后，能够自动化生成构建组件并将其上传到存储系统。自动化测试一旦自动构建系统构建了组件，某种类型的测试套件应该确保它们正常工作。自动化部署部署应该由计算机执行，而不是人。小型部署构建系统应该支持小的、自包含的更改。这些原则为运维人员带来直接收益:  通过消除手工和重复的任务来减轻工程师的操作负担。  强制同行评审和版本控制，因为自动化通常是基于代码的。  建立一致的、可重复的、自动化的流程，从而减少错误。  添加对发布管道的监控，通过解决以下问题进行测量和持续改进:          –发布版本需要多长时间生产环境才生效?      –发布成功的频率是多少?一个成功的版本是一个没有严重缺陷或SLO违规的、客户可用的版本。      –可以做哪些更改来尽早的捕获管道中的缺陷?      –哪些步骤可以并行化或进一步优化?      CI/CD与发布自动化相结合可以持续改进开发周期，如图16-1所示。当发布自动化时，你可以更频繁地发布。对于变更率很高的软件来说，更频繁地发布意味着在任何给定的发布工件中捆绑更少的更改。而更小的、自包含的发布工件使得在出现bug时回滚任何给定的发布工件变得成本更低、更容易。更快的发布节奏意味着可以更快地修复bug。平衡发布速度和可靠性快速发布(以下称为发布)和可靠性常常被视为相反的目标。企业希望以100%的可靠性尽快发布新特性和产品改进!然而这个目标是不可能实现的(因为100%从来不是可靠性的正确目标;参见第2章)，但可以在满足特定产品的特定可靠性目标的同时，尽可能快地进行交付。实现这个目标的第一步是了解发布对软件可靠性的影响。在谷歌的经验,大多数事件都是由二进制或配置推送导致的(见附录C)。许多类型的软件更改都可能导致系统故障 - 例如，底层组件的行为更改，依赖关系（例如API）的更改，或DNS等配置更改。尽管对软件进行变更存在固有的风险，但是这些变更(bug修复、安全补丁和新特性)对业务的成功是必需的。你可以使用SLOs和错误预算的概念来衡量发布新版本对可靠性的影响，而不是提倡反对变更。你的目标应该是在满足用户期望的可靠性目标的同时尽快发布软件。下一节将讨论如何使用canary流程来实现这些目标。分离变更频率不同的组件服务由具有不同变更频率的多个组件组成:二进制文件或代码、基础环境(如JVM、内核/OS)、库、服务配置或标志、特性/测试配置和用户配置。如果只有一种发布变更的方法，那么这些组件单独变更会比较困难。特性标志或测试框架(如Gertrude、Feature和PlanOut)允许你将特性启动从二进制版本中分离出来。如果二进制版本包含多个特性，你可以通过更改测试配置一次启用一个特性。这样，就没有必要将这些小的变更集合为一个大的变更，或者为每个特性执行单独的版本。更重要的是，如果只有一些新特性的行为不像预期的那样，你可以选择性地禁用这些特性，直到下一个构建/发布周期可以部署新的二进制文件为止。你可以将特性标志/试验原则应用于服务的任何类型的更改，而不仅仅是软件版本。Canarying是什么？Canarying一词是指将金丝雀带入煤矿以确定该矿是否对人类安全的做法。 由于鸟类比人类更小，呼吸更快，因此它们被危险气体毒害的速度比人类更快。即使你的发布管道是完全自动化的，在真正的流量到达服务之前，你依然无法检测到所有与发布相关的缺陷。当一个发布版本准备好部署到生产环境中时，你的测试策略应该充分保证该版本是安全的，并且按预期工作。然而，测试环境与生产环境并不是100%相同的，并且测试不可能会涵盖100％的场景。依然会存在一些会影响生产缺陷。如果一个版本立即部署到系统的全部地方，那么可能存在的缺陷亦将到达系统的全部地方。如果你能够快速地检测和解决缺陷，则可以接受此方案。但是，更安全的选择是:首先使用灰度发布向新版本导入一些生产流量。灰度发布允许部署管道在尽可能少地影响你的服务的前提下，更快地检测出问题。发布工程和灰度发布在部署系统的新版本或其关键组件(如配置或数据)时，我们将变更(通常未公开给真实输入的更改，如面向用户的流量、或用户提供的批处理数据)打包。变更会带来新的特性和功能，但也存在部署之后出现问题的风险。我们的目标是通过测试一小部分流量来降低风险，以确保没有任何不良影响。我们将在本章后面讨论评估过程。灰度过程还让我们对变更充满信心，因为我们将其暴露给越来越大的流量。为变更引入实际生产流量还使我们能够识别在单元测试或负载测试等测试框架中可能不可见的问题，这些问题通常更为人为。我们将使用一个实际的示例来检查灰度过程及其评估，同时避免深入研究统计数据。相反，我们关注点是整个过程和典型的实际考虑。我们使用App Engine上的一个简单应用程序来说明发布的各个方面。灰度发布流程的需求针对特定服务的灰度发布需要特定功能：将变更通过灰度发布部署到服务全部子集的方法。      一个评估过程，用来评估变更是好还是坏。将评估集成到发布过程中。最后，当灰度检测到有问题的发布版本，并在没有误报的情况下识别出好的发布版本时，灰度发布展示了它的价值。我们的示例环境我们将使用一个简单的前端web服务应用程序来演示一些灰度发布的概念。该应用程序提供了一个基于http的API，消费者可以使用它来操作各种数据(如产品价格等简单信息)。示例应用程序有一些可调参数，我们可以使用这些参数来模拟各种生产环境，由灰度发布流程进行评估。例如，可以让应用程序为20%的请求返回错误，或者规定5%的请求至少需要两秒钟。我们使用部署在谷歌应用程序引擎上的应用程序来演示灰度发布流程，这些原则同样适用于其他环境。虽然示例应用程序是经过设计的，但是在实际场景中，类似的应用程序与我们的示例可以共享灰度发展中使用的指标。我们的示例服务有两个可能的版本:当前版本和候选版本。当前版本是当前部署在生产环境中的版本，而候选版本是新构建的版本。使用这两个版本来说明发布概念，以及如何实现灰度发布以使发布过程更安全。回滚部署与简单的Canary部署比较我们将在发生中断时根据错误预算节省和一般影响，来对没有灰度发布的部署流程和灰度发布流程进行比较。我们的部署过程以开发环境为基础。一旦我们感觉代码在开发环境中正常工作，我们就将该版本部署到生产环境中。在部署之后不久，监视开始报高错误率(参见图16-2，在图16-2中，为了模拟示例服务中的缺陷，对示例应用程序进行配置以使20％的请求失败)。对于示例，假设部署流程不支持回滚到以前已知的配置正常的版本时。修复这些错误的最佳选择就只有在生产版本中查找缺陷，对其进行补救，并在停机期间重新部署一个新版本。这种做法肯定会延长错误对用户的影响。 图 16-2 部署之后错误率增加 为了改进这个初始部署过程，我们可以在使用灰度发布来减少推送错误代码所造成的影响。 我们需要一种方法来在小部分生产环境中运行候选版本，而不是一次性部署到生产环境。 然后将一小部分流量发送到该生产环境（the canary金丝雀）并将其与其他部分（the control 主控）进行比较。 使用此方法，我们可以在所有生产受到影响之前发现候选版本中的缺陷。我们在示例应用程序中的进行简单灰度发布，在应用程序的特定版本之间分配流量。 您可以使用App Engine或其他任何方法来分割流量（例如负载均衡器上的后端权重，代理配置或循环DNS记录）。图16-3显示了当我们使用灰度发布，变更的影响会大大降低;事实上，这些错误几乎不可见!这提出了一个有趣的问题:与总体流量趋势相比，灰度发布的流量趋势很难看到和跟踪。 图 16-3 部署之后错误率增canary部署错误率； 因为进行canary部署的只是系统的一小部分，因此总体错误率降低 为了更清楚地了解需要在合理范围内跟踪的错误，我们可以通过App Engine应用程序版本查看关键指标(HTTP响应代码)，如图16-4所示。当我们查看每个版本的分解趋势图时，我们可以清楚地看到新版本引入的错误。我们还可以从图16-4中观察到当前版本提供的错误非常少。现在，我们可以根据应用程序版本的HTTP错误率对部署进行调优。如果灰度发布的错误率大于全部系统的错误率，这表明canary部署是糟糕的。我们应该暂停并回滚部署，或者联系他人来帮助解决问题。如果错误率相似，我们可以正常地进行部署。在图16-4中，我们的canary部署显然很糟糕，我们应该回滚它。 图 16-4 应用程序HTTP响应码； 新版本产生多数错误、当前版本产生小数错误（图中显示10%的log） Canary实施现在我们已经看到了一个相当简单的canary部署实现，接下来让我们更深入地了解成功的canary流程所需的参数。最小化SLOs和错误预算的风险第2章讨论了SLOs如何反映设计服务可用性的业务需求。这些需求也可以通过canary实现。canary进程的风险仅仅是我们错误预算的一小部分，它受到时间和canary规模大小的限制。全局部署会很快将SLO置于危险之中。如果实例中为系统全面部署候选版本，我们将面临20%的请求失败的风险。如果我们使用5%的canary规模，我们将为5%的流量提供20%错误，导致1%的总体错误率(如图16-3所示)。这个策略允许我们保留我们的错误预算—预算的影响与暴露于缺陷的流量的数量成正比。我们可以假设，对于全局部署和灰度部署，检测和回滚花费的时间差不多，但是当我们将灰度发布集成到部署过程中时，我们会以更低的成本获得有关新版本的有价值信息。这是一个假设负载均匀的极简模型。它还假设我们可以将整个错误预算用于灰度发布。这里我们只考虑新版本引入的不可用性，而不是实际可用性。我们的模型还假设新版本具有100%的失败率，这是最坏的情况。而进行灰度的部分不会导致线上系统100%不可用。我们还允许在灰度部署期间，整个系统的可用性低于SLO。这个模型有明显的缺陷，但它是一个可靠的起点，你可以根据业务需求进行调整。我们建议使用最简单的模型来满足你的技术和业务目标。根据我们的经验，专注于使模型在技术上尽可能正确，常常会导致在建模上的过度投资。对于具有高复杂性的服务，过于复杂的模型可能导致持续的模型调优，而没有真正的好处。选择灰度规模和持续时间选择合适的灰度持续时间，需要考虑发布频率。 如果需要每天发布，那么在一次只运行一个灰度的情况下，无法使灰度保持一周,如果每周部署一次，就可以执行较长的灰度发布。 如果持续部署（例如，一天20次），灰度的持续时间必须明显缩短。 在一些说明里，虽然可以同时运行多个灰度，但这样做会增加大量精力来跟踪系统状态。 在任何情况下，需要快速推断系统状态时，同时运行多个灰度会成为问题。如果灰度重叠，同时运行多个灰度也会增加信号污染的风险。我们强烈建议一次只运行一个灰度。对于基本的评估，不需要大规模的灰度来检测关键条件。然而，一个有代表性的灰度发布流程需要跨多个维度进行决策:规模和持续时间它的规模应够大，持续时间应够长，足以代表整个部署。仅在接收到少量查询后终止canary部署，对于以具有不同功能的不同查询为特征的系统来说，这无法提供有用的信号。处理率越高，获取代表性样本所需的时间就越少，以确保所观察到的行为实际上是由变更引起的，而不仅仅是随机因素。流量我们需要在系统上接收足够的流量，以确保它是一个具有代表性的示例，并且系统有机会对输入做出负面反应。通常，请求越均匀，所需要的流量就越少。时间点性能缺陷通常只在高负载下出现，因此在非高峰时间部署可能不会触发性能相关的缺陷。度量指标灰度的代表性与我们选择评估的指标密切相关(我们将在本章后面讨论)。我们可以快速评估诸如查询成功之类的琐碎指标，但是其他指标(如队列深度)可能需要更多的时间或较大规模的灰度来提供清晰的信号。但问题是，这些要求可能相互冲突。Canarying是一种平衡行为，它通过对最坏情况的冷静分析和系统过去的实际记录来实现。一旦您从过去的灰度中收集了指标，您就可以根据典型的canary评估失败率而不是假想的最坏情况来选择canary参数。选择和评估度量标准到目前为止，我们一直在研究成功率，这是评估灰度发布的一个非常清晰和明显的指标。但是直觉上，我们知道这个单一的指标对于有意义的canary流程来说是不够的。如果我们以10倍的延迟为所有请求提供服务，或者在这样做时使用10倍的内存，那么我们可能也会遇到问题。并不是所有的指标都适合评估灰度发布。哪些指标最适合评估灰度发布版本是好是坏?度量标准应指出问题首先，指标需要能够指出服务中的问题。这很棘手，因为构成问题的并不总是客观的。我们可能会认为用户请求失败是有问题的。但是如果一个请求的响应时间增加了10%，或者系统内存增加了10%?，这该如何判断？我们通常建议使用sla作为开始考虑canary指标的地方。良好的服务质量指数往往与服务健康状况密切相关。如果已经使用SLIs来度量SLO是否符合，那么我们可以重用这些工作。几乎任何指标在极端情况下都可能出现问题，但是向灰度流程中添加太多的指标也会产生成本。我们需要为每个指标正确定义可接受行为。如果可接受行为定义过于严格，我们会得到大量的误报;也就是说，我们会认为灰度很糟糕，即使实际不是这样。相反，如果对可接受行为的定义过于宽松，我们更有可能忽略掉有问题的灰度部署。正确选择什么是可接受的行为可能会成本较大——既耗时又需要分析。然而，如果做得不好，错误的结果会完全误导你。此外，随着服务、其特性集和行为的发展，您需要定期重新评估期望。我们应该根据这些指标多大程度上能够表明系统中实际用户的体验来进行排名，选择排名靠前的几个指标(可能不超过12个)。太多的度量标准会带来递减的回报，并且在某种程度上，收益会被维护它们的成本所抵消，或者在发布过程中如果不维护它们，会对发布结果无法保证100%的信任。为了使这个指导原则更加具体，让我们回头再来看示例。它有许多我们可以评估的指标:CPU使用量、内存占用、HTTP返回码(2xx、3xx等等)、响应延迟、正确性等等。在这种情况下，我们最好的度量标准可能是HTTP返回码和响应延迟，因为它们的降级最接近于实际用户影响。在这个场景中，CPU使用率并没有那么有用:资源使用的增加不一定会影响服务，并且可能导致不稳定或嘈杂的canary进程。这会导致操作人员禁用或忽略canary进程，这会首先破坏使用canary进程的目的。对于前端服务，我们直观地知道，响应较慢或响应失败通常会真实反映服务中存在的问题。HTTP返回码包含一些有趣的复杂情况，例如状态码404，它告诉我们没有找到资源。这可能是因为用户获得了错误的URL(想象一下在一个流行的论坛上分享了一个错误的URL)，或者因为服务器错误地停止了对资源的服务。通常，我们可以通过排除canary评估中的400级状态码，并添加黑盒监控来测试特定URL的存在，从而解决此类问题。然后，我们可以将黑盒数据作为canary分析的一部分，以帮助将canary流程与奇怪的用户行为隔离开来。度量标准应该具有代表性和可归属性观察到的指标变化其来源，应该清楚地归因于正在进行的变更，并且不应该受到外部因素的影响。在一个大的系统中(例如，许多服务器或许多容器)，我们可能会有外部性——超过连接的机器、运行具有不同性能特征的不同内核的机器，或者网络中过载的机器。此时金丝雀部分和主系统部分之间的差异，既是我们所部署的两个基础设施之间的差异，也会是我们变更导致的差异。管理金丝雀是多种力量之间的平衡。增加金丝雀的规模是减少这个问题影响的方法(如前所述)。当我们的系统达到我们认为的合理的金丝雀规模时，我们需要考虑我们选择的指标是否会显示出很大的差异。我们还应该知道canary和control环境之间共享的失败域;坏金丝雀会对控制产生负面影响，而系统中的坏行为可能会导致我们错误地评估金丝雀。同样，确保您的度量标准是良好隔离的。考虑一个同时运行我们的应用程序和其他进程的系统。整个系统的CPU使用量的急剧增加会导致糟糕的度量，因为系统中的其他进程(数据库负载、日志轮转等)可能会导致这种增加。更好的度量标准是在处理请求时所花费的CPU时间。更好的度量标准是在服务进程实际计划在CPU上的时间窗口上为处理请求服务所花费的CPU时间。虽然与我们的进程相关的严重超额的机器显然是一个问题(监控应该捕捉到它!)，但它不是由我们正在进行的更改引起的，因此不应该将其标记为金丝雀部署失败。金丝雀也需要是可归属的;也就是说，您还应该能够将canary度量与SLIs联系起来。如果一个度量可以在不影响服务的情况下发生巨大变化，那么它不适合用来评估灰度发布。评估前/评估后依然是有风险的canary过程的前后是归因问题的延伸。在这个过程中，旧系统被新系统完全替代，你的canary评估将在一段时间内比较变更之前和之后的系统行为。你可以将此过程称为时空中的canary部署，在此过程中，您通过分割时间来选择A/B组，而不是通过机器、cookie或其他方法来分割总体。由于时间是观察到的指标变化的最大来源之一，因此很难在评估之前/之后来判断性能是否下降。虽然canary部署可能导致降级，但原有系统本身也可能会降级。如果需要长时间运行canary部署，就会变得更加复杂。例如，如果在周一进行发布，可能会将工作日的行为与周末的行为进行比较，从而引入大量噪音。在该示例中，用户可能在周末以不同的方式访问该服务。从而在canary进程中引入噪音。评估前/后过程本身引入了一个问题，即大而短的错误率(由前/后评估引入)是否优于小而长的错误率(由一个小金丝雀引入)。如果新版本完全被破坏，我们能多快地检测和恢复? 大规模的金丝雀之前/之后可以更快地检测到问题，但恢复的总体时间可能仍然相当长，与较小的金丝雀类似。在此期间，用户会一直受到影响。使用渐进的灰度会更好选择的度量标准即使不符合我们理想中的属性，但仍然很有价值。我们可以通过使用更细微的灰度过程来介绍这些指标。我们可以使用包含多个阶段的canary来反映我们对度量的推理能力，而不是简单地评估单个canary阶段。在第一阶段，我们对这个版本没有信心或不了解。因此，我们希望使用一个小的阶段，以尽量减少负面影响。在小型灰度中，我们更喜欢能够最清晰地显示问题的指标——应用程序崩溃、请求失败等等。一旦这一阶段成功地过去，下一阶段将增加灰度规模，从而增强我们分析变化影响的信心。依赖和隔离正在测试的系统不会在完全真空中运行。出于实际原因，灰度和主系统可以共享后端、前端、网络、数据存储和其他基础设施。甚至可能与客户端有非常不明显的交互。例如，假设一个客户端发送了两个连续的请求。第一个请求可以由灰度部分来处理。其响应可能会改变第二个请求的内容，第二个请求可能会落在主系统部分，从而改变主系统的行为。不完美的隔离会带来几个后果。最重要的是，我们需要知道，如果灰度过程的结果表明我们应该停止生产变更并调查情况，那么灰度并不一定是错误的。这一事实对于一般的canarying来说是正确的，但是在实践中，它经常由于隔离问题而导致被强制执行。此外，不完美的隔离意味着灰度部署的错误行为也会对原始系统产生负面影响。Canarying是A/B比较，A和B有可能同时改变;这可能会导致评估灰度变得混乱。还必须使用绝对度量，例如定义的SLOs，以确保系统正确运行。在非交互系统中进行Canarying本章重点讨论了交互式请求/响应系统，它在许多方面是最简单和最常讨论的系统设计。其他系统，如异步处理管道，也同样重要，但有不同的canarying注意事项，我们将简要列举。有关数据处理管道的canarying的更多信息，请参见第13章。首先，canary的持续时间和部署本质上依赖于工作单元处理的持续时间。当涉及到交互系统时，我们忽略了这个因素，假设工作单元处理的时间不会超过几秒钟，这比canary的持续时间要短。非交互式系统中的工作单元处理(如呈现管道或视频编码)可能需要更长的时间。因此，确保canary持续时间至少跨越单个工作单元的持续时间。对于非交互式系统，隔离可能变得更加复杂。许多管道系统只有一个工作分配程序和一组使用应用程序代码的工作人员。在多阶段管道中，工作单元由工作人员处理，然后返回到池中，由同一工作人员或另一个工作人员执行下一阶段的处理。金丝雀分析有助于确保处理特定工作单元的工人总是从相同的工人池中提取——要么是金丝雀池，要么是控制池。否则，信号就会变得越来越混杂(有关理清信号的需要的更多信息，请参见349页的监视数据的要求)。最后，度量标准的选择可能更加复杂。我们可能感兴趣的是端到端处理工作单元的时间(类似于交互系统中的延迟)，以及处理本身的质量(当然，这是完全特定于应用程序的)。考虑到这些警告，canarying的一般概念仍然是可行的，并且适用相同的高级原则。监控要求在评估灰度部署时，您必须能够将部署了灰度的系统与未部署灰度的系统进行比较。通常，这需要在构造监视系统时多加注意—有效的比较非常简单，并且能够产生有意义的结果。考虑之前的例子，在5%的规模中进行灰度，错误率为20%。因为监视很可能将系统作为一个整体来观察，所以它只能检测到1%的总体错误率。根据系统的不同，这个信号可能与其他错误源无法区分(参见图16-3)。如果我们通过按照服务请求的对象来（金丝雀与主系统）分解指标，(参见图16-4)我们可以清楚地看到主系统与canary之间的错误率，这清楚地说明了全局部署将带来什么。在这里，我们看到，对整个服务的监控不足以分析灰度是否ok。在收集监视数据时，能够执行细粒度的分解非常重要，这些分解使得能够区分金丝雀和主系统的指标。收集指标的另一个难点是金丝雀的部署受到设计的时间限制。当度量指标在特定时期内进行聚合时，这可能会导致问题。考虑每小时的度量误差。我们可以通过对过去一小时的请求求和来计算这个度量。如果我们使用这个度量来评估我们的canary，我们可能会遇到问题，如下面的时间表所述:  某些事件会导致一些错误发生。  一只金丝雀被部署在5%的人口中;金丝雀的持续时间是30分钟。  canary系统开始监视每小时的错误度量，以确定部署是好是坏。  部署被检测为错误，因为每小时的错误度量与控制总体的每小时的错误显著不同。此场景是使用每小时计算一次的度量来评估仅30分钟长的部署的结果。因此，canary进程提供了一个非常模糊的信号。当使用度量来评估canary的成功时，确保度量的间隔与canary的持续时间相同或小于持续时间。相关概念通常，与客户的对话涉及到在生产中使用蓝/绿部署、人工负载生成和/或流量测试。这些概念类似于canarying，因此虽然它们不是严格意义上的金丝雀流程，但亦可使用。蓝/绿部署蓝/绿部署维护系统的两个实例：一个提供流量（绿色），另一个准备提供流量（蓝色）。 在蓝色环境中部署新版本后，将流量切换到其中。切换过程不需要停机，并且回滚只是简单逆转路由器而已。 一个缺点是该设置使用的资源是传统部署的两倍。在该设置中，您正在有效地执行前/后金丝雀（前面已讨论过）。通过同时(而不是分开地)使用蓝/绿部署，您可以或多或少地将蓝色/绿色部署用作常规的金丝雀。在此策略中，您可以将canary部署到blue(备用)实例，并在绿色和蓝色环境之间缓慢地分配流量。您的评估和比较蓝色环境和绿色环境的指标都应该与流量控制相关。这种设置类似于A/B金丝雀，此时绿色环境是主系统，蓝色环境是金丝雀部署，金丝雀数量由发送到每个金丝雀的流量控制。人工负载生成与其将实时用户流量暴露给canary部署，还不如在安全性方面犯点错误，使用人工负载。通常，您可以在多个部署阶段(QA、预生产，甚至在生产中)运行负载测试。虽然根据我们的定义，这些操作不符合canarying，但是它们仍然是找到缺陷的可行方法，但需要注意一些事项。使用人工负载进行测试可以很好地最大化代码覆盖率，但不能提供良好的状态覆盖率。在可变系统(具有缓存、cookie、请求关联等的系统)中人工模拟负载尤其困难。人工负载也可能无法准确地模拟真实系统中流量变化。有些问题可能只在无人工负载的情况下出现，从而导致覆盖率有所差距。人工负载在可变系统中也很难工作。例如，试图在计费系统上生成人工负载可能非常危险:系统可能开始向信用卡供应商发送呼叫，然后信用卡供应商将开始主动向客户收费。虽然我们可以避免测试危险的代码逻辑，但是在这些逻辑上缺乏测试会降低我们的测试覆盖率。流量测试如果人工流量不具有代表性，我们可以复制流量并将其发送到生产系统和测试环境。这种技术被称为流量镜像。生产系统服务于实际流量并响应请求，canary部署服务于副本流量并丢弃响应。您甚至可以将canary响应与实际响应进行比较，并运行进一步的分析。这种策略可以提供有代表性的流量，但通常比更直接的canary流程更复杂。在有状态系统中，流量测试也不能充分识别风险;流量副本可能会在看似独立的部署之间引入意外的影响。例如，如果canary部署和生产系统共享一个缓存，人为导致的缓存命中率增加将使canary指标的性能度量无效。结论您可以使用许多工具和方法来自动化版本发布，并将canarying引入到发布管道中。没有一种测试方法是万能的，测试策略应该由系统的需求和行为决定。Canarying可以作为一种简单、健壮且易于集成的方法来补充测试。当您及早发现系统缺陷时，用户受到的影响最小。Canarying还可以为频繁发布提供信心，并提高开发速度。正如测试方法必须随着系统需求和设计而发展一样，canarying也必须如此。前言]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十五章 配置细节]]></title>
      <url>/sre/2020/01/15/%E9%85%8D%E7%BD%AE%E7%BB%86%E8%8A%82/</url>
      <content type="text"><![CDATA[管理生产系统是SRE为组织提供价值的众多方式之一。在生产中配置和运行应用程序,需要深入了解这些系统如何组合在一起以及如何工作。当出现问题时，随时响应的工程师需要确切知道配置的位置以及如何更改配置。如果团队或组织未花精力去解决与配置相关的问题，则此责任可能成为负担。本书详细介绍了琐事的主题（见第6章）。如果您的SRE团队承担了大量与配置相关的工作负担，我们希望实现本章中介绍的一些想法可以帮助您节省部分更改配置所花费的时间。配置带来的琐事在项目生命周期的开始阶段，配置通常相对轻量且简单。您可能有一些数据格式的文件，如INI，JSON，YAML或XML。管理这些文件几乎不需要辛劳。应用程序、服务器和变体的数量随着时间的推移而增加，配置可能变得非常复杂和冗长。例如，一开始可以通过单个配置文件来进行“配置更改”，但现在必须更新多个位置的配置文件。阅读这样的配置也很困难，因为重要的差异被无关且重复细节所淹没。这种与配置相关的琐事是重复的琐事：管理跨系统配置的无技术含量的任务。这种工作不仅限于大型组织和庞大的系统 –对于具有许多独立配置组件的微服务架构而言，这种情况尤为常见。工程师通常通过构建自动化或配置框架来应对重复工作。它们旨在消除配置系统中的重复性，并使配置更易于理解和维护。重复利用软件工程中的技术，这种方法通常使用“配置语言” .Google SRE创建了许多配置语言，旨在减少我们最大和最复杂的生产系统的辛劳。不幸的是，这种策略并不能根除配置导致的琐事。将你从大量的个人配置中解脱出来，该项目（及其配置资料库）以新的速度增长。不可避免地，你遇到了复杂的琐事：处理复杂自动化中出现的、有时是不受欢迎的挑战性行为和令人沮丧的任务。该琐事通常在较大的组织（10多名工程师）和一直增长的混合系统中出现。你越早解决就越好;  配置文件的大小和复杂性只会随着时间的推移而增长。减少配置导致的琐事如果项目充斥着与配置相关的工作，您可以采取一些基本策略来改善这种情况。在极少数情况下，如果您的应用程序是自定义构建的，您可以选择完全删除配置。在处理配置的某些方面时，应用程序可能天然地就比配置语言更好：让应用程序使用默认值是有意义的，因为它可以访问有关机器的信息或者动态地改变某些值，或者可以根据负载进行扩展。如果配置不可删除，并且重复琐事正在成为问题，请考虑自动化以减少配置文件中的重复性。可能需要集成新的配置语言，或者需要改进或替换现有的配置文件。接下来，第317页的“配置系统的关键属性和缺陷”一节提供了有关选择或设计系统的一些指导。如果选择新的配置框架，则需要将配置语言与需要配置的应用程序集成。“集成现有应用程序：Kubernetes。（第322页）使用Kubernetes作为现有应用程序示例，要集成的应用程序和“集成自定义应用程序（内部软件）”（第326页）提供了一些更常规的建议。这些部分使用Jsonnet（作为代表进行说明）演示一些示例。一旦有适当的配置系统 - 不管是否是现有解决方案，还是选择新的配置语言进行实施 。 “有效运行配置系统”（第329页）中的最佳实践，“何时评估配置”（第331页）和“防止滥用配置”（第331页）都有助于优化设置，无论使用哪种语言。采用这些流程和工具有助于最大限度地降低复杂程度。配置系统的关键属性和缺陷第14章概述了任何配置系统的一些关键属性。除了理想中的通用要求（如轻量级，易学，简单和富有表现力）之外，高效的配置系统必须：  通过配置工具对配置文件进行管理（线程，调试器，格式化程序，IDE集成等）可以支持配置合法性检查，（增强）工程师信心和（提高）工作效率  提供回滚配置和一般可重复性的密封评估。  单独的配置和数据，以便于分析配置和一系列配置界面。普遍而言，人们不觉得这些属性是至关重要的，并且达到目前理解的程度已经是一个征程。（以至于）在此过程中，Google也发明了几种缺乏这些关键属性的配置系统。但这不仅止存在于我们之中，虽然流行的配置系统种类繁多，但你很难找到一个不会违反以下任意一条的系统。缺陷一：未能将配置视为编程语言问题如果你不是有意设计一门语言，那么最终得到的“语言”很可能不是一门好语言。虽然配置语言描述数据而不是行为，但它们仍然具有编程语言的其他特征。如果我们的配置策略以仅使用数据格式为目标开始，那么编程语言功能往往会渗透到后门。该格式不是仅保留数据语言，而是一种深奥而复杂的编程语言。例如，某些系统将count属性添加到正在配置的虚拟机（VM）的架构中。此属性不是VM本身的属性，而是表示需要多个属性。虽然有用，但这是编程语言的一个特性，而不是数据格式，因为它需要外部编译器或解释器。经典编程语言方法将使用工件外部的逻辑（例如for循环或列表理解）来根据需要生成更多VM。另一个例子是一种配置语言，它产生字符串插值规则而不是支持通用表达式。这些字符串似乎只是“数据”，尽管它们实际上可以包含复杂的代码，包括数据结构操作，校验和，base64编码等。流行的YAML+Jinja解决方案也有缺点。简单的纯数据格式（如XML，JSON，YAML和文本格式的协议缓冲区）是纯数据用例的绝佳选择。同样，文本模板引擎（如Jinja2或Go模板）非常适合HTML模板化。但是，当使用配置语言时，人类和工具难以维护和分析。在这些情况下，该缺陷将导致出现复杂的、深奥不适合工具的“语言”。缺陷二：设计意外或特殊语言功能在大规模操作系统中，SRE通常会觉察到配置可用性问题。新语言不具备良好的工具支持（IDE支持，良好的连接），如果开发语言具有未公开的、或深奥的语义特性，那么开发自定义工具则很痛苦。随着时间的推移，将特殊编程语言功能添加到简单的配置格式可能会拥有一个功能完整的解决方案，但是临时语言更复杂，并且通常比其他经过设计的等价语言更不使用。这其中还会带来开发陷阱和特性风险，因为设计者无法提前考虑功能之间的相互作用。如果不希望配置系统变得足够复杂，而是简单的编程结构就能解决的话，最好在初始设计阶段考虑好这些要求。缺陷三：构建太多特定领域的优化对于新的特定领域的解决方案，用户群越小则其出现的的时间就会越长, 因为其需要积累足够的用户来证明构建工具的合理性。工程师不愿意花时间理解该语言，因为它在该领域之外几乎没有适用性。像Stack Overflow这样的学习资源基本不可用。缺陷四：混淆“配置评估”与“副作用”副作用包括在配置运行期间更改外部系统或咨询带外数据源（DNS、VM ID、最新构建版本）。允许这些副作用的系统会破坏密封性，影响配置与数据分离。在极端情况下，如果不花钱保留云资源，就无法调试配置。为了分离配置和数据，首先评估配置，然后将结果数据提供给用户进行分析，然后才考虑副作用。缺陷五：使用现有的通用脚本语言，如Python、Ruby或Lua这似乎是避免前四个陷阱的一种微不足道的方法，但使用通用脚本语言的实现是重量级的和/或需要侵入式沙盒来确保密封性。由于通用语言可以访问本地系统，基于安全性考虑也可能需要沙盒。此外，无法保证维护配置人员熟悉所有语言。为了避免这些陷阱，开发了用于配置的可重用特定语言（DSL），例如HOCON、Flabbergast、Dhall和Jsonnet。我们建议使用现有的DSL进行配置。即使DSL看起来太强大，无法满足你的需求，可能需要在某些时候使用附加功能，并且始终可以使用内部样式指南来限制语言的功能。   Jsonnet的简介   Jsonnet是一个密封的开源DSL，可以用作库或命令行工具为任何应用程序提供配置。在Google内外都广泛使用。  这种语言对程序员来说很熟悉：它使用类似Python的语法、面向对象和功能构造。它是JSON的扩展，这意味着JSON文件只是一个输出自身的Jsonnet程序。在使用引号和逗号时，Jsonnet比JSON更方便，并支持注释。更重要的是，它增加了计算结构。  你不需要特别熟悉Jsonnet语法来完成本章的其余部分，只需花一些时间阅读在线教程就可以入门。  Google或我们的读者群中没有主流配置语言，但我们需要选择语言方便我们提供示例。本章使用Jsonnet来展示我们在第14章中所提供建议的示例。  如果你尚未使用特定配置语言并且想要使用Jsonnet，则可以直接应用本章中的示例。我们会尽力让你尽可能轻松地从代码示例中抽象出基础原理。  此外，一些示例探索了你可能希望在编程书中找到的概念（如图灵完整性）。我们只在必要时深入研究，以解释在生产中真正困扰我们的微妙之处。在大多数复杂的系统中 - 当然还有配置方面 - 故障处于边缘。集成配置语言本节使用Jsonnet讨论如何将配置语言与你需要配置的应用程序集成，相同的技术也适用其他配置语言。以特定格式生成配置配置语言可以以正确的格式本机输出。例如，Jsonnet输出JSON，它与许多应用程序兼容。对于扩展JSON的语言的消费者，JSON也是足够的，例如JavaScript、YAML或HashiCorp的配置语言。如果这是你面对的情况，则无需进行其他任何集成工作。对于本机不支持的其他配置格式：  你需要找到一种在配置语言中表示配置数据的方法。这并不难，因为配置值（如图、列表、字符串和其他原始值）是通用的，并且可用于所有语言。  一旦用配置语言表示了这些数据，就可以使用该语言的结构来减少重复（减少工作量）。  你需要为必要的输出格式编写（或重用）序列化函数。例如，Jsonnet标准库具有从其内部类似JSON的表示中输出INI和XML的功能。如果配置数据无法在配置语言中表示（例如，Bash脚本），你可以使用基本的字符串模板技术作为最后手段。可以在http://bit.ly/2La0zDe找到使用示例。推动多种应用一旦可以从配置语言驱动任意现有应用程序，你就可以从同一配置中定位多个应用程序。如果你的应用程序使用不同的配置格式，则需要做一些转换工作。一旦能够以一定的格式生成配置，你就可以轻松统一、同步和消除整个配置文件库中的重复。鉴于JSON和基于JSON格式的普及，甚至可能不必生成不同的格式 - 例如，如果使用部署体系结构，使用GCP部署管理器，AWS CloudFormation或Terraform作为基础架构，以及Kubernetes作为容器，则情况确实如此。此时，你可以：  从单个Jsonnet评估中输出Nginx Web服务器配置和Terraform防火墙配置，该评估仅定义端口一次。  从相同文件配置监控仪表盘，保留策略和警报通知管道。  通过将初始化命令从一个列表移动到另一个列表，管理VM启动脚本和磁盘映像构建脚本之间的性能权衡。在将不同的配置统一到之后，会有很多机会来优化和抽象配置。配置甚至可以嵌套 - 例如，Cassandra配置可以嵌入其基础架构的DeploymentManager配置内或Kubernetes ConfigMap内。一个优秀的配置语言可以处理任何笨拙的字符串引用，通常这个操作自然而简单。为了便于为各种应用程序编写许多不同的文件，Jsonnet有一种模式，配置执行产生一个JSON对象，将文件名映射到文件内容（根据需要进行格式化）。可以在其他配置语言中模拟此功能，方法是在字符串之间产生映射，并使用后续处理步骤或脚本来编写文件。集成现有应用程序：KubernetesKubernetes提出了一个有趣的案例研究，原因如下：  运行在Kubernetes上的作业需要配置文件，并且配置可能会很复杂。  Kubernetes没有附带绑定的配置语言（甚至没有专门的配置语言）。对于最简单的结构，Kubernetes用户只需使用YAML即可。对于具有较大的基础结构，Kubernetes用户可以使用Jsonnet等语言扩展其工作流程，以其作为该规模所需的抽象工具。Kubernetes提供什么Kubernetes是一个开源系统，用于在一组机器上编排容器化工作负载。它的API允许你自己管理容器和许多重要的细节，例如容器之间的通信、集群内外的通信、负载平衡、存储、渐进式部署和自动扩展。每个配置项都用一个JSON对象表示，该对象可以通过API进行管理。命令行工具kubectl允许从磁盘读取这些对象并将它们发送到API。在磁盘上，JSON对象实际上被编码为YAML流，YAML易于读取，并可以通过常用库轻松转换为JSON。开箱即用的用户体验包括编写代表Kubernetes对象的YAML文件并运行kubectl以将它们部署到集群。要了解配置Kubernetes的最佳实践，请参阅有关该主题的Kubernetes文档。Kubernetes配置示例YAML是Kubernetes配置的用户界面，它提供了一些简单的功能，如注释，并且具有大多数人中所意的简洁的原始JSON语法。然而，YAML在抽象方面不尽如人意：它只提供锚点，这在实践中很少有用，而且Kubernetes不支持。假设你要使用不同的命名空间、标签和其他微小差异，将Kubernetes对配置文件复制四次。遵循基础结构不变的最佳实践，可以存储所有四个文件的配置，复制配置的相同处。以下代码片段提供了其中一个文件（为简洁起见，我们省略了其他三个文件）：# example1.yamlapiVersion: v1kind: Servicemetadata:     labels:        app: guestbook        tier: frontend     name: frontend     namespace: prodspec:    externalTrafficPolicy: Cluster    ports:    - port: 80       protocol: TCP       targetPort: 80    selector:       app: guestbook       tier: frontend    sessionAffinity: None    type: NodePort此格式难以阅读和维护，因为重要的差异被模糊了。集成配置语言如第315页上的“配置引发的操作”中所述，管理大量YAML文件可能会花费大量时间。配置语言可以帮助简化此任务。最直接的方法是从Jsonnet的每次执行中发出一个Kubernetes对象，然后将生成的JSON直接传递给kubectl，kubectl处理JSON，就好像它是YAML一样。或者，您可以发出YAML流（一系列此类对象或单个kubectl列表对象，或让Jsonnet从同一配置发出多个文件。有关进一步的讨论，请参阅Jsonnet网站）。开发人员应该意识到，通常，YAML允许您编写JSON中无法表达的配置（因此，Jsonnet无法生成）。YAML配置可以包含异常的IEEE浮点值，如NaN，或者包含非字符串字段的对象，如数组、其他对象或null。实际上，这些功能很少使用并且Kubernetes不允许使用它们，因为配置在发送到API时必须进行JSON编码。以下代码段显示了我们的示例Kubernetes配置在Jsonnet中的样子：请注意以下事项：// templates.libsonnet{    MyTemplate:: {          local service = self,          tier:: error 'Needs tier',          apiVersion: 'v1',          kind: 'Service',          local selector_labels = { app: 'guestbook', tier:service.tier },          metadata: {                labels: selector_labels,                name: 'guestbook-' + service.tier,                namespace: 'default',           },           spec: {                externalTrafficPolicy: 'Cluster',                ports: [{                    port: 80,                    protocol: 'TCP',                    targetPort: 80,                }],            selector: selector_labels,            sessionAffinity: 'None',            type: 'NodePort',        },    },}// example1.jsonnetlocal templates = import 'templates.libsonnet';templates.MyTemplate {    tier: 'frontend',}// example2.jsonnetlocal templates = import 'templates.libsonnet';templates.MyTemplate {    tier: 'backend',    metadata+: {        namespace: 'prod',    },}// example3.jsonnetlocal templates = import 'templates.libsonnet';templates.MyTemplate {    tier: 'frontend',    metadata+: {        namespace: 'prod',        labels+: { foo: 'bar' },},}// example4.jsonnetlocal templates = import 'templates.libsonnet';templates.MyTemplate {    tier: 'backend',}注意以下几点：  我们通过四次实例化抽象来表达所有四种变体，但你也可以使用功能抽象。  虽然我们为每个实例使用单独的Jsonnet文件，但你也可以将它们合并到一个文件中。  在抽象模板中，空间命名为默认值，并且必须被覆盖。  乍一看，Jsonnet略显冗长，但随着模板实例化数量的增加而降低了工作量。在MyTemplate中，local关键字定义了一个变量服务，该服务初始化为self（对最近的封闭对象的引用）。这允许您从嵌套对象中引用对象，其中self被重新定义。tier字段有两个冒号（而不是常规的JSON单冒号），并且在生成的JSON中隐藏（不输出）。否则，Kubernetes将拒绝tier为无法识别的字段。隐藏字段仍然可以被覆盖和引用 - 在本例中为service.tier。模板本身不能使用，因为引用service.tier会触发错误构造，这会引发给定文本的运行时错误。为避免错误，模板的每个实例都会使用其他表达式覆盖tier字段。换句话说，这种模式表达类似于纯虚拟/抽象方法的东西。使用抽象函数意味着配置只能参数化。相反，模板允许您覆盖父项中的任何字段。如第14章所述，虽然简洁性应该是您设计的基础，但简单易行的能力非常重要。模板覆盖提供了一个有用的避开方式，可以更改通常被认为太低级别的特定细节。例如：templates.MyTemplate {    tier: 'frontend',    spec+: {        sessionAffinity: 'ClientIP',    },}这是将现有模板转换为Jsonnet的典型工作流程：  将其中一个YAML格式转换为JSON。  通过Jsonnet格式化程序运行生成的JSON。  手动添加Jsonnet构造以抽象和实例化代码（如示例中所示）。该示例显示了如何在保留不同的某些字段的同时删除重复内容。随着差异越来越微妙（例如，字符串只是略有不同）或表达具有挑战性（例如，配置具有结构差异，如阵列中的附加元素，或者应用于阵列的所有元素的相同差异），使用配置语言变得更加引人注目。通常，抽象不同配置的共性可以促进关注点的分离，并且与编程语言中的模块化具有相同的好处。您可以针对许多不同的用例利用抽象功能：      单个团队可能需要创建几乎（但不完全）相同的多个配置版本。例如，在跨不同环境（prod/stage/dev/test）管理部署，调整不同体系结构上的部署或调整时区不同地区的能力。        组织可能拥有一个基础架构团队，负责维护可重用组件-API服务框架、缓存服务器或MapReduces。对于每个组件，基础结构团队可以维护一个模板，该模板定义大规模运行该组件所需的Kubernetes对象。每个应用程序团队都可以实例化该模板以添加其应用程序的详细信息。  集成自定义应用程序（内部软件）如果你的基础架构使用任何自定义应用程序（即内部开发的软件，而不是现成的解决方案），那么可以将这些应用程序设计为与可重用的配置语言共存。用于编写配置文件或与生成的配置数据交互时（例如，出于调试目的或与其他工具集成时），本节中的建议应改善整体用户配置体验。它们还应简化应用程序的设计并将配置与数据分开。处理自定义应用程序的通用策略应该是：  让配置语言处理它的设计目的:语言问题的方面。      让应用程序处理所有其他功能。以下最佳实践包括使用Jsonnet的示例，但相同的建议也适用于其他语言：    使用单个纯数据文件，然后让配置语言使用import将配置拆分为文件。这意味着配置语言实现只需要发出（并且应用程序只需要使用）单个文件。此外，由于应用程序可以以不同方式组合文件，因此该策略明确且清晰地描述了如何组合文件以形成应用程序配置。  使用对象表示命名实体的集合，其中字段包含对象名称，值包含实体的其余部分。避免使用每个元素都有名称字段的对象数组。      Bad JSON:      [          { "name": "cat", ... },          { "name": "dog", ... }      ]  Good JSON:      {           "cat": { ... },           "dog": { ... }   }        该策略使得集合（和单个动物）更容易扩展，并且您可以通过名称引用实体（例如，animals.cat）而不是引用索引（例如，动物[0]）。    避免在顶级按类型对实体进行分组。构造JSON，以便将逻辑相关的配置分组到同一子树中。这允许抽象（在配置语言级别）遵循功能边界。      Bad JSON:      {          "pots": { "pot1": { ... },"pot2": { ... } },          "lids": { "lid1": { ... }, "lid2":{ ... } }      }  Good JSON:      {          "pot_assembly1": { "pot": { ... },"lid": { ... } },          "pot_assembly2": { "pot": { ... },"lid": { ... } }      }        在配置语言级别，此策略支持以下抽象：      local kitchen = import 'kitchen.libsonnet';  {  pot_assembly1: kitchen.CrockPot,  pot_assembly2: kitchen.SaucePan { pot+: { color: 'red' }},  }        保持数据一直简单:：          –避免在数据表示中嵌入语言功能（如“陷阱1：无法将配置识别为编程语言问题”（第317页）中所述）。这些类型的抽象将只会产生混淆，因为它们会强制用户决定是使用数据表示形式还是配置语言中的抽象功能。      –不要担心过于冗长的数据表示。减少冗长的解决方案会带来复杂性，并且这个问题可以使用配置语言管理。      –避免在应用程序中解释自定义字符串插值语法，例如字符串中的条件或占位符引用。有时解释是不可避免的 - 例如，当您需要描述在生成配置的纯数据版本（报警，处理程序等）之后执行的操作时。但除此之外，让配置语言尽可能多地完成语言级别的工作。      如前所述，如果您可以完全删除配置，那么这样做始终是您的最佳选择。虽然配置语言可以通过使用具有默认值的模板来隐藏底层模型的复杂性，但生成的配置数据并不是完全隐藏的 - 它可以由工具处理、由人检查或加载到配置数据库中。出于同样的原因，不要依赖配置语言来修复模型本身中底层modelfix中不一致的命名、复数或错误。如果您无法修复模型中的不一致性，最好在语言级别使用它们以避免更多的不一致。根据我们的经验，配置更改往往会在系统中随着时间的推移成为导致停机的根本原因（请参阅附录C中的停机的主要原因列表）。验证配置更改是保持可靠性的关键步骤。我们建议在配置执行后立即验证生成的配置数据。单独的语法验证（即，检查JSON是否可解析）将不会发现许多错误。在通用模式验证之后，检查特定于应用程序域的属性 - 例如，是否存在必填字段、是否存在引用的文件名，以及提供的值是否在允许的范围内。您可以使用JSONschema验证Jsonnet的JSON。对于使用协议缓冲区的应用程序，您可以从Jsonnet轻松生成这些缓冲区的规范JSON格式，协议缓冲区实现将在反序列化期间进行验证。无论您决定如何验证，都不要忽略无法识别的字段名称，因为它们可能表示配置语言级别的拼写错误。Jsonnet可以使用::语法屏蔽不应输出的字段。在precommit hook中执行相同的验证也是一个好主意。有效地运行配置系统在以任何语言实现“配置为代码”时，我们建议遵循通常有助于软件工程的规程和流程。版本配置语言通常会触发工程师编写模板库和实用程序函数。通常，一个团队维护这些库，但许多其他团队可能会使用它们。当您需要对库进行重大更改时，您有两种选择：  提交所有客户端代码的全局更新，重构代码以使其仍然有效（这可能在组织上不可行）。  使用版本库，以便不同的消费者可以使用不同的版本并独立迁移。选择使用弃用版本的消费者将无法获得新版本的好处，并将产生技术债务 - 有一天，他们将不得不重构他们的代码以使用新库。大多数语言，包括Jsonnet，都没有为版本控制提供任何特定的支持; 相反，你可以轻松使用目录。有关Jsonnet中的实际示例，请参阅ksonnet-lib存储库，其中版本是导入路径的第一个组件：    local k = import 'ksonnet.beta.2/k.libsonnet';源控制第14章主张保留配置更改的历史记录（包括谁创建它们）并确保回滚简单可靠。检查配置到源代码控制中可以带来所有这些功能，还可以编写查看配置更改的代码。工具考虑如何强制执行样式和lint配置，并调查是否有一个编辑器插件将这些工具集成到您的工作流程中。您的目标是在所有作者之间保持一致的风格、提高可读性并检测错误。有些编辑器支持可以为您运行格式化程序和其他外部工具的写后hook.。您还可以使用预先挂钩来运行相同的工具，以确保签入的配置具有高质量。测试我们建议对上游模板库实施单元测试。确保库在实例化时生成预期的具体配置。与之对应的，为了便于维护，函数库也应该包括单元测试在Jsonnet中，你可以将测试编写为Jsonnet文件：  导入要测试的库。  应用库  使用assert语句或标准库assertEqual函数来验证其输出。后者在其错误消息中显示所有不匹配的值。以下示例为测试joinName函数和MyTemplate：// utils_test.jsonnetlocal utils = import 'utils.libsonnet';std.assertEqual(utils.joinName(['foo', 'bar']),'foo-bar') &amp;&amp;std.assertEqual(utils.MyTemplate { tier: 'frontend' }, {... })对于较大的测试套件，你可以使用Jsonnet社区成员开发的更全面的单元测试框架。你可以用此框架以结构化方式定义和运行测试套件-例如，报告所有失败测试的集合，而不是在第一个失败的断点中中止执行。何时评估配置我们的关键属性包括封闭性;也就是说，无论它们在何时何地执行，相同的配置语言必须生成相同的配置数据。如第14章所述，如果系统依赖于其密封环境之外可以改变的资源，则系统可能很难或无法回滚。通常，封闭性意味着Jsonnet代码始终可以与它所代表的扩展JSON互换。因此，你可以在任何时间从Jsonnet生成JSON。我们建议在版本控制中存储配置。你可以在注册之前验证配置。此外，应用程序在需要JSON数据时可以评估配置。同样，你可以在构建时进行评估。你可以根据用例的具体情况对每个选项进行评估优化。初期：检查JSON你可以在检查版本控制之前从Jsonnet代码生成JSON。典型的工作流程如下：  修改Jsonnet文件。  运行Jsonnet命令行工具（可能包装在脚本中）以重新生成JSON文件。  勾选预先提交确保Jsonnet代码和JSON输出始终一致。  将所有内容打包成拉取请求以进行代码审查。优点  审阅者可以检查具体的更改 - 例如，重构不应该影响生成的JSON。  可以在生成和抽象级别上跨不同版本检查多个作者的行注释。同样利于对变更的审核。  在运行时你无需运行Jsonnet，这样可以降低复杂性、二进制大小和风险。缺点  生成的JSON不一定是可读的 - 例如，如果它嵌入了长字符串。  由于其他原因，JSON可能不适合检查版本控制 - 例如，如果它太大或包含隐私。  如果单个Jsonnet文件的许多并发编辑同时合并到单个JSON文件，则可能会出现合并冲突。中期：构建时评估你可以通过在构建时运行Jsonnet命令行实用程序并将生成的JSON嵌入到发布工件中（例如，作为tarball）来避免将JSON检入源控件。应用程序代码只是在初始化时从磁盘读取JSON文件。如果你使用的是Bazel，则可以使用Jsonnet Bazel规则轻松实现此目的。在谷歌，我们通常使用这种方法，该方法有如下优点。优点  你可以控制运行时的复杂性、二进制大小和风险，而无需在每个拉取请求中重建JSON文件。  原始Jsonnet代码与生成的JSON之间不存在去同步的风险。缺点  构建更复杂。  在代码审查期间评估具体变化更加困难。后期：在运行时评估链接Jsonnet库允许应用程序本身随时解释配置，产生的JSON配置的内存中表示。优点  它更简单，不需要事先评估。  可以在执行期间评估用户提供的Jsonnet代码。缺点  任何链接库都会增加覆盖范围和风险。  可能会在运行时发现配置错误，为时已晚。  如果Jsonnet代码不稳定，则必须特别小心。（我们在第333页的“防止滥用配置”中讨论了原因）按照我们的运行示例，如果你正在生成Kubernetes对象，何时应该运行Jsonnet？答案取决于你的具体实施。如果你正在构建类似ksonnet（从本地文件系统运行Jsonnet代码的客户端命令行工具），最简单的解决方案是将Jsonnet库链接到该工具并评估正在进行的Jsonnet。这样做是安全的，因为代码在作者自己的机器上运行。Box.com的基础架构使用Git将配置更改推送到生产环境。为了避免在服务器上执行Jsonnet，Git会对保存在存储库中的生成的JSON进行操作。对于像Helm或Spinnaker这样的部署管理守护程序，唯一的选择是在运行时评估服务器上的Jsonnet（下一节中将介绍注意事项）。防止滥用配置与长时间运行的服务不同，配置执行应该随着配置生成快速终止。然而，由于错误或恶意攻击，配置可能会占用任意数量的CPU时间或内存。为了说明原因，请考虑以下非终止Jsonnet程序：    local f(x) = f(x +1); f(0)使用无界内存的程序与之类似：    local f(x) = f(x +[1]); f([])你可以使用对象而不是函数或其他配置语言编写等效示例。可以尝试通过限制语言来避免过度消耗资源，以使其不再是图灵计算机完成的。但是，强制所有配置终止并不一定能防止过度消耗资源。编写一个耗费足够时间或内存的程序而实际是不终止的程序是很容易的。例如：    local f(x) = if x== 0 then [] else [f(x - 1), f(x - 1)]; f(100)实际上，即使使用简单的配置格式（如XML和YAML），也存在此类程序。当然，这些情景的风险取决于具体情况。问题较少的情况，假设命令行工具使用Jsonnet构建Kubernetes对象，然后部署这些对象。在这种情况下，Jsonnet代码是可信的：很少产生非终止的事故，你可以使用Ctrl-C来缓解它们。很少会产生内存耗尽。另一个极端情况，使用类似Helm或Spinnaker这样的服务，它接受来自最终用户的任意配置代码并在请求处理程序中对其进行评估，你需要避免占用请求处理程序或耗尽内存的DOS攻击。如果在请求处理程序中评估不受信任的Jsonnet代码，则可以通过沙盒化Jsonnet执行来避免此类攻击。一个简单的策略是使用单独的进程和ulimit（或其非UNIX等价物）。通常，你需要fork到命令行可执行文件而不是链接Jsonnet库。因此，未在给定资源内完成的程序将执行失败并通知最终用户。为了进一步防御C++内存漏洞利用，你可以使用Jsonnet的本机Go实现。结论无论是使用Jsonnet、采用其他配置语言还是开发自己的配置语言，我们都希望你能够应用这些最佳实践来管理配置生产系统所需的复杂性和操作负载。至少，配置语言的关键属性是优秀的工具，封闭配置以及配置和数据的分离。你的系统可能不至于复杂到使用配置语言。过渡到像Jsonnet这样的特定于域的语言是一种在你的系统复杂度增加时可以考虑的策略。它会提供一致且结构良好的界面，让你的SRE团队有更多时间来处理其他重要项目。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十四章 系统配置最佳实践]]></title>
      <url>/sre/2020/01/14/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</url>
      <content type="text"><![CDATA[系统配置是SRE经常要面对的问题。这是一项繁琐的工作，有时还会让人沮丧，特别是当工程师不熟悉系统，或是系统配置目标不够清晰时这种情况更为明显。系统配置常见的场景如下：在系统初始阶段的配置设计，出现事故时的紧急配置设计。本章基于经验和策略，以基础架构系统工程师的角度来进行系统配置，从而达到“安全和可持续”的目标。什么是配置？系统并不是永恒不变的。不断变化的业务需求、基础架构的需求和其他因素都会导致系统发生变化。当需要对系统快速迭代时（这个过程是昂贵和冗长的，不仅仅包含系统的重构、部署和代码的更改，系统配置的更新也是重要的一部分。由此，我们需要提供一种低开销的和人机界面的方式进行系统配置。SRE会利用此系统进行系统部署、性能调整和事件响应期间的配置变更。我们将系统分为三个关键组件：. 应用程序. 数据集. 系统配置实际上，我们是无法将以上三个部分清楚的区分。例如，许多系统使用编程语言进行配置。同样，数据集可能包含代码，例如存储SQL的过程，这些代码已经构成了“应用程序”。而良好的配置界面可以完成快速、可信和可测试的配置更改。减少错误的发生，降低工程师的学习曲线。配置的可靠性系统最终由人来进行管理和配置。系统配置人机界面的质量会影响团队运行该系统的能力和可靠性。精心设计的配置界面对使用者的影响类似于代码质量对系统可维护性的影响。但在一些方面，配置往往与代码有不同的意义。通过代码更改系统功能是一个冗长且复杂的过程，涉及的范围往往是小增量的更改、代码审查和测试。相比之下，更改单个配置选项可能会对功能产生重大影响。例如，一个错误的防火墙配置规则可能会将自己锁到系统之外。而且，配置通常存在于未经测试（甚至是不可测试）的环境中。而且，系统配置更改可能需要工程师处于很大的压力下。在故障期间，可以简单安全地调整配置是必不可少的过程。举个航空的例子，早期，飞机的控制界面和指示灯混乱导致了许多安全事故。研究表明，无论飞行员技能或经验如何，操作故障都是频繁的。所以，可靠的配置是至关重要的。原理和机制在设计新软件或使用现有软件组装新系统时我们需要讨论配置：如何配置它？配置如何加载？我们将配置设为两部分：配置理论和配置机制。配置理论适用于完全独立于所选语言和其他机制的配置方面。我们对原理的讨论包括如何构造配置，如何实现抽象，以及如何无缝地支持不同的用例。我们对配置机制讨论涵盖了语言设计，部署策略以及与其他系统的交互等方面。本章重点关注机制，部分原因是语言选择已经在整个行业中进行了广泛的讨论。此外，一些特定的组织可能已经具有强大特色化的要求，例如预先存在的配置基础架构，因此配置机制不容易推广。Jsonnet的以下章节给出Jsonnet现有软件中配置机制的案例——特别是语言设计方面的。分别讨论理论和机制使我们能够更清楚地进行配置。实际上，如果配置需要大量难以理解的用户输入，那么配置语言（无论是XML还是Lua）等实现的细节也无关紧要。相反，如果必须将它们输入到非常麻烦的界面中，即使最简单的配置输入也会导致问题。比如旧的Linux内核配置的过程是——必须通过一系列命令进行配置设置每个参数。为了进行最简单的校正，用户必须从头开始配置过程。配置理论本节讨论内容基于完整配置实现，因此下文一些观点是对所有配置实现的概况。在以下理论观点中，我们的理想配置是不需要任何配置。在理想场景下，新系统部署前，能根据部署信息、负载或其他配置自动生成正确配置。当然，这些实际都不太可能实现。需要指出的是，这个想法指出了配置的目标：避免复杂、多样的配置，向简单化努力。历史上，NASA的核心系统提供了大量的控制操作（相当于配置），这需要对操作者进行高强度的训练才能掌握。图14-1，展现了NASA的一名操作者，通过复杂的操作排列进行飞行器控制。在现代工业中，这种培训已不再可行。 图14-1 NASA航天器控制中心的控制面板，说明了配置复杂性 尽管这些理想的配置可以减少对操作员的训练，但也让操作员对问题的深入理解降低。然而，随着系统复杂性增加，操作员对系统的认知理解却越来越重要。当我们把这些原则应用到Google的系统时，目标是让内部用户使用简单、全面和低成本。与用户交互的配置问题无论你的配置是什么，如何配置，最终都体现在与计算机交互的一个界面，来询问用户接下来如何操作，让用户来选择。无论是XML编辑，还是GUI向导，这种模型都适用。在现代软件系统中，我们可以从两个不同的角度来看待这个模型：以基础设施为主：提供尽可能多的配置。这样做使用户能够根据他们的确切需求调整系统。配置越多越好，因为系统可以调整到完美。以用户为主：首先会询问用户一部分关于基础设施的问题，之后才能回归到实际业务上。这样的配置，越少越好，因为回答问题是很繁琐、麻烦的事情。在最初的理论模型中，我们推崇以用户为中心的理念。这样的软件设计脱离了实际。以用户为中心的配置，要求你的软件设计需要真正考虑到用户的需求，专注于用户，这就需要对用户的需求进行深入挖掘。相比而言，以基础设施为中心的配置，需要你为用户提供丰富的配置，来达到系统操作的目的。这些模型互相不冲突，但调试他们比较困难。在配置中，选项可枚举是比较好的，而不是设计出一个极其通用的软件，真正做到“开箱即用”。实际中，可以通过各种方式（后续章节会介绍）来删除一些配置，让系统的配置从以基础设施为主，向以用户为主进行转变。交互性问题更应接近用户目标当我们以用户为中心进行配置时，提出的交互式问题，需要确保用户能够准确理解。我们可以思考用户输入的本质：一方面，针对用户的每一项提问，要有更少的配置选项；另一方面，用户又想了解系统如何实现他们的需求，这就需要更多的选项。让我们以沏茶的过程来比喻如何配置的过程。在配置项比较少的情况下，用户可以要求“热绿茶”，并能基本满足用户需求。相反，配置项很多的情况下，用户可以要求：水量、水温、茶叶品牌、茶叶分量、浸泡时间、茶杯类型。为了获取接近完美的茶，而使用更多配置项，坚持这些细节所付出的成本和代价，可能太大。这个比喻对用户和配置系统开发人员都很有帮助。当用户确定操作步骤时，系统应按照他们要求进行。但是当用户只清楚自己目标时，我们的系统可以改进其中的配置步骤，最终实现用户目标即可。因此，预先了解用户目标是很有必要的。此理论在实际应用中发挥的价值，以任务调度系统来补充说明。假如你需要运行一个分析进程，通过Kubernetes或Mesos可以实现你的目标，而不需要你花费很长时间去配置细节参数，比如选择哪台物理机运行等。配置的必选项和可选项配置分为两类：必选项和可选项。必选项的配置回答的问题针对核心功能。例如谁为一项手术收费。可选项一般不代表核心功能，但配置这些选项可以提高功能的质量——例如，设置一些工作进程。为了保持以用户为中心并确保易用性，你的系统应尽量减少必选配置的数量。这不是一件容易的事，但这很重要。虽然人们可能会争辩说，增加一个或两个小步骤只会增加很少的成本，但工程师的生活往往是一个无穷无尽的单独步骤链。这些小步骤的减少可以显着提高工作效率。最初的一组必选配置通常包括您在设计系统时考虑的问题。减少必选项的最简单方法是将它们转换为可选项，这意味着这些默认配置可以安全有效地应用于大多数（如果不是全部）用户。例如，我们可以简单地执行运行，而不是要求用户定义执行是否应该运行。虽然默认值通常是保存在代码中的静态值，但并非必须如此。它可以基于系统的其他属性动态确定。利用动态确定可以进一步简化配置。对于上下文，请参考以下动态默认示例。计算密集型系统通常可以通过配置控制使用多少计算线程。它的动态缺省配置了与系统（或容器）具有执行核数一样多的线程。在这种情况下，单个静态默认值没有用。动态默认值意味着我们不要求用户给定平台上部署的正确线程数。同样，单独部署在容器中的Java二进制文件可以根据容器中的可用内存自动调整其堆限制。这是两个常见的动态默认值示例。如果您需要限制资源使用，则对能够覆盖配置中的动态默认值非常有用。使用动态默认值可能不适用于所有人。随着时间的推移，用户可能更喜欢不同的方法并要求更好地控制动态默认值。如果很多用户反映动态配置有问题，一般来说这表示你的动态配置逻辑可能不再符合当前用户群的要求。需要考虑实施改进，使您的动态默认值无需额外的配置即可运行。如果只有一小部分用户不满意，他们最好手动设置配置选项。更复杂的系统会增加用户的工作量（例如，增加了文档的阅读难度）。在为可选项选择默认选项时，无论您选择静态还是动态默认值，请仔细考虑您选择的影响。经验表明，大多数用户会使用默认值，因此默认值的配置既是机会也是责任。你可以巧妙地向人们推进正确的方向，但指定错误的默认值会造成很大的伤害。例如，考虑配置默认值及其在计算机科学之外的影响。器官默认捐献的国家的器官捐献都比例明显高于器官默认不捐献的国家。简单地选择特定的默认值会对整个系统中的医疗选择产生深远的影响。一些可选项在没有明确用例的情况下开始。您可能想要完全删除这些问题。大量可选项可能会使用户感到困惑，因此您应该仅在真正需要的情况下添加配置选项。最后，如果您的配置恰好使用了继承的概念，那么能够恢复配置中任何可选项的默认值是很有用的。避免简单到目前为止，我们已经讨论过将系统配置简化为最简单的形式。但是，配置系统也可能需要考虑高级用户。回到我们的茶类比，如果我们真的需要在特定时间内浸泡茶怎么办？适应高级用户的一种策略是找到常规用户和高级用户所需要的最低公分母，并将此复杂性作为默认值。缺点是这个决定会影响每个人; 即使是最简单的用例现在也需要以低级别的角度来考虑。通过根据默认行为的可选覆盖考虑配置，用户配置“绿茶”，然后添加“将茶浸泡五分钟。”在此模型中，默认配置仍然是高级别并且接近用户的目标，但用户可以微调低级别配置。这种方法并不新颖。我们可以用高级编程语言（如C ++或Java）做类比，程序员能够将代码中的机器（或VM）指令包含在以高级语言编写的代码中。在某些消费者软件中，我们看到具有高级选项的屏幕可以提供比典型视图更精细的控制。优化整个配置的总时间是有用的。不仅要考虑配置本身的行为，还要考虑用户在提供许多选项时可能遇到的决策困难，在纠正错误配置所需的时间，由于信心较低而导致的修改配置速度较慢等等。在考虑配置设计备选方案时，如果能够更轻松地支持最常见的用例，则可以选择以较少但难度较大的步骤完成复杂配置的选项。如果您发现超过一小部分用户需要复杂配置，则可能错误地识别了常见用例。如果是这样，请重新审视系统的初始产品假设并其他用户进行研究。配置机制到目前为止，我们的讨论涵盖了配置哲学。本节将重点转移到用户如何与配置交互的机制。单独的配置和产生的数据存储配置的语言是一个不可避免的问题。您可以选择使用INI、YAML或XML文件中的纯数据。或者，配置可以存储在更高级语言中，以允许更灵活的配置。从根本上说，向用户提出的所有问题都可以归结为静态信息）。这显然对“应该使用多少线程”等问题的静态回答）“但是，即使”每一个请求都应该使用什么功能？“也只是功能的静态引用。要回到配置是代码还是数据这个古老的问题，我们的经验表明，代码和数据都有，但将两者分离是最优的。系统基础结构应该对纯静态数据进行操作，这些数据可以是协议缓冲区、YAML或JSON等格式。这种选择并不意味着用户需要与纯数据进行实际交互。用户可以与生成此数据的高级接口进行交互。然而，这种数据格式可以被API使用，从而允许系统和自动化的进一步堆叠。这个高级接口几乎可以是任何东西。它可以是一种高级语言，如基于Python的域特定语言（DSL）、Lua或专用构建语言，如Jsonnet（我们将在第15章中详细讨论）。我们可以把这样的接口看作一个编译，类似于我们如何对待C++代码。高级接口也可能根本不是语言其配置由web UI消化。从有意与静态数据表示分离的配置UI开始，意味着系统具有部署的灵活性。不同的组织可能具有不同的文化规范或产品需求（例如使用公司内的特定语言或需要将配置外部化到最终用户），并且这种通用的系统可以适用于支持不同的配置需求。毫不费力地支持多种语言。参见图14-2。 图14-2。配置流具有单独的配置界面和配置数据基础结构。请注意，Web UI通常还会显示当前配置，从而使关系成为双向关系。 这种分离对于用户来说是完全不可见的。用户的共同路径可能是在配置语言中编辑文件，而所有其他的事情都发生在幕后。例如，一旦用户向系统提交更改，新存储的配置就自动编译成原始数据静态配置数据一旦获得，也可以在数据分析中使用。例如，如果生成的配置数据是JSON格式的，那么可以将其加载到PostgreSQL中，并用数据库查询进行分析。作为基础架构所有者，您可以快速且容易地查询正在使用哪些配置参数以及由谁使用这些配置参数。此查询对于识别您可以删除的特性或测量bugy选项的影响非常有用。当使用最终的配置数据时，您会发现存储有关配置如何被摄取的元数据也很有用。例如，如果您知道数据来自Jsonnet中的配置文件，或者您在将数据编译成数据之前已经拥有了原始数据的完整路径，那么您可以跟踪配置作者。配置语言是静态数据也是可以接受的。例如，您的基础结构和接口都可能使用普通JSON。但是，要避免接口使用的数据格式和内部使用的数据格式之间的紧密耦合。例如，您可以在内部使用包含配置所消耗的数据结构的数据结构。内部数据结构还可能包含完全特定于实现的数据，这些数据永远不需要在系统外部出现。工具的重要性工具可以区分混乱的噩梦和可持续的可伸缩的系统，但在设计配置系统时经常会被忽略。本节讨论优化配置系统应该有的关键工具。语义验证虽然大多数语言提供现成的语法验证，但不要忽视语义验证。即使您的配置在语法上有效，它是否可能做有用的事情？或者用户是否引用了一个不存在的目录（由于打字错误），或者需要比实际数据库多一千倍的RAM（因为单位不是用户所期望的）？尽可能验证配置在语义上是否有意义，有助于防止中断并降低运营成本。对于每个可能的错误配置，我们应该问自己，在用户提交配置时是否可以阻止它，而不是在提交更改之后。配置语法虽然能够确保配置满足用户需求，但消除机械障碍也很重要。从语法角度来看，配置语言应该具备一下特点：在编辑器中高亮显示语法（在公司内使用）通常，您已经通过重用现有语言解决了这个问题。但是，特定语言可能具有额外的语法方式，从特定的方面突出显示 。短绒使用linter来识别语言使用中的常见不一致。 Pylint是一种流行的语言示例。自动语法格式化内置标准化可最大限度地减少关于格式化的讨论，并在贡献者切换项目时减少认知负荷。标准格式化还可以实现更轻松的自动编辑，这在大型组织中很有用。现有语言中的autoformatters示例包括clang-format和autopep8。这些工具使用户能够轻松地编写和编辑配置并确保其语法正确。在面向空白的配置中进行正确的缩进会产生很大的优势。权限和变更跟踪由于配置可能会影响公司和机构的关键系统，因此确保良好的用户隔离以及了解系统中发生的变化非常重要。如第10章所述，有效的死后文化可以避免责怪个人。但是，它既可以在事件期间进行，也可以在进行事后调查时知道谁更改了配置，并了解配置更改如何影响系统。无论事故是由于事故还是恶意行为都是如此。系统的每个配置代码段都应具有明确的所有者。例如，如果使用配置文件，则其目录可能由单个生产组拥有。如果目录中的文件只能有一个所有者，则跟踪谁进行更改会更容易。版本控制配置，无论其执行方式如何，都允许您及时返回以查看在任何给定时间点配置的内容。将配置文件检入版本控制系统（如Subversion或Git）是当今常见的做法，但这种做法对于Web UI或远程API提取的配置同样重要。您可能还希望在配置和正在配置的软件之间实现更紧密的耦合。通过这样做，您可以避免无意中配置软件中尚不可用或不再支持的功能。在相关的说明中，将配置和生成的应用程序的更改记录到系统是有用的（有时是必需的）。提交新版本配置的简单操作并不总是意味着直接应用配置（稍后将详细介绍）。如果在事件响应期间怀疑系统配置更改是罪魁祸首，则能够快速确定进行更改的完整配置编辑集非常有用。这样可以实现可靠的回滚，并能够通知其配置受到影响的各方。安全配置变更申请如前所述，配置是对系统功能进行大量更改的简单方法，但它通常不经过单元测试甚至不易测试。由于我们希望避免可靠性事件，因此我们应该检查配置更改的安全应用是什么。要使配置更改安全，它必须具有三个主要属性：  逐步部署，避免全有或全无变化的能力  如果证明存在风险，则可以回滚更改  如果更改导致失控，则自动回滚（或至少是停止进度的能力）部署新配置时，避免全局一次性推送非常重要。相反，逐步推出新配置 - 这样做可以让您在导致100％中断之前检测问题并中止有问题的推送。这就是Kubernetes等工具使用滚动更新策略更新软件或配置而不是一次更新每个集群的原因之一。（有关相关讨论，请参阅第16章。）回滚能力对于减少故障持续时间非常重要。回滚有问题的配置可以比临时修复程序更快地缓解故障-对修补程序改进的内在信心肯定较低。为了能够向前滚动和回滚配置，它必须是密封的。需要可在其密封环境之外进行更改的外部资源的配置可能很难回滚。例如，存储在引用网络文件系统上的数据的版本控制系统中的配置不是密封的。最后但同样重要的是，在处理可能导致操作员控制突然丧失的变更时系统应特别小心。在桌面系统上，如果用户未确认更改，屏幕分辨率更改通常会提示倒计时并重置。这是因为不正确的显示器设置可能会阻止用户恢复更改。同样，系统管理员通常会意外地将自己防火墙移出他们当前正在设置的系统。这些原则并非配置所独有，适用于更改已部署系统的其他方法，例如升级二进制文件或推送新数据集。结论琐碎的配置更改可能会以极大的方式影响生产系统，因此我们需要刻意设计配置以减轻这些风险。配置设计包含API和UI设计的各个方面，应该是有目的的，而不仅仅是系统实现的副作用。将配置分为哲学和机制有助于我们在设计内部系统时获得清晰度，并使我们能够正确地进行讨论。应用这些建议需要时间和勤勉。有关我们如何在实践中应用这些原则的示例，请参阅有关Canary Analysis Service的ACM Queue文章。在设计这个实用的内部系统时，我们花了大约一个月的时间来尝试减少强制性问题并为可选问题找到合适的答案。我们的努力创造了一个简单的配置系统。因为它易于使用，所以它在内部被广泛采用。我们已经看不到用户支持的需求 - 因为用户可以轻松了解系统，他们可以放心地进行更改。当然，我们还没有完全消除错误配置和用户支持，我们也没有想到。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十三章 数据处理管道]]></title>
      <url>/sre/2020/01/13/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%AE%A1%E9%81%93/</url>
      <content type="text"><![CDATA[数据处理属于一个复杂的技术领域，为了满足越来越大的数据集的处理需求，以及密集的数据转换和快速，可靠和低成本获得结果的需求。当前广泛需要处理的数据源有很多——从移动使用统计到集成传感器网络，再到Web应用程序日志等。数据处理管道目标是将这些无限、无序、全球规模的数据集转换为结构化的索引存储，来帮助关键业务决策或解锁新产品功能。除了提供对系统和用户行为的深入了解之外，数据处理对业务而言也是至关重要。在面向用户的功能中，可能会出现管道延迟或不正确的数据。这些问题的排查成本昂贵，且需要很长时间才能修复。本章首先使用产品示例来研究大数据处理管道的一些常见类型的应用程序。然后，我们将探索如何识别管道需求和设计模式，并列举在整个开发生命周期中管理数据处理管道的一些最佳实践。我们将介绍可以权衡优化管道和检测管道健康信号的技术。为了使服务在部署后保持稳定和可靠，SRE（以及开发人员）需要能够应对所有这些任务。理想情况下，SRE应该从早期阶段就参与这项工作：Google的SRE团队定期与开发数据处理管道的团队协商，以确保管道可以轻松发布，修改和运行，而不会给客户带来问题。最后，Spotify案例研究概述了其事件交付处理流程，该流程管理使用内部Google Cloud和其他第三方解决方案的组合来管理复杂的业务关键型数据处理管道。无论你是直接拥有管道，还是拥有依赖于管道产生的数据的其他服务，我们希望你可以利用本章中的信息来帮助你的管道（和服务）更可靠。有关Google数据处理管道理念的全面讨论，请参阅我们的第一本SRE手册的第25章。管道应用有各种各样的管道应用程序，每个应用程序都有自己的优势和使用范例。管道可以涉及多个阶段，每个阶段都是一个独立的过程，并依赖于其他阶段。一个管道也可能包含多个阶段，这些阶段使用高级规范进行抽象。云数据流就是一个很好的例子：用户使用相对高级的API编写业务逻辑，管道技术本身将这些数据转换为一系列步骤或阶段，其中一个输出是另一个的输入。为了让你了解管道应用程序的广度，接下来我们将介绍几种管道应用程序及其推荐用途。我们使用具有不同管道来实现要求的两个示例公司来演示满足其各自数据需求的不同方式。这些示例说明了特定用例如何定义项目目标，以及如何使用这些目标来明智地决定哪种数据管道最适合你的产品。事件处理/数据转换为订单或结构数据收集处理标准化（ETL）模型是数据处理中的常见范例：数据从源数据源中收集起来，这些数据可能是非规范化的，然后经过处理成专用格式。站在现代机器学习的角度，这可能看起来像一个认知过程：从某种传感器（实时或回放）获取数据，然后进行选择和编组，然后是“训练”特定数据结构（如机器学习网络）。ETL管道也是以类似的方式进行工作的。数据从单个（或多个）源提取，转换，然后加载（或写入）到另一个数据源。转换阶段可以服务于各种用例，例如：  更改数据格式以添加或删除字段  跨数据源聚合计算功能  对数据应用索引，使其具有更好的服务于基于数据的作业的特性通常，ETL管道会存储你的数据以供进一步分析或提供给其他服务。如果使用正确，ETL管道可以执行复杂的数据操作，并提高系统的效率。 ETL管道的一些示例包括：  机器学习或商业智能用例的预处理步骤  计算，例如计算给定事件类型在特定时间间隔内发生的次数  计算和准备账单报告  索引管道，例如为谷歌网络搜索提供支持的管道数据分析商业智能（BI）指的是收集、集成、分析和呈现大量信息以进行更好决策的技术、工具和实践。无是零售产品，移动游戏还是物联网传感器，在多个用户或设备之间聚合数据都可以帮助进行问题定位或状态判断。为了说明数据分析用例，让我们来看看一个虚构的公司和他们最近推出的手机和网络游戏Shave the Yak。所有者想要了解他们的用户如何在移动设备和网络上与游戏互动。作为第一步，他们生成游戏的数据分析报告，处理有关玩家事件的数据。该公司的业务负责人要求每月报告最常用的游戏功能，以便他们规划新的功能开发并进行市场分析。游戏的移动和网络分析存储在Google CloudBigQuery表中，Google Analytics每天会更新三次。团队设置了一个作业，每当新数据添加到这些表时运行。完成后，该作业将在公司的每日汇总表中进行记录。机器学习机器学习（ML）可用于各类领域，例如帮助预测癌症，对垃圾邮件进行分类以及为用户个性化产品推荐。通常，ML系统具有以下阶段：  数据特征及其标签是从较大的数据集中提取的。  ML算法在提取的特征上训练模型。  在一组测试数据上对模型进行评估。为了展示ML管道的实际运作，让我们看一个虚构公司Dressy的例子，该公司在网上销售服装。该公司希望通过向用户提供有针对性的建议来增加收入。当新产品上传到网站时，Dressy希望他们的系统在12小时内开始将该产品合并到用户推荐中。最终，Dressy希望在用户与网站互动时，为他们提供近乎实时的推荐，并对服装进行评分。作为推荐系统的第一步，Dressy研究了以下方法：共同点    显示彼此相似的产品。聚类    显示类似用户喜欢的产品。基于内容的推荐    显示与用户查看或喜欢的其他产品类似的产品。作为一个在线商店，Dressy拥有一组用户个人资料信息和评论，因此他们选择使用聚类过滤器。上传到他们系统的新产品没有结构化数据或一致标签（例如，一些供应商可能包括关于使用不同类别和格式的服装的颜色，尺寸和特征的额外信息）。因此，他们需要实现一个管道，将数据预处理为与TensorFlow兼容的格式，该格式连接产品信息和用户配置文件数据。 ML系统包括用于预处理来自训练模型所需的多个源的数据的管道。使用培训数据，Dressy的开发团队创建了TensorFlow模型，以便向客户提供适当的建议。图13-1显示了完整的ML解决方案。我们将详细介绍了每一步。 图13-1 ML数据处理管道   开发团队选择使用流数据流管道Google CloudDataflow，通过向返回特征列表的图像分类服务发送图像，将数据预处理为带标签的dress格式。  该团队对来自多个来源的数据进行预处理，这些数据将用于训练一个模型，该模型将返回最相似的前5条裙子。其工作流程–根据存储在BigQuery的客户资料中的服装产品数据和购买历史生成ML模型。  他们选择使用流数据管道将数据预处理为客户个性化配置文件。这些配置文件用作训练TensorFlow模型的输入。经过TensorFlow模型训练的二进制文件存储在Google云端存储（GCS）存储桶中。在部署到生产之前，团队确保该模型在对经过预处理的测试数据进行评估时满足其准确性。  服务为给定客户提供推荐内容，网络和移动设备前端进行调用。该团队使用TensorFlow和Cloud ML在线预测服务。  面向客户的前端购物服务根据预测服务提供的最新推荐为用户提供数据。Dressy注意到，一个新模型偶尔会在24小时内无法发布，而这些推荐会引发间歇性的错误。这是第一次部署新模型时常见的问题; 然而，有一些简单的步骤可以解决这个问题。如果你发现决策、分类或推荐内容要么没有显示，要么陈旧或不正确，请问自己：  在对数据进行预处理以训练模型之前，数据是否会进入管道？  是否因软件错误而导致ML模型不佳？是否有很多垃圾邮件？用于训练模型的特征选择是否恰当？  ML模型的新版本是最近生成的，还是生产环境中仍在运行旧版本的模型?幸运的是，Dressy有一套工具可以在客户遇到任何问题之前监控和检测问题。如果发生中断，这些工具可以帮助他们快速修复或回滚任何违规代码。有关实施监控和警报的更多详细信息，请参阅第4章。管道最佳实践以下管道最佳实践适用于其他作为服务运行的管道（即，负责及时正确处理数据以供其他系统调用的管道）。一套管道的部署需要多个步骤。这些步骤包括通过SLO定义和预测客户需求，优雅地故障响应和降级，编写文档以及创建在问题到达生产之前捕获问题的开发生命周期。定义和衡量服务水平目标自动检测管道何时不健康以及是否未能满足客户的需求非常重要。当您面临超出错误预算的危险时，接收通知(有关错误预算的详细信息，请参见第2章)有助于最小化客户影响。同时，在可靠性和特性发布之间取得一个适当的平衡是很重要的——客户会关心这两点。本节的其余部分将提供管道SLOs的示例以及如何维护它们。数据延迟大多数管道数据延迟SLO采用以下格式之一：  以Y [秒，天，分钟]处理的X％数据。  最旧的数据不早于Y [秒，天，分钟]。  管道作业在Y [秒，天，分钟]内成功完成。例如，Shave the Yak手机游戏可以选择一个SLO，要求所有影响用户分数的99%的用户动作在30分钟内反映在记分牌上。数据正确性为数据正确性创建SLO可确保您收到有关管道中潜在数据错误的警报。例如，计费管道中的一个正确性错误可能导致客户收取的费用过多或过少。正确性目标很难度量，特别是在没有预定义的正确输出的情况下。如果没有访问这些数据的权限，则可以生成这些数据。例如，使用测试帐户来计算预期的输出。一旦有了这个“黄金数据”，就可以比较预期输出和实际输出。从那里，您可以创建错误/差异的监控，并在测试数据流经实际生产系统时实现基于阈值的警报。另一个数据正确性SLO涉及向后分析。例如，您可以设置一个目标，即每个季度不超过0.1%的发票是错误的。您可以为管道输出数据提供的坏数据或错误的小时/天数设置另一个SLO目标。数据正确性的概念因产品和应用而异。数据隔离/负载均衡有时您将拥有优先级更高或需要更多资源来处理的数据段。如果您承诺对高优先级数据进行更严格的SLO，那么务必知道，如果资源受到限制，将在低优先级数据之前处理这些数据。这种支持的实现因管道而异，但通常表现为基于任务的系统或不同作业中的不同队列。Pipeline workers可以配置为执行最高可用优先级任务。可以有多个管道应用程序或workers作业在不同配置的资源(如内存、CPU或网络层)下运行，如果在较低配置workers上失败，可以在较高配置的workers上重试。在资源或系统受限的情况下，当不可能快速处理所有数据时，这种分离允许优先处理高优先级的项，而不是低优先级的项。端到端测量如果您的管道有一系列的阶段，那么很容易测量每个阶段或每个组件的SLO。然而，以这种方式度量SLOs并不能捕获客户的体验或系统的端到端健康状态。例如，假设您有一个基于事件的管道，如谷歌Analytics。端到端SLO包括日志输入收集和在数据到达服务状态之前发生的任意数量的管道步骤。您可以单独监视每个阶段，并为每个阶段提供一个SLO，但是客户只关心所有阶段的总和。如果您正在为每个阶段测量SLOs，那么您将被迫加强percomponent警报，这可能会导致更多不模拟用户体验的警报。此外，如果只在每个阶段测量数据的正确性，则可能会遗漏端到端数据损坏bug。例如，管道中的每个阶段都可以报告一切正常，但是其中一个阶段引入了一个字段，它期望下游作业处理该字段。此上游阶段假设额外的数据已被处理并用于向用户提供请求。下游作业不期望有额外的字段，因此会删除数据。两个作业都认为它们是正确的，但是用户看不到数据。依赖服务故障的预案一旦您定义了您的SLO，最好确认您没有过度依赖其他没有实现其产品承诺的SLOs/ sla。许多产品，如谷歌云平台，在其网站上列出了SLA承诺。一旦您确定了任何第三方依赖项，至少要为它们所宣传的sla中出现的最大故障进行设计。例如，在定义SLO时，将数据读写到云存储的管道的所有者将确保所宣传的正常运行时间和保证是适当的。如果单区域正常运行时间保证低于管道满足其数据处理时间SLO的要求，管道所有者可以选择跨区域复制数据，以获得更高的可用性当服务提供者的基础设施破坏其sla时，结果可能会对依赖管道产生负面影响。如果您的管道依赖于比服务提供者宣传的更严格的保证，那么即使服务提供者仍然在其SLA中，您的服务也可能失败。有时候，实际规划依赖性失败可能意味着接受较低的可靠性级别，并向客户提供较宽松的SLA。在Google，为了鼓励在管道开发时考虑到依赖故障，我们会计划中断演练。例如，Google的许多管道都依赖于运行数据中心的可用性。我们的灾难恢复测试（DiRT）经常针对这些系统，模拟区域中断。当发生区域中断时，已计划失败的管道会自动故障转移到另一个区域。其他管道被延迟，直到故障管道的操作员通过监控警告并手动做故障转移。手动故障转移成功的前提是管道可以获得足够的资源来在另一个区域中启动生产堆栈。在最佳情况下，不成功的手动故障转移会延长中断时间。在最坏情况下，处理作业可能会继续处理陈旧数据，这会在任何下游管道中引入过时或不正确的数据。此类事件的恢复策略因您的设置而异。例如，如果使用不正确的数据覆盖了正确的数据，则您可能必须从先前的备份版本还原数据并重新处理丢失的数据。总之，为您所依赖的系统不可用的那一天做好准备是一种很好的做法。即使是最好的产品也会失败并经历不可用时期。定期执行灾难恢复方案，以确保您的系统能够适应常见和不常见的故障。评估您的依赖关系并尽可能自动化您的系统响应。创建和维护管道文档在编写和维护良好的情况下，系统文档可以帮助工程师可视化数据管道及其依赖关系，理解复杂的系统任务，并尽可能缩短中断时间。我们为您的管道推荐以下三类文档。系统图系统图（类似于图13-2）可以帮助值班的工程师快速找到潜在的故障点。在Google，我们鼓励团队绘制系统图，显示每个组件（管道应用程序和数据存储），以及每个步骤发生的转换。图中显示的每个组件和转换都有可能卡住，导致数据停止流入系统。每个组件还可能引入影响数据正确性的软件或应用程序配置bug。系统图应包含指向不同管道阶段的其他监视和调试信息的快速链接。理想情况下，这些链接应从实时监控信息中提取，显示每个阶段的当前状态（例如，等待从属作业完成/处理/完成）。显示历史运行时信息还可以指示流水线阶段花费的时间是否超过预期。这种延迟可以预示性能下降或中断。最后，即使在复杂的系统中，系统图也可以使开发人员更容易分析在功能启动期间应该注意的数据依赖性。 图13-2 管道系统图（PII：个人身份信息） 流程文档记录如何执行常见任务非常重要，例如发布新版本的管道或引入数据格式的更改。理想情况下，您还应记录不太常见（通常是手动）的任务，例如新区域中的刚开始的服务启动或最终的服务关闭。在这些任务写成文档后，研究使任何手动任务自动化的可能性。如果任务和系统是自动化的，请考虑直接从源生成文档，以便保持同步。Playbook条目系统中的每个警报条件都应具有相应的playbook条目，该条目描述了恢复的步骤。在Google，我们发现在发送给值班的工程师的任何警报消息中链接此文档很有用。关于Playbook条目的更多信息可以参考第一本书的第11章。管道开发生命周期如图13-3所示，管道的开发生命周期（或对管道的更改）与其他系统的开发生命周期没有太大差别。本节遵循管道开发生命周期每个阶段的典型发布流程。 图13-3 管道开发生命周期与发布工作流程 原型第一阶段的开发涉及管道原型设计和语义验证。原型设计可确保您表达执行管道所需的业务逻辑。您可能会发现，一种编程语言可以让您更好地表达业务逻辑，或者特定语言更容易与现有库集成。特定的编程模型可能适合您的特定用例（例如，Dataflow与MapReduce，批量与流式传输）。有关已完成的编程模型比较的示例，请参阅我们的博客文章“Dataflow / Beam＆Spark：A ProgrammingModel Comparison”。如果要向现有管道添加功能，我们建议在原型阶段添加代码并运行单元测试。用1％的适运行进行测试完成原型后，使用生产数据在完整堆栈上运行小型设置会很有帮助。例如，使用一组实验来运行管道，或在非生产环境中运行1％的生产数据。逐步扩大规模，跟踪您的管道性能，确保您不会遇到任何瓶颈。当您的产品发布给客户时，请运行性能测试。这些测试是一个不可或缺的开发步骤，有助于预防新功能推出导致的中断。分期在部署到生产环境之前，在预发（或临时）环境中运行系统很有用。暂存环境中的数据应尽可能接近实际生产数据。我们建议保留生产数据的完整副本或至少保留代表性子集。单元测试不会捕获所有管道问题，因此让数据在端到端流经系统以捕获集成问题非常重要。集成测试还可以识别错误。使用单元测试和集成测试，比较新生成的数据与先前生成的已知良好的数据。例如，在测试通过并准备好发布到生产环境之前，请检查先前版本是否存在预期或意外的差异。金丝雀发布与无状态作业相比，管道测试和验证需要更多的时间和精力 - 数据被持久化并且转换通常很复杂。如果您的生产版本出现问题，尽早发现问题非常重要，这样您就可以控制影响。管道使用金丝雀可以帮助降低影响！金丝雀是一个流程，您可以部署部分服务（在本例中为管道应用程序）并监控结果。有关金丝雀的更详细讨论，请参阅第16章。金丝雀与整个管道相关联，而不是与单个流程相关联。在金丝雀阶段，您可以选择处理与实时管道相同的实际生产数据，但跳过写入生产存储；两相突变等技术可以提供帮助（参见第279页的“幂等和两相突变”一节）。通常，在发现任何影响客户的问题之前，您必须等待完整的处理周期完成。在测试运行（或两阶段突变）后，将您的金丝雀管道的结果与您的实时管道进行比较，以确认其健康状况并检查数据差异。有时可以通过金丝雀发布，逐步更新作业任务或先更新一个区域然后再更新另一个区域，但管道并不总是这样。使用复制数据的管道（例如Dataproc和Dataflow）支持区域端点并阻止这种金丝雀流程 - 您无法将一个单元格与另一个单元格隔离进行重新加载。如果运行多宿主管道，则可能无法像使用服务作业那样部署到单个区域（或一定比例的服务器）。相反，首先对一小部分数据执行首次展示，或者如前所述，首先在测试模式下推出。在验证您的金丝雀或预发环境时，评估管道的健康状况非常重要。通常，您可以使用用于跟踪SLO的相同指标。验证您的金丝雀是一项非常适合自动化的任务。执行分级部署除了改变您的变更之外，您可能还希望执行分级部署，尤其是在涉及主要功能启动或更改的情况下，这些情况会可能会影响到系统和资源使用。如果不首先对实例的变更进行小范围内的测试，，就很难预测这类启动的影响您可以在管道中将分级部署实现为接受允许的数据子集的标志或配置选项。考虑首先在一个或两个帐户上处理新功能，然后逐渐增加数据量（例如，~1％，~10％，~50％，最后是100％的样本数据）。分级部署在多个方面都可能出错：输入数据不正确或延迟，您的数据处理有错误，或者您的最终存储有错误。任何这些问题都可能导致中断。避免向低延迟前端提升损坏的数据集。目标是在这类错误被用户感知前发现并解决这类问题。部署到生产一旦您完全升级了新的管道二进制文件和/或配置到生产，您应该有理由相信您已经审查了任何潜在的问题（如果确实发生了问题，您的监控将提醒您）。如果部署出错，能够从已知良好状态快速恢复（例如，回滚二进制文件）并将任何可能损坏的数据标记为错误（例如，使用先前备份版本中的数据替换错误数据，请确保不要读取受影响的数据，和/或在必要时重新处理数据。减少瓶颈点和平衡工作负载当资源因过度访问而过载时会发生热点，从而导致操作失败。管道易受工作负载模式的影响 - 通过读取和写入 - 可能导致隔离的数据区域延迟。一些常见的热点示例包括：  抛出错误，因为多个管道工作者正在访问单个服务任务，从而导致过载。  由于并发访问仅在一台计算机上可用的数据而导致的CPU耗尽。通常，数据存储的内部具有最低级别的粒度，如果大量访问可能会变得不可用（例如，即使大多数数据存储都很好，Spanner平板电脑也会由于数据部分有问题而变得过载）。  由于数据库中的行级锁争用导致的延迟。  由于并发访问硬盘驱动器而导致的延迟，这超出了驱动器头移动速度足以快速定位数据的物理能力。在这种情况下，请考虑使用固态驱动器。  需要大量资源的大型工作单元。热点可以被隔离到数据子集。要打击热点，您还可以阻止细粒度数据，如单个记录。如果该数据被阻止，则管道的其余部分可以进行。通常，您的基础结构可以提供此功能。如果一大块处理工作消耗了不成比例的资源，那么管道框架可以通过将工作分成更小的部分来动态地重新平衡。为了安全起见，最好在客户端逻辑中建立紧急关闭，以允许您停止处理并隔离以大量资源使用或错误为特征的细粒度处理工作块。例如，您应该能够快速设置标志或推送允许您跳过与特定模式或有问题用户匹配的输入数据的配置。其他减少热点的策略包括：  重构数据或访问模式以均匀分布负载  减少负载（例如，静态分配部分或全部数据）  减少锁定粒度以避免数据锁争用自动弹性伸缩和资源规划工作量的峰值很常见，如果您没有准备就绪可能导致服务中断。自动伸缩可以帮助您处理这些峰值。通过使用自动伸缩，您无需在100％的时间内关注峰值负载（有关自动缩放的更多详细信息，请参阅第11章）。对持续运行峰值容量投入工作人员是昂贵且低效的资源使用。自动缩放会降低闲置工作人员的数量，因此您无需支付不需要的资源。此策略对于流式传输管道和可变工作负载尤为重要。批处理管道可以同时运行，并将消耗尽可能多的资源。预测系统的未来增长并相应地分配容量可确保您的服务不会耗尽资源。权衡资源成本与提高管道效率所需的工程工作量也很重要。在进行资源规划并估算未来增长时，请记住，成本可能与运行管道工作无关。您可能还需要支付数据存储和网络带宽成本，以跨区域或跨区域写入和读取复制数据。此外，一些数据存储系统比其他系统更昂贵。即使单位存储成本很低，这些成本也会迅速增加非常大的数据集或昂贵的数据访问模式，这些模式使用存储服务器上的大量计算资源。通过定期检查数据集和修剪未使用的内容来帮助降低成本是一种很好的做法。虽然应根据其端到端SLO来衡量一系列管道阶段的有效性，但应在每个阶段测量管道效率和资源使用情况。例如，假设您有许多使用Big-Query的作业，并注意到发布后BigQuery资源使用量的显着增加。如果您可以快速确定哪些工作负责，您可以将工作重点放在这些工作上以降低成本。访问控制和安全策略数据流经您的系统，并且通常会持续存在。管理任何持久数据时，我们建议您遵守以下隐私，安全和数据完整性原则：  避免将个人身份信息（PII）存储在临时存储中。如果您需要临时存储PII，请确保数据已正确加密。  限制对数据的访问。为每个管道阶段仅授予读取前一阶段输出数据所需的最小访问权限。  为日志和PII设置生存时间（TTL）限制。考虑一个与GCP项目相关联的BigQuery实例，该项目的访问权限可以通过Google CloudIdentity and Access Management进行管理（例如，前面描述的Dressy示例）。每个函数创建不同的项目和实例允许更细粒度的范围来限制访问。表可以具有主项目和客户端项目之间的交叉创建视图，以允许它们进行受控访问。例如，Dressy限制访问包含来自特定项目角色的作业的敏感客户信息的表。管道升级将管道设计为弹性非常重要，这样系统故障（如机器或区域中断）永远不会触发SLO违规页面。当您被分页时，您需要手动干预，因为所有自动化措施都已用完。如果您有明确定义的SLO以及可靠的指标和警报检测，那么在您的客户发现或报告问题之前，您会收到警报。违反SLO时，快速响应并向客户发送主动通信非常重要。管道需求设计今天的市场提供了许多管道技术和框架选项，并且确定哪一个最适合您的用例可能是压倒性的。一些平台提供完全托管的管道。其他人为您提供更多灵活性，但需要更多实际管理。在SRE中，我们经常在设计阶段花费大量时间来评估哪种技术最适合。我们根据用户需求，产品要求和系统约束来比较和对比各种设计选项。本节讨论可用于评估管道技术选项和改进现有管道的工具。你需要什么功能？表13-1提供了我们建议您在管理数据处理管道时进行优化的功能列表。其中一些功能可能已经存在于您现有的管道技术中（例如，通过托管管道平台，客户端应用程序逻辑或操作工具）。您的应用程序可能不需要某些功能，例如，如果您的工作单元是幂等的，并且可以针对相同的结果执行多次，则您不需要“仅此一次”语义。幂等和两相突变管道可以处理大量数据。当管道发生故障时，必须重新处理一些数据。您可以使用幂等突变设计模式来防止存储重复或不正确的数据。幂等突变是一种可以多次应用并具有相同结果的突变。实现此设计模式允许使用相同的输入数据单独执行管道，以始终产生相同的结果。在测试或管道化管道时，您需要根据预期的输出知道管道所有者是否可以接受您应用的突变。两阶段突变设计模式可以在这里提供帮助。通常，从源读取数据并进行转换，然后应用突变。通过两阶段突变，突变本身存储在临时位置。可以针对这些潜在的突变运行单独的验证步骤（或管道）以验证它们的正确性。只有在突变通过验证后，后续管道步骤才会应用经过验证的突变。图13-4显示了两阶段突变的示例 图13-4 两相突变 检查点通常，管道是长时间运行的进程，用于分析或改变大量数据。没有特别考虑，提前终止的管道将失去其状态，需要再次执行整个管道。对于创建AI模型的管道尤其如此，因为模型计算的每次迭代都依赖于先前的计算。检查点是一种技术，可以使管道等长时间运行的流程定期将部分状态保存到存储，以便以后可以恢复该过程。虽然检查点通常用于故障情况，但是当作业需要被抢占或重新安排时（例如，更改CPU或RAM限制），它也很有用。工作可以干净地关闭，重新安排后，它能够检测到哪些工作单元已经处理完毕。检查点具有额外的优势，即允许管道跳过可能昂贵的读取或计算，因为它已经知道工作已完成。代码模式一些常见的代码模式可以使您的管道更有效地进行管理，并减少进行更改或更新所需的工作量。重用代码如果您运行多个类似的管道并希望实施新的监控功能或指标，则必须检测每个单独的系统。如果您使用正确的策略，这种常见的工作流程并不困难。通过实现可重用代码库，您可以在一个位置添加监控指标，并在多个管道或阶段之间共享。共享库允许您：  以标准方式获取所有数据管道的洞察力。  为每个管道重用其他数据分析系统（例如，适用于所有管道的流量报告）。  针对多个作业提供相同的度量标准，例如通用数据新鲜度警报。使用微服务方法创建管道使用微服务时，让服务执行单个任务并做得很好很重要。操作一组使用相同核心库的微服务（仅在其业务逻辑上有所不同）比操作许多自定义服务更容易。类似的模式可以应用于管道。而不是创建一个单片管道应用程序，创建较小的管道，您可以单独释放和监视。这样，您将获得与微服务架构相同的好处。管道生产准备如第18章所述，PRR（生产准备审核）是Google SRE团队用于登录新服务的过程。本着同样的精神，我们在咨询管道技术的选择或设计时使用管道成熟度矩阵。管道成熟度矩阵表13-2中的矩阵测量了五个关键特征（但您可以扩展矩阵以测量您希望优化或标准化的其他特征）：  容错性  可扩展性  监控和调试  透明度和易于实施  单元和集成测试成熟度矩阵代表了Google许多管道专家的集体知识。这些人员负责跨多个Google产品运行管道并生成相关系统。每个特征的测量范围为1到5，其中1表示“混乱”（计划外，临时，有风险，完全手动），5表示“持续改进”。要对系统进行评分，请阅读下面每个特征的说明，并选择最匹配的里程碑。如果适用多个里程碑，请使用中间的分数（即2或4）。完整的评分表将为您提供系统需要改进的清晰图像。我们建议您花时间在矩阵识别的任何薄弱区域进行改进。检测矩阵推荐的监测，警报和其他工具可能需要大量时间。在进行改进时，您可以首先查找符合您需求的现有产品或开源工具，而不是创建自己的产品。在Google，我们鼓励团队使用现有的管道技术或工具，提供开箱即用的管道支持和功能。可以重用的工具和流程越多越好。管道故障：预防和响应导致管道故障的原因很多，但最常见的是数据延迟和数据损坏。在Google，当发生服务中断或SLO违规时，我们会跟踪MTTD和MTTR这两个指标来进行故障定位，实践证明这两个指标在检测和修复问题方面效果显著。本节介绍一些常见的故障模式，帮助防止未来管道故障的策略。潜在的故障模式数据延迟如果输入或输出延迟，管道服务是故障的。如果没有适当的预防措施，下游作业要具备可以正常运行的能力，因为陈旧数据也比不正确的数据好。如果您的管道处理不完整或数据损坏，这会将错误传播到下游。恢复或重新处理不良数据需要的时间可能会很长。相反，如果您的管道服务停止，等待数据，然后在数据可用后再恢复起来，则数据仍然是高质量的。创建所有阶段都尊重的数据依赖关系非常重要。根据管道的类型，延迟数据的影响范围可以从陈旧的应用程序数据到停滞的管道。在批处理管道中，每个阶段等待其前任在开始之前完成。流系统更灵活：使用事件时间处理（例如Dataflow），下游阶段可以在相应的上游部分完成时立即开始一部分工作，而不是等待所有部分完成。当发生此类性质的中断时，您可能需要通知任何相关服务。如果中断是用户可见的，您可能还需要通知您的客户。在调试管道中断时，查看当前和过去管道运行的进度以及直接链接到日志文件和数据流图表是有帮助的。在分析其计数器和统计数据时，能够通过系统跟踪工作单元也很有用。数据损坏如果未检测到，损坏的管道数据（输入和/或输出）可能会导致面向用户的问题。 您可以通过使用可识别损坏数据的测试，并使用可提醒您潜在损坏的逻辑来规避许多面向用户的问题。例如，管道系统可以实施阻止策略和滥用/垃圾邮件检测，以自动或手动过滤掉不良数据源。损坏的数据可能有多种原因：软件错误，数据不兼容，不可用区域，配置错误等。修复损坏的数据涉及两个主要步骤：  通过防止进一步损坏的数据进入系统来减轻影响。  从先前已知的正常版本恢复数据，或重新处理以修复数据。如果单个区域正在提供损坏的数据，则可能需要从该区域中耗尽服务作业和/或数据处理。 如果软件或配置错误有问题，您可能需要快速回滚相关的二进制文件。 通常，数据损坏会导致数据窗口不正确，并且一旦修复了基础问题就需要重新处理，例如修复管道二进制文件中的软件错误。要降低重新处理的成本，请考虑选择性重新处理 - 读入并仅处理受数据损坏影响的用户或帐户信息。 或者，您可以保留一些可用作检查点的中间数据，以避免从端到端重新处理管道。如果管道的输出已损坏，则下游作业可能传播损坏的数据，或者服务作业可能会提供不正确的数据。即使有最好的测试，开发和发布实践，软件或配置错误也可能导致数据损坏。 我们建议您计划此可能性，并能够快速重新处理和恢复您的数据。 从这种数据中恢复损坏是劳动密集型的，并且难以自动化。可能的原因管道依赖性当您尝试确定中断的原因时，调查管道依赖性（例如存储，网络系统或其他服务）很有用。这些依赖关系可能会限制您的请求/流量，如果资源不足，则拒绝任何新数据。 由于各种原因，输入/输出速率可能会变慢：  输出接收器或存储器可能拒绝写入一段数据。  可能存在无法完成的特定热点数据范围。  可能存在存储错误。某些管道依赖性问题无法自行解决。 提交故障单或错误，并留出足够的时间来添加更多资源或解决流量模式非常重要。实施负载平衡和丢弃低优先级数据可能有助于减轻影响。管道应用程序或配置管道故障可能是瓶颈，管道作业中的错误或配置本身的错误（例如，CPU密集型处理，性能退化，内存不足故障，易于热点的滥用数据，或者 配置指向不正确的输入/输出位置）。根据原因，有几种可能的解决方案：  回滚二进制文件/配置，挑选修复程序或修复任何权限问题。  考虑重组导致问题的数据。应用程序或配置错误可能会导致数据不正确或导致数据延迟。这些错误是导致中断的最常见原因。 我们建议花时间进行流水线开发，并确保新的二进制文件和配置在非生产环境中完好无损部署。意外的资源增长系统负载突然和意外跳转可能导致管道故障。您可能需要其他未计划的资源来保持服务正常运行。 自动扩展应用程序作业可以帮助满足新负载的需求，但是您还应该意识到管道负载的增加也会对下游依赖性造成压力 - 您可能还需要规划更多的存储和/或网络资源。良好的资源规划和准确的增长预测可以在这些情况下提供帮助，但这种预测可能并不总是正确的。我们建议您熟悉申请其他紧急资源的过程。 根据管道部署的性质和所需资源的数量，获取这些资源所需的时间可能很长。 因此，我们建议您准备临时解决方案以保持服务正常运行 - 例如，通过管道确定不同类别数据的优先级。地区级中断区域性中断对所有管道都不利，但单独的管道特别容易受到攻击。如果您的管道在突然变得不可用的单个区域中运行，则管道将停止，直到该区域重新启动。 如果您拥有具有自动故障转移功能的多宿主管道，您的响应可能就像从受影响区域中排放处理或提供服务一样简单，直到中断结束。当某个区域出现故障时，数据可能会滞留或延迟，从而导致管道输出错误。 结果，可能损害来自任何从属作业或服务的数据输出的正确性。案例研究：SpotifySpotify是全球领先的音乐流媒体公司。 每天，数以万计的人使用Spotify收听他们喜欢的歌曲，与朋友分享音乐，并发现新的艺术家。本案例研究描述了我们的事件传递系统，该系统负责可靠地收集Spotify应用程序生成的数据。该数据有助于我们更好地了解最终用户，并在适当的时间为他们提供合适的音乐。活动交付我们将最终用户交互称为事件。每当用户收听歌曲，点击广告或跟随播放列表时，我们都会记录一个事件。 Spotify每天捕获并向我们的服务器发布数千亿个事件（多种类型）。这些事件在Spotify中有很多用途，从A / B测试分析到播放计数，为个性化发现播放列表提供支持。最重要的是，我们根据交付的活动向艺术家支付版税。我们必须拥有可靠的事件存储和交付方式。在我们处理事件数据之前，需要收集这些数据并将其传递到持久化存储中。我们使用事件传递系统来可靠地收集和保留所有已发布的事件。事件传递系统是我们数据基础架构的核心支柱之一，因为几乎所有数据处理都直接或间接地依赖于它提供的数据。所有传递的事件都按类型和发布时间进行分区。如图13-5所示，在任何给定时间内发布的事件被组合在一起并存储在指定的目录中，称为传递小时桶。然后将这些存储桶分组为事件类型目录。此分区方案简化了Spotify的数据访问控制，所有权，保留和使用。图13-5 保存传递数据的小时桶小时存储桶是我们的数据作业与事件传递系统唯一的接口。因此，我们根据每个事件类型每小时桶的运行情况来衡量性能并为我们的事件交付系统定义SLO。事件传递系统设计和架构我们的每小时数据库部署在Google云端存储（GCS）上。 在设计初期，我们决定将数据收集与系统内的数据交付分离。为实现这一目标，我们使用全球分布式持久化队列Google Cloud Pub / Sub作为中间层。 解耦后，数据收集和交付成为相互独立的故障域，限制了生产问题的相互影响，从而获得更具弹性的系统。图13-6描述了我们的事件传递系统的体系结构。图13-6 事件传递系统架构数据采集生成的事件按事件类型分组。 每种事件类型都描述了Spotify应用程序中的用户操作。 例如，一种事件类型可以指代订阅播放列表的用户，而另一种事件类型可以表示用户开始播放歌曲。为确保单独的事件类型不会相互影响，系统具有完整的事件类型隔离。 来自不同事件类型的各个事件将发布到Google CloudPub / Sub中分配的主题。 发布由我们的微服务执行，这些微服务在Spotify数据中心和Google Compute Engine（GCE）上运行。 交付过程中，每个发布的事件流由ETL过程的专用实例处理。提取变换加载ETL过程负责将已发布的事件传递到GCS上正确的小时桶。 ETL过程有三个步骤/组件：1.专用的微服务使用事件流中的事件.2.另一个微服务将事件分配给它们的每小时分区。3.在Dataproc上运行的批处理数据作业从其每小时分区中重复删除事件，并将它们持久保存到GCS上的最终位置.每个ETL组件都有一个单一的职责，这使组件更易于开发，测试和操作。数据传递我们的客户（Spotify的其他工程团队）直接动态启用或禁用事件类型交付。 通过简单的配置控制交付。 在配置中，客户定义应交付的事件类型。当打开或关闭某种事件类型的传递时，微服务动态地获取并释放运行ETL的GoogleGCE资源。 以下代码显示了客户可以启用/禁用的示例事件类型：events:-CollectionUpdate-AddedToCollection-RemovedFromCollection当客户能够提供新的事件类型时，我们事先并不知道需要多少资源来保证交付。因此，很难手动确定必要的资源。 为了达到最佳效果，我们使用GCE Autoscaler用于交付不同事件类型的资源利用率。事件传递系统操作为我们的事件传递系统定义和沟通SLO，在以下三个方面有帮助。设计和开发在开发我们的系统时，清晰的SLO可以为我们提供工作目标。 这些目标有助于我们做出务实的设计选择，并简化我们的系统。确定性能问题一旦我们的系统部署在生产环境中，SLO就可以帮助我们确定系统的哪些部分表现不佳以及我们需要集中注意的地方。设定客户期望SLO使我们能够管理客户期望并避免不必要的支持请求。 当客户很明确我们系统的限制时，他们有权决定如何设计，构建和运行依赖于我们数据的自己的系统。我们为客户提供三种SLO类型用于我们的活动交付系统：及时性，完整性和偏斜（下文讨论）。 这些SLO是基于GCS提供的每小时数据桶。 为了尽可能客观，并避免使用与其无关的功能进行膨胀事件传递，我们使用独立的外部系统（例如，Datamon，下一节中介绍的数据可视化工具）测量所有SLO。时间线我们的及时性SLO定义为每小时数据传输的最大延迟。 交货延迟计算为铲斗交付时间与铲斗可能关闭的最早理论时间之间的时间差。 图13-7提供了此传递延迟的示例。 该图显示了12,13和14小时的桶。如果13小时的桶在14:53关闭，我们会说关闭延迟是53分钟。图13-7. 事件时间分区数据交付的及时性是我们用来评估数据管道性能的指标。为了测量和可视化及时性，我们使用了一个名为Datamon的工具，我们的内部数据监控工具是围绕每小时桶的概念构建的。图13-8显示了典型的Datamon UI。 每个绿色矩形（灰度，绝大多数矩形）代表按时每小时桶。灰色矩形（在右侧聚集在这里）表示尚未交付的桶，而红色矩形（最上面的3个黑色矩形）表示未在所需SLO内交付的桶。 成功交付所有小时的天数显示为单个绿色矩形。图13-8 Datamon for Spotify的数据监控系统下游数据作业只有在它们依赖的小时桶交付后，才能开始作业。在处理数据之前，每个数据作业都会定期检查其依赖项的传递状态。 交货延迟会影响下游工作的及时性。 我们的客户非常关注及时交付数据。 为了帮助我们确定事件发生时事件的优先顺序，我们的事件传递系统的及时性SLO分为三个优先级：高，正常和低。 我们的客户为其事件类型配置了适当的等级。偏态我们将偏态SLO定义为每天可能错位的最大数据百分比。偏斜（和完整性）是特定于我们的事件传递系统的概念，并不存在于我们的其他数据管道中。在我们设计事件传递系统时，为这些概念定义SLO是一个关键要求，因为它处理（以及其他事件类型）财务承载事件。对于所有其他事件，尽力而为地交付是足够好的，我们不公开相应的SLO。事件是否为财务承担由客户配置决定。为了确定何时应该交付每小时桶，我们的事件传递系统使用启发式方法。根据定义，启发式方法并不总是完全正确的。因此，以前交付的存储桶中未传递的事件在以后可能会传递到不正确的每小时存储桶。这种错位的事件被称为倾斜。偏差可能会对工作产生负面影响，因为他们可能会首先报告偏差内容，然后在一段时间内报告价值。图13-9显示了倾斜数据传送的示例。图13-9. 交付偏斜数据完整性事件在分布式系统中的多个方面丢失 - 例如，我们软件的新版本可能包含错误，云服务可能会关闭，或者开发人员可能会意外删除某些持久性事件。为确保我们收到有关数据丢失的警报，我们会衡量完整性。我们将完整性定义为在成功发布到系统后交付的事件的百分比。我们每天报告偏度和完整性。为了衡量这些价值，我们使用内部审计系统来比较所有已发布和已交付事件的计数。报告任何不匹配，我们采取适当的措施。为了获得SLO保证的及时性，偏斜性和完整性，我们在我们的服务器上接收时将事件分配给我们的每小时桶，而不是在客户端生成它们。如果我们的用户处于离线模式，则生成的事件可以在发布之前在客户端上缓存最多30天。此外，用户可以修改其设备上的系统时间，这可能导致时间戳不准确的事件。出于这些原因，我们使用Spotify服务器的时间戳。我们不会通过我们的活动交付系统提供有关数据质量或事件准确性的任何SLO。我们观察到，在大多数情况下，质量取决于每个事件的内容，这些事件由我们客户的业务逻辑组成。为了使我们的系统能够根据客户数量进行扩展，我们将其专注于提供数据。在这方面，我们使用类比，事件传递应该像邮政服务：您的邮件应该按时交付，完整和未打开。我们有责任为拥有业务逻辑的内部团队提供高质量的SLO，从而了解数据的内容。客户整合与支持许多Spotify团队每天都与事件传递系统进行交互。 为了鼓励采用并减少学习曲线，我们采取了以下步骤来简化用户与事件传递系统的交互：事件交付作为完全托管服务我们希望避免将系统的复杂性暴露给客户，使他们能够专注于他们试图解决的具体问题。我们努力隐藏定义明确且易于理解的API背后的任何系统复杂性。功能有限为了简化API，我们仅支持一组有限的功能。事件只能以特定的内部格式发布，并且只能使用单个序列化格式传递到每小时桶。这些简单的API涵盖了我们的大部分用例。需要明确启用每个事件的传递当客户启用事件交付时，他们会定义事件是否为财务承担及其相关的及时性要求。此外，事件所有权需要明确定义为启用流程的一部分。我们坚信，让我们的内部团队对他们生成的事件负责会带来更高的数据质量。明确事件所有权也为我们在事件传递期间提供了明确的沟通渠道。文档无论与系统的交互多么简单，都需要良好的文档来提供良好的客户体验。 Subspar和陈旧文档是Spotify等快节奏公司的常见问题。 为了解决这个问题，我们将文档视为任何其他软件产品：我们团队的所有支持请求都被视为文档问题或实际产品问题。大多数支持请求都与系统的公共API相关。 我们在编写文档时尝试回答的一些问题示例包括：•如何启用事件类型的传递？•数据在何处交付？•数据如何分区？•我们的SLO是什么？•我们的客户在事故中应该得到什么样的支持？我们的目标是在客户群增长时尽量减少我们收到的寻求支持次数。系统监控监控我们的SLO可以显示我们系统总体健康状况。可靠的全能监控解决方案可确保在出现问题时始终会发出警报。使用SLO违规作为监控标准的主要问题是：我们收到报警往往是在我们的客户受到影响之，为避免这种情况，我们需要对系统进行完全的监控，以便在SLO中断之前解决或缓解问题。我们分别监控系统的各个组件，从基本系统指标开始，然后构建到更复杂的系统。例如，我们将CPU使用率监视为健康状况的信号。 CPU使用率并不总是最关键的资源，但它作为基本信号很有效。当我们试图定位和修复生产问题时，有时系统监控是不够的。为了补充我们的监控数据，我们还维护应用程序日志。这些日志包含与其描述的组件的操作和运行状况相关的重要信息。我们非常小心，以确保我们只收集正确的记录数据的数量，因为有用的日志很容易被没有用的日志淹没。例如，错误实现的日志记录可能会记录组件中所传入的所有请求。假设大多数请求都相似，那么记录每个请求并不会增加太多价值。此外，当记录的请求太多时，很难找到其他日志条目，磁盘填满速度更快，并且我们服务的整体性能开始下降。更好的方法是对记录的请求进行速率限制，或者仅记录异常的请求（例如导致未处理异常的请求）。通过阅读应用程序日志来调试生产中的组件是一项挑战，应该是最后的选择。容量规划事件传递系统的可靠性需要正确数量资源来保证，特别是因为组件被部署到单个GCP项目中并且它们共享公共配额池。我们使用容量规划来确定每个系统组件需要多少资源。对于我们的大多数系统组件，容量规划基于CPU使用率。我们在高峰时段为每个组件配置50％的CPU使用率。该条款充当安全边际，允许我们的系统处理意外的流量突发。当Spotify运行自己的数据中心时，我们为每个组件提供了静态资源。这导致在非高峰时段浪费资源并且无法处理突增的请求。为了提高资源利用率，我们将GCE Autoscaler用于我们的一些无状态组件。在实施Autoscaler的早期，我们有一些痛苦的经历;在某些情况下，Autoscaler会导致故障。例如，我们使用CPU使用率作为度量来执行自动缩放。自动缩放器本身依赖于CPU使用率与每个组件实例执行的工作量之间的强相关性。如果关系被破坏 - 通过向每个组件实例添加CPU的守护进程，或者由于组件实例在没有做任何工作的情况下大量使用CPU，Autoscaler将启动太多实例。 当Autoscaler的CPU使用率不断增加且与执行的工作量无关时，它将无限扩展，直到它使用它可以找到的所有资源。为防止Autoscaler耗尽我们的所有配额，我们实施了一些解决方法：•我们限制Autoscaler可以使用的最大实例数。•我们严格限制在实例上运行的所有守护程序的CPU使用率。•一旦检测到没有完成任何有用的工作，我们就会积极地限制组件的CPU使用率。即使使用Autoscaler，我们也需要进行容量规划。我们需要确保我们有足够的配额，并且Autoscaler可以使用的最大实例数设置得足够高，以便在峰值期间提供流量，但又足够低以限制“失控”自动缩放的影响。发展进程为了快速发布新功能和改进，我们在持续集成和持续交付（CI / CD）流程之后开发了事件交付系统（如图13-10所示）。根据此流程，一旦完成，就会部署有效、经过验证或已审核的系统变更。拥有足够的测试覆盖率是每个变更成功部署的先决条件，而不会对我们的SLO产生负面影响。我们按照“测试金字塔”的理念编写测试。这意味着对于我们的每个组件，我们都有大量的单元测试，专注于组件的内部工作 - 除了少量的集成测试，专注于组件的公共API。在测试金字塔的最高级别，我们进行了系统范围的端到端测试。在此端到端测试中，所有组件都被视为黑盒子，因此测试环境中的系统尽可能类似于生产中的系统。在最初的开发之后，每个变化都经过同行评审。作为审核过程的一部分，所有测试都在共享CI / CD服务器上执行，结果将呈现给开发人员。只有在审阅者批准更改并且所有测试都已成功通过后，才能合并更改。合并更改后，将立即触发部署过程。事件传递系统是Spotify基础架构中的关键组件。如果它停止提供数据，Spotify中的所有数据处理都会停止。出于这个原因，我们决定采用更保守的方法进行部署，并分阶段部署每个变更。在部署可以从一个阶段到达到另一个阶段之前，我们需要手动批准。图13-10 发展进程在第一个部署阶段，更改将部署到测试环境。这种低风险的分期系统无法处理生产流量。 出于测试目的，生产流量的代表性部分在临时系统中进行镜像，该系统是生产中运行的系统的副本。 在第二个部署阶段，将更改部署到生产实例或金丝雀的一小部分。只有在我们确保一切顺利进行后，我们才能执行完整的生产部署，包括分段和金丝雀（参见第16章）。事件处理在处理事故时，我们的首要任务是止损并恢复系统的稳定性。为避免使情况变得更糟，我们禁止在事件发生期间对我们的组件进行任何重大更改。此规则的例外情况是，如果得出结论，事件是由最近的变更引起的。此时，我们立即将系统回滚到以前的正常版本。现在，我们遇到的最常见的操作故障是由系统故障引起的（例如，我们引入了软件错误或性能回归）或者我们所依赖的外部服务失败（例如，服务API的更新不向后兼容或服务中断其SLO）。我们使用许多经过实战考验的Google Cloud和内部Spotify服务，如Cloud Pub / Sub和Helios，以加快我们系统的开发并减少我们的运营负担。如果由外部服务引起事故，我们会有专门的随叫随到的团队提供支持。使用外部服务的一个缺点是我们自己无法解决问题。此外，将问题传达给第三方会在事件中花费宝贵的时间。即使问题出现再第三方上，但依旧会感到无能为力。。 重负载下意外的系统行为是操作失败的另一个常见原因。在准确的生产条件下测试服务是不可能的，因此很难预测可能发生的所有边缘情况。模拟生产中组件面临的负载也很困难。重负载与无法预料的边缘情况相结合可能会导致不可预料的故障情况，例如前面“容量规划”（第295页）中介绍的Autoscaler示例。操作系统故障可能导致我们的SLO中断。如果我们的数据新鲜度SLO被破坏，则不需要客户操作;客户必须等待他们的数据到达。但是，如果我们的偏差或完整性SLO被破坏，我们可能需要让客户参与，因为数据质量会受到影响。当我们检测到完整性或偏斜问题时，受影响的事件需要正确传递重新处理：•为了处理不完整性，需要从已知良好的最后一个检查点重新传递事件。•为了应对过度偏斜，已经交付的事件将重新分配到正确的每小时桶中。事件的重新传递和重新调整都是手动完成的。在交付事件被修改后，我们强烈建议客户重新处理它们以生成足够质量的数据。总结Spotify的事件传递系统多年来不断发展。由于之前的迭代不太可靠，我们的工程师每隔几晚都会被寻找。我们将大部分的开发时间用于事件补救和事后调查。在设计当前的版本时，我们专注于构建一个模块化的系统，它可以很好地完成一项核心任务：提供事件。此外，我们希望将事件交付作为产品提供给Spotify的其余部分。为实现这一目标，我们需要定义和满足SLO，以便为客户设定明确的期望。我们采用一系列策略来保持服务的正常运行 - 从详细记录的通话程序到使用久经考验的外部服务（例如Goo-gle CloudPub / Sub）。此外，一个团队负责在整个生命周期内开发和运行系统。这种开发结构使我们能够利用我们从维护系统中获得的团队经验来不断改进它。通过这些努力，我们现在拥有了一个可靠的系统，使我们能够将时间集中在满足更加雄心勃勃的完整性，偏斜性和及时性SLO上。这样可以提高可用性并改善整体客户体验。结论 将SRE最佳实践应用于管道可帮助您进行智能设计选择并开发自动化工具，以便管道易于操作，更有效地扩展，并且更可靠。 Spotify的事件传递系统是构建管道的一个例子 并考虑到核心SRE原则，使用各种技术 - 内部，Google云和第三方 - 选择满足客户及时数据处理的需求。如果没有适当注意操作最佳实践，管道可能更容易出现故障并需要大量手动工作，尤其是在增长，迁移，功能启动或停机后清理期间。与任何复杂的系统设计一样，了解您的要求和您选择保留的SLO，评估可用技术，记录设计以及如何执行常见任务非常重要。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十二章 非抽象大系统介绍设计]]></title>
      <url>/sre/2020/01/12/%E9%9D%9E%E6%8A%BD%E8%B1%A1%E5%A4%A7%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%BB%8B%E7%BB%8D/</url>
      <content type="text"><![CDATA[由于负责生产运营和产品工程，SRE工程师处于使业务用例需求和操作成本保持一致的独特地位。产品工程团队可能不知道他们设计的系统的维护成本，特别是当产品团队正在构建一个单独的组件从而产生更大的生态系统时这种可能性更会增加。基于谷歌开发系统的经验，我们认为可靠性是任何生产系统的最关键特性。我们发现延迟可靠性设计过程中的问题类似于以更高的成本换取更少的特性。通过遵循作为系统设计和实现的迭代风格，我们得到了健壮的易于升级的低运营成本的系统设计。我们称之为非抽象大系统设计(NALSD)。什么是NASLD？这一章介绍了NALSD方法:我们从问题陈述开始，收集需求，而且使迭代设计变得越来越复杂直到我们找到一个可行的解决方案。最终，我们针对多种失效模式得出了一个稳定的系统设计方法，满足我们在迭代时的初始要求和附加条件。NALSD描述了SRE的关键技能：评估、设计和评估大型系统的能力。实际上，NALSD将容量规划、组件隔离和优雅的系统降级等元素组合在一起，这些元素对生产系统的高可用性至关重要。谷歌SRE被希望能够从系统的基本白板图开始资源规划，考虑各种扩展和故障领域，并将其设计集中到资源的具体建议中。因为这些系统会随着时间的推移而变化，所以SRE能够分析和评估系统设计的关键方面是至关重要的。为什么非抽象所有系统最终都必须在使用真实网络的真实数据中心的真实计算机上运行。谷歌已经认识到(艰难的)设计分布式系统的人员需要开发并不断地锻炼将白板设计转换为过程中多个步骤的具体资源估计的能力。如果没有这种严格性，创建在现实世界中不能完全转换的系统就太有诱惑力了。这种额外的前期工作通常会减少最后一刻的系统设计更改，以应对一些不可预见的物理约束。请注意，当我们将这些练习推进到离散结果(例如，机器的数量)时，声音推理和假设的例子比任何最终值都重要。早期的假设对计算结果有很大的影响，而做出完美的假设并不是NALSD的必要条件。这个练习的价值在于将许多不完美但合理的结果结合在一起，从而更好地理解设计。AdWords的例子谷歌AdWords服务在谷歌Web搜索中显示文本广告。点击率(CTR)指标告诉广告商他们的广告表现有多好。CTR是点击广告的次数与显示广告的次数之比。这个AdWords示例旨在设计一个能够为每个AdWords ad测量和报告准确的CTR的系统。我们需要计算CTR的数据记录在搜索和ad服务系统的日志中。这些日志分别记录每个搜索查询显示的广告和点击的广告。设计过程谷歌使用迭代的方法来设计满足我们目标的系统。每次迭代都定义一个潜在的设计，并检查它的优缺点。这种分析要么提供给下一个迭代，要么指出什么时候设计足够好以至于被推荐。总的来说，NALSD过程有两个阶段，每个阶段有两到三个问题。在基本设计阶段，我们试图设计出一种符合原则的设计。我们问两个问题:这个是可能的吗？       这个设计可能吗?如果我们不需要担心足够的内存、CPU、网络带宽等等，我们会设计什么来满足需求呢?我们可以做的更好吗？       对于这样的设计，我们会问:“我们能做得更好吗?”例如，我们能让这个系统有意义地更快、更小、更高效吗?如果设计在O(N)时间内解决了这个问题，我们能否更快地解决这个问题，比如O(ln(N))?在下一个阶段中，我们尝试扩展我们的基本设计—例如，通过显著地增加需求。我们问三个问题:它是可行的吗？       在资金、硬件等方面受到限制的情况下，是否有可能扩展这种设计?如果有必要，什么样的分布式设计才能满足需求?它是弹性的吗？        设计能优雅地失效吗?当这个组件失效时会发生什么?当整个数据中心失效时，系统如何工作?我们如何做的更好？      虽然我们通常以大致的顺序来讨论这些阶段和问题，但在实践中，我们在问题和阶段之间来回切换。例如，在基本的设计阶段，我们经常在我们的头脑中有成长和扩展。有了这些概念，让我们来回顾一下NALSD迭代过程。初始需求每个广告客户可能有多个广告。每个广告都由ad_id键入，并与广告商选择的搜索词列表相关联。当向广告客户展示仪表盘时，我们需要知道以下每个信息：  这个搜索词触发这个广告的频率是多少  看到广告的人点击了多少次有了这些信息，我们可以计算CTR:点击次数除以查看次数。我们知道广告商关心两件事:仪表盘能否快速展示并且数据是最新的。因此，在迭代设计时，我们将根据SLOs来考虑我们的需求(详见第2章)：  99.9%的仪表板查询在&lt; 1秒内完成  99.9%的时间，显示的CTR数据少于5分钟。这些SLOs提供了一个合理的目标，我们应该能够始终如一地满足。他们还提供了错误预算(参见站点可靠性工程中的第4章)，我们将在每次设计迭代中对我们的解决方案进行比较。我们的目标是创建一个能够满足我们的SLOs的系统，并支持数以百万计希望在仪表盘上看到他们点击率的广告客户。对于事务率，我们认为每秒有500,000个搜索查询和10,000个广告点击。一台机器时最简单的起点是考虑在一台计算机上运行整个应用程序。对每个搜索查询，我们记录如下信息：time：       查询发生的时间query_id:       唯一的查询标识符（查询ID）search_term:       查询的内容ad_id:       搜索显示的所有AdWords广告的id这些信息一起形成查询日志。用户每次点击广告时，我们都会记录的时间、查询ID和单击日志中的ad_id。你可能想知道为什么我们不简单地将search_term添加到单击日志中以减少复杂性。在我们提供的例子任意缩减的范围内，这可能是可行的。然而，在实践中，CTR实际上只是从这些日志中计算出的许多结论之一。单击日志来自url, url具有固有的大小限制，这使分离查询日志成为一个更可扩展的解决方案。我们不会通过在练习中添加额外的ctr-like需求来证明这一点，而是简单地承认这个假设并继续前进。仪表盘展示需要来自两个日志的数据。我们需要保证，我们可以实现我们所展示SLO数据的更新时间在一秒钟以内。要实现这种SLO，需要在系统处理大量单击和查询时保持计算CTR的速度不变。为了满足在一秒钟内显示仪表盘所要求SLO数据，我们需要快速查找每个给定ad_id的search_term中被单击和显示的query_id的数量。我们可以从查询日志中提取每个search_term和ad_id所显示的query_id的详细信息。CTR仪表盘需要来自ad_ids的查询日志和单击日志的所有记录。如果我们有更多的广告商，扫描查询日志和单击日志来生成仪表盘的效率会非常低。因此，我们的设计要求我们的一台机器创建一个合适的数据结构，以便在接收日志时能够进行快速的CTR计算。在一台机器上，使用具有query_id和search_term索引的SQL数据库应该可以在一秒钟内提供答案。通过在query_id上连接这些日志并按search_term分组，我们可以报告每个搜索的CTR。计算我们需要计算需要多少资源来解析所有日志。为了确定缩放限制，我们需要做一些假设，从查询日志的大小开始：time：      64位整数，8个字节query_id：      64位整数，8字节ad_id：      3个64位整数，8字节search_term：      一个长度为500字节的字符串其它元数据：   500 - 1000字节的信息，比如哪台机器提供广告，搜索用的哪种语言，以及搜索词返回的结果为了确保我们不会过早地达到一个阈值，我们将每个查询日志条目整理为2kb。单击日志卷应该比查询日志卷小得多:因为平均CTR为2%(10,000次单击/ 500,000次查询)，所以单击日志将拥有2%与查询日志一样多的记录。请记住，我们选择了大数字来说明这些原则可以实现任意大的扩展。这些估计似乎很大，因为它们本应该如此。最后，我们可以使用科学的表示法来限制由单位上的不一致引起的算术错误。24小时内生成的查询日志量为：(5 × 105 queries/sec) × (8.64 × 104 seconds/day) × (2 × 103 bytes) = 86.4 TB/day因为我们收到的点击量是查询的2%，而且我们知道数据库索引将增加一些合理的开销，所以我们可以将86.4 TB/天的存储空间增加到100 TB，以存储一天的日志数据。 由于总存储需求约为100 TB，我们需要作出一些新的假设。 这种设计是否仍适用于单台机器？ 虽然有可能 将100 TB的磁盘连接到一台机器上，但是我们可能会受到机器从磁盘读取和写入磁盘的能力限制。例如，常见的4 TB HDD可能能够支持每秒200次输入/输出操作（IOPS）。 如果每个日志条目可以存储并以每个日志条目平均一个磁盘写入为索引，我们会看到IOPS是我们查询日志的限制因素：    (5 × 105 queries/sec) / (200 IOPS/disk) = 2.5 × 103 disks or 2,500 disks即使我们可以以10：1的比例批量查询以限制操作，但在最佳情况下，我们需要数百个HDD。 考虑到查询日志写入只是设计IO要求的一个组成部分，我们需要使用比传统HDD更好地处理高IOPS的解决方案。为简单起见，我们将直接评估RAM并跳过评估其它存储介质，例如固态磁盘（SSD）。单台机器无法完全在RAM中处理100TB的占用空间：假设我们的标准机器占用空间为16核，64 GB RAM和1 Gbps网络吞吐量，我们需要：    (100 TB) / (64 GB RAM/machine) = 1,563 machines评估暂时忽略我们的计算并想象我们可以将这个设计放在一台机器上，我们真的想要这样实现吗？ 如果我们通过询问当该组件发生故障时会发生什么来测试我们的设计，我们会找出一长串单点故障列表（例如，CPU，内存，存储，电源，网络，冷却）。 如果其中一个组件出现故障，我们是否可以合理地支持我们的SLO？ 几乎可以肯定的是，即使是一个简单的电力循环也会对我们的用户产生极大影响。回到我们的计算，我们的单机设计看起来是不可行，但这一步并不浪费时间。我们已经发现了有关如何推理系统约束及其初始要求的有价值的信息。我们需要将设计发展为使用多台机器。分步式系统我们需要的search_terms位于查询日志中，ad_ids位于单击日志。 既然我们知道我们需要多台机器，那么什么是连接它们的最佳设计？MapReduce我们可以使用MapReduce处理和连接日志。 我们可以定期获取累积的查询日志和单击日志，MapReduce将生成由ad_id组织的数据集，显示每个search_term接收到的单击次数。MapReduce作为批处理器工作：它的输入是一个大型数据集，它可以使用许多机器通过进程处理该数据并产生结果。一旦所有机器处理完他们的数据，他们的输出就可以合并 - MapReduce可以直接为每个AdWords广告和搜索字词创建每个CRT的摘要。我们可以使用此数据创建我们需要的dashboard。评价MapReduce是一种广泛使用的计算模型，我们相信它可以横向扩展。 无论我们的查询日志和单击日志输入有多大，添加更多的机器总是能够在不耗尽磁盘空间或RAM的情况下成功完成流程。不幸的是，这种类型的批处理过程无法在收到日志的5分钟内满足我们的加入日志可用性的SLO。 要在5分钟内提供结果，我们需要小批量运行MapReduce作业 —— 每次只需几分钟的日志。批次的任意和非重叠性质使小批量不切实际。 如果已记录的查询在批处理1中，并且其单击位于批处理2中，则单击和查询将永远不会被连接。 虽然MapReduce可以很好地处理独立批次，但它并未针对此类问题进行优化。 此时，我们可以尝试使用MapReduce找出可能的解决方法。 然而，为简单起见，我们将继续研究另一种解决方案。LogJoniner用户点击的广告数量明显小于所投放广告的数量。 直观地说，我们需要专注于扩展两者中的较大者：查询日志。 我们通过引入新的分布式系统组件来实现此目的。而不是像我们的MapReduce设计那样小批量查找query_id，如果我们创建了一个所有查询的存储，我们可以按需查询query_id，该怎么办？ 我们称之为QueryStore。 它包含查询日志的完整内容，query_id为主键。为了避免重复，我们假设我们从单个机器设计的计算将应用于QueryStore，我们将QueryStore的审查限制为我们已经涵盖的内容。 有关这样的组件如何工作的深入讨论，我们建议您阅读有关Bigtable的内容。因为点击日志也有query_id，所以我们的处理循环的规模比现在要小得多：它只需要遍历点击日志并引入所引用的特定查询。 我们将此组件称为LogJoiner。如果我们没有找到点击查询（接收查询日志的速度可能会减慢），我们将其搁置一段时间并重试，直到时间限制。 如果我们在该时间限制内找不到查询，我们会放弃该点击日志。点击率仪表盘对每个ad_id和search_term需要两个组件：展示次数和点击的广告数量。 ClickMap需要合作伙伴来保存查询，由ad_id组织。 我们称之为QueryMap。 QueryMap直接从查询日志中提供所有数据，并通过ad_id索引条目。图12-1描述了数据如何流经系统。LogJoiner设计引入了几个新组件：LogJoiner，QueryStore，ClickMap和QueryMap。 我们需要确保这些组件可以扩展。 图12-1 基本的LogJoiner设计; 处理并存储点击数据，以便仪表板可以检索它 计算根据我们在之前的迭代中执行的计算，我们知道QueryStore将为一天的日志提供大约100 TB的数据。 我们可以删除太旧而不具有价值的数据。LogJoiner应该在进入时处理点击并检索相应的点击从QueryStore的日志。    (104 clicks/sec) × (2 × 103 bytes) = 2 × 107 = 20 MB/sec = 160 MbpsQueryStore查找会产生额外的网络开销。 对于每个单击日志记录，我们查找query_id并返回完整的日志记录：    (104 clicks/sec) × (8 bytes) = 8 × 104 = 80 KB/sec = 640 Kbps    (104 clicks/sec) * (2 × 103 bytes) = 2 × 107 = 20 MB/sec = 160 MbpsLogJoiner还会将结果发送到ClickMap。 我们需要存储query_id，ad_id和time。 search_term、time和query_id都是64位整数，因此数据将小于1 KB：    (104 clicks/sec) × (103 bytes) = 107 = 10 MB/sec = 80 Mbps总计约400 Mbps是我们机器可管理的数据传输速率。ClickMap必须为每次单击存储时间和query_id，但不需要任何其他元数据。我们将忽略ad_id和search_term，因为它们是一个小的线性因素（例如，广告商数量×广告数量×8字节）。 即使是拥有10个广告的1000万广告客户也只有约800 MB。 一天的ClickMap值是：    (104 clicks/sec) × (8.64 × 104 seconds/day) × (8 bytes + 8 bytes)     = 1.4 × 1010 = 14 GB/day for ClickMap我们将ClickMap最多为20 GB /天，以计算任何开销和我们的ad_ids。在我们填写QueryMap时，我们需要为显示的每个广告存储query_id。我们需要增加存储空间，因为每个搜索查询可能会点击三个ad_id，因此我们需要记录query_id 最多三个条目：    3 × (5 × 105 queries/sec) × (8.64×104 seconds/day) × (8 bytes + 8 bytes)     = 2 × 1012 = 2 TB/day for QueryMap2 TB足够小，可以使用硬盘驱动器托管在一台机器上，但我们从单机迭代中知道，单个小写操作太频繁将无法存储在硬盘驱动器上。 虽然我们可以计算使用更高IOPS驱动器（例如SSD）的影响，但我们的工作重点是证明系统可以扩展到任意大的尺寸。在这种情况下，我们需要围绕单个机器的IO限制进行设计。因此，缩放设计的下一步是对输入和输出进行分片：将传入的查询日志和单击日志分成多个流。Sharded LogJoiner我们在此迭代中的目标是运行多个LogJoiner实例，每个实例位于数据的不同分片上。 为此，我们需要考虑几个因素：数据管理为了加入查询日志和单击日志，我们必须将每个单击日志记录与query_id上的相应查询日志记录进行匹配。 该设计应该防止网络和磁盘吞吐量在我们扩展时限制我们的设计。可靠性我们知道机器可能随时出现故障。 当一台机器运行LogJoiner时故障了，我们如何确保我们不会失去正在进行的工作？效率我们可以做扩容而没有浪费吗？ 我们需要使用最少的资源满足我们的数据管理和可靠性需求。我们的LogJoiner设计表明我们可以加入查询日志和点击日志，但产生的数据量非常大。 如果我们将工作划分为基于query_id的分片，我们可以并行运行多个LogJoiner。提供了合理数量的LogJoiner实例，如果我们均匀地分发日志，则每个实例仅通过网络接收一小撮信息。 随着点击流量的增加，我们通过添加更多LogJoiner实例来水平扩展，而不是通过使用更多的CPU和RAM来垂直扩展。如图12-2所示，为了使LogJoiners收到正确的消息，我们引入了一个名为日志分片器的组件，它将每个日志条目定向到正确的目的地。 对于每条记录，我们的点击日志分片器执行以下操作：  哈希记录的query_id。  用N（分片数）模数结果并加1以得到介于1和N之间的数字。  在第2步中将记录发送到分片编号。 图12-2 分片应该如何工作） 现在，每个LogJoiner将获得分解的传入日志的一致子集 query_id，而不是完整的点击日志。QueryMap也需要进行分片。 我们知道需要很多硬盘来支持QueryMap所需的IOPS，并且一天的QueryMap（2TB）的大小对于我们的64 GB机器来说太大而无法存储在RAM中。 但是，我们将在ad_id上进行分片，而不是像LogJoiner那样使用query_id进行分片。 ad_id在任何读取或写入之前都是已知的，因此使用与LogJoiner和CTR仪表盘相同的散列方法将提供一致的数据视图。为了保持实现的一致性，我们可以将ClickMap的相同日志分片设计重用为QueryMap，因为ClickMap比QueryMap小。现在我们知道我们的系统将扩展，我们可以继续解决系统的可靠性问题。 我们的设计必须能够适应LogJoiner故障。 如果LogJoiner在收到日志消息后但在加入日志消息之前失败，则必须重做其所有工作。 这会延迟准确数据到达仪表板，这将影响我们的SLO。如果我们的日志分片器进程将重复的日志条目发送到两个分片，则系统可以继续全速执行并处理得到准确的结果，即使LogJoiner失败（可能是因为它所在的机器失败）。通过以这种方式复制工作进程，我们减少（但不消除）丢失这些连接日志的机会。 两个分片可能会同时中断并丢失中继日志。 通过分配工作负载以确保在同一台计算机上没有重复的分片，我们可以减轻大部分风险。 如果两台机器同时发生故障并且我们丢失了分片的两个副本，则系统的错误预算（参见第一本SRE手册中的第4章）可以涵盖剩余的风险。 当灾难发生时，我们可以重新处理日志。 仪表板将仅显示短时间内超过5分钟的数据。图12-3显示了我们对分片及其副本的设计，其中LogJoiner、ClickMap和QueryMap都构建在两个分片上。从连接的日志中，我们可以在每个LogJoiner机器上构建ClickMap。 要显示我们的用户仪表盘，需要组合和查询所有ClickMaps。结论在一个数据中心中托管分片组件会产生单点故障：如果刚好不幸一对机器或数据中心断开连接，我们将丢失所有ClickMap工作，并且用户仪表盘完全停止工作！我们需要改进我们的设计以使用多个数据中心。 图12-3。 使用相同的query_id对日志进行分片以复制分片） 多数据中心跨不同地理位置的数据中心复制数据使我们的服务基础架构能够承受灾难性故障。如果一个数据中心关闭（例如，由于电源或网络中断），我们可以故障转移到另一个数据中心。要使故障转移起作用，必须在部署系统的所有数据中心中提供ClickMap数据。这样的ClickMap甚至可能存在吗？我们不希望将计算需求乘以数据中心的数量，但我们如何才能有效地同步站点之间的工作以确保充分复制而不会产生不必要的重复？我们刚刚描述了分布式系统工程中众所周知的共识问题的一个例子。有许多复杂的算法可以解决这个问题，但基本思路是：  一个服务要有三个或五个副本（如ClickMap）。  用像Paxos等一致性算法，以确保在发生数据中心级别故障时我们可以可靠地存储计算状态。  在参与节点之间实现至少一个网络往返时间以接受写入操作。此要求限制了系统的顺序吞吐量。基于一致性map仍然需要并行写操作。按照刚刚列出的步骤，多数据中心设计现在看来原则上是可行的。它还能在实践中发挥作用吗？我们需要哪些类型的资源，以及我们需要多少资源？计算使用故障隔离数据中心执行Paxos算法的延迟意味着每个操作大约需要25毫秒才能完成。该延迟的假设基于至少相距几百公里的数据中心。因此，就顺序过程而言，我们每25毫秒只能执行一次操作或每秒40次操作。如果我们需要每秒执行10次连续进程（点击日志），我们需要为每个数据中心至少250个进程（由ad_id分片）用于Paxos操作。在实践中，我们希望添加更多进程以提高并行性，以便能处理任何宕机或流量高峰所造成的积压。基于我们之前对ClickMap和QueryMap的计算，并使用每秒40次连续操作来估算，我们的多数据中心设计需要多少台新机器？因为我们的分片LogJoiner设计为每条日志记录引入了一个副本，所以我们每秒创建ClickMap和QueryMap的事务数量翻了一番：每秒20,000次点击和每秒1,000,000次查询。我们可以通过把每秒总查询数除以每秒最大操作数来计算所需的最小进程数或任务数 ：    (1.02 × 106 queries/sec) / (40 operations/sec) = 25,500 tasks每个任务的内存量（2 TB QueryMap的两个副本）：    (4 × 1012 bytes) / (25,500 tasks) = 157 MB/task每台机器的任务数：    (6.4 × 1010 bytes) / (1.57 × 108 bytes) = 408 tasks/machine我们知道我们可以在一台机器上安装许多任务，但我们需要确保我们不会达到IO的瓶颈。 ClickMap和QueryMap的总网络吞吐量（使用每个条目2 KB的高估计）：    (1.02 × 106 queries/sec) × (2 × 103 bytes) = 2.04 GB/sec = 16 Gbps每项任务的吞吐量：    16 Gbps / 25,500 tasks = 80 KB/sec = 640 Kbps/task每台机器的吞吐量：    408 tasks × 640 Kbps/task = 256 Mbps对于每个任务15MB内存和640Kbps吞吐量的组合是易于管理的。我们在每个数据中心需要大约4 TB的RAM来托管分片的ClickMap和QueryMap。 如果我们每台机器有64 GB的RAM，我们可以只使用64台机器处理数据，这将会只使用每台机器25％的网络带宽。评估现在我们已经设计了一个多数据中心的系统，让我们来看看数据流是否有意义。图12-4显示了整个系统设计。 您可以查看每个搜索查询和广告点击是如何与服务器进行通信的，以及如何收集日志并将其推送到每个组件中。我们可以根据我们的需求检查这个系统：每秒10,000次广告点击     LogJoiner可以水平扩展以处理所有日志点击，并将结果存储在ClickMap中。每秒500,000次搜索查询      QueryStore和QueryMap被设计为能够以此速率存储一整天的数据。99.9％的仪表盘查询在&lt;1秒内完成      CTR仪表板从QueryMap和ClickMap获取数据，这些数据由ad_id键入，使此事务变得快速而简单。99.9％的时间，显示的CTR数据不到5分钟      每个组件都设计为水平扩展，这意味着如果管道处理太慢，添加更多计算机将减少端到端管道延迟。我们相信该系统架构可以扩展以满足我们对吞吐量，性能和可靠性的要求。 图 12-4 多数据中心设计 总结NALSD描述了Google用于生产系统的系统设计的迭代过程。 通过将软件分解为逻辑组件并将这些组件放入具有可靠基础架构的生产生态系统中，我们得出了对数据一致性、系统可用性和资源效率都能达到合适目标的系统。NALSD的实践使我们能够在不重复每次迭代的情况下改进设计。虽然本章中提出的各种设计迭代都满足了我们原始的问题陈述，但每次迭代都揭示了新的要求，我们可以通过扩展我们以前的工作来满足这些要求。在整个过程中，我们根据我们对系统增长的预期来分离软件组件。 该策略允许我们独立地扩展系统的不同部分，并消除对单个硬件或单个软件实例的依赖性，从而产生更可靠的系统。在整个设计过程中，我们通过对NALSD的四个关键问题进行提问来持续改进每次的迭代：可能吗？       我们可以在没有“魔法”的情况下建造它我们可以做得更好吗？      它是否像我们可以合理地制造一样简单？这可行吗？       它是否符合我们的实际限制（预算，时间等）？它有弹性伸缩的吗？       它会偶尔存在不可避免的中断吗？NALSD是一项有学问的技能。与任何技能一样，您需要定期练习以保持熟练程度。 谷歌的经验表明，从抽象需求推理到具体的资源是建立健康和长寿命系统的关键。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十一章 应对过载]]></title>
      <url>/sre/2020/01/11/%E5%BA%94%E5%AF%B9%E8%BF%87%E8%BD%BD/</url>
      <content type="text"><![CDATA[服务永远不会100％可用：比如突发的流量高峰导致系统崩溃；或者船锚意外扯住了跨大西洋的光缆造成网络不可用。作为服务提供者，我们要为客户提供持久稳定的服务。面对这些突发的情况，如何才能使我们的基础设施尽可能具备可靠性？本章介绍了Google应对过载的方法，希望能够使用这些最佳实践来提高服务的可靠性和可用性。多年来，我们发现，没有单一的解决方案来均衡和稳定网络负载。因此，多种工具、技术和策略的组合才是帮助保持我们的服务可靠性的方法。在我们深入讨论本章之前，我们建议阅读《SRE：Google运维解密》第19章《前端服务器的负载均衡》和20《数据中心内部的负载均衡系统》中的内容。Google云服务负载均衡目前，大多数公司都没有开发和维护自己的全局负载均衡解决方案，而是选择使用来自更大的公有云供应商提供的负载均衡服务。我们将讨论Google云负载均衡（GCLB）作为大规模负载平衡的具体示例，但我们描述的所有最佳实践的案例几乎也适用于其他云提供商的负载均衡。过去18年来，谷歌一直致力于基础设施的建设，以提高服务的可靠性。今天，YouTube使用了我们的系统，地图，Gmail，搜索以及许多其他产品和服务也在用我们的系统。GCLB是我们面向用户的全球负载均衡解决方案。本节介绍GCLB的组件以及面对用户的请求时是如何协同工作的。我们跟踪典型的用户请求的全生命周期。Niantic PokémonGO的案例具体描述了GCLB的具体实施。我们的第一本SRE书的第19章描述了基于DNS的负载均衡。他是在用户开始连接阶段进行平衡均衡最简单和最有效的方法。我们还讨论了这种方法的一个地域性问题：它依靠客户端来正确地获取DNS记录。而GCLB不使用DNS进行负载均衡。相反，我们使用任播“anycast”，一种将客户端的请求发送到最近的群集，而不依赖DNS地理定位的方法。Google的全局负载均衡知道客户端所在的位置，并将数据包定向到最近的Web服务，从而在使用单个VIP（虚拟IP）时为用户提供低延迟的服务。使用单个VIP意味着我们可以增加DNS记录的生存时间（TTL），从而进一步减少延迟。任播任播是一种网络寻址和路由方法。它将数据报从发送方路由到一组潜在接收方中拓扑最近的节点。这些接收方都由相同的目标IP地址标识。Google通过我们网络中多个点的边界网关协议（BGP）确定IP的地址。我们依靠BGP路由网格将来自用户的数据包传递到TCP会话最近的前端路由位置。此部署消除了单播IP扩散和为用户找到最接近的目标接口上。但这仍有两个主要问题：若附近具有太多用户可能会压倒前端的接口。  BGP路由计算可能会重置连接。  考虑这么一个ISP供应商，提供频繁的BGP路由计算以便给用户提供延迟更低的服务。但是每次BGP路由“振荡”时，所有正在进行的TCP流都会被重置，导致得结果就是用户的数据包被重定向到没有TCP会话状态的新的前端。为了解决这些问题，我们利用我们的连接层负载均衡器——Maglev，即使在路由振荡时也能够汇集TCP流。我们将此技术称为“稳定的任播”。稳定的任播如图11-1所示，Google使用自定义的负载均衡器Maglev实现“稳定的任播”。为了稳定任播，我们为每个Maglev节点提供一种将客户端IP映射到最近的Google前端站点的方法。有时Maglev会为一个靠近另一个前端站点的客户端处理发往任播VIP的数据包。在这种情况下，Maglev会将该数据包转发到最近的前端站点。然后最近的前端站点的Maglev简单地其路由到本地后端。 图11-1 稳定的任播） MaglevMaglev，如图11-2所示，是Google的定制分布式数据包层负载均衡器。作为云架构不可或缺的部分，Maglev集群管理传入的流量。它们在我们的前端服务器上提供有状态的TCP层负载均衡。Maglev在一些关键方面与其他传统硬件负载均衡器不同点如下：  所有发往给定IP地址的数据包可以通过等价多路径（ECMP）均匀的转发到maglev集群中。这使我们只需扩容服务器即可提高maglev集群容量。均匀分布数据包使Maglev集群的冗余度建模为N+1，从而提高了传统负载均衡系统（通常依靠主动/被动提供1+1的冗余）的可用性和可靠性。  Maglev是Google自定义解决方案。我们可以对系统进行端到端地控制，这使我们能够快速进行实验和迭代。  Maglev在我们数据中心的商用硬件上运行，极大地简化了部署。 图11-2 Maglev maglev数据包传送使用一致型散列和连接跟踪。这些技术在我们的HTTP反向代理（也称为Google前端或GFE）中合并为TCP流，这些代理终止TCP会话。一致型散列和连接跟踪是Maglev按包扩展而不是按连接数扩展的关键。当路由器收到发往Maglev托管的VIP的数据包时，路由器会通过ECMP将数据包转发到集群中的任何的Maglev节点。当Maglev收到数据包时，它会计算数据包的5元组散列，并在其连接跟踪表中查找散列值，该表包含最近连接的路由结果。如果Maglev找到匹配项且所选后端服务仍然是健康的，则会重新使用该连接。否则，maglev将回归利用哈希来选择后端。这些技术的组合消除了在各个Maglev机器之间共享连接状态的需要。全球软件负载均衡GSLB是谷歌的全球软件负载均衡器。它允许我们平衡集群之间的实时用户流量，以便我们可以将用户需求与可用服务容量相匹配，因此我们可以对用户透明的方式处理服务故障。如图11-3所示，GSLB控制到GFE的连接分配和后端服务请求的分配。GSLB允许我们为后端运行的用户和在不同集群中运行的GFE提供服务。除了前端和后端之间的负载均衡之外，GSLB还了解后端服务的运行状况，并可以自动从失败的集群中摘除流量。 图11-3 GSLB 谷歌前端如图11-4所示，GFE位于外部和Google服务（网络搜索，图像搜索，Gmail等）之间，并且通常是客户端HTTP(S)请求时遇到的第一个Google服务器。GFE终止客户端的TCP和SSL会话，并检查HTTP标头和URL路径，以确定哪个后端服务应该处理请求。一旦GFE决定将请求发送到某处，它就会重新加密数据并转发请求。有关此加密过程如何工作的详细信息，请参阅白皮书“Google Cloud中的传输加密”。GFE还负责对其后端进行健康检查。如果后端服务器返回异常(NACKs请求)或运行健康检查超时，GFE将停止向失败的后端发送流量。我们使用此信号更新GFE后端，而不会影响正常的链接时间。通过将GFE后端置于健康检查失败的模式，同时继续响应正在进行的请求，我们可以在不中断任何用户请求的情况下优雅地从服务中剔除GFE后端。我们称之为“跛脚鸭”模式，我们将在第一本SRE书的第20章中对其进行更详细的讨论。 图11-3 GFE GFE还为所有活跃的后端维护持久的会话，以便在请求到达时就可以立即进行连接。此策略有助于减少用户的延迟，尤其是在我们使用SSL保护GFE和后端之间的连接时。GCLB：低延迟网络配置策略旨在减少用户访问的延迟。因为通过“TTPS协商安全连接”需要在客户端和服务器之间进行两次网络往返，所以我们最大限度地减少“请求时间”的延迟尤为重要。为此，我们将网络边缘扩展到主机Maglev和GFE。这些组件尽可能靠近用户的进行SSL连接，然后通过长期加密连接将请求转发到我们网络中更深层次的后端服务。我们在这个组合的Maglev/GFE增强边缘网络上构建了GCLB。当客户创建负载均衡器时，我们会设置任播VIP并对Maglev进行编程，以便在我们网络边缘的GFE上对其进行全局负载均衡。GFE的作用是终止SSL，接受和缓冲HTTP请求，将这些请求转发给客户的后端服务，然后将代理响应回用户。GSLB提供每层之间的粘合剂：它使Maglev能够找到具有可用容量的最近的GFE位置，并使GFE能够将请求路由到具有可用容量的最近的VM实例组。GCLB: 高可用性为了向我们的客户提供高可用性，GCLB提供99.99％的可用性SLA。此外，GCLB还提供支持工具，使我们的客户能够改进和管理自己的应用程序的可用性。将负载均衡系统视为一种流量管理器是有用的。在正常操作期间，GCLB将流量路由到具有可用容量的最近的后端。当服务的实例失败时，GCLB会检测到故障并将流量路由到健康的实例。金丝雀发布有助于GCLB保持高可用性。金丝雀发布是我们的标准发布程序之一。如第16章所述，这个过程是程序首先发布到极少数的服务器，然后逐渐增加流量并仔细观察系统行为以确认是否需要回滚。这种做法通过在金丝雀发布的早期阶段捕捉异常来减少影响。如果新版本崩溃或无法进行健康检查，负载均衡器则进行重新路由请求。如果检测到非致命的回滚，则可以从负载均衡器中以管理方式删除实例组，而无需触及应用程序的主要版本。案例研究1：GCLB上的PokemonGONiantic在2016年夏天推出了PokémonGO。这是第一款神奇宝贝相关的游戏，也是Niantic与一家大型娱乐公司的第一个项目。这个游戏受到了超过预期的欢迎——那个夏天你会经常看到球员们在虚拟世界中带着神奇宝贝进行决斗。PokémonGO的成功大大超过了Niantic的期望。在发布之前，他们对系统的堆栈进行了负载测试，最多可处理最乐观估算5倍的流量。实际每秒启动请求数（RPS）估计接近50倍——足以应对几乎所有的用户的挑战的堆栈容量。为了使游戏体验更加愉快，PokémonGO支持世界范围内的高度互动，并在用户之间进行全球共享。特定区域内的所有玩家都会看到同样的游戏世界，并在这个世界里互相交流。这要求游戏近乎实时的产生并分发状态给所有参与者。为了达到50倍以上RPS的目标，Niantic研发团队需要应对巨大的挑战。此外，谷歌的许多工程师也给他们提供了帮助——为成功发布扩展服务。在迁移到GCLB两天之内，PokémonGO应用程序成为最大的单一GCLB服务，很轻松与其他十大GCLB服务相提并论。如图11-5所示，当它推出时，神奇宝贝GO使用了谷歌的区域性网络负载均衡器（NLB），用于对Kubernetes中的入口流量进行负载均衡。每个集群都包含一组Nginx实例，它们用作第7层反向代理，建立SSL，缓冲HTTP请求，执行路由并使用跨应用程序服务器后端的实例进行负载平衡。 图11-5 神奇宝贝GO （预GCLB） NLB负责IP层的负载均衡，因此使用NLB的服务有效地成为Maglev的后端。 在这种情况下，依赖NLB对Niantic有以下问题：  Nginx后端负责终止客户端的SSL，这需要从客户端设备到Niantic的前端代理两次往返。  缓冲来自客户端的HTTP请求的会导致代理层上的资源耗尽，导致客户端只能缓慢发送字节时。  数据包级代理无法有效改善SYN Flood等低级网络攻击。为了解决这些问题，Niantic需要在大型边缘网络上使用高级别的代理。使用NLB无法实现此解决方案。迁移到GCLB大型SYN泛洪攻击使PokémonGO迁移到GCLB成为优先事项。这个迁移是Niantic CRE团队与Google SRE团队共同开展。最初的迁移发生在用户使用量的低谷时期。当时，并没有发现问题。然而，随着流量的增加达到峰值，对于Niantic和Google来说都出现了无法预料的问题。Google和Niantic发现客户流量的需求高于以往峰值的200％。Niantic前端代理收到了过多的请求以至于他们无法响应所有的以接收的请求。任何连接都以拒绝方式返回给用户。这种流量激增导致了经典的级联故障情景。众多API-Cloud数据存储区，PokémonGO后端和API服务器以及负载均衡系统——超出了Niantic云的可用容量。过载导致Niantic的后端变得极其缓慢，请求超时波及到了负载平衡层。在这种情况下，负载均衡器重试GET请求。极高的请求量和重试机制的组合使得GFE中的SSL客户端代码处于前所未有的水平，因为它试图重新构建对于无响应的后端。这在GFE中引起严重的性能退化，使得GCLB的全球产能有效减少了50％。由于后端失败，PokémonGO应用程序试图重试失败的请求用户时，应用程序的重试策略是立即重启，接下来是不断的重启。随着重启的进行，服务有时会返回大量错误报告 - 例如，重新启动共享后端时，这些错误响应有助于有效地同步客户端重试，产生“雷鸣般的”群体问题，其中许多客户请求基本上是相同的时间。如图11-6所示，这些同步请求峰值增加了小到20倍之前的全球RPS峰值。 图11-6 由同步客户机重试引起的流量峰值 解决问题这些请求峰值与GFE容量回归相结合，导致所有GCLB服务的排队和高延迟。Google的SRE通过执行以下操作来减少对其他GCLB用户的附带损害：  隔离可以从主负载平衡器池中提供PokémonGO流量的GFE。  扩大Pokémon GO 应用的集群池，直到它能够处理峰值流量，尽管性能下降。此操作将容量瓶颈从GFE转移到Niantic堆栈，其中服务器仍在超时，特别是在客户端重试开始同步和峰值时。  在Niantic的协助下，TrafficSRE实施了管理覆盖，以限制负载均衡代表PokémonGO接受的流量。该策略包含客户端需求，足以让Niantic重新建立正常连接并开始垂直扩展。图11-7显示了最终的网络配置。 图11-7 Pokémon GO GCLB 面向未来在此事件发生后，Google和Niantic都对其系统进行了重大调整。Niantic为其客户端引入了抖动和截断指数降级，从而抑制了级联故障期间经历的大规模同步重试峰值。谷歌将GFE后端视为潜在的重要负载来源，并制定了检测GFE和负载测试由后端缓慢或以其他方式引起的性能下降。最后，两家公司都意识到他们应该尽可能地靠近客户来衡量负载。如果Niantic和Google CRE能够准确预测客户的RPS需求，那么我们会先行扩容给Niantic，这比我们在迁移到GCLB之前所做的要及时的多。自动弹性伸缩像GCLB这样的工具可以帮助有效地均衡整个系统的负载，使服务更加稳定可靠。有时根本没有足够的资源来管理现有流量。此时可以使用自动弹性伸缩来扩展系统。无论是增加每台计算机的资源（垂直扩展）还是增加池中的计算机总数（水平扩展），弹性伸缩都是一种功能强大的工具，如果使用得当，可以提高服务可用性和利用率。相反，如果配置错误或误用，弹性伸缩可能会对服务产生负面影响。本节介绍弹性伸缩的一些最佳实践，常见故障模式和当前限制。处理不健康的实例自动调节所有实例的利用率，无论其状态如何，并假设实例在请求处理效率方面是同质的。当计算机无法提供服务时（称为不健康的实例），自动调节会遇到问题，但仍然会计入平均利用率。在这种情况下，不会发生弹性伸缩。以下情况都可以触发此故障模式，包括：  需要很长时间准备服务的实例（例如，加载二进制文件或预热时）  陷入非保存状态的实例（即僵尸）我们可以使用各种策略改善这种情况。可以组合或单独进行以下改进：负载均衡使用负载均衡观察到的容量指标进行自动弹性伸缩。这将自动从平均值中扣除不健康的实例。在收集指标之前，请等待新实例稳定下来您可以将autoscaler配置为仅在新实例变为健康状态时收集有关新实例的信息（GCE将此不活动时段称为冷却时段）。自动弹性伸缩和自动修复自动修复监视系统实例，并尝试在不健康的情况下重新启动它们。通常，将自动加密器配置为监视实例公开的运行状况指标。如果自动修复检测到实例已关闭或运行状况不佳，则会尝试重新启动。配置时，务必确保在重新启动后为实例留出足够的时间使其恢复正常。使用这些解决方案的混合，可以优化水平弹性伸缩以仅跟踪健康的实例。请记住，在运行服务时，自动调节器会不断调整系统实例的大小。创建新实例绝不是即时的（需要一定的时间）。有状态的系统有状态的系统将用户会话中的所有请求一致地发送到同一后端服务器。如果这些路径负担过重，添加更多实例（即水平扩展）将无济于事。分散负载的智能任务型路由（例如，使用一致性哈希）是对有状态系统的更好策略。垂直自动伸缩在有状态系统中很有用。当与任务型平衡结合使用以均衡系统负载时，垂直自动弹性伸缩可以帮助吸收短期热点。但请谨慎使用此策略：由于垂直自动调节通常在所有实例中均匀分布，因此低流量的实例可能会出现资源的浪费。谨慎的配置使用自动弹性伸缩扩展比使用缩放更重要且风险更小，因为无法扩展可能导致过载和流量下降。按照设计，大多数自动调节器实现对流量的跳跃都比对流量的下降更敏感。扩展时，自动缩放器倾向于快速增加额外的服务容量。按比例缩小时，它们会更加谨慎，并且在缓慢减少资源之前等待更长时间以使其缩放条件成立。当服务进一步远离瓶颈时，你可以吸收的负载峰值会增加。我们建议配置自动扩展器，以使服务远离关键系统瓶颈（例如CPU）。自动定标器还需要足够的时间来做出反应，特别是当新实例无法启动并立即投入使用时。我们建议面向用户的服务为过载保护和冗余保留足够的备用容量。设置约束Autoscaler是一款功能强大的工具; 如果配置错误，它可能会造成意想不到的后果。例如，请考虑以下方案：  您已将自动扩展配置为根据CPU利用率进行扩展。您发布了系统的新版本，其中包含导致服务器在不执行任何工作的情况下使用CPU的错误。Autoscaler通过反复升级此作业来做出反应，直到浪费了所有可用配额。  服务中没有任何变化，但依赖性失败。此故障导致所有请求卡在您的服务器上并且永远不会完成，从而消耗资源。Autoscaler将扩大工作范围，导致越来越多的流量卡住。失败的依赖项上的负载增加可以防止依赖项恢复。限制允许自动缩放器执行的工作很有用。设置缩放的最小和最大界限，确保您有足够的配额可以缩放到设置的限制。这样做可以防止您耗尽配额并帮助您进行容量规划。支持禁用和手动执行如果您的自动伸缩出现问题，最好使用kill开关。确保工程师了解如何禁用自动弹性伸缩以及如何在必要时手动进行弹性伸缩。自动弹性伸缩终止开关功能应该简单，明显，迅速且运行良好。避免重载后端正确配置的自动缩放器将根据流量的增加进行扩展。流量的增加会对堆栈产生影响。后端服务（如数据库）需要吸收服务器可能产生的任何额外负载。因此，在部署自动缩放器之前对后端服务执行详细的依赖性分析是个好主意，特别是因为某些服务可能比其他服务更加线性扩展。确保您的后端有足够的额外容量来提供增加的流量，并且在超载时能够优雅地降级。使用分析中的数据来告知自动缩放器配置的限制。服务部署通常运行各种共享配额的微服务。如果微服务扩大以响应流量峰值，它可能会使用大部分配额。如果单个微服务上的流量增加意味着其他微服务上的流量增加，则剩余的微服务将无法增加可用配额。在这种情况下，依赖性分析可以帮助指导您预先实施有限的扩展。或者，您可以为每个微服务实现单独的配额（这可能需要将您的服务拆分为单独的项目）。避免流量不平衡一些自动调节器（例如，AWS EC2，GCP）可以跨区域实例组（RMiG）平衡实例。除了常规的自动弹性伸缩之外，这些自动编程器还运行一个单独的工作，不断尝试均衡整个区域中每个区域的大小。以这种方式重新平衡避免流量集中在某一区域。如果使用的系统为每个区域分配配额，则此策略可以均衡您的配额使用情况。此外，跨区域的自动调整为故障域提供了更多的多样性。结合管理负载均衡的策略如果系统足够复杂，可能需要使用多种负载管理。例如，可以运行多个托管实例组，这些实例组可以按负载进行扩展，但是可以跨多个区域克隆容量; 因此，还需要平衡区域之间的流量。在这种情况下，系统需要同时使用负载均衡和基于负载的自动扩展。或者可能在世界各地的三个共同设施中运营一个网站，希望在本地提供延迟服务，但由于部署更多计算机需要数周时间，因此溢出的流量需要定位到其他位置。如果网站在社交媒体上受欢迎，并且突然间流量增加了五倍。因此，实施减载以减少多余的流量。在这种情况下系统需要同时使用负载平衡和减载。或者，数据处理管道可能位于一个云区域的Kubernetes集群中。当数据处理速度显着降低时，它会提供更多的pod来处理工作。但是，当数据进入如此之快以至于读取它会导致内存不足或减慢垃圾收集时，pod可能需要临时或永久地释放该负载。在这种情况下，系统需要使用基于负载的自动弹性伸缩和减载技术。负载均衡，减载都是为同一目标而设计的系统：均衡和稳定系统负载。由于这些系统通常是分别实现、安装和配置的，因此它们看起来是独立的。但是，如图11-8所示，它们并非完全独立。以下案例研究说明了这些系统如何相互作用。 图11-8 一个完整的流量管理系统 案例研究2：减载以应对流量攻击Dressy是一家流量驱动的服装电商销售平台。其开发团队将应用部署到了三个地区已应对单区域故障问题（他们是这样认为的）。在一次故障案例中，Dressy的客户服务团队开收到客户投诉：无法访问该应用程序。 Dressy的开发团队调查并注意到一个问题:他们的负载均衡系统将所有用户流量吸引到区域A，即使该区域是满溢的，B和C都是空的（同样的资源规模下），这是令人费解的。故障的时间表（见图11-9）如下：  在一天开始时，仪表盘流量图显示所有三个集群稳定在90 RPS的访问。  在上午10:46，由于购物者开始寻找便宜货，所有三个地区的流量开始上升。  在上午11点，区域A在区域B和C之前达到120 RPS。  在上午11点10分，A区继续增长到400 RPS，而B和C下降到40 RPS。  负载均衡器稳定了流量请求，将大部分的请求指向A区。  击中A区的大多数请求都返回503错误。  请求到达此群集的用户开始抱怨。 图11-9 区域流量 如果开发团队排查负载均衡器的饱和度图表，他们会看到一些意料之外的东西。负载均衡器从Dressy的容器中读取CPU利用率并根据此信息来估计饱和度。而每个请求的CPU利用率在区域A时比B和C都低10倍。负载均衡确定所有区域的负载均等，认为其工作正常。发生了什么事？本周早些时候，为了防止级联过载，该团队实现了减载。每当CPU利用率达到某个阈值时，服务器就会为其收到的任何新请求返回错误响应，而不是尝试处理它们。在这一天，A区域略微超过其他区域。每个服务器开始拒绝收到的10％的请求，然后是20％的请求，然后是50％。在此时间范围内，CPU使用率保持不变。就负载均衡器系统而言，每个连续丢弃的请求使CPU利用率降低。区域A比区域B和C更有效。它在80％CPU（上限）下服务240RPS，而B和C仅有120 RPS。从逻辑上讲，它决定向A发送更多请求。什么地方出了错？简而言之，负载均衡器不知道“有效”请求是错误的，因为负载减少和负载平衡系统没有通信。每个系统都是由不同的工程师单独添加和启用的。没有人将它们视为一个统一的负载管理系统。经验总结为了有效地管理系统负载，我们需要慎重考虑各个负载管理工具的配置和他们的交互管理。例如，Dressy案例研究中，将错误处理添加到负载均衡器逻辑可以解决问题。假设每个“错误”请求计为120％的CPU利用率（超过100的任何数字都可以）。现在区域A看起来超载了。请求将扩展到B和C，系统将平衡。可以使用类似的逻辑将此示例推断为任何负载管理策略的组合。采用新的负载管理工具时，请仔细检查它与系统已使用的其他工具的交互方式，并检测是否有交集的地方。添加监控以检测反馈循环是否存在。确保有紧急关闭触发器以便在负载管理系统之间进行协调，并且如果这些系统的行为严重失控，请考虑添加自动关闭触发器。如果没有预先采取适当的预防措施，以下的预案可能需要的。以下是可能会需要的预防措施，具体取决于负载管理的类型：负载均衡 负载均衡通过路由到最靠近用户的位置来最小化延迟。自动弹性伸缩可以与负载均衡协同工作，更靠近用户，然后在那里路由更多流量，从而创建正反馈循环。如果需求主要靠近一个位置，那么该位置的负载将会增加，增加该位置的服务容量以应对请求。如果此位置出现故障，其余位置将出现过载，并且可能会丢弃一部分流量。弹性伸缩不是即时的应对措施。您可以通过为每个位置设置最小实例数来避免这种情况，以保留备用容量进行故障转移。减载最好设置一个阈值，以便在减载开始之前系统自动调整。否则，如果设置值过，系统可能会开始减少它可能服务的流量。使用RPC管理负载处理正确的请求对于提高效率非常重要：不希望自动调整以提供不会使用户受益的请求，或者因为处理不重要的请求而不必要地减少负载。在同时使用自动缩放和减载时，在RPC请求上设置截止日期非常重要。进程为所有正在进行的请求保留资源，并在请求完成时释放这些资源。在没有特定截止日期的情况下，系统将为所有正在进行的请求保留资源，直至达到最大可能限制。默认情况下，此截止日期是一个非常大的数字（这取决于语言实现 - 某些语言API在固定时间点工作，而其他语言API在一段时间内工作）。此行为会导致客户端（最终用户）遇到更高的延迟。该服务还存在资源（如内存）耗尽和崩溃的风险。为了优雅地处理这种情况，我们建议服务器终止花费太长时间的请求，并且客户端取消对它们不再有用的请求。例如，如果客户端已向用户返回错误，则服务器不应启动昂贵的搜索操作。要设置服务的行为期望，只需在API的.proto文件中提供注释即可建议默认的截止日期。此外，为客户设置有意的截止日期（例如，请参阅我们的博客文章“gRPC和截止日期”）。结论根据Google的经验，没有完美的负载管理配置。自动弹性伸缩是一种强大的工具，但很容易出错。除非是详细定制的配置，否则自动伸缩可能会导致灾难性后果 - 例如，当这些工具单独配置时，负载平衡，负载切除和自动扩展之间可能存在灾难性的反馈周期。正如PokémonGO案例那样，当负载管理是基于系统级别的整体架构时，负载管理效果最佳。一次又一次案例中，我们已经看到，减载，自动弹性伸缩或限制它们之间没有协调配置时，系统是会出现灾难性故障的。例如，在PokémonGO案例研究中，我们有一个“雷鸣般的群体问题”，即客户端重试以及等待无响应的后端服务器的负载均衡器。要应对服务的过载，需要提前计划以减少潜在问题。缓解策略可能涉及设置标志，更改默认行为，启用日志记录，或流量管理系统的参数值引入制定管理决策中。我们希望本章提供的策略和见解可以帮助您，管理自己服务的流量并让用户满意。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第十章 事后总结：从失败中学习]]></title>
      <url>/sre/2020/01/10/%E4%BA%8B%E5%90%8E%E6%80%BB%E7%BB%93-%E4%BB%8E%E5%A4%B1%E8%B4%A5%E4%B8%AD%E5%AD%A6%E4%B9%A0/</url>
      <content type="text"><![CDATA[经验表明，真正对事不对人的事后总结文化可以带来更可靠的系统——这也是我们认为这种做法对于创建和维护一个成功的SRE组织十分重要的原因。将事后总结引入组织既是一种文化变革，也是一种技术变革。这样的转变似乎是令人生畏的，本章的关键点是，做出这种改变是可能的，不是一个难以克服的挑战。不要指望你的系统能够自行解决问题。你可以从引入一个非常基础的事后调查程序开始，反映和调整你的流程来适应你的组织——跟很多事情一样，没有放之四海而皆准的方法。如果总结的很好，可以采取行动并广泛分享，事后总结可以成为积极推动组织变革和防止重复故障的利器。为了可以说明优秀的事后总结的写作原则，本章介绍了一个曾经发生在Google的故障案例进行研究。一个糟糕的事后总结的案例可以突显出为什么“糟糕”的事后总结对于努力创建健康的事后分析文化的组织是有害的。将糟糕的事后总结与实际事后总结进行比较后，可以突出高质量事后总结的原则和最佳实践。本章的第二部分分享了我们在实现强大的事后总结文化激励机制以及识别（和补救）文化破裂的预兆方面所学到的知识。最后，我们提供了用于引导事后总结文化的工具和模板。有关对事不对人的事后总结哲学的全部讨论，请参阅我们的第一本书“站点可靠性工程”中的第15章。案例分析本案例研究的是例行机架退役导致用户服务延迟增加的case。我们的自动化维护系统的一个bug，加上限速不足，导致数千台承载生产流量的服务器同时宕机。虽然Google的大多数服务器都位于我们的专有数据中心，但我们在托管设施（或“colos”）中也有机架代理/缓存机器。colos中包含我们代理机器的机架被称为卫星，由于卫星经常进行例行维护和升级，所以在任何时间点都会安装或退役许多卫星机架。在Google，这些维护流程基本是自动化的。退役过程使用我们称为diskerase流程覆盖机架中所有驱动器的全部内容。一旦机器进入diskerase，它曾存储的数据将不再可检索。典型的机架退役步骤如下：  获取卫星上所有活跃的机器  machines = GetMachines(satellite)将所有通过“filter”匹配到的候选机器发送decom  SendToDecom(candidates = GetAllSatelliteMachines(), filter=machines)我们的案例研究始于一个标记为退役的卫星机架。退役过程的diskerase步骤已成功完成，但负责剩余机器退役的自动化失败了。为了调试失败，我们重新尝试了停用过程。第二次退役如下：  获取卫星上所有活跃的机器      machines  = GetMachines(satellite) 因为decom流已经在运行了，因此”machines”是一个空的列表 API bug：anmpty list被视为“无过滤，即为在全部机器上运行”，而不是“不在任何机器上运行” 将所有通过“filter”匹配到的候选机器发送到decom    SendToDecom(candidates=GetAllSatelliteMachines(), filter=machines) 将所有候选机器发送到diskerase。几分钟内，全球所有卫星机架的磁盘数据都被删除。这些机器处于不可用状态，无法接受用户的连接，因此后续用户的连接直接路由到我们的数据中心。结果导致用户延迟增加。得益于良好的容量规划，很少有用户注意到这两天我们在受影响的colo机架中重新安装机器。事件发生后，我们花了几周的时间进行审核，并为自动化添加了更多的健全性检查，使我们的退役工作流程具有幂等性（其任意多次执行所产生的影响均与一次执行的影响相同）。故障发生的三年后，我们遇到了类似的事件：由于许多卫星被耗尽导致用户延迟增加。根据原始事后总结，本次事件后实施的行动大大减小了二次事故的影响范围和速度。假设你是负责为此案例研究撰写事后总结总结的人。你想了解什么，以及你会采取什么行动来防止此类故障再次发生？让我们从这个事件的一个糟糕的事后总结示例开始。糟糕的事后总结示例：   事后总结：所有卫星机器进入diskerase流程   2014-8-11:  负责人：maxone@，logantwo@， sydneythree@，dylanfour@与以下人员共享：satellite-infra-team@状态：不可更改事件日期：2014年8月11日发布时间：2014年12月30日  执行摘要  影响：所有卫星机器都被发送到diskerase，实际导致Google Edge不可用。  根本原因：dylanfour@忽略了自动化设置并手动运行了集群启动逻辑，从而触发了现有bug。  故障摘要  故障持续时间：40分钟受影响的产品：satellite-infra-team   受影响的产品百分比：所有卫星集群。 用户影响：进入卫星的所有查询都是由Core提供的，导致延迟增加。 收入影响：由于查询异常，部分广告未投放。目前确切的收入影响未知。 监控：监控报警。 解决方案：将流量转移到核心，然后手动修复边缘集群。  背景（可选）  影响      用户影响：   进入卫星的所有查询都是由Core提供的，导致延迟增加。    收入影响：    由于查询异常，部分广告未投放。    根本原因和触发点 集群开启和关闭的自动化并不意味着是幂等的，该工具有安全措施确保某些步骤不能多次运行。但无法阻止某个人手动多次运行代码，也没有文件提及这个问题。因此，大多数团队成员认为工具失效时，可以多次运行该过程。  正好在机架的常规退役期间发生这种情况。机架正在被一个新的基于lota的卫星取代。dylanfour@忽略了已经执行了一次启动并在第一次执行时出现问题。由于粗心以及无知，他们引发了一个错误的交互，即将所有卫星机器分配给了弃用团队。  为恢复生产投入的努力  经验教训      事情进展顺利：              报警及时发现问题。        事故处理进展顺利。              事情进展受挫：              团队（特别是maxone@，logantwo@）从未编写任何文档告知SRE不要多次运行自动化。        on-call处理的不够及时，没有阻止大多数卫星机器被删除。这已经不是第一次出现处理故障不及时的情况了。              幸运的              Core能够为原本进入边缘集群的所有流量提供服务。简直无法相信我们这次能幸免于难！              行动列表                    行动列表        类型        优先级        负责人        bug跟踪                            完善自动化工具。        缓解        P2        logantwo@                             报警改善        检测        P2                                      sydneythree@ 需要学习正确的跨站点轮值文档，避免发生重复的问题        缓解        P2                 BUG6789                    训练大家不要运行不安全的命令        避免        P2                                名词解释为什么这份总结十分糟糕？示例包含一些我们试图避免的常见故障模式。以下说明如何改进这份事后总结。缺少上下文从一开始，作为示例的事后总结引入了特定于流量服务的术语（例如，卫星）和Google机器管理自动化的较低层（例如，“diskerase”）。如果你需要提供其他上下文作为总结的一部分，请在背景或名词解释部分进行添加（可以链接到更长的文档）。上述总结在这两部分都是空白的。如果在编写事后总结时没有将内容置于正确的上下文中，文档可能会被误解或被忽略。谨记，你的受众并不只仅仅是有着直接关系的团队。省略了关键细节多个部分包含摘要但缺少重要细节。例如：问题总结针对多个服务的中断，应该提供数字来表示影响范围。示例中唯一的数据是故障的持续时间。没有足够的细节来评估故障的规模或影响。即使没有一个具体值，一个估计的值也比没有数据好。毕竟，你如果不知道如何衡量它，那么你也不知道它是否被修复了！根本原因和触发点确定根本原因和触发点是编写事后总结的重要原因之一。示例包含一个描述根本原因和触发点的小段落，但没有探索故障的底层细节。为恢复生产投入的努力对读者来说，事后总结是事件记录。一份好的事后总结能让读者知道发生了什么，该如何减轻问题，以及用户受到了什么影响。很多问题的答案通常在投入恢复的努力中可以找到，但示例中，这部分是空的。如果故障值得写入事后总结中，那么你还应该花时间准确获取并记录必要的详细信息。读者可以全面了解停机情况，更重要的是可以了解新事物。缺失了关键行动列表示例的“行动列表”（AIs）部分缺少防止此类故障再次发生的可执行的行动计划。例如：  行动列表主要是缓解措施。为了最大程度的降低重复发生中断的几率，还应该包括一些预防性和修复性的操作。一个“预防性的”行动列表说明我们“让人不会轻易出错”。一般来说，试图改变人类行为比改变自动化系统和流程更不靠谱。（正如Dan.Milstein曾打趣道：“让我们为未来做好计划，因为未来的我们跟今天一样愚蠢。”）  所有操作项都标记了相同的优先级。没法确认首先要执行的行动。  列表前两个操作项用词模糊不清，如“改善”和“完善”。用词不当会很难衡量和理解成功的标准。  只有一个操作项标明跟踪bug。如果没有正式的跟踪过程，事后总结的行动列表往往会被遗忘，导致故障再次发生。  用Google全天候运维副总裁Ben TreynorSloss的话来说：“对我们的用户而言，没有后续行动的事后总结和没有事后总结并无差别。因此，所有影响到用户的事后总结都必须至少有一个与它们相关的P[01]错误。例外情况由我亲自审查，但几乎没有例外。”适得其反的指责每一次事后总结都可能会陷入相互指责中。来看一些例子：事情变得糟糕整个团队都被指责要对故障负责，尤其是这两名成员（maxone@和logantwo@）。行动列表列表的最后一项指向了sydneythree@，负责跨站点轮岗。根本原因和触发点dylanfour@为本次故障全权负责。在事后总结中强调个体似乎是个好主意，但实际上，这种做法会导致团队成员不愿承担风险，因为害怕被当众羞辱。他们可能会掩盖那些防止再次发生故障的事实。Animated语言事后总结基于事实，不应该受个人判断和主观语言的影响，应该考虑多种观点并尊重他人。示例中包含了多个反面例子：根本原因和触发点多余的语言（例如，“粗心无知”）事情变得糟糕Animated文字（例如，“这太荒谬了”）幸运的一种夸张的感叹（例如，“无法相信我们能够幸免于难！”）动画语言和对事件的戏剧性描述稀释了关键信息，降低了警惕性。应该提供可验证的数据来证明事件的严重性。缺少负责人宣布官方所有权会产生问责制，从而促进采取行动。示例中有几个缺少所有权的例子：  总结列出了四个负责人。理想情况下，负责人是单点联系人，负责事后总结，后续以及完善工作。  “行动列表”部分很少甚至没有提及各条目的负责人。没有明确负责人的行动项目不大可能会被解决。最好的是拥有一个负责人和多个协作者。受众有限示例事后总结仅在团队成员之间共享。默认情况下，公司的每个人都应该可以访问该文档。建议尽可能广泛的分享你的事后总结，甚至和客户分享。总结的价值和所创造的经验成正比。能够从过去事件中吸取教训的人越多，重复发生的可能性就越低。周密和诚实的事后总结也是恢复信任的关键。随着体验和舒适度的提高，可以将“受众”扩展到非人类。成熟的事后总结文化通常会添加机器可读标签（和其他元数据）以启用下游分析。延迟发布示例是在事件发生四个月后公布的。在此期间，如果事故再次发生（实际上确实发生过），团队成员可能会忘记总结中提到的关键细节。优秀的事后总结示例  这是一份真实的事后总结。个人和团队的名字均为虚构，为了保护敏感容量信息，我们使用了占位符替换实际值。在你为内部分享的事后总结中，应该包含具体的数字。   事后总结：所有发送到diskerase的卫星机器   2014-8-11:  负责人：      事后总结：maxone@，logantwo@，    数据中心自动化：sydneythree@，    网络：dylanfour@    服务器管理：finfive@    与以下人员共享：all_engineering_employees@google.com@  状态：不可更改事件日期：2014年8月11日, 星期一，PST8PDT 17:10至17:50   发布时间：2014年8月15日, 星期五  执行摘要  影响：前端查询丢失。部分广告未投放近两天由卫星提供的服务延迟增加根本原因：自动调节系统中的某个错误导致所有机架的卫星服务器被发送磁盘diskerase指令。导致所有卫星机器进入退役工作流程，磁盘数据被擦除。致使全球卫星前端中断。。  故障摘要  故障持续时间：故障：周一，8月11日，PST8PDT 17:10至17:50。                     周三，8月13日，07:46进行重建工作，之后故障解除。 受影响的产品：前端基础设施，尤其是卫星所在地。  受影响的产品百分比：全球——所有由卫星提供服务的流量（占全球查询的60%）。 用户影响：[ ]前端查询在40分钟内有所下降（[ ]QPS在此期间处于平均值，占全球流量的百分比[ ]）。所有由卫星提供的服务延迟增加。 收入影响：目前未知确切的收入影响。 监控：黑盒报警：对于每个卫星，流量团队收到“卫星a12bcd34有过多失败的HTTP请求”报警。 解决方案：通过将所有Google的前端流量转移到核心集群，以用户请求的额外延迟为代价，迅速缓解故障。  背景（可选）  影响      用户影响：              [_]个前端查询在40分钟的时间段内丢失，QPS在此期间持平，占全球流量的[ ]%。我们的监控表明这是个大故障；然而数据并不可靠，监控将自身停止监控的但仍在服务的卫星视为请求被拒绝。附录描述了如何估算上述数字。。        最近两天所有由卫星提供的服务延迟增加。                      –核心集群附近的RTT峰值[ ]ms            –对于更依赖卫星的地点（例如澳大利亚，新西兰，印度），延迟+[ ]ms                                收入影响：              由于请求丢失，部分广告未投放。目前尚不清楚确切的收入影响        显示和视频：由于日常波动，数据的误差较大，但我们估计故障当天有[ ]%到[ ]%的收入损失。        搜索：在17:00到18:00之间，在使用同样的误差时，有[ ]%到[ ]%的损失。              团队影响：              流量团队花了大约48小时全力投入重建卫星。        因为需要对过载的对等链路进行流量工程设计，NST的故障/报警负载高于正常值。        由于GFE的缓存命中率降低，某些服务可能会在前端提供更多响应。                      —例如，请参阅线程[链接]关于[缓存依赖服务]。            —[缓存相关服务]在恢复之前，GFE的缓存命中率从[ ]%下降到[ ]%。                                故障文件    [我们的事后总结文档的链接。]  根本原因和触发点 流量管理服务器中一个长期存在的输入验证bug，由于手动重新执行a12bcd34卫星的工作流程而被触发的。该bug删除了执行退役操作的机器的约束，发送并停用了所有卫星机器。 因此，数据中心自动化执行了退役工作流程，擦除了大多数卫星机器的硬盘驱动器，在此之前无法停止这项操作。Traffic Admin服务器提供ReleaseSatelliteMachines RPC。此处理程序使用三个MDB API调用卫星停用：      查找与边缘节点关联的机架名称（例如，a12bcd34 -&gt;）。    查找与机架关联的机器名称（-&gt;等）。    将这些计算机重新分配给diskerase，间接触发退役工作流程。    由于MDB API的行为以及安全检查不是幂等的。如果卫星节点先前已成功发送到decom，则上面步骤2返回一个空列表，步骤3中将其解释为机器主机名上没有约束。这种危险行为已存在一段时间，但被调用不安全操作的工作流程隐藏：调用RPC的工作流程步骤标记为“运行一次”，意味着工作流引擎一旦成功就不会重新执行RPC。但是，“运行一次”的语义不适用于工作流的多个实例。当集群启停团队手动启动a12bcd34的另一个工作流时，会触发admin_server bug。  为恢复生产投入的努力    [我们的时间线日志的链接已被省略。在真正的事后总结中，这些信息始终包含在内。]  经验教训      事情进展顺利：              疏散边缘。核心中的GFE明确的进行容量规划能允许这种情况发生，生产主干也是如此（除了对等链路之外；请参阅下一节中的故障列表）。这种边缘疏散使得流量团队能迅速减缓故障。        自动减轻卫星故障。覆盖的线路自动将来自故障卫星的流量拉回到核心集群，并且当检测到异常抖动时会自行排出。        尽管可能会造成混乱，但卫星decom/diskerase工作十分高效和迅速。        故障通过OMG触发了快速的IMAG响应，并且该工具适用于持续的事件跟踪。跨团队的反应非常棒，OMG帮助大家保持交流。              事情进展受挫：              故障                      Traffic Admin服务器没有对其发送到MDB的命令进行适当的健全性检查。所有命令都应该是幂等的，或者至少在重复调用时是自动防故障的。            MDB不拒绝缺少主机名约束的所有权更改请求。            decom工作流程不与其他数据源（例如，计划的机架decom）交叉检查decom请求。因此，对已清除（地理上不同）的机器的请求没有异议。            decom工作流不受速率限制。一旦机器进入decom，磁盘擦除和其他decom步骤以最大速度进行。            当卫星停止服务时，由于出口流量转移到不同位置，Google和各国之间的一些对等链路过载，而请求是从核心集群提供服务。导致了在卫星恢复且匹配NST缓解工作之前，选择对等链路的阻塞短暂爆发。                          恢复                      重新安装卫星机器的速度很慢且不可靠。在高延迟链路末端传输到卫星时，重新安装使用TFTP传输数据效果不佳。            Autoreplacer基础架构无法在故障时设置GFE的[ ]。需要多个SRE并行手动执行设置来匹配自动化设置的速度。以下因素导致自动化的缓慢：                              —SSH超时阻止了Autoreplacer在远程卫星上的操作。                —无论机器是否已具有正确的版本，都执行了慢速内核升级过程。                —Autoreplacer中的并发回归阻止了每个工作机器运行两个以上的机器设置任务。                                      当23%的目标被移除时，没有触发监控配置的安全检查参数（25%变化），当读取相同内容（剩余的29%）时触发了。导致重新启用卫星监控延迟30分钟。            “安装人员”有限，因此，变更过程困难又缓慢。            使用超级用户权限将机器从diskerase拉回来时留下了很多僵尸进程，导致后续清理困难。                                幸运的              核心集群的GFE与卫星GFE的管理方式不同。他们没有受到decom的影响。        同样，YouTube的CDN作为独立的基础设施运行，因此没有受到影响。否则故障将更加严重和持久。              行动列表  由于此事件的广泛性，我们将行动列表分为五个主题：      预防/风险教训    紧急响应    监控/报警    卫星/边缘    清理/其他    表10-1.预防/风险教训                    行动列表        类型        优先级        负责人        bug跟踪                            审核所有能够将实时服务器转换为宕机状态的系统（即，不仅仅是维修和diskerase工作流）        调查        P1        sydneythree@        BUG1234                    提交bug，跟踪BUG1234识别出的所有系统的拒绝错误输入实施的情况。        预防        P1        sydneythree@        BUG1235                    禁止任何单个会影响跨命名空间/类边界的服务器操作。        减缓        P1        maxone@        BUG1236                    流量管理服务器需要进行安全检查才能在超过[ ]节点数的情况下运行。        减缓        P1        dylanfour@        BUG1237                    流量管理服务器应该依据批准破坏性工作。        预防        P0        logantwo@        BUG1238                    MDB应拒绝对非预期的当前约束提供值的操作。        预防        P0        louseven@        BUG1239              表10-2.紧急响应                    行动列表        类型        优先级        负责人        bug跟踪                            确保由核心提供的服务不会使出口网络链路过载。        修复        P2        rileyslx@        BUG1240                    确保在[我们的紧急停止文档]和[我们的升级联系页面]下注明了decom工作流问题。        减缓        P2        logantwo@        BUG1241                    为decom工作流添加一个大红色禁用按钮a        减缓        P0        maxone@        BUG1242              a : 由于灾难性环境中避免进一步损坏的关闭开关（例如，紧急电源关闭按钮）的常见术语。表10-3.监控/报警                    行动列表        类型        优先级        负责人        bug跟踪                            监控目标的安全检查，不允许发布无法回滚的变更。        减缓        P2        dylanfour@        BUG1243                    当超过[ ]%的机器退役需要添加报警。16:38机器从卫星上取下，17:10开始世界范围的报警。        监测        P1        rileyslx@        BUG1244              表10-4.卫星/边缘                    行动列表        类型        优先级        负责人        bug跟踪                            利用IPXE配合HTTPS可以使重新安装更快更可靠。        减缓        P2        dylanfour@        BUG1245              表10-5.清理/其他                    行动列表        类型        优先级        负责人        bug跟踪                            在我们的工具中查看与MDB相关的代码，并将管理服务器备份放至unwedge调节中。        修复        P2        rileyslx@        BUG1246                    安排DiRT测试：在diskerase后带回卫星；对YouTube CDN执行相同操作。        减缓        P2        louseven@        BUG1247              名词解释 管理服务器RPC服务器，支持自动化为前端服务基础结构执行特权操作。自动化服务器常参与PCR和集群启停操作。  Autoreplacer将非Borgified服务器从一台机器移动到另一台机器的系统。在机器故障时保持服务运行，并且支持colo重新配置。  Borg集群管理系统，旨在管理大规模任务和机器资源。Borg拥有Borg单元中所有机器，并将任务分配给具有可用资源的机器。  Decom退役的缩写。设备的decom是一个与许多运维团队相关的过程。  Diskerase在生产硬盘驱动器离开Google数据中心前安全擦除生产硬盘的过程（以及相关的硬件/软件系统）。diskerase是decom工作流的一个步骤。  GFE（Google前端）外部连接(几乎)所有谷歌服务的服务器。  *IMAG（Google事件管理）一个程序，一种标准，以一致的方式来处理从系统中断到自然灾害的所有类型的事件——并组织有效的响应。  MDB（机器数据库）事件管理仪表盘/工具，用于跟踪和管理Google所有正在进行的事件的中心位置。  卫星小巧便宜的机器机架，仅提供提供来自Google网络边缘的非视频、前端流量。几乎没有传统的生产集群基础设施可用于卫星。卫星不同于CDN，它提供来自Google边缘网络的YouTube视频内容，以及来自互联网中更广泛的其他地方的视频内容。YouTube CDN未受此事件的影响。  附录为什么释放卫星机器不是幂等的？ [该问题的回复已被删除]  管理服务器将所有卫星分配给diskerase团队后发生了什么？ [该问题的回复已被删除]  故障期间真正的QPS损失是多少？ [该问题的回复已被删除]  IRC日志[IRC日志已被删除]  图表  更快的延迟统计——卫星曾为我们做过什么？从这次故障经验得到，卫星会在核心集群附近的许多位置产生[ ]ms延迟，离主干更远的位置甚至会达到[ ]ms：[图表的解释已被删除]  核心与边缘服务负载为重建服务所付出的努力是个很好的例证。边缘服务恢复50%的流量需要大约36小时，恢复到正常的流量水平需要额外的12小时（见图10-1和图10-2）。  来自流量转换的对等压力  [图表省略] 该图显示了由网络区域聚合的数据包丢失情况。在活动期间有一些短的尖峰，但大部分损失发生在卫星覆盖少的各个地区的高峰时刻。  人与机器，GFE [省略了人机与自动机器设置速率的图表说明。] 图10-1.故障期间核心与边缘QPS分布    图10-2.故障期间核心与边缘QPS分布（替代表示）   为什么这份事后总结示例更好？  这个事后总结符合了好几条写作要求。明晰事后总结组织的很好，详细解释了关键术语。例如：名词解释一个精心编写的名词解释让事后总结更容易被大众接受和理解。行动列表这是一个涉及许多小的行动列表的大事件。按照主题对操作项进行分组可以更加轻松的分配负责人和优先级。量化指标事后总结提供了相关事件的有用数据，例如缓存命中率、流量级别和影响持续时间。数据的相关部分将显示原始来源的链接。这种数据透明性消除了歧义并为读者提供了上下文参考。具体行动列表没有行动列表的事后总结是无效的。这些行动列表有一些显著特点：负责人所以操作项都有负责人和bug跟踪号。优先级为所有操作项分配优先级。可测性操作项具有可验证的最终状态（例如，“当我们的机器中超过X%的机器退役时添加报警”）。预防措施每个操作项“主题”都有预防/缓解操作项，这些操作项有助于避免故障重复发生（例如，“禁止任何单个会影响跨命名空间/类边界的服务器操作。”）不指责作者关注的是系统设计中的差距，正是这些差距导致了非预期的故障，例如：事情进展受挫没有任何人或团队因此事件受到指责。根本原因和触发点关注“什么”出了问题，而不是“谁”造成了这一问题。行动列表旨在改善系统而不是改善人。深度事后调查不仅仅是调查系统故障的近似区域，也研究了多个团队的影响和系统缺陷。尤其：影响本节包含来自不同视角的大量细节，尽可能的做到平衡，客观。根本原因和触发点本节对事件进行深入研究，找到根本原因和触发点。由数据推及结论提出的所有结论均基于事实和数据。用于得出结论的数据都和文档相关联。其他资源以图表的形式进一步呈现有用的信息。向不熟悉系统的读者解释图表帮助其理解上下文。及时事件结束后不到一星期就写完并传播了事后总结。快速的事后总结往往更加准确，因为此时任何参与者心理都记着这件事。而受故障影响的人正在等待一个解释，证明你们已经控制了故障。等待的时间越长，他们就越能散发想象，那样对你十分不利。简明该事件是全球范围的事件，影响多个系统。事后总结记录了且随后分析了大量数据。冗长的数据源（例如聊天记录和系统日志）被抽象化，未经编辑的版本可从主文档中链接到。总体而言，这份总结在冗长和可读性之间取得了平衡。组织激励理想情况下，高级领导应该支持和鼓励有效的事后总结。本节描述了一个组织如何激励健康的事后总结文化。我们着重描述了总结文化失败的征兆，并给出了一些解决方案。同时还提供了工具和模板来简化和自动化事后处理流程。模型以及对事不对人为了正确的支持事后总结文化，领导者应始终如一的坚持对事不对人的原则，并在事后讨论中鼓励对事不对人。可以使用一些具体策略来强制组织执行对事不对人这一准则。使用对事不对人的语言指责性的语言会影响团队协作。请考虑以下情况：  Sandy 错过了服务Foo培训，且不确定如何运行特定的更新命令。因而导致故障时间的延长。SRE Jesse [对Sandy的leader说]:“你是经理，为什么不确保每个人都完成培训？”这个交流凸显了一个主要问题，即让收件人处于劣势。更平衡的回应是：  SRE Jesse [对Sandy的leader]：“看完事后总结，能够注意到on-call错过了一次重要的培训，导致没有更快的解决故障。因此是否应该要求团队成员加入on-call轮转之前都完成此培训？或者是否可以提醒on-call，如果操作卡住可以尽快升级事件。毕竟，升级不是错误——尤其它有助于降低客户的负担！从长远来看，因为一些细节很容易被忘记，因此我们不能完全依赖培训。”事后总结的创作要包含所有事件参与者当事后总结是单人或由单个团队编写时，很容易忽略导致故障的关键因素。收集反馈明确的审查过程和事后计划可以帮助防止指责的语言和观点在组织内传播。有关的结构化审核流程请参阅第221页的“事后检查清单”部分。奖励事后总结事后总结培训是积极推动组织变革和防止重复故障的有效工具。如果写的够好，采取行动并广泛分享，可以考虑以下策略来激励事后总结文化。对完成行动列表进行奖励如果你奖励工程师编写事后总结而不是完成了相关的行动列表，那么可能会出现总结中的行动项目未完成的事情。需要在编写事后总结和成功完成行动计划间平衡奖励措施。对积极的组织变革进行奖励你可以将事后总结的重要性作为提高组织影响的依据，通过对标奖金、积极的绩效评估、晋升等作为奖励。来激励并广泛实施事后总结教训。突出提高可靠性随着时间的推移，有效的事后总结可以减少故障，让系统更加可靠。因此，团队可以专注于特性功能的开发速度，而不是基础架构的修补上。在总结、演示文稿和绩效评估中强调这些改进在本质上是会提供动力的。把事后总结的负责人当做领导者通过电子邮件或会议完成事后总结，或者通过给作者向受众提供经验教训的机会，能够吸引那些喜欢公共赞誉的人。对于寻求同行认可的工程师而言，可以将负责人设置为某种类型的故障的“专家”。例如，你可能会听到有人说：“和Sara说，她现在是专家了。她参与了事后总结的撰写，并且想出了解决问题的方法！”游戏化一些人会被成就感和更远大的目标所激励，例如修复系统薄弱点和提高可靠性。对于这些人而言，事后总结行动列表的记录或完成所获得的成就已经是奖励了。在Google，我们每年举办两次“FixIt”周。完成最重要的行动列表项目的SRE会收到小额赞赏和吹牛的权利。图10-3显示了一个事后总结排行榜的示例。 图10-3.事后总结排行榜 公开分享事后总结为了在组织内保持健康的事后总结文化，要尽可能广泛的分享事后总结。以下策略可以提供一些帮助。在整个组织内分享总结在内部沟通渠道、电子邮件、Slack等中宣传事后总结的可用性。如果你负责一个公司，可以分享一个最近的有趣的事后总结。进行跨团队审核对事后总结进行跨团队审查。过程中，一个团队过一遍故障，其他团队提出问题并间接学习。在Google，几个办公室都设有非正式的事后总结俱乐部，向所有员工开放。此外，由开发人员、SRE和组织领导组成的跨职能小组审核整个事后总结流程。他们每个月都会审查事后总结过程和模板的有效性。进行培训练习使用“命运之轮”训练新入职工程师：一群工程师重新扮演事后总结的角色，当时的事故总控负责人也参与其中，确保这次演习尽可能的“真实”。每周总结事件和故障每周对过去七天内发生的事件和故障的进行总结，并尽可能广泛的进行分享。响应事后总结文化的失败事后总结文化的崩溃可能并不明显，以下介绍了常见的故障模式和推荐的解决方案。逃避逃避事后总结过程可能是一个组织的事后总结文化失败的征兆，例如，假设SRE 主管 Parker无意中听到以下对话：  SWE Sam：哇，你听说了这次的大故障了吗？SWE Riley：听说了，太可怕了。他们现在得写一个事后总结了。SWE Sam：不是吧，还好我没有参与进去。SWE Riley：对啊，我是真的不想参与那个讨论会议。确保对产生这些抱怨的事件进行高可见度的事后总结可以避免这种逃避。此外，分享高质量的案例并讨论参与的人如何获得奖励将有助于重新团结每个人。。没有强调文化当高级管理人员使用责备的语言做出回应可能会使事情更糟糕。假设一个高级领导在会议上对故障做出以下声明：  VP Ash：我知道应该对事不对人，但有人事先知道这个操作可能会产生问题，你为什么不听那个人的？可以通过更有建设性的话术来减少损害，例如：  SRE Dana：我确信每个人的出发点都是好的，所以为了保持对事不对人的准则，我们一般会这样问：是否有任何应该注意到的告警以及我们为何会忽略它们。对于组织而言，立足正确的出发点，并根据现有的最佳信息做出决策，调查误导性信息的来源比分配责任更有帮助。（如果你知道敏捷原则，那么你应该对这个更加清楚。）没有时间写事后总结优质的事后总结撰写是需要时间的。当一个团队负担其他任务时，总结的质量会受到影响。低质量的没有完整的行动列表的事后总结会更容易导致故障复发。事后总结是你写给团队未来成员的信件：以免你不小心教给未来的队友一个错误的教训，保持一致的质量标准十分重要。应该优先考虑事后检查工作，跟踪事后完成情况和审查，并让团队有足够的时间来实施相关的行动计划。我们在第220页的“工具和模板”一节中讨论的工具可以帮助完成此项活动。重复故障如果团队在遇到类似故障时采用以前的经验失败了，那么就该深入挖掘了。要考虑以下问题：  行动列表项目是否需要很长时间才能完成？  故障速度是否超过了可靠性的修复速度？  最先获得的是正确的行动项目吗？  重构的故障服务是否过期？  是否把Band-Aids定位成更严重的问题上了？如果你发现了系统性流程或技术问题，应该退一步考虑整体服务运行状况。将每个类似事件的事后总结作者聚集到一起，讨论防止故障重复发生的最佳行动方案。工具和模板一组工具和模板可以让编写事后总结和管理相关数据变得更轻松，从而引导事后总结文化。在这一领域，你可以利用Google和其他公司提供的大量资源。事后总结模板模板可以使编写和分享完整的事后总结更加轻松。使用标准格式可以使非专业的读者更容易理解事后处理过程。你可以自定义模板。例如，获取特定团队的元数据（如数据中心团队的硬件品牌/型号）或受移动团队影响的Android版本可能更有用。随着团队在这方面的成熟，还可以自定义模板。Google模板Google已经通过http://g.co/SiteReliabilityWorkbookMaterials以Google文档格式分享了我们的事后模板。我们在内部主要使用Docs来编写事后总结，可以通过共享编辑权限和注释促进合作。我们的一些内部工具可以使用元数据预填充此模板让事后总结更容易编写。我们利用Google Apps脚本自动化部分创作，并将大量数据捕获到特定的部分和表格中，以便我们的事后总结存储库更容易解析数据。其他行业模板其他几家公司和个人分享了他们的事后总结模板：  报警职责  改编原始的Google可靠性站点工程书籍模型  GitHub上托管的四个模板列表  GitHub用户Julian Dunn  服务器故障事后总结工具在撰写本文时，Google的事后总结管理工具无法供外部使用（请查看我们的博客获取最新更新）。但是，我们可以解释我们的工具是如何促进事后总结文化的。事件管理工具我们的事件管理工具收集并存储大量关于故障的有用数据，并将该数据自动推动到事后总结模板中。我们推送的数据类型包括：  故障指挥人和其他角色  详细的事件时间表和IRC日志  受影响的服务和导致根本原因的服务  事件严重性  事件检测机制事后总结清单为了帮助作者确保正确完成事后检查，我们提供了一个事后检查清单，通过关键步骤引导负责人。以下是列表中的一些示例检查：  对事件影响进行全面评估。  进行足够详细的根本原因分析，推动行动列表的规划。  确保行动列表项目通过服务技术主管的审查和批准。  和更多的组织分享事后总结。完整的清单可在http://g.co/SiteReliabilityWorkbookMaterials找到。归档事后总结我们将事后总结归档在一个名为Requiem的工具中，这样任何Google员工都可以轻松找到它们。我们的事件管理工具会自动将所有事后总结推送到Requiem，组织中的任何人都可以发布他们的事后总结给所有人查看。我们有成千上万的总结存档，可以追溯到2009年。Requiem会解析个人事后总结的元数据，使其可以用于搜索、分析和总结。跟进事后总结我们的事后总结归档在Requiem的数据库中。任何生成的操作项都会在我们的集中式bug跟踪系统中归档为bug。因此，我们可以监控每个事后总结的行动项目的结束与否。通过这种级别的跟踪，可以确保行动项目不会有漏洞以致服务越来越不稳定。图10-4显示了由我们的工具启用的事后总结操作项监控的模型。 图10-4.事后总结行动项目监控 事后总结分析我们的事后总结管理工具将信息存储在数据库中以供分析。团队可以使用这些数据编写有关其事后趋势的总结，并确定易受攻击的系统。这有助于我们发现潜在的不稳定因素或可能被忽略的故障管理障碍。例如，图10-5显示了使用我们的分析工具构建的图表。这些图表显示了我们每个组织每月有多少次事后追踪、事件平均持续时间、检测时间、解决时间和故障半径的趋势。 图10-5.事后总结分析 其他行业工具以下是一些可以帮助你创建、组织和分析事后总结的第三方工具：  报警职责事后调查  Etsy的档案室  VictorOps尽管完全实现自动化编写事后总结是不可能的，但我们发现事后总结模板和工具会使整个流程更加顺畅。这些工具可以节省时间，让作者能够专注于事后的关键部分，例如根本原因的分析和行动项目计划。结论在培养事后总结文化的持续投资中，能够减少故障，为用户提供更好的体验，以及让依赖你的人对你更加信任。这些实践的应用可以使系统设计更完善、宕机时间更短、工程师工作效率更高且工作更快乐。如果最坏的情况确实发生并且故障再次发生，那么你受到的损失会更小并且恢复的更快，而且有更多的数据帮助健壮生产环境。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第九章 故障响应]]></title>
      <url>/sre/2020/01/09/%E4%BA%8B%E4%BB%B6%E5%93%8D%E5%BA%94/</url>
      <content type="text"><![CDATA[  写在开头:  故障总会发生！如何对故障快速进行有组织的响应？Google方式是一个很好的借鉴。每个团队都希望服务没有故障发生，但这个世界是不完美的，像断电这类的事件不可避免。当一个紧急故障需要多人或团队协作解决时，如何响应故障并解决问题是我们要应对的。处理故障的目标是减轻影响或将服务恢复到先前的状态。而故障管理意味着以有效的方式协调团队的响应工作，并确保响应者和利益相关者之间的信息流通。包括谷歌在内的许多科技公司都有自己的“最佳实践”来管理应急响应，并且在不断的完善。故障管理的基本前提是以结构化的方式响应故障。大规模故障是单人无法解决的；结构化的应急响应可以减少混乱。在灾难发生之前制定沟通和协调规范，使你的团队可以集中精力解决故障，而不用担心沟通和协调问题。故障响应的过程并不是困难的事情。大量实践经验总结可以为我们提供一些指导，比如在第一本SRE书中的《故障管理》章节。故障响应的基本原则包括以下内容：  保持清晰的指挥线  明确角色  随时掌握调试工作记录  响应进度的实时更新本章介绍了如何在Google和PagerDuty中进行故障管理。通过一些Case说明我们在其中达到的目标以及没有达到的目标。 “将最佳实践付诸实践”（第191页）中的清单可以帮助你开始创建自己的故障响应实践。Google故障管理故障响应是用于响应和管理故障的系统。由一个框架和一组定义的程序组成。Google的故障响应系统是基于故障命令系统（ICS）实现的。故障指挥系统ICS成立于1968年，是消防员管理野火的一种方式。该框架提供了在故障响应期间进行通信和明确角色的标准化方法。基于该模型，公司后来采用ICS来应对计算机和系统故障。本章探讨了两个这样的框架：PagerDuty的故障响应流程和Google故障管理（IMAG）。故障响应框架有三个共同目标，也称为事件管理的“三个C”（3C）：  协调响应工作  在故障响应者、组织内部和外部之间进行通信  保持对故障响应的控制当故障响应出现问题时，罪魁祸首可能出现在其中一个方面。掌握3C对于有效的事件响应至关重要。故障响应中的主要角色故障响应中的主要角色是故障指挥官（IC），通信主管（CL）和操作或行动主管（OL）。 IMAG将这些角色组织成一个层次结构：IC引导故障响应，CL和OL报告给IC。灾难发生时，声明故障的人通常会进入IC角色并指挥故障的高级别状态。 IC专注于3C，并执行以下操作：  命令和协调故障响应，根据需要委派角色。默认情况下，IC会假定尚未委派的所有角色。  有效沟通。  保持对故障响应的控制。  与其他相应人员合作解决此事件。IC可以将其角色交给其他人并承担OL角色，或将OL角色分配给其他人。 OL通过应用工具来缓解或解决故障，从而对故障做出响应。虽然IC和OL致力于减轻和解决故障，但CL是故障响应团队的消息通讯核心。 CL的主要职责包括定期向故障响应团队和利益相关者实时更新故障响应的进展。CL和OL都可以领导一个团队来帮助管理他们特定的故障响应区域。这些团队可以根据需要进行扩展或收缩。如果故障变得足够小，那么CL角色就可以被包含到IC角色中。案例研究以下四个大型故障说明故障响应如何在实践中起作用。其中三个案例研究来自Google，最后一个是来自PagerDuty的案例研究，该研究提供了其他组织如何使用ICS派生框架的观点。Google的例子以一个没有有效管理的故障开始，并在有故障管理时对故障响应的改观。案例研究1：软件错误—灯还开着，但没有人(Google HOME)这个例子展示了故障发生初期不进行通报，在没有工具快速有效地响应故障时，团队是如何响应故障的。虽然这一故障在没有重大灾难的情况下得到了解决，但是越早组织，就会产生更好的效果。背景Google Home是一款智能扬声器和家庭助手，可响应语音命令。语音命令与Google Home的软件（称为Google智能助理）进行交互。当用户说出一个触发Google智能助理的热门词组时，就会启动与Google Home的互动。多个用户可以通过培训助理来监听给定的热门词汇，从而使用相同的Google Home设备。识别扬声器的热词模型是在客户端进行的，但是数据（例如扬声器识别文件）存储在服务器上。服务器处理数据的双向流，为了在繁忙的时候处理超载，服务器对Google助手有一个配额政策。为了保护服务器免受过大请求值的影响，配额限制明显高于在给定设备上的Google助手的基准使用量。Google智能助理1.88版中的错误导致扬声器识别文件的获取频率超过预期的50倍，超出此配额。最初，美国中部的GoogleHome用户只有很少的流量损失。然而，随着所有GoogleHome设备的推出逐步增加，用户在2017年6月3日的周末期间丢失了一半的请求。故障太平洋标准时间5月22日星期一上午11:48，谷歌主页on-call开发人员Jasper正在看着每秒查询（QPS）图表并注意到一些奇怪的事情：谷歌助理每隔30分钟就会收到培训数据，而不是像预期的那样每天一次。他停止了已经推到了25％用户的1.88版本发布。他提了一个漏洞——称之为bug 12345——用谷歌的漏洞追踪系统来探索为什么会发生这种情况。在这一问题上，他指出，谷歌助手每天会对数据进行48次的ping请求，导致其超过了QPS的容量。另一位开发人员Melinda将此问题与先前报告的漏洞相关联，我们将其称为错误67890：每当应用程序刷新设备身份验证和注册状态时，语音处理器都会重新启动。该版本将在版本1.88发布后修复，因此该团队要求临时增加模型的配额，以减轻额外查询的过载。版本1.88版本再次启动并继续推出，到5月31日星期三达到50％的用户。不幸的是，该团队后来了解到错误67890，虽然负责一些额外的流量，但并不是Jasper所注意到的更频繁的取回的真正根源。同一天早上，客户开始向Google支持小组报告问题：每当有人说“OK Google”（或任何其他热门词汇来激活Google Home）时，设备都会回复并显示错误消息，此问题阻止用户向Google智能助理发出命令。该团队开始调查可能导致用户报告的错误的原因。他们怀疑配额问题，所以他们要求增加配额，这似乎可以缓解这个问题。与此同时，该团队继续调查bug 12345，看看是什么触发了错误。尽管在调试过程的早期就建立了配额连接，但是客户端和服务器开发人员之间的误解导致了开发人员在故障排除过程中走错了方向，而完整的解决方案仍然无法实现。该团队还对为什么Google智能助理的流量不断达到配额限制感到困惑。客户端和服务器开发人员对客户端错误感到困惑，这些错误似乎没有被服务器端的任何问题触发。开发人员将日志记录添加到下一个版本，以帮助团队更好地理解错误，并希望在解决事件方面取得进展。截至6月1日星期四，用户报告此问题已得到解决。没有报道任何新问题，因此版本1.88版本继续推出。但是，原始问题的根本原因尚未确定。在6月3日的周六早上，版本1.88的发布超过了50%。这一发布是在一个周末进行的，当时开发团队并没有人值班。该团队并没有遵循在工作日期间执行部署的最佳实践，以确保开发人员在场。在6月3日星期六，当版本1.88发布的时候达到了100%，客户端又一次达到了Google助理流量的服务器限制。来自客户的错误报告开始出现。谷歌员工报告称，他们的Google HOME设备出现了错误。Google Home支持小组收到了大量关于此问题的客户来电，反馈也包括了推文和Reddit帖子。 Google Home的帮助论坛也出现了正在讨论这个问题的帖子。尽管有大量的用户报告和反馈，bug并没有升级到更高的优先级。6月4日星期日，随着客户报告数量的不断增加，支持团队最终将错误优先级提升到最高水平。该团队没有通报故障，而是继续通过“常规”方法解决问题—使用bug跟踪系统进行通信。on-call开发人员注意到一个数据中心集群中的错误率，SRE进行了ping操作，要求他们排除它。与此同时，该团队提出了另一项增加配额的请求。之后，开发团队的一名工程师注意到流量通道已将错误推入其他单元格，这为配额问题提供了额外的证据。下午3：33，开发人员团队经理再次增加了Google智能助理的配额，并停止了对用户的影响。故障结束。该团队此后不久确定了根本原因（参见前面的“环境”部分）。总结故障处理的某些方面进展顺利，而其他方面则有改进的余地。首先，工程师在周末处理故障并为解决问题提供了宝贵的意见，这既好又坏，虽然团队重视这些人在周末所付出的时间和精力，但成功的故障管理不应该依赖于个人的英勇行为。如果无法联系到开发人员怎么办？Google鼓励良好的工作与生活平衡——工程师不应在空闲时间内解决与工作相关的问题。相反，我们应该在工作时间进行部署，或者组织一次在工作时间之外提供付费保障的on-call轮换。接下来，该团队致力于缓解这一问题。Google首先要求是阻止故障的影响，然后找到根本原因（除非根本原因只是在早期发现）。一旦问题得到缓解，找到根本原因同样重要，以防止问题再次发生。在这个故障事件中，成功地在三个不同的场合控制了故障影响，但团队只有在发现根本原因后才能防止问题再次发生。在第一次故障得到控制之后，最好是等到根本原因完全确定后再开始实施，避免周末发生大混乱。最后，在问题首次出现时，团队没有通告故障。我们的经验表明，管理故障可以更快地解决。尽早通告故障可确保：  防止客户端和服务器开发人员之间的沟通错误。  根源识别和故障解决发生得更快。  相关团队提前进入，使外部沟通更快捷顺畅。集中式通信是IMAG协议的重要原则。例如，当灾难发生时，SRE通常聚集在一个“作战室”中。作战室可以是像会议室一样的真实环境，也可以是虚拟的：团队可能聚集在IRC频道。这里的关键是将所有的故障响应者集中在一个地方，并实时沟通以管理并最终解决故障。案例研究2：服务故障—如果可以，请对我进行缓存下面的故障说明了当一个“专家级”团队试图调试一个具有复杂交互系统时会发生什么——没有一个人能够掌握所有的细节。背景Kubernetes是一个由许多公司和个人贡献者共同建立的开源容器管理系统。 Google Kubernetes Engine（或称GKE）是Google管理的系统，可为用户创建、托管和运行Kubernetes群集。用户以最适合他们的方式上传和管理工作负载。当用户首次创建新群集时，GKE将获取并初始化其群集所需的Docker镜像。理想情况下，这些组件是在内部获取和构建的，因此我们可以验证它们。但Kubernetes是一个开源系统，新的依赖关系有时会让系统出现问题。故障在太平洋标准时间一个星期四上午6点41分，伦敦GKE的on-call人员Zara寻访了多个区域的CreateCluster探查器故障，新的集群没有被成功地创建。 Zara检查了prober仪表板，发现两个区域的故障率都在60％以上。他确认此问题影响了用户创建新群集的功能，但现有群集的流量未受影响。 Zara遵循GKE的文件化程序，于上午7:06对故障进行了通告。最初，有四人参与处理了这一故障：  Zara是第一个注意到这个问题的人，因此被指定为默认故障指挥官。  Zara的两名队友。  Rohit由故障程序分配的客户支持工程师。由于Rohit总部设在苏黎世，Zara（IC）开设了一个GKE Panic IRC频道，团队可以在那里一起调试。在另外两个SRE深入调查监控和错误信息时，Zara解释了故障及其对Rohit的影响。截至上午7点24分，Rohit向用户发布通知称，创建集群的功能在欧洲西部地区出现故障。这提高了故障的等级。早上7点到8点20分，Zara、Rohit和其他人一直致力于解决这个问题。他们检查了集群启动日志，其中显示了一个错误：无法运行Kubelet；无法创建证书签名——他们需要确定证书创建的哪个部分失败。SRE研究了网络、资源可用性和证书签名过程。所有这些似乎都运作得很好。上午8点22分，Zara向故障管理系统发布了故障调查摘要，并寻找可以帮助他的开发人员。值得庆幸的是，GKE有一位on-call开发人员可以在紧急情况下提供协助。开发人员Victoria加入了该频道。他要求跟踪错误，并要求团队将问题上报给基础架构的on-call团队。现在是上午8点45分，第一个西雅图SRE，II-Seong来到办公室，轻轻地泡了杯咖啡，为这一天做好了准备。 II-Seong是一名资深的SRE，在故障响应方面拥有多年的经验。当他得知正在发生的故障时，他立即进入故障响应频道。首先，II-Seong根据警报的时间检查当天的发布情况，并确定当天的发布不会导致事故障的发生。然后，他开始整理工作文件，收集笔记。他建议Zara将故障升级为基础架构，云网络和计算引擎团队，以尽可能多地消除这些根源。由于Zara升级，其他人加入了故障响应：  GKE节点的开发负责人  云网络值班人员  计算引擎值班人员  Herais，另一个西雅图SRE上午9点10分，故障频道有十几个参与者。故障发生2.5小时，没有找到根本原因，也没有控制住影响。沟通成为了一种挑战。通常情况下，从伦敦到西雅图的on-call交接时间是上午10点，但Zara决定在上午10点之前将故障指挥权移交给II-Seong，因为他对IMAG有更多的经验。作为故障指挥官，II-Seong建立了一个正式的响应组织结构来解决这一事件。然后，他指定Zara为Ops Lead，Herais为通信（Comms）负责人。 Rohit仍然是外部沟通负责人。 Herais立即发送了一封“全体人员齐上阵”的电子邮件给GKE，包括所有开发人员的负责人，并要求专家加入故障响应。到目前为止，故障响应者了解到了以下情况：  当节点试图向主机注册时，集群创建失败。  错误消息表明证书签名模块是罪魁祸首。  欧洲所有集群创建都失败了;其地区都正常。  欧洲没有其他GCP服务出现网络或配额问题。之后，GKE安全团队成员Puanani加入了这项工作。他注意到证书签发者没有开始。证书签发者试图从DockerHub中提取图像，图像似乎已损坏。Victoria（GKE on-call开发人员）在两个地理位置运行了Docker的图像拉取命令。它在欧洲的集群上运行失败，在美国的集群上成功。这表明欧洲集群是问题的所在。上午9点56分，该团队确定了一个看似合理的根本原因。因为DockerHub有一个外部依赖，故障控制和故障溯源将特别具有挑战性。对于Docker的工作人员来说，第一个控制故障的方法是快速修复。第二个选择是重新配置集群，从不同的位置获取图像，例如Google容器注册表（GCR），Goole的安全图像托管系统。所有其他依赖项，包括对图像的其他引用，都位于GCR中。 II-Seong指派负责人追查这两种可能。然后，他委派了一个小组去调查失败的集群。讨论对于IRC来说过于密集，因此详细的调试转移到共享文档，IRC成为决策的中心。对于第二个可能，推送新配置意味着重建二进制文件，这需要大约一个小时。上午10:59，当团队完成90％的重建工作时，他们发现另一个使用错误图像获取路径的位置。作为回应，他们不得不重新启动构建。当IRC的工程师们致力于这两个缓解方案时，SRE中的Tugay有了一个想法。如果他们拦截了Docker的pull请求并使用内部缓存图像替换Docker的响应，那么如何重建配置并将其推出（一个笨重且有风险的过程）呢？ GCR有一个镜像可以做到这一点。 Tugay联系了GCR的SRE团队，他们确认团队可以在Docker配置上设置&lt;–registry-mirror =https://mirror.gcr.io&gt;。Tugay开始设置此功能，并发现镜像已经到位！上午11点29分，Tugay向IRC报告说这些图像是从GCR镜像中拉出来的，而不是DockerHub。上午11点37分，故障指挥官在呼叫GCR值班人员。上午11点59分，GCR值班人员在欧洲存储层清除了腐败的图像。截止到下午12点11分，所有欧洲地区的误差都降至0％。故障结束了。剩下的只是清理工作，故障文档的整理。在修复之前，CreateCluster在欧洲失败了6小时40分钟。在IRC中，整个事件中出现了41个独立用户，IRC日志扩展到26,000个单词。这项工作在不同的时间分拆了七个IMAG工作组，并且在任何时候都有多达四个同时工作。六支on-call队伍的参与，后期包含28个行动项目。总结无论从哪个角度，GKE CreateCluster中断是一件重大故障。让我们探讨一下哪些事情进行得很顺利，哪些事情本可以处理得更好。什么进展顺利？该团队有几个记录在案的升级路径，熟悉故障响应策略。GKE值班人员 Zara很快就证实了这种影响正在影响实际客户。然后，她使用了一个常用的故障管理系统来通知Rohit，Rohit将故障告知客户。什么可以更好地处理？该服务本身有一些值得关注的方面。复杂性和对专家的依赖是有问题的。记录对于故障定位来说是不够的，并且团队因为DockerHub上的变化而分散了注意力，而且这不是真正的问题。故障发生之初，故障指挥官没有制定一个正式的应急预案。虽然Zara承担了这一角色并将对话转移到IRC，但他可以更积极地协调信息和做出决策。结果，少数应急人员在没有协调的情况下进行自己的调查。II-Seong在第一个警报后两小时就建立了正式的故障响应组织。最后，该故障揭示了GKE灾难准备方面的一个不足：该服务没有任何可以减少用户影响的早期通用预案。通用预案是第一响应者采取的降低影响的操作流程，甚至在完全理解根本原因之前都可以使用。例如，当中断与发布周期相关时，响应者可以回滚最近的版本，或者重新配置负载平衡器以避免错误被本地化时出现区域。值得注意的是，通用预案也有弊端，可能会导致其他服务中断。然而，虽然它们可能具有比精确解决方案更广泛的影响，但是当团队发现并解决根本原因时，它们可以快速到位以停止进一步扩大影响。让我们再次查看此故障的时间表，看看通用预案可能在哪些方面有效：  上午7点（评估影响）。 Zara确认用户受到中断的影响。  上午9:56（找到可能的原因）。 Puanani和Victoria确定了一个可能的根本原因。  上午10点59分（定制缓解措施）。几个团队成员致力于重建二进制文件以推送一个新配置，该配置将从不同位置获取图像。  上午11:59（找到根本原因并解决问题）。 Tugay和GCR值班人员取消了GCR缓存，并从其欧洲存储层中清除了损坏的图像。在步骤2（找到可能的原因）之后的通用预案在这里将非常有用。如果响应者在发现问题后将所有发布回滚到已知的良好状态，则故障将在上午10点之前得到缓解。为了缓解故障，不必完全了解详细信息——你只需要知道根本原因的位置即可。能够在完全理解其中断之前缓解中断对于运行具有高可用性的强大服务至关重要。在这种情况下，响应者可以从某种回滚的工具中受益。通用预案工具确实需要时间来开发。创建通用缓解工具的正确时间是在故障发生之前，而不是在应对紧急情况时。浏览postmortems是一种发现缓解故障的好方法，这些缓解故障在回滚过程中非常有用，并将它们构建到服务中，以便在将来更好地管理故障。重要的是要记住，第一响应者必须优先考虑通用预案，否则解决问题的时间还会拉的很长。实施通用预案措施（例如回滚）可加快恢复速度并使客户更快乐。最终，客户并不关心你是否完全理解导致中断的原因。他们想要的是停止接收错误。将控制影响作为首要任务，应以下列方式处理积极故障:  评估故障的影响。  减轻影响。  对故障进行根本原因分析。故障结束后，定位故障的原因并写下事后分析报告。之后，你可以运行故障响应练习演练来修复系统中的漏洞，并且工程师可以在项目中处理这些漏洞。案例研究3：断电—闪电从未发生过两次……直到它发生前面的示例表明，如果没有良好的故障响应策略时，会出现什么问题。下一个示例演示了成功管理的事件。当你遵循一个定义良好且清晰的响应协议时，您甚至可以轻松地处理罕见或异常的事件。背景电网事件（例如雷击）导致进入数据中心设施的电力变化很大。影响电网的雷击是罕见的，但并不出人意料。Google可以使用备用发电机和电池来防止突发的意外断电，这些设备经过了充分的测试，并且已知可以在这些情况下正常工作。Google的许多服务器都有大量的磁盘连接到它们，这些磁盘位于服务器上方或下方的一个单独的托盘上。这些托盘有自己的不间断电源(UPS)电池。当停电发生时，备用发电机会启动，但启动需要几分钟时间。在此期间，连接到服务器和磁盘托盘上的备用电池提供电力，直到备用发电机完全运行，从而防止电网事件影响数据中心的运行。故障2015年年中，比利时谷歌数据中心附近的电网在两分钟内被闪电击中四次。数据中心的备用发电机被激活，为所有的机器供电。当备份发电机启动时，大多数服务器都使用备用电池运行了几分钟。磁盘托盘中的UPS电池并没有在第三次和第四次雷击时将电量用在备用电池上，因为雷击间隔太近了。结果，磁盘托盘失去了电力，直到备用发电机开始工作。这些服务器没有断电，但无法访问那些有电的磁盘。在持久磁盘存储中丢失大量磁盘托盘会导致许多在Google Compute Engine(GCE)上运行的虚拟机(VM)实例出现读写错误。持久磁盘SRE在调用时立即发送了这些错误。一旦持久磁盘SRE团队确定了影响，就会向所有受影响的各方通报故障。持久磁盘SRE on-call人员承担了故障指挥官的角色。经过利益相关者之间的初步调查和沟通，我们确定:  由于临时断电而丢失磁盘托盘的每台机器都需要重新启动。  在等待重新启动时，一些客户VMs在读取和写入磁盘时出现问题。  任何同时具有磁盘托盘和客户vm的主机都不能在不丢失未受影响的客户vm的情况下“重新启动”。持久磁盘SRE请求GCE SRE将未受影响的vm迁移到其他主机。持久磁盘SRE的主要值班人员的保留了IC角色，因为该团队对客户影响的可视性最强。运维团队成员的任务如下:  安全恢复电源，使用电网电源而不是备用发电机。  重新启动所有非vm主机。  协调持久磁盘SRE和GCE SRE，在重新启动之前安全地将vm从受影响的机器移开。前两个目标被清楚地定义、很好地理解和记录。数据中心运维值班人员立即开始安全恢复电源，定期向IC提供状态报告。持久磁盘SRE定义了重新启动所有机器而不是虚拟机的程序。一个团队成员开始重新启动这些机器。第三个目标更加模糊，不包括任何现有的程序。故障指挥员指派了一个专门的行动小组成员与GCE SRE和持久磁盘SRE进行协调。这些团队合作将VMs安全地从受影响的机器移开，以便重新启动受影响的机器。IC密切关注着他们的进展，并意识到这项工作需要快速编写新的工具。IC组织了更多的工程师向运维团队报告，以便他们能够创建必要的工具。沟通负责人观察并询问所有与事件相关的活动，并负责向多个受众报告准确的信息：  公司领导需要关于问题严重程度的信息，并确保问题得到解决。  有存储问题的团队需要知道他们的存储何时可以再次完全可用。  需要主动告知外部客户他们的磁盘在这个云区域的问题。  提交支持票据的特定客户需要知道他们所看到的问题的更多信息，以及关于解决方案和时间安排的建议。在我们减轻了最初的客户影响之后，我们需要做一些后续工作，例如:  诊断为什么磁盘托盘使用的UPS失败，并确保它不会再次发生。  更换发生故障的数据中心的电池。  手动清除由于同时丢失这么多存储系统而导致的“卡住”操作。事后分析显示，只有一小部分未写入磁盘——在事故发生期间断电的机器上的等待写入操作。由于持久磁盘快照和所有云存储数据都存储在多个数据中心中以实现冗余，因此只有0.000001%的运行GCE计算机的数据丢失，并且只有运行实例的数据存在风险。总结通过及早通报故障，并以明确的领导组织结构有效地处理了这个复杂的故障。故障指挥官将恢复电源和重启服务器的正常问题委托给了适当的运维负责人。工程师们致力于解决这个问题，并将他们的进展报告给运维主管。要同时满足GCE和持久磁盘的需求，更复杂的问题需要在多个团队之间进行协调决策和交互。事故指挥员确保从两个小组中指派适当的行动小组成员来处理事故，并直接与他们一起工作，朝着解决问题的方向努力。事故指挥官明智地将注意力集中在事故最重要的方面：尽快解决受影响客户的需求。案例研究4：PagerDuty事件响应  作者：PagerDuty的Arup ChakrabartiPagerDuty在几年的时间里开发并完善了内部故障响应实践。最初，配备了一名常设的全公司故障指挥官，并为每个服务配备专门的工程师参与故障响应。随着PagerDuty发展到超过400名员工和几十个工程团队，故障响应过程也发生了变化。每隔几个月都会仔细检查故障响应流程，并更新它们以反映业务需求。所有的经验总结都记录在https://response.pagerduty.com上。我们的故障响应过程并不是一成不变的；它们就像我们的业务一样不断变化和发展。PagerDuty重大事件响应通常，小的故障只需要一个值班工程师来响应。当涉及到更大的故障时，我们非常重视团队合作。在高压力和高影响的情况下，工程师不应该感到孤独。我们使用以下技巧来促进团队合作：参与模拟演习我们教授团队合作的一个方法是参加“失败星期五”。PagerDuty从Netflix公司的Simian Army(猿人部队)里汲取灵感，制作了这个节目。最初，Failure Friday是一个手动的故障注入练习，目的是了解更多关于我们的系统可能崩溃的方式。今天，我们还使用这个每周练习来重现生产和事件响应场景中的常见问题。在“失败星期五”开始之前，我们提名一个故障指挥官(通常是一个训练成为IC的人)。在进行故障注入练习时，他们应该表现得像真正的IC一样。在整个演练过程中，主题专家使用与实际事件相同的过程和术语。这种做法既使新值班工程师熟悉事故障响应语言和流程，又为经验丰富的值班工程师提供了一种复习。玩限时模拟游戏虽然“失败星期五”练习对工程师在不同角色和过程中培训大有帮助，但它们不能完全复制实际重大事故的紧迫性。我们使用具有时限紧迫性的模拟游戏来捕捉事件响应的这一方面。“继续说下去，没有人会爆炸”是我们大量使用的一款游戏。它要求玩家在限定时间内共同拆除炸弹。游戏的压力和密集的交流性质迫使玩家有效地合作和有效地协同工作。从以往的故障中吸取教训从过去的故障中学习可以帮助我们更好地应对未来的重大故障。为此，我们进行并定期审查故障分析报告。PagerDuty事后调查过程包括开放式会议和全面记录。通过使这些信息易于访问和发现，我们的目标是减少未来事件的解决时间，或防止未来故障一起发生。我们还会记录所有涉及重大故障的电话，这样我们就可以从实时通信feed中学习。让我们看看最近的一个故障，其中PagerDuty不得不利用我们的故障响应流程。故障发生在2017年10月6日，持续时间超过10个小时，但对客户的影响非常小。  下午7:53 PagerDuty SRE团队的一名成员被告知PagerDuty内部NTP服务器正在显示时钟漂移。值班的SRE验证了所有自动恢复操作已经执行，并完成了相关运行手册中的缓解步骤。这个工作记录在SRE团队的专用Slack频道中。  晚上8点20分，PagerDuty软件团队A的一名成员收到了关于他们服务中时钟漂移错误的自动警报。软件团队A和SRE团队致力于解决这个问题。  晚上9点17分，PagerDuty软件团队B的一名成员收到了关于他们服务上时钟漂移错误的自动警报。B组的工程师加入了Slack频道，该频道已经对问题进行了测试和调试  晚上9点49分，值班SRE宣布发生重大故障，并通知值班故障指挥官。  晚上9点55分，IC组建了响应团队，其中包括依赖NTP服务的每个on-call工程师，以及PagerDuty的客户支持。IC让响应小组加入专门的电话会议和Slack频道。在接下来的8个小时里，响应小组致力于解决和减轻这个问题。当我们运行手册中的程序没有解决问题时，响应团队开始有条理地尝试新的恢复选项。在这段时间里，我们每四个小时轮换一次on-call工程师和IC。这样做可以鼓励工程师们休息，并为响应团队带来新的想法。  上午5：33，值班的SRE对NTP服务器进行了配置更改。  上午6点13分，IC与他们各自的值班工程师验证所有的服务都恢复了。验证完成后，IC关闭了电话会议和Slack频道，并宣布故障完成。鉴于NTP服务的广泛影响，有必要进行事后分析。在结束故障之前，IC将事后分析分配给值班的SRE小组。用于故障响应的工具我们的故障响应流程利用了三个主要工具：  PagerDuty。我们将所有值班的信息、服务所有权、事后分析、事件元数据等存储在PagerDuty中。这使我们能够在出现问题时迅速组建正确的团队。  Slack。我们保持一个专门的频道(#incident-war-room)，作为所有主题专家和故障指挥官的聚会场所。该频道主要用作记录员的信息分类，用于捕获操作、所有者和时间戳。  电话会议当被要求加入任何故障响应时，on-call的工程师需要拨打一个固定的会议电话号码。我们希望所有的协调决策都在电话会议中做出，而决策结果都记录在Slack中。我们发现这是做出决策的最快方法。我们还会记录每次通话，以确保我们可以重新创建任何时间轴，以防记录员遗漏了重要的细节。虽然Slack和电话会议是我们的沟通渠道，但你应该使用最适合贵公司及其工程师的沟通方式。在PagerDuty中，我们如何处理响应直接关系到公司的成功。我们不是毫无准备地面对这些故障，而是通过进行模拟练习，回顾以往的故障，选择合适的工具来帮助我们应对可能发生的任何重大事故障，从而有目的地为故障做准备。将最佳实践付诸实践我们见过一些处理得很好的故障的例子，有些则没有。当警报提醒你一个问题的时候，已经来不及考虑如何处理这个故障了。开始考虑故障管理过程的时间是在故障发生之前。那么，在灾难降临之前，你如何准备并将理论付诸实践呢？本节提供了一些建议。故障响应训练我们强烈建议培训应急人员来组织故障，这样他们在真正的紧急情况下就有一个模式可以遵循。知道如何组织一个故障，在整个故障中使用共同的语言，并分享相同的期望，可以减少沟通失误的可能性。完整的故障指挥系统方法可能超出了你的需要，但是你可以通过选择故障管理过程中对你的组织非常重要的部分来开发处理故障的框架。例如:  让接听电话的人知道，他们可以在故障发生时委派和升级。  鼓励采取缓解措施。  定义故障指挥官、通信主管和运维主管角色。你可以调整和总结你的故障响应框架，并创建一个PPT展示给新的团队成员。我们了解到，当人们能够将故障反应理论与实际场景和具体行动联系起来时，他们更容易接受故障响应训练。因此，一定要包括亲身实践的练习，分享过去发生的故障，分析哪些进展顺利，哪些进展不太顺利。还可以考虑使用专门从事事件响应课程和培训的外部机构。事先做好准备除了故障响应训练，它还有助于事先为故障做好准备。使用以下的技巧和策略来做好准备。确定沟通渠道事先决定并同意一个通信渠道(Slack, a phone bridge, IRC, HipChat，等等)——没有事故指挥官想在事故发生时做出这样的决定。练习使用它，这样就不会有意外了。如果可能的话，选择一个团队已经熟悉的沟通渠道，这样团队中的每个人都能舒服地使用它。让利益相关方知情除非你承认某个事件正在发生并且正在被积极处理，否则人们会自动地认为没有采取任何措施来解决这个问题。同样，如果你在问题减轻或解决后忘记取消响应，人们会认为事件正在发生。你可以通过定期更新状态，在事件发生的整个过程中不断通知受众，从而抢占这种动态。准备一份联系人列表(请参阅下一条提示)可以节省宝贵的时间，确保你不会错过任何人。提前考虑如何起草、审查、批准和发布公共博客文章或新闻稿。在Google，团队寻求公关团队的指导。另外，为共享信息准备两三个现成的模板，确保值班的人知道如何发送它们。没有人愿意在没有指导原则的极端压力下写这些公告。这些模板使得与公众共享信息变得简单，压力最小。准备一份联系人列表事先准备好要发邮件或浏览的人的名单可以节省大量的时间和精力。在第180页的“案例研究2：如果可以的话缓存我”中，通讯主管通过发送电子邮件给预先准备好的GKE列表，发出了一个“全体人员待命”的电话。建立故障标准有时很明显，告警问题确实是一个故障。其他时候，情况就不那么清楚了。有一个确定的标准列表来确定一个问题是否确实是一个事件是很有帮助的。一个团队可以通过查看过去的停机情况，并考虑到已知的高风险区域，从而得出一个可靠的标准列表。综上所述，在应对事件时，建立协调和沟通的共同基础是很重要的。确定沟通事件的方式，你的受众是谁，以及在事件中谁负责。这些指南易于制定，对缩短事件的解决时间有很大的影响。演练故障管理过程中的最后一步是实践你的故障管理技能。通过在不太危急的情况下进行练习，你的团队会在闪电袭击时养成良好的习惯和行为模式——无论是比喻意义上还是字面意义上。通过培训介绍了事件响应理论之后，实践可以确保事件响应技能保持新鲜。有几种方法来进行故障管理演练。Google在全公司范围内运行弹性测试(称为灾难恢复测试，或DiRT；请参阅Kripa Krishnan的文章《抵御意外》(Weathering theUnexpected)。在这篇文章中，我们创建了一个可控的紧急情况，实际上并不影响客户。团队对受控的紧急情况做出反应，就好像这是真正的紧急情况一样。随后，各小组回顾了应急反应程序，并讨论了发生了什么。接受失败作为一种学习的方式，在发现的差距中发现价值，让我们的领导参与进来是成功在Google建立DiRT计划的关键。在较小的范围内，我们使用诸如“不幸之轮”(参见“网络可靠性工程中的灾难角色扮演”)等练习来应对特定事件。你还可以通过有意地将次要问题视为需要大规模响应的主要问题来练习事件响应。这可以让你的团队在现实世界中使用低风险的过程和工具进行实践。演练是一个尝试新的故障响应技能的友好方式。团队中任何可能深入到故障响应的人——SREs、开发人员、甚至客户支持和营销合作伙伴——都应该对这些策略感到满意。要进行演练，可以制造中断并允许你的团队对事件进行响应。你还可以从事后分析中制造中断，其中包含大量事件管理演练的想法。尽可能使用真实的工具来管理事件。考虑破坏你的测试环境，以便团队能够使用现有工具执行真正的故障排除。如果这些演习是周期性的，那么它们就会有用得多。你可以通过对每次练习进行跟踪，详细列出哪些做得好，哪些做得不好，以及如何更好地处理事情，来让演练产生影响。进行演练最有价值的部分是检查它们的结果，这可以揭示事件管理中的任何漏洞。一旦你知道了它们是什么，你就可以努力关闭它们。总结当灾难来临时做好准备。如果你的团队定期实践和更新故障响应过程，那么当不可避免的故障发生时，便不会感到恐慌。在故障发生前，你需要与同事合作的圈子会随着事件的规模而扩大。当你和你不认识的人一起工作的时候，流程会帮助你建立你需要的快速解决方案的结构。我们强烈建议在未报警前提前建立这些流程。定期回顾并重复你的事件管理计划和剧本。事故指挥系统是一个简单的概念，很容易理解。它会根据公司的规模和事件的大小进行放大或缩小。虽然理解起来很简单，但实现起来却并不容易，尤其是在突然发生恐慌时。在紧急情况下保持冷静并遵循反应结构需要练习，练习可以建立“肌肉记忆”。这使你对待真正的紧急情况有了信心。我们强烈建议在你的团队繁忙的日程中抽出一些时间，定期实践事件管理。确保得到领导的支持，让他们有专门的实践时间，并确保他们了解事件响应如何工作，以防你需要让他们参与到真正的事件中。备灾可以从响应时间中节省宝贵的时间或数小时，并使你具有竞争优势。没有任何一家公司总是能把事情做好——从错误中吸取教训，继续前进，下次做得更好。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第八章 On-Call]]></title>
      <url>/sre/2020/01/08/On-Call/</url>
      <content type="text"><![CDATA[On-call轮值意味着在某段时间内随叫随到，随时响应紧急问题。站点可靠性工程师（SRE）通常需要参与on-call轮值工作。在on-call轮值期间，SRE需根据需要判断、缓解、修复或升级事件。此外，SRE还需定期响应非紧急生产事件。在Google，on-call轮值是SRE的职责之一。SRE团队可以缓解故障，修复生产环境问题且自动执行运维任务。由于大多数SRE团队的运维任务还未完全实现自动化，升级需要人为联系on-call工程师。SRE团队的on-call工作是根据所支持系统的重要程度或系统所处的开发状态而定的。根据我们的经验，大多数SRE团队都需要参与on-call轮值工作。On-call是一个庞大而复杂的话题，限制因素很多，但是试错率却很少。我们的第一本书《Site Reliability Engineering》第11章“on-call轮值”已经探讨过这一主题。本章介绍一些我们收到的有关该章的反馈和问题。其中包括：  “我们不是Google，我们的规模要小得多。我们没有那么多人参与轮值，并且没有位于不同时区的站点。你在第一本书中描述的内容与我无关。”  “我们的开发人员和DevOps是混合在一起参与on-call轮值的。如何组织是最佳方案？如何分担责任？”  “我们的on-call工程师在24小时轮值中约要处理100个问题。很多问题都被忽略了，而真正重要的问题也淹没其中。我们应该从哪开始处理？”  “我们的on-call轮值周转率很高，如何解决团队内部的认知差距？”  “我们打算将我们的DevOps团队重组为SRE(注1)。”  SRE on-call、DevOps on-call和开发人员on-call的区别是什么？因为DevOps团队非常关注这点，所以请具体说明。我们将为这些问题提供实用的建议。Google是一家拥有成熟SRE组织的大型公司，多年来我们学到的很多东西都可以应用于任何规模和成熟度的公司或者组织中。Google在各种规模的服务上都有数百个on-call轮值人员，从简单到复杂的服务对应着不同的on-call设定。on-call并不专属于SRE：许多开发团队对于他们所负责的服务也需要on-call。每个on-call设定都应满足对应服务的需要。本章介绍Google内部以及其他公司的on-call设定。你的设定和情况可能与我们展示的具体示例不同，但我们所涵盖的基本概念是普遍适用的。在深入研究和分析手机报警负载的原因后，我们提出优化报警信息设置的策略并最大限度的减少负载。最后，我们分享了Google内部实践的两个例子：on-call的灵活性和on-call团队的动态变化。这些实践证明无论on-call设定的数学方法是什么，都不能完全依赖on-call人员的后续处理。需要适当考虑对on-call人员进行激励和人文关怀。回顾第一本SRE书中“On-Call轮值”《站点可靠性工程师》在“On-Call轮值”一章中阐述了Google on-call轮值的基本原则。本节将讨论该章节的重点内容。在Google，on-call的目标是确保不牺牲on-call工程师的健康为前提下覆盖到重点服务，保障服务的可靠性。因此，SRE团队的工作应该是个健康的平衡的职责搭配：on-call和日常项目工作。我们要求SRE团队至少花50%的时间进行工程项目开发，以便战略性的解决生产环境中发现的各种问题。团队人员必须确保有时间参与项目开发工作。为确保有足够时间跟进，每个on-call轮值班次内最多跟进两个故障（注2）。如果报警信息负载过多，需要采取纠正措施。（我们将在本章后面探讨报警信息负载。）注2：不管同一个“问题”发出了多少报警，都被定义为一个“故障”。一个轮值班次是12个小时。安全感（注3）对于on-call的有效轮转至关重要。on-call期间的压力很大，为了减轻on-call人员的压力，调节他们的生活，应该提供一系列清晰的程序和问题升级路线的支持。注3：David Blank-Edelman（O’Reilly）在Seeking SRE一书中有更多关于此主题的内容。针对工作时间之外的on-call工作应给予合理的补贴。不同的公司可能有不同的方式进行补贴。Google提供年假或者现金补贴，同时按一定程度的工资比例作为上限。补贴措施激励SRE按需参与on-call工作，且避免因经济原因而过多的参与on-call工作。Google内部和其他公司的On-Call设定示例本节介绍了Google和Evernote的on-call设置，这是一家致力于帮助个人和团队创建、汇总和共享信息的跨平台应用程序的加利福尼亚公司。我们探讨了每家公司on-call设定、理念以及实践背后的原因。Google：组建新团队初始场景几年前，Google Mountain View（地名：山景城）的SER Sara组建了一个新的SRE团队，该团队需要在三个月内胜任on-call工作。Google的大多数SRE团队默认新员工需要三到九个月时间来准备承担on-call工作。新组建的Mountain View SRE团队将支持三个Google Apps服务，这些服务之前是由位于华盛顿州Kirkland（地名：柯克兰）的SRE团队提供支持的（从Mountain View起飞需要两小时才能到达）。Kirkland团队在伦敦有一个姊妹团队，该团队会继续支持这些服务，以及新组建的Mountain View SRE团队和部分产品开发团队（注4）注4：Google的SRE团队通过跨时区协同工作来确保服务的连续性。新成立的MountainView SRE团队很快聚集了七个人：  Sara，SRE技术主管  Mike，来自另一个SRE团队的具有丰富经验的SRE  从新产品开发团队转岗过来的SRE  四名Nooglers（Nooglers：新员工，特指近期才为Google工作的人）面对新服务的on-call工作，即使是个成熟的团队，也是充满挑战的，而新的Mountain View SRE团队是一个相对初级的团队。尽管如此，新团队做到了在不牺牲服务质量或项目速度的前提下提供服务。他们很快着手改进服务，包括将机器成本降低40%，通过灰度发布和其它安全检查完成自动化发布。新团队持续提供可靠性服务，目标为99.98%的可用性，或每季度约26分钟的停机时间。新的SRE团队是如何通过自我完善来实现该目标的？答案是通过入门项目，指导和培训。培训方案虽然新的SRE团队对他们的服务对象知之甚少，但Sara和Mike对Google的生产环境和SRE工作非常熟悉，且四位Nooglers也通过了公司的招聘，Sara和Mike整理了一份包含二十多个重点领域的清单供组员在on-call之前进行练习，例如：  管理生产作业  了解调试信息  集群流量切换  回滚有问题的版本  阻止或限制恶意请求  提供额外的服务能力  使用监控系统（报警和仪表盘）  了解服务的架构，各种组件以及依赖关系Nooglers(新人)通过研究现有文档和代码（指导，实践编码教程）找到这类信息，并通过研究入门项目来理解相关主题。当团队成员学习到与Nooglers的初学者项目相关的主题时，该成员会召开简短的临时会议，将所学知识分享给其他成员。Sara和Mike会介绍剩余的主题。该团队还进行实践练习，通过执行常见的调试和降损操作帮助成员形成肌肉记忆，增加对自己能力的信心。除了练习清单外，这个新团队还进行了一系列“深度潜水”来深入了解他们的服务。团队浏览了监控控制台，确定正在运行的作业，并尝试修复最近的报警。Sara和Mike解释道，要想做到对每项服务都十分熟悉，工程师并非需要多年的专业知识。他们指导团队也是从这一原则出发，鼓励Nooglers熟悉这些服务。他们每个人理解的知识都是有限的，这会教导成员在何时向别人寻求帮助。在整个成长过程，新团队并不孤单。Sara和Mike前往其它SRE团队和产品开发团队，向他们取经。新团队通过视频会议、邮件和IRC与Kirkland和伦敦团队进行沟通。此外，该团队还参加每周的生产会议，查看on-call轮值表和事后报告，并浏览现有的服务文档。Kirkland团队派来一名SRE与新团队交流解答问题，伦敦的SRE整理了一套完整的灾难情景，并在Google灾难恢复培训期间进行了运行展示（请参阅“站点可靠性工程”第33章“灾难预案与演习”部分）。该小组还通过“幸运之轮”训练演习（见第28章“故障处理分角色演习”一节）如何on-call，扮演各类角色，练习解决生产问题。演习期间，鼓励所有SRE提供解决模拟生产环境故障的建议。在每个人的能力都得到增强之后，团队仍举办这类演习，每个成员轮流担任演习负责人，并且将演习过程记录下来以供未来参考。在进行on-call工作之前，团队查看了有关on-call工程师职责的指导原则。例如：  在每次轮岗开始时，要从上一个on-call工程师那获得轮岗转换邮件。  on-call工程师需要先止损，然后确保完全解决问题。  在轮岗结束时，on-call工程师向待命的on-call发送轮岗转换邮件通知。操作指南规定了问题何时升级到其他人以及如何为大型事件编写事后总结报告。最后，该团队阅读并更新了on-call的操作指南。操作指南中有针对报警的详细说明，解释了报警的严重级别和影响，还有针对完全解除报警的操作意见和需要采取的措施。对于SRE，每当产生报警时，都会创建对应的操作指南记录。这些记录可以减小on-call压力，平均恢复时间（MTTR）以及人为犯错误的风险。   维护操作指南   操作指南中涉及的细节变化与生产环境的变化保持同步。针对日常发布，指南可能需要随着发布时间进行更新。就像任何一种方式的沟通一样，编写一份好的文档是很难的。因此，如何维护好你的操作指南呢？  Google的一些SRE主张操作指南条目要保持通用性，这样迭代的速度就会缓慢些。例如，所有的“RPC Errors High”报警放在一个条目下，经验丰富的on-call工程师可以结合当前报警服务的架构图进行阅读。为了减少人员变更因素影响以及降低MTTR，另有部分SRE主张逐步开放分享操作指南。如果你的团队对指南中的做法另有异议，那么操作指南可能会衍生出多个分支。  这个话题颇具争议。不管你想做成什么样的，但至少你和你的团队要明确操作指南的最小粒度和结构化的细节，并时刻关注操作指南的内容是否累计到超出了最初的设定。在这过程中，要学会将实践获取的知识自动化部署到到监控平台。如果你的操作指南是个明确的由命令组成的列表，当对应的报警触发时，on-call工程师会按照列表执行命令的话，我们建议将其转化为自动化执行。两个月后，Sara，Mike和他们的SRE承担了即将卸任的Kirkland SRE团队的on-call备岗工作。在第三个月，他们成了on-call主岗，Kirkland SRE作为备岗。通过这样的方式，Sara和他的SRE团队随时可以替代Kirkland SRE团队。接下来，Nooglers作为更有经验的SRE成员的备岗加入了轮值工作。丰富的文档和前文所述的各种策略方法都有助于团队形成坚实的基础并迅速获得提升。虽然on-call意味着压力，但团队已经具备足够的信心让他们在采取行动之前不会怀疑自己。即使他们升级事件，他们的反应也是基于团队的集体知识以及自身心理素质，仍然是个称职的on-call工程师。后续虽然MountainView SRE仍在成长，但他们了解到他们在伦敦的姊妹团队将转而负责新的项目，并且在苏黎世成立了一个新团队来负责伦敦团队之前的工作。对于第二次工作交接，Mountain View SRE使用了相同的方法，事实证明也是成功的。MountainView SRE之前准备的入职和培训资料帮助新成立的苏黎世SRE团队获得成功。当一群SRE组成一个新团队时，Mountain View SRE的方法是有效的，但当团队新加入一个成员时，只需要用更轻量级的方法即可。考虑到将来的轮转，SRE绘制了服务架构图，并将基础培训列表正式化为一系列的练习，这些练习无需导师全程参与，可由成员半自主完成。例如描述存储层，执行扩容以及了解HTTP请求过程。Evernote：在云中寻找我们的根将我们的本地基础架构迁移到云如生活中的大多数事情一样，需求是发明之母，因此我们并没有着手重新设计我们的on-call流程。在2016年12月之前，Evernote仅运行在本地数据中心，支持我们的单体式应用程序。我们的网络和服务器在设计时考虑了特定的架构和数据流，结合其他一些约束，意味着我们缺乏支持水平架构所需的灵活性。Google Cloud Platform（GCP）为我们提供了具体的解决方案。但是，仍有一个障碍需要克服：将我们的所有产品和基础设施迁移到GCP。历时70天，通过艰苦卓绝的努力和无数壮举（例如，移动数千台服务器和3.5PB的数据），我们住进了新家。至此，我们的工作仍未完成：我们如何监控，报警，最重要的——如何在新环境应对问题？调整on-call策略和流程应用迁移到云环境激发了我们基础设施快速增长的潜力，减小了我们的基础设施快速增长的阻力，但我们的on-call策略和流程尚未随着这种增长而调整。迁移完成后，我们着手解决问题。在之前的物理数据中心中，我们几乎在每个组件中都创建了冗余。对我们而言，组件故障很常见，但基本上很少有单个组件对用户体验产生负面影响。要知道任何小的抖动都是源于系统的某处故障，而因为我们可以控制它，所以我们的基础设施非常稳定。我们的报警策略是基于以下思路构建的：一些丢弃的数据包，导致JDBC（Java数据库连接）连接异常，意味着VM（虚拟机）主机即将发生故障，或控制面板某一开关一直处于失常。甚至在我们第一天步入云端之前，我们就意识到这种类型的报警/响应系统在未来是不可行的。在实时迁移和网络延迟的世界中，我们需要采用更全面的监控方法。根据第一原则重新构建报警事件，并将这些原则写下来作为明确的SLO（服务级别目标），这有助于团队明确重要信息，从监控基础架构中减少冗余。我们专注更高级别的指标，例如API响应而非类似MySQL中的InnDB行锁等低级别的基础结构，这意味着将更多时间集中在用户在服务中断时遇到的痛点上。对团队而言，也意味着可以减少追踪瞬态问题的时间。相对应的，有了更多的睡眠时间，更高效，工作满意度也更高。重构监控和指标我们的on-call轮值人员是由一个小而充满斗志的工程师团队组成，他们负责生产基础设施和一些业务系统（例如，升级和构建管道基础设施）。每周进行一次轮岗，且在每日的晨会上对之前一天的事故进行复盘。我们的团队规模小，但责任范围大，因此需要努力减轻流程负担，专注于尽快响应报警/报警分类/处理报警/事后分析复盘。我们实现这一目标的方法之一是通过维护简单但有效的报警SLA（服务级别协议）来保持低信噪比。我们将指标或监控基础架构产生的所有故障分成三类：P1：立即处理  需要立即采取行动  呼叫on-call  导致事件分类  是否影响SLOP2：下个工作日处理  通常不面向客户，或范围有限  向团队发送电子邮件并通知事件流向P3：故障仅需知晓  信息收集在仪表盘，自动发送的邮件中等  与容量规划相关的信息所有P1和P2故障都附有故障单，用于描述事件分类，跟踪处理措施，SLO影响，发生的次数和事后报告链接。当出现P1级别的事件时，on-call人员需要评估该事件对用户的影响。从1到3对事件的严重性做分级。对于严重性等级为1（Sev 1）的事件，我们有一套标准流程以便响应人员尽可能快速的做出升级决策。故障升级后，我们会组建一个故障团队开始故障处理流程。由记录员和通讯负责人负责故障通报，沟通渠道是完全开放的。故障解决后，我们会主动进行复盘并在公司内部分享结果。对于级别为Sev 2或Sev 3的故障，on-call人员负责处理故障以及故障的事后报告。保持流程的轻量化有助于参与项目工作的同事胜任on-call工作，鼓励on-call在遇到故障时立即采取修复行动，并在完成故障复盘后发现工具或流程中的不足之处。通过这种方式，在每次on-call轮岗期间都有持续的改进和灵活的循环方式，能和环境的变化速度保持一致。我们的目标是每个on-call轮次都比上一次更好。追踪观察我们的表现随着SLO的引入，我们希望按照时间维度跟踪性能，并将这些信息分享给公司内部的利益相关者。我们举办了月度级别的服务回顾会议，任何有兴趣的人都可以参加，会议主要回顾和讨论上个月份的服务情况。同时通过该会议判断on-call人员的负担，on-call的负担情况是团队健康的晴雨表，在压力过大时我们需要讨论缓解措施。会议的另一目的是在公司内部宣传SLO的重要性，督促技术团队对我们的服务健康和我们的健康负责。与CRE合作合理表达我们在SLO方面的目标是与Google客户可靠性工程（CRE）团队合作的奠定了基础。在与CRE讨论我们的SLO以明确它们是否真实可衡量后，两个团队决定针对会影响SLO的故障，都参与报警接收。隐藏在云抽象层背后的故障根本原因是很难被找到的，Google员工的参与在黑盒事件分类方面给予了帮助。更重要的是，这项举措进一步减小了用户最关心的MTTR。保持自我延续的循环我们现在有更多时间从团队角度思考如何推进业务发展，而不是将所有时间投入到分类/根因分析/事后分析的事情上。例如，改进我们的微服务平台，为我们的产品开发团队建立生产环境标准等项目。后者包括了我们重组on-call时遵循的很多原则，对于团队第一次上战场“接收报警”十分有帮助。因此，我们也延长改善了on-call的循环时间。实际实施细节至此，我们已经讨论了Google和Google以外的on-call设定的细节。但是对于即将参与on-call有哪些具体考虑因素呢？以下部分更深入的讨论了这些实现细节：  报警负载——它是什么，如何工作，如何管理它  如何让on-call时间表更具灵活性，为SRE创造更健康的工作/生活平衡环境  对于特定的SRE团队和合作团队要有动态的团队策略手机报警负载剖析你的手机一直有报警提醒，多到团队都受到了影响。假定你已经阅读了《》Site Reliability Engineering》的第31章，并和你的团队以及所支持的开发团队定期召开生产会议。现在大家都知道你的on-call工程师因为报警负载而不开心。然后呢？手机报警负载的定义是on-call工程师在轮值期间（每天或每周）收到的报警数量。一个故障可能导致多个报警产生。我们将介绍各种影响手机报警负载的因素并提出最小化报警负载的技术。   合适的响应时间   除非有充足的理由，否则工程师无需在收到报警的几分钟内上机器处理问题。虽然面向客户的创收服务故障需要立即响应，但一些不太严重的问题（例如，备份失败），你完全可以在几小时内处理。  我们建议你检查当前的报警设置，判断是否应该为当前触发报警的所有事件提供报警服务。你可能试图采用自动修复来解决问题（相对于人为修复，计算机能更好的解决问题）或者采用工单（如果它不是高优先级）。表8-1显示了一些案例和相对的响应。  表8-1. 实际响应时间案例             故障描述      响应时间      对SRE的影响                  影响盈利的网络中断      5分钟      SRE需要保证手头的电脑有足够的电量且能联网；不能外出；必须始终与备岗协调保持联系。              客户订单处理系统挂了      30分钟      SRE可以出门，短期在外；在此期间，备岗无需保持在线。              用于预发的数据库备份失败      提工单（工作时间处理）      无。      场景：超负荷的团队（假设）负责前端负载均衡和终端用户连接的Connection SRE团队发现自身的报警负载超负荷了。他们已经建立了每次轮值报警事件小于2次的目标，但在过去一年中，他们每次轮值平均接收5次报警事件。分析表明，有三分之一的轮值班次内报警数量超出预设值。团队成员已经及时的响应了报警，但仍然无法解决根因；没有足够的时间找到报警根因并妥善处理解决后续问题。一些工程师离开了团队，加入了运维负担较小的团队。由于on-call工程师的时间只够用来缓解眼前的故障，没法跟踪报警的根本原因。团队的视野是开阔的：拥有遵循SRE最佳实践的成熟的监控系统，遵循SRE最佳时间。报警阈值设置和SLO保持一致，且报警本质上是基于业务表现特征的，意味着仅在客户受到影响时才会触发。高层管理人员在获知这些信息后，认为该团队已经处于超负荷状态，为了让团队恢复健康状态，他们开始审查项目计划。不幸的是，随着时间的推移，Connection团队已经从10多个开发团队中获得了软件组件的所有权，并且对Google面向客户的边缘和骨干网络有着强依赖。群际关系很复杂，也慢慢变得难以管理。尽管团队遵循构建监控的最佳实践方法，但所面临的很多报警都超出了他们的直接控制范围。例如，黑盒探测可能会因网络拥塞而失败，导致数据丢包。团队可以采取的唯一措施就是将事件升级到直接负责该网络的团队。除了运维负担外，团队还需要为前端系统提供新功能，供所有Google服务使用。更糟糕的是，他们的基础架构正在从一个已有10年历史的遗留框架和集群管理系统中迁移到更高的支持替代品中。该团队的服务受到全所未有的变化速度的影响，这些变化本身也引起了大部分的on-call负担。该团队需要各种技术来平衡减少过多的报警负载，团队的技术项目经理和人事经理向高级管理层提交了一份项目建议书，高级管理层审核并通过该建议书。团队全力投入减小报警负载中，在此过程中也获得了宝贵的经验教训。报警负载来源解决报警负载的第一步是明确负载出现的原因。报警负载受到三个主要因素的影响：生产环境中的bug （注5）、报警和人为因素。这些因素都有对应的来源，本节将详细讨论其中一部分来源。注5：文中的“bug”是由软件或配置错误导致的非预期的系统行为。代码中的逻辑错误，二进制文件的错误配置，错误的容量规划，错误配置的负载平衡或新发现的漏洞都是导致报警负载的“生产 bug”的原因。对于生产环境：  生产环境中存在的bug数量  将新bug引入生产环境  识别到新引入的bug的速度  缓解bug并从生产环境中删除之的速度对于报警：  触发报警的阈值  引入新的报警规则  将服务的SLO与其所依赖的服务的SLO关联对齐对于人为因素：  严格的修复和追踪bug  收集报警的数据质量  注意报警负载变化  人为驱动的生产环境变化已经存在的bug。不存在完美的系统。无论是在你的代码里，还是在你依赖的软件和库中，或者是接口之间，产品总会存在bug。虽然这些bug可能并不会立即触发报警，但它们却是客观存在的。你可以利用一些技术来识别或防止尚未导致报警的bug：  确保系统的复杂度和实际相符，并不是越复杂越好。（见第7章）。  利用修复bug的机会，定期更新系统所依赖的软件或库（请参阅下一节有关新bug的部分）。  定期执行破坏性测试或模糊测试（例如，使用Netflix的Chaos Monkey）。  除集成和单元测试外，还执行常规负载测试。新bug。理想情况下，SRE团队及其合作的开发团队应该在新bug进入生产环境之前检测到。事实上自动化测试漏测了很多bug，这些bug最终进入了生产环境。软件测试是个覆盖面很广的主题（例如，Martin Fowler on Testing）。这项技术在减少进入生产环境的bug数量以及减少bug在生产环境停留的时间方面很有帮助：  随着时间推移不断改进测试（方法、技术）。尤其是你在生产环境中每发现一个bug，都要自问“如何才能在预发环境检测到这个bug？”确保有必要的工程技术跟进解决此问题。（请参阅“严谨跟踪”，第164页）。  不要忽略负载测试，虽然负载测试的优先级常被视为低于功能测试的。但许多bug仅在特定的负载条件下或特定的请求组合中才会显露出来。  在生产环境中集成（使用类似生产环境但是是合成的流量进行测试）。我们将在本书的第5章简要讨论生成合成流量。  在生产环境执行canarying（第16章）。  对新bug保持较低的容忍度。遵循“检测，回滚，修复和发布”策略，而不是“检测，虽然找到bug，但继续发布，修复并再次发布”策略。（相关详细信息，请参阅第162页的“减少延迟”。）这种回滚策略需要可预测且频繁发布，因此回滚任何版本的成本都很小。我们在《Site Reliability Engineering》一书“发布工程”章节中讨论了相关主题。一些bug可能仅仅是由于改变客户端行为导致的。例如：  仅在特定负载水平下出现的bug——例如，9月返校流量，黑色星期五，网络星期一，或一年中夏令时即欧洲和北美时差一小时的那一周，意味着更多用户同时保持清醒和在线状态。  只有特定混合请求才显示的bug——例如，用于亚洲字符集的语言编码，更接近亚洲的服务器的流量消耗更大。  仅在用户以意想不到的方式运行系统时才会显示的bug——例如，（在）航空公司订票系统使用的日期（下运行系统）！因此，为了测试能够覆盖到不常发生的行为（导致的bug），扩展您的测试方案是十分必要的。当生产系统受到多个并发错误的影响时，判断报警是由于现有bug还是新bug引起的是很困难的。最大限度的减少生产环境中的bug不仅可以减少报警负载，还对新bug的识别和分类很有帮助。因此。尽快从系统中删除生产环境的bug至关重要，修复现有bug的优先级应该在开发新功能之上；如果过程中需要跨团队合作，请参阅第18章。架构或程序问题，例如自动健康检查，自我修复和减小负载，可能需要大量的工程工作来解决。为简单起见，我们将这些问题视为“bug”，即使它们的规模、复杂度或解决它们需要的工作量很大。《SiteReliability Engineering》中第3章描述了错误预算如何控制新bug发布到生产环境的方法。例如，当服务的SLO超过其总季度错误预算的某一部分时——事先在开发人员和SRE团队间达成一致意见——可以暂停新功能开发以及和功能相关的部署，以专注于系统稳定，减少报警的频率。示例中的Connection团队采用严格的策略，要求每次故障都需要追踪bug。该举措能让团队的技术项目经理知道产生新bug的根本原因在哪。数据显示，人为错误是生产环境中新bug产生的第二大常见原因。由于人类容易出错，如果对生产系统所做的所有变更都是通过（人为开发的）配置自动生成的，那么效果会更好。在对生产环境进行变更之前，自动化手段可以执行人类无法进行的测试。Connection团队是半手工的对生产环境进行复杂的变更的。毫无疑问，团队的手动变更有时会出错；该团队引入了触发报警的新bug。在新bug进入生产系统并触发报警前，将要做出类似变更的自动化系统就会判断出这种变更是不安全。技术项目经理将这些数据提供给团队，说服他们优先考虑进行自动化项目。识别延迟。及时识别报警的原因十分重要，这个识别的时间越长，意味着报警再次产生的几率越大。例如，有一个仅在高负载情况下才会产生的报警，如果在下一个峰值之前未识别有问题的代码或配置，那么问题可能会再次发生。你可以用这些技术来减少报警识别时间：使用合理有效的报警和控制台确保报警页面链接到相关的监控控制台，且该控制台突出显示系统运行超出规范的位置。在控制台中，将黑盒和白盒监控报警相关联，并对关联的图表执行相同的操作。确保操作指南是最新的，提供相应每种报警类型的行动建议。on-call工程师应在相应的报警触发时用最新信息更新操作指南。实践应急响应进行“幸运之轮”练习（在《Site Reliability Engineering》中有描述），和同事共享常用的和针对特定服务的调试技术。执行小变更如果您频繁执行局部（部分功能、部分模块）的变更而不是偶尔的整体（所有功能、所有模块）变更，那么能很容易的将bug与引入它们对应的变更相关联。第16章中描述的Canarying版本给出了一个判断，表明新bug是否是由于新版本引起的。日志变更将变更信息聚合到可搜索的时间线中可以更简单（且更快）的将新bug与引入它们的变更相关联。Jenkins的Slack插件可能会有所帮助。寻求帮助在《SiteReliability Engineering》“故障管理”中，我们讨论了共同管理大型故障的问题。on-call工程师从来不会只是一个人；要让你的团队在寻求帮助时有安全感。减少延误。一旦找到bug，修复bug所需的时间越长，就越可能再次发生问题并产生报警。可以考虑这些减少延误的技术：回滚变更  如果bug是在一次最近的代码、配置变更中引入的，在安全和恰当的情况下（单独回滚代码、配置可能是必要的，但如果bug是因为数据损坏导致的，那只回滚代码、配置就不能解决问题了）我们可以通过立即回滚生产环境的变更消除bug。谨记，即使是“快速修复”也需要时间进行验证，构建和发布。验证是至关重要的，要确保“快速修复”确实可以修复bug，并且不会引入额外的bug或其他非预期的影响。通常，采取“回滚，修复和发布”要优于“发布，修复和再发布”操作。  如果你的目标是99.99%的可用性，那么每季度约有15分钟的错误预算时间。上线发布的构建步骤可能需要15分钟以上，因此回滚对用户的影响更小。（99.999%的可用性对应每季度80秒的错误预算，这样的系统可能需要自我修复的属性，超出了本章的讨论范围。）  如果可能，避免接入无法回滚的变更，例如API不兼容的变更和锁步版本。使用功能隔离  设计你的系统，以便在功能X出错时，可以通过一个功能标志禁用它，而不影响功能Y。该策略还能提高发布速率让禁用X功能变得简单——且不需知道产品经理是否习惯于禁用功能。切走请求流量  把请求流量从出现bug的系统组件中切走（即重定向客户请求）。例如，如果bug是代码或配置上线导致的，并且是逐步发布到生产环境中的，那么你还有机会通过把流量从已发生变更的基础架构的元素切走（达到快速止损的目的）。这样你可以在几秒钟内降低对客户的影响，但回滚可能需要几分钟或更长时间。报警。Google SRE每次轮值时间即12小时最多发生两次不同的报警事件，因此我们对如何配置报警以及如何引入新的报警是经过深思熟虑的。网站可靠性工程“监控分布式系统”描述了Google定义报警阈值的方法。严格遵守这些准则有助于健康的on-call轮转。需要强调一下，这章讨论了一些关键元素：  收到的所有报警都应该立即去操作。我们希望团队在收到系统无法自愈的报警后立刻采取行动。信噪比要高，确保较低的误报率；低信噪比会增加on-call工程师产生“狼来了”的感觉的几率。  如果团队的报警规则是基于SLO，或错误上限（请参阅站点可靠性工程中的“黑盒监控与白盒监控”部分），那么所有参与开发和维护站点可靠性的团队都需要认同SLO的重要性并明确他们的工作优先级。  如果团队完全基于SLO和现象制订报警策略，那么放宽报警阈值是对报警的合理调整。  就像新的代码，新的报警策略也应该经过彻底和周密的审查，每条报警都应该有对应的操作指南条目。接收报警会对人产生负面的心理影响。为了最大限度的减少这类影响，最好只有在真正需要时才引入新的报警规则。团队中任何人都可以编写新的报警策略，但新的策略需要经过整个团队的审核建议以及提出替代方案。在将新策略发布到线上之前，要彻底测试生产中的新策略来审查是否有误报。例如，可以在报警触发时给作者发送电子邮件，而不是直接呼叫on-call工程师。新的报警信息会帮你发现之前并不知道的生产环境问题。在解决了这些bug之后，报警将仅被新bug触发，也起到了回归测试的作用。确保新报警在测试环境下运行的时间足够长，能适应典型的生产环境，例如常规软件部署，云提供商的维护需求，每周负载峰值等。通常一周的测试时间是足够的，但具体时间窗口仍取决于报警和系统。最后，利用测试期间报警的触发率预测新报警可能会产生的报警负担。对新报警配置的批准或禁止要以团队为单位。如果引入新报警会导致你的服务超出报警阈值，那么需要额外注意系统的稳定性。事后密切跟进。目的是确定每个报警的根本原因。查找“根因”的范围要从机器层面延伸到团队流程层面。服务中断是由一个本可以通过单元测试发现的bug导致的吗？根因可能不是代码中的bug，而是代码审查中团队流程的bug。如果你知道根因，你就可以修复它防止再次困扰你或你的同事。如果你的团队无法确定根本原因，可以添加监控或日志记录，帮助在下次发生这种情况时找到报警的根本原因。如果没有足够的信息来识别bug，你可以做一些事情来帮助进一步调试bug。或者至少可以得出结论，即报警是由“未知原因”触发的。请牢记，身为on-call工程师，你永远不是孤军奋战，所以可以请同事帮忙检查你的发现，看看是否有遗漏的地方。通常，报警触发后有新的证据可用时，很快能找到报警的根本原因。将一个报警解释为“瞬态的”或由于系统“自行修复”或莫名其妙“消失”而不采取任何行动时，这个报警很可能会再次发生并导致另一个报警，会给下一下on-call工程师带来麻烦。简单修复眼前的bug（或进行一个“点”修复）错过了一个避免将来出现类似报警的黄金机会。把报警信息看作一个带来工程工作的机会，这种工程工作可以改进系统并且消除可能出现的一类bug。可以在你的团队的生产组件中归档项目bug来做到这一点，我们提倡通过收集这个项目会消除的bug以及报警数量，按轻重缓急进行bug修复。如果你的提案需要3个工作周或120个工作时来实施，并且报警平均需要4个工作时才能正确处理，那么30个报警产生后会有一个明确的盈亏平衡点。举个例子，假设有这样一种情况，在同一故障域上存在很多服务器，例如这些机器在数据中心中的同一个交换机下，会导致定期同时发生多个机器的故障。点修复在众多故障域中重新平衡当前的覆盖区。系统修复使用自动化手段确保此类服务器和所有其他类似服务器始终分布在足够的故障域中，并在必要时自动重新平衡。监控（或预防）修复当故障域多样性低于预期水平但尚未影响服务时，预先发出警告。理想情况下，警报将是故障工单警报，而不是呼叫报警，因为不需要立即响应。尽管处于较低的冗余水平，该系统仍可以进行服务。为确保您对寻呼警报的后续工作有所了解，请考虑以下问题：  如何防止此特定bug再次发生？  对于此系统和我负责的其他系统，如何防止此类bug再次发生？  哪些测试可以防止此bug被发布到生产环境中？  哪些故障工单警报会触发操作以防止bug在被报警前变的严重？  在变得严重之前，哪些报警信息会出现在控制台上？  我是否最大化了修复bug带来的收益？当然，对于on-call工程师，仅仅提交值班期间发生的呼叫报警相关的bug是不够的。重要的是，SRE团队会迅速处理他们确定的bug以减少它们再次发生的可能性。要确保SRE和开发人员团队的资源规划考虑了响应bug所需的工作量。我们建议保留一小部分SRE和开发人员团队的时间来响应出现的生产bug。例如，Google on-call工程师通常不会在轮值期间处理项目工作。相反，他们处理可以改善系统健康状况的bug。确保你的团队常规下处理生产环境bug的优先级高于其他项目工作。SRE经理和技术主管应确保及时处理生产环境bug，必要时要升级到开发人员团队决策者。当电话报警严重到需要事后调查时，遵循此方法来安排和跟踪后续行动更为重要。（有关详细信息，请参阅第10章。）数据质量。一旦识别出系统中导致报警的bug，就会出现一些问题：  如何明确先修复那个bug？  如何得知系统中哪个组件导致大多数报警？  如何确定on-call工程师为解决这些报警而采取的重复性手动操作？  如何判断有多少报警仍有未识别的根本原因？  如何得知哪些bug是真实存在的、最严重的，而不是未确定的？答案很简单：收集数据！你可能会通过跟踪和收集on-call负载的方式来收集数据，但这种方法是有局限性的。更加可持续的做法是，为你的bug跟踪系统（例如，Jira，Issue-Tracker）中的每个电话报警提交一个bug，当on-call工程师意识到每个报警都是已存在的bug的表征时，需要在监控系统的相关报警和相关bug间建立链接。你将在一列中找到尚未解决的bug列表，以及每个相关联bug的页面列表。当你拥有有关报警原因的结构化数据，就可以着手分析数据生成报告，这些报告能够回答以下问题：  哪些bug导致大多数的报警？理想情况下，我们会立即回滚并修复bug，但有时候，查找根本原因并部署修复程序需要很长时间，有时忽略关键报警并不是一个合理的选择。例如，上述Connection SRE团队可能会遇到持续的网络拥塞，这种拥塞无法立即解决，但仍需要跟踪问题。为团队收集导致了最多的报警和压力的生产环境问题的数据，支持进行数据驱动的有系统的、有优先级的对话。  系统的哪个组成部分是大多数报警的原因（支付网关，身份验证微服务等）？  与其他监控数据相关联时，特定报警是否与其他信号相对应（请求量高峰，并发客户会话数，注册次数，提款次数等）？将bug数据和报警根本原因数据结构化还有其他好处：  你可以自动填充现有bug列表（即已知bug），这对你所支持的团队可能有益处。  你可以根据每个bug导致的报警数确定bug的优先级。你所收集的数据质量将决定人工或机器可以做出的决策质量。为了确保高质量的数据，请考虑以下技术：  定义并记录你的团队对报警数据收集的策略和预期。  设置来自监控系统的非呼叫报警，突出显示未处理报警的位置。经理和技术主管应确保达到预期。  当轮岗交接不符合预期时，队友应该相互帮助跟进。积极的评论有“也许跟bug123有关”，“我已经根据你的调查结果提交了bug报告，所以我们可以进一步跟进了”，或“这看起来像我上周三轮岗发生的事情：&lt;报警，bug的链接&gt;”强化预期行为，确保最大化的改进。没人愿意为上一轮岗就已发生的报警再接收一次报警。警觉。很多时候，团队会因为多次减员而陷入运维过载中。为了避免温水煮青蛙，要注意on-call工程师的健康状况，确保SRE和开发团队始终优先考虑生产环境健康状况。以下技术可以帮助团队密切关注报警呼叫负载：  在生产会议上（参见“站点可靠性工程”中的“沟通：生产会议”一节，第31章），定期根据收集的结构化数据分析报警呼叫负载的趋势。追踪21天的平均值非常有用。  当呼叫报警负载超过你的团队事先明确的“告警”阈值时，设置针对技术主管或经理的故障单报警。  在SRE团队和开发团队之间定期召开会议，讨论当前的生产状况以及当前SRE为解决的生产环境bug。on-call灵活性   值班时长   on-call值班期间每天需要处理一个或几个报警，因此值班安排必须是合理可持续的：我们建议将时长限制为12小时。较短的值班时长对on-call工程师的健康是有利的。当在岗时间太长时，团队成员大概率会觉得疲惫，随之而来的是他们在工作中可能会犯错误。如果一直进行on-call工作，大多数人无法保持高质量的产出。许多国家都有关于最长工作时间，休息时间和工作条件的法律。  虽然理想情况下是一直在白天值班，但12小时轮岗制也并不需要全球分布的团队。整夜12小时处于on-call中比on-call24小时或更长时间更好。即使工作在一个地方，你也可以进行12小时轮岗值班。例如，在为期一周的班次中，不是让一名工程师每天24小时on-call，而是两名工程师一人在白天on-call，一人在夜间on-call。  根据我们的经验，如果没有缓解机制，24小时on-call是不可持续的。虽然不理想，但偶尔on-call一整夜至少可以确保你的工程师的休息时间。另一个选择是缩短值班时间——比如3天值班，4天休息。情景：个人情况的变化想象一下，你是一个大型服务的on-call团队成员，该服务具有跨越两个站点的24/7跟随太阳模型。为了在提高服务可靠性的同时保持运维负载的可控性，虽然你并不乐意在上午6点可能会接到报警，但你对你和团队正在进行的工作感到满意。一切都很好…直到某天你才意识到on-call的时间表和你个人生活的需求开始发生冲突。有许多潜在的原因——例如，成为父母，需要短期旅行，休假或生病。你需要on-call的职责和新的个人日程表能够共存。许多团队和组织在成熟时都面临这一挑战。随着时间推移，人们的需求发生变化，为了保持多元化团队成员的健康平衡，on-call轮值的需求变的多样化。保持健康，公平以及on-call工作和个人生活健康的平衡的关键在于灵活性。为满足团队成员的需求，确保覆盖到你的服务或产品，你可以通过多种方式灵活的进行on-call轮转。指定一套全面的，一刀切的指导方针是不可能的。我们鼓励将灵活性作为一项原则，而不是简单的采用此处列举的实例。自动化on-call时间安排。随着团队的发展，时间表的安排受到以下约束——休假计划，on-call工作日与周末的分布，个人偏好，宗教要求等，时间表的安排变得越来越困难。你无法手动管理此任务，很难找到任何解决方案，更不用说公平的解决方案了。“公平”并不意味着跨团队成员的每个变化都是一致的。不同的人有不同的需求和不同的偏好。因此，团队应该分享这些偏好并尝试以智能的方式满足这些偏好。团队组成和首选项决定了你的团队是更喜欢统一分发，还是以自定义的方式来满足日程安排首选项。使用自动化工具来安排on-call班次会更容易。这个自动化工具应该有这些基本特征：  它应该重新安排on-call班次以适应团队成员不断变化的需求。  它应该自动重新平衡报警负载以响应任何更改。  应该尽量通过考虑个人偏好来确保公平，例如“4月份周末不用上学”，以及历史信息，例如最近每位on-call的值班负载。  因此，on-call工程师可以依据on-call班次进行计划，但绝不能改变已经生成的时间表。时间表既可以是完全自动化的，也可以是团队人员安排。同时，一些团队更愿意让成员明确遵守时间表，而其他团队则对完全自动化的流程感到满意。如果你的需求很复杂，可以选择在内部开发自己的工具，此外也有许多商业和开源软件包可以帮助自动化生产on-call时间表。短期互换的计划。on-call时间表通常会收到的短期变化请求。没人能在周一就承诺周四肯定不会感冒。或者你可能需要在on-call期间处理无法预料的紧急事务。你可能还希望因为非常规原因能够在on-call中换岗——例如，允许on-call人员参加运动训练课程。在这种情况下，团队成员可以交换一天的on-call日（例如，周日的一半）。非竞争性的互换通常是更好的选择。具有严格报警响应SLO的团队需要考虑通勤时间。如果你的报警响应SLO为5分组，而你的通勤时间为30，那么要确保其他人在你上班途中能处理紧急情况。为了在灵活性方面实现这些目标，我们建议给予团队成员权利更新on-call轮值表。此外，有一个记录下来的策略描述转换如何操作。权利下放的策略包括只有经理可以改变的完全集中的政策，到任何成员都可以改变的完全分散的政策。根据我们的经验，对变更进行同行评审可以在安全性和灵活性之间进行良好的权衡。长期休息的计划。由于个人情况或职业倦怠的变化，有时团队成员需要停止on-call工作。团队的结构应该能够允许on-call人员暂时不参与值班。理想情况下，团队规模应该满足在（临时）员工减少时其他成员能够承受增加的运维负担。根据我们的经验，每个站点至少需要五个人进行多站点全天候的on-call，至少需要8个人进行单站点全天候的on-call。因此，假设每个站点需要一名额外的工程师来防止人员减少，每个站点（多站点）最多需要6名工程师，每个站点（单站点）为9名。兼职工作的时间表计划。on-call工作的时间表看起来是不兼容的，但我们发现如果你采取某些预防措施，on-call工作和兼职工作是能够做到兼容的。以下讨论假设你的on-call成员是兼职工作，他们无法在兼职工作周之外完成值班工作。兼职工作主要有两种模式：  每周工作减少一天——例如，每周工作4天，而非5天  每天减少工作时间——例如，每天工作6小时，而非8小时两种模式都可以兼容on-call工作，但需要对on-call时间进行调整。如果非工作日是一直不变的，那么第一个模式很容易和on-call工作兼容。对应的，你可以采用每周少于7天的on-call时间（例如，周一至周四，或周五至周日），并自动调整时间表以便在兼职工程师非工作时间不会参与on-call工作。第二种模式可以通过以下几种方式实现：  与另一名工程师分担on-call时间，这样当兼职工程师不在时，仍然有人值班。例如，如果on-call工程师需要从上午9点工作到下午4点，你可以将值班的前半部分（上午9点到下午3点）分配给他们，后半部分（下午3点到晚上9点）可以以相同的方式分配给其他on-call成员。  如果on-call频率不是太高，兼职工程师可以在on-call日工作整整几个小时也是可行的。如站点可靠性工程的第11章所述，根据当地劳动法和法规，Google SRE会在正常工作时间之外补偿小时工资或休假时间。在确定on-call补偿时，要考虑兼职工程师的时间表。为了平衡项目时间和on-call时间，工作时间较少的工程师对应的工作内容应该少点。与小型团队相比，较大的团队更容易吸收额外的on-call负载。on-call团队动态我们的第一本书谈到了高报警负载和时间压力等压力因素是如何迫使on-call工程师采用基于直觉的未经详细考虑而非基于理性和数据的决策策略（参加该书第11章“安全感”一节）。基于团队心理学的讨论，你如何建立一个积极的动态团队？考虑一个on-call团队，其中包含以下一组假设问题。情景：“一周生存”的文化一家公司从几位创始人和少数员工开始，他们都是开发人员，每个人都相互了解，每个人都需要接收报警。公司规模开始变大。on-call的职责仅限于一小部分更有经验的功能开发人员，因为他们更了解系统。公司变得更大。他们增加了ops角色来解决可靠性问题。该团队负责生产环境监控，成员主要集中在运维，而非编码。功能开发人员和ops人员轮流进行on-call工作。功能开发人员在维护服务方面有最终决定权，而ops仅限于运维任务。到目前为止，有30名工程师参与on-call工作：25名功能开发人员和5名ops，都位于同一站点。团队被高报警量所困扰，尽管遵循了本章前面所述的建议，尽量减少报警负载，但团队的士气仍然很低落。由于功能开发人员优先考虑开发新功能，因此on-call的后续工作需要很长时间才能实现。更糟糕的是，由于功能开发人员关注的是自己子系统的健康状况，尽管团队中其他人提出了投诉，但有位功能开发人员坚持按错误率而非关键模块错误比率来进行报警。这些报警很嘈杂，会有很多误报或者不可执行的报警。高报警负载对on-call岗的其他成员的影响不会特别大，确实有许多报警，但大多数报警都没有花太多时间来解决。正如一名on-call工程师所说：“我快速浏览一下报警主题，知道它们是重复的。所以我要做的就是忽略它们。”听起来很熟悉？Google的一些团队在成熟的早期阶段遇到过类似问题。如果不小心处理，这些问题可能扰乱功能开发团队和运维团队，并阻碍on-call的操作。没有灵丹妙药能解决这些问题，但我们发现了一些特别有用的方法。虽然你的方法可能有所不同，但总体目标应该是相同的：建立积极的团队氛围，避免混乱。建议一：给你的ops工程师授权。你可以根据本书和站点可靠性工程中列出的指南对运维组织进行重新构建，甚至可以更改名称（SRE或类似名称）来表示角色的更改。重新命名你的运维组织并非灵丹妙药，但它有助于体现别于旧的以操作为中心的模型的新的责任变化。向团队和整个公司明确说明SRE拥有站点操作权限，包括定义可靠性的共享路线图，推动问题的全面解决，维护监控策略等。功能开发人员是必要的协作者，但没有这些权限。回到我们之前假设的团队，本公告引入了以下运维变化：  操作项仅分配给5个DevOps工程师——即SRE。SRE与项目专家合作——大多为开发人员——来完成这些任务。SRE就前面提到的：“错误率与错误比例”的报警策略与功能开发人员进行协商。  如果可能，鼓励SRE深入研究代码以自行进行更改。他们将代码审查发送给项目专家。这样有利于在SRE之间建立主人翁意识，并在未来的场合提升他们的技能和权威。通过这种安排，功能开发人员是可靠性功能的明确协作者，且SRE有权利拥有站点以及改进站点的责任。建议二：改善团队关系。另一种可能的解决方案是建立更强有力的团队关系。Google设置了一个“有趣的预算”，专门用于组织异地活动来加强团队合作。我们发现，强大的团队关系可以增强团队成员之间的理解和协作精神。因此，工程师修复bug，完成操作项目并且帮助同事的几率更高。例如，假设你关闭了夜间管道工作，但忘记关闭检查管道是否成功运行的监控。结果，同事在凌晨3点收到了报警。如果你和那位同事为处理报警花了点时间，你对这件事感到很抱歉，并在将来对此类操作更加小心。“我要保护我的同事”这一心态会转化成为更富有成效的工作氛围。我们还发现，无论职称和职能如何，让on-call的所有成员坐在一起，有助于改善团队关系。还可以鼓励团队一起吃午饭，不要低估这些相对简单的变化，它会直接影响团队动力。结论SRE on-call与传统的ops角色不同。SRE不仅专注于日常运维，且拥有生产环境权限，并通过定义适当的可靠性阈值，开发自动化工具以及开展战略工程项目来获得更好的生产环境。on-call的站点操作十分重要，公司必须正确处理。on-call是个人和集体压力的根源。但如果你盯着怪物的眼睛看久了，就会发现智慧。本章阐述了一些关于on-call的案例；希望我们的经验可以帮助他人避免或解决类似的问题。如果你的on-call团队淹没在无休止的报警中，我们建议你退一步观察更顶层的情况，和其他SRE和合作伙伴团队对比讨论，一旦收集了必要的信息，就要系统的解决问题。对on-call工程师，on-call团队以及整个公司来说，构建合理的on-call机制是值得投入时间的。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第七章 简单化]]></title>
      <url>/sre/2020/01/07/%E7%AE%80%E5%8D%95%E5%8C%96/</url>
      <content type="text"><![CDATA[简单化是SRE的重要目标，因为它与可靠性密切相关：简单的软件很少出现故障，在故障发生时更容易且迅速地修复。简单的系统更易于理解、维护以及测试。对于SRE而言，简单化是一个端到端的目标：它应该超越代码本身，延伸到系统架构以及用于管理软件生命周期的工具和流程中。本章探讨了一些样例，这些样例展示了SRE是如何衡量、思考和鼓励简单化的。衡量复杂度衡量软件系统的复杂度并不是一门绝对的科学。有许多方法可以衡量软件代码的复杂性，大多数是非常客观的。最著名且使用最广泛的衡量标准应该是代码圈复杂度，它通过一组特定的语句来衡量不同代码路径的数量。例如，没有循环或条件语句的代码块的圈复杂度（CCN）为1。其实软件社区很擅长测量代码复杂度，并且有许多用于集成开发环境的测量工具（包括Visual Studio，Eclipse和IntelliJ）。我们无法判断所得到的测量复杂度是必然还是偶然的，一种方法的复杂度是如何影响到系统的，以及哪种方法更适合重构。另一方面，衡量系统复杂性的正式的方法很少见。你可能尝试使用类似CCN的方法来计算不同实体（例如，微服务）的数量以及它们之间可能存在的通信路径。但是，对于大多数较大规模的系统而言，这个数字的增幅十分迅速。针对系统级复杂度，有一些更实用的替代度量方法：训练时长新成员多久能参与on-call工作？糟糕的或缺失的文档可能是主观复杂性的重要来源。解释时长向团队新成员解释服务的全面高级视图需要多久（例如，在白板上绘制系统架构图并解释各个组件的功能和依赖关系）？管理多样性有多少种方法可以在系统的不同部分配置类似的设置？配置是集中存储在一个位置还是存储在多个位置？部署配置的多样性生产过程中部署了多少唯一的配置（包括二进制文件、二进制版本、标志和环境）？年龄系统使用多久了？Hyrum定律指出，随着时间的推移，API的用户依赖于它实现的每个方面，导致了脆弱和不可预测的行为。虽然测量复杂度有时是有价值的，但过程很困难。然而以下这些结论是没有争议的：  一般而言，除非付出努力补偿，否则现存的软件系统的复杂度将会随时间增加。  付出这样的努力是值得的。简单化是端到端的，并且SRE会获益于此通常，生产系统不是通过整体的方式设计的；相反，它们是有机地生长。随着团队添加新特性和推出新产品，它们会逐渐积累组件和连接。虽然单个变更可能相对简单，但每个变更都会影响周围的组件。因此，整体复杂度很快就会超出控制。例如，在一个组件中添加重试可能会使数据库过载并使整个系统不稳定，或者使对给定查询在系统中遵循的路径进行推理变得更加困难。一般而言，复杂度带来的成本并不直接影响引入它的个人、团队或从经济角度来看的任何角色，复杂度是一种外部特性。相反，复杂性会影响那些继续在其中和周围工作的人。因此，有个拥护端到端系统简单化的支持者十分重要。SRE非常适合这个角色，因为他们的工作需要他们将系统作为一个整体来对待。除了维护自己的服务，SRE还必须深入了解与服务有交互的系统。Google的产品开发团队通常无法查看生产范围内的问题，因此他们可以通过咨询SRE来获取系统设计和运营的相关建议。（一般说明）读者操作：在工程师第一次加入on-call工作之前，鼓励他们绘制（或重绘）系统架构图。可以在你的文档中保留一组规范的图表：不仅对新加入的工程师非常有帮助，还可以帮助更多有经验的工程师随时跟上系统的变更。根据我们的经验，通常产品开发人员的工作局限在子系统或组件中。因此，他们没有形成针对整个系统的思维模式，所在的团队也没有制作系统级别的架构图。系统架构图的价值在于可以将系统交互可视化地呈现给成员，并且帮助成员使用常用词汇来阐明问题。通常，SRE团队都绘制了所有服务的系统级架构图。（一般说明）读者操作：SRE要检查所有重要的设计文档，且团队文档中需要说明新设计会如何影响系统结构。如果一个设计会增加系统复杂度，SRE可能会建议选择降低系统复杂度的替代方案。案例学习1：端到端API简单化背景之前章节的一位作者在一家使用键/值包数据结构的核心库的初创公司工作。RPCs（远程过程调用）取一个包并返回一个包；实际参数作为键/值对存储在包中。核心库支持包的常见操作，比如序列化、加密和日志记录。看起来所有的核心库和API都非常简单灵活，对吧？遗憾的是，答案是否定的：核心库的客户最终为核心API的抽象化付出了代价。每个服务都需要仔细记录键和值（和值类型）的集合，但通常做法并非如此。此外，随着时间的推移、参数的添加、删除或更改，维护向后/向前的兼容性变得很困难。经验教训类似Google Protocol Buffers或Apache Thrift这样的结构化数据类型看起来可能比它们抽象的通用替代方案更复杂。但是由于它们强制预先设计方案和准备文档，获得了更简单的端到端解决方案。案例学习2：项目生命周期复杂度当您查看现有系统，发现它像一团乱麻，您可能希望用一个新的、干净的、简单的系统取而代之，且这个简单的系统能解决相同的问题。不幸的是，在保持现有系统的同时创建新系统的成本可能超乎您的预期。背景Borg是Google的内部容器管理系统。运行了大量Linux容器且具有多种使用模式：批处理与生产，管道与服务器等。多年来，随着硬件的变化，功能的增加以及规模的不断扩大，Borg及其周边生态系统在不断的发展壮大。Omega旨在成为一个更合理，更清爽的Borg版本，且能支持相同的功能。然而，从Borg到Omega的转变过程产生了一些严重的问题：  Omega发展的同时，Borg的发展也没有停滞，因此Omega一直在追逐一个变化的目标。  事实证明，前期对改善Borg难度的估计太过悲观，而对Omega的期望太过乐观（实际上，外国的月亮未必更圆）。  我们对从Borg迁移到Omega的困难没有了然于胸。数百万行配置代码跨越数千个服务和多个SRE团队，这意味着迁移工作在工程和时间维度上成本都是极高的。可能需要数年时间完成迁移，在这期间，我们必须同时支持和维护这两个系统。我们决定做什么最后，我们提供了一些在设计Omega回归Borg时出现的想法。我们还使用了很多Omega的概念来启动Kubernetes，一个开源的容器管理系统。经验教训在考虑重写时，要考虑整个项目生命周期，包括对移动的目标的开发，完整的迁移计划以及在迁移时间窗口内可能产生的额外成本。具有大量用户的APIs很难迁移。在您投入了相应的努力之前，不要想当然的将预期结果与当前系统进行比较。在确保已经衡量了成本和收益以及没有低估成本的前提下，有时重写是最好的前进方式。重获简单化大多数的简化工作是从系统中删除元素。简化工作有时很直接（例如，消除对从远程系统获取的未使用数据的依赖）。简化工作有时需要重新设计。例如，系统的两个部分需要访问相同的远程数据。一个更简单的系统可能只需要获取一次数据并转发结果而非获取两次。无论什么工作，领导层必须确保优先考虑简化工作。这里的简化指的是效率-而不是节省计算或网络资源，它节省了工程时间和认知负荷。项目成功的简化就如同成功启用了一个有价值的功能，就如同成功的度量并对代码进行了增删。例如，Google的内部网络会为删除大量代码的工程师显示“Zombie Code Slayer”徽章。简化是一项功能。您需要明确优先级并给出待简化的项目，同时为SRE预留时间。如果产品开发和SRE人员发现待简化项目对他们的工作没有益处，他们就不会承担这些项目。对于特别复杂的系统或过载的团队而言，可以将简单化作为明确的目标，安排一个独立的时间来完成这项工作。例如，为“简单化”项目保留10%的工程项目时间。（一般说明）读者行动：让工程师集体讨论系统中已知的复杂度，并讨论如何简化。随着系统复杂度的增加，SRE团队存在分裂的趋势，每个新的团队分别集中运维系统的某一部分。这样的操作有时是必要的，但新团队规模的缩小可能会降低他们推动较大简化项目的动力或能力。可以考虑指定一个小的轮转的SRE团队来维护整个堆栈的工作信息（可能比较浅显），推动整个堆栈的整合和简化。如前所述，绘制系统图表的行为可以帮助您理解系统并预测其行为。例如，在绘制系统图表的过程中，你可能需要查找以下内容：放大当一个调用操作返回一个错误或超时，且在几个级别上进行重试时，会导致RPC的总数相乘。循环依赖当组件依赖于自身（通常是间接的）时，系统完整性可能会严重受损-整个系统可能无法进行冷启动。案例学习3：简化广告网络的展示背景Google的广告展示业务有许多关联产品，其中包括一些收购于DoubleClick，AdMob，Invite Media等公司的产品。这些产品必须适用于Google基础架构和现有产品。例如，我们希望使用DFP广告管理系统的网站展示Google AdSense筛选的广告，也希望使用Double Click Bid Manager进行投标时可以通过访问Google Ad Exchange进行实时竞价。独立开发的产品形成了难以推理的互连后端系统，很难观察流量在各组件的流通情况，因此不便且无法精确的为每个产品配置合适的容量。为了确保删除了查询流量中的所有无限循环，我们在其中添加了测试。我们决定做什么Ads的运维团队自然而然会推动标准化：虽然产品的每个组件都有特定的开发团队，但SRE是服务于整个系统的。我们的首要任务是制订统一的标准，与开发团队合作逐步采用这个标准。这些标准是：  建立一种复制大规模数据集的方法  建立一种执行外部数据查找的方法  提供用于监控、配置、组态的通用模板在此之前，需要为每个产品单独提供前端和拍卖功能。如图7-1所示，当广告请求可能到达两个系统时，需要重写请求以符合第二个系统的要求。过程中，增加了额外的代码和处理，还加大了非预期循环的可能。 图7-1：之前，广告请求可能会同时触及AdMob和AdSense系统 为了简化系统，我们为满足所有用例的常用程序增加了逻辑，并且添加了用于保护程序的标志。随着时间的推移，我们删除了标志，将功能整合到较少的的服务器后端中。当服务器统一时，拍卖服务器可直接与两个目标服务器通信。如图7-2所示，当多个目标服务器需要查找数据时，查询只需统一在拍卖服务器中进行一次。 图7-2：统一后的拍卖服务器只需执行一次数据查询 经验教训最好将已经在运行的系统逐步集成到你的基础架构中。正如在单个程序中存在相似的函数表示“代码气味”来反应更深层次的设计问题一样，单个请求的冗余查询表示“系统气味”。当你通过SRE和开发人员的支持建立了有明确定义的标准时，你可以提供更清晰的蓝图以便管理者对高复杂度的系统更认可和鼓励。案例学习4：在共享平台上运行数百个微服务背景在过去15年，Google成功开发了多个垂直类产品（搜索、广告和Gmail，仅举几例），并源源不断的产生了新的重构的系统。其中很多系统都有专门的SRE团队和与之对应的特定领域生产堆栈，包括定制化开发工作流程，持续集成和持续交付（CI/CD）软件周期以及监控。生产堆栈的定制化带来了巨大的维护、开发以及新的SRE成员工作的成本。此外也为团队之间轮转服务（或工程师！）以及新增服务带来困难。我们决定做什么负责社交网络领域的一组SRE团队致力于将其服务的生产堆栈融合到一个托管的微服务平台中，由一个SRE团队管理。共享平台是到目前为止的最佳实践，平台会绑定并自动配置一些之前并未充分利用的功能，这些功能可以提高可靠性且便于调试。无论该SRE团队有多熟悉所负责的服务，新增的服务都必须使用通用平台，而旧式服务必须迁移到新平台或逐步被淘汰。共享平台在社交网络领域取得成功后，谷歌的其他SRE团队和非SRE团队也开始使用它。设计要知道，单个整体服务的变化是缓慢的，使用微服务可以迅速更新和部署功能。微服务实现自我管理，而非托管：团队可以有效的管理他们所负责的服务，无需委托个别团队管理和负责。微服务为每个团队提供工作流程工具用于发布、监控等功能。微服务提供的工具包括UI，API和SRE以及开发人员常用的命令行交互界面。即使这些工具可能涉及许多底层系统，开发人员的体验感却是统一的。成果微服务平台的高质量和功能集成带来了意想不到的好处：开发人员团队可以运行数百项服务，而无需任何SRE的深入参与。通用平台还改变了SRE和开发人员的关系。Google的SRE团队开始分层的参与到工作中，从咨询和设计审查到深度参与（即SRE承担on-call职责）。经验教训从稀疏的或不明确的标准转变为高度标准化的平台是一个长期项目。每个步骤可能都让人觉得是增量式的，但最终，这些步骤可以减少开销并使大规模运行服务成为可能。这种转变可以让开发人员看到价值所在。即不要尝试说服人们执行一个只在全部完成后才得到回报的巨大重构工程，而是在每个开发阶段解锁增量生产力。案例研究5：pDNS不再取决于自身背景当Google生产的客户要查询服务的IP地址时，通常使用名为Svelte的查找服务。过去，为了找到Svelte的IP地址，客户端使用了名为pDNS（生产DNS）的Google命名服务。通过负载均衡访问pDNS服务，负载均衡使用Svelte查找实际pDNS服务器的IP地址。问题描述pDNS对自身具有传递依赖性，某种程度上说这是无意中引入的，后来被明确为是可靠性问题。由于pDNS服务可复制，且在生产中的始终可以获得打破依赖关系循环所需的数据，因此查找通常不会遇到问题。然而，冷启动是无法做到的。借用一位SRE的话来说，“我们就像穴居人，只能依赖现有篝火来点火。”我们决定做什么我们修改了Google生产中的低级组件以便为所有Google生产机器的本地存储附近的Svelte服务器维护当前IP地址列表。除了打破前文所述的循环依赖之外，此举还消除了对大多数其他Google服务的pDNS的隐式依赖。为了避免此类问题，我们还引入了一种方法，将允许与pDNS通信的服务集列入白名单，并慢慢减少该集合。因此，生产中每个服务的查找都通过系统且具有更简单更可靠的路径。经验教训注意服务的依赖关系 - 使用明确的白名单以防止意外添加。另外，需要注意循环依赖。结论通常简单的系统往往是可靠的且易于运行的，因此简单化自然而然就是SRE的目标。很难定量衡量分布式系统的简单性（或取逆，即复杂度），但可以挑选和改进合理的替代测量方案。SRE对系统有着端到端的理解，在识别，预防和修复复杂度来源方具有优势，在软件设计，系统架构，配置，部署过程或是其他地方，SRE都应该参与设计讨论，提供对成本和效益的独特见解，尤其是简单化。SRE还可以主动制订标准来使生产统一化。作为SRE，追求简单化应该是工作的重点内容。我们强烈建议SRE领导层授予SRE团队权利和奖励来推动简单化。系统在不断发展的过程中会不可避免的越来越复杂，因此追求简单化的斗争道路需要持久的关注和付出-但这份追求是值得的。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第六章 减少琐事]]></title>
      <url>/sre/2020/01/06/%E5%87%8F%E5%B0%91%E7%90%90%E4%BA%8B/</url>
      <content type="text"><![CDATA[  战术性的：  琐事是突然出现的，应对性的工作，而非策略驱动和主动安排的，处理紧急报警是琐事，我们可能永远无法完全消除这种类型的工作，但我们必须继续努力减少它。Google SRE的大量时间用于系统优化，通过工程化的方法，与开发一起协同努力，追求卓越。哪怕是很少的性能收益也是值得的。但优化范围不仅局限于服务器资源，SRE的工作耗时也是优化的范畴。首先，SRE的工作不是琐事（关于琐事请参阅《SRE：Google运维解密》第5章内容）。本章我们将琐事定义为：与维护服务相关的，重复的、可预测的、持续的任务流。对于产品运维团队来说，琐事不可避免。运维不可避免地需要处理部署、升级、重启、告警等工作。如果没有系统的方法，这些工作很快将耗尽整个团队精力。Google将SRE团队日常操作的耗时占比限制在50%以内（包括琐事和非劳动密集型工作。这样做的原因，请参阅《SRE：Google运维解密》书中第5章内容）。虽然这个目标可能不适合所有团队，但花费在琐事上的时间上限仍然很重要，因为识别和量化琐事是团队时间优化的第一步。琐事的定义琐事往往具有如下特征：这在我们的上一本书中有所阐述（《SRE：Google运维解密》译者注）。在这里，我们列举出琐事的特征，并给出了一个具体的例子加以解释：  手动性: 当web服务器上的/tmp目录磁盘占用率达到95%时，工程师Anne登录到服务器，在文件系统中查找并删除了无用的日志文件。  重复性: 写满/tmp目录的事情不太可能只发生一次，因此我们需要反复处理。  可以被自动化: 假设修复文件的工作包括如下几个步骤：“X登录，执行此命令，检查输出，执行命令，并通过命令的输出来判断是否需要重启Y”。这些指令流本质上就是伪代码！在上面的例子中，解决方案实际上已经可以部分自动化了。如果不需要人来运行脚本，可以自动化的检测故障并修复是再好不过了。更进一步，我们可以提交一个补丁使软件不再因为文档损坏的问题而中断。  非技术性: “磁盘写满”和“服务宕机”之类的告警会分散工程师的注意力，从而忽略高价值的事情，并可能掩盖其他更严重的告警。大量类似的告警造成的后果会波及到服务的健康状况。  没有持续的价值: 完成一项任务会带来一种令人满意的成就感。但长远来看，这种重复的满足感不能给工程师带来持续的价值。比如，处理告警能够确保用户查询持续进行；确保HTTP请求状态码小于400，以便可以让应用提供持续的服务，这些固然很好。然而，今天解决的问题并不能防止将来不再出现类似的问题，所以这样做的回报只是短期的。  与服务同步增长: 许多业务工作量的增长速度与基础设施规模的增长速度一样快(或许更快)。例如，你花费在修复硬件故障的时间会随着服务器集群规模的增加而增加。但请注意，相关的辅助任务(例如，软件/配置更改)不一定是这个趋势。我们并不能将带来琐事的原因规范化和标准化，但是我们需要知道琐事的一些的特征。除上述特征外，还要考虑某项工作对团队士气的影响。人们是乐于完成一项觉得会有回报的任务？还是会处理无益的琐碎和无聊的任务？答案显而易见，琐事会慢慢地降低团队士气——时间往往花在琐事上而不是花在批判性思考或者是表达创造力上了；只有减少琐事，工程师才能更好地将时间用于思考和进行创造的领域。  案例：人工处理琐事作者：John Looney，Facebook资深 SRE  哪些工作内容是琐事，通常是模糊的。一个“创造性”的解决方案，可能使问题得到最优解决，因此，SRE团队应奖励那些分析根因并解决问题的人，而不是那些掩盖问题的人。  我加入Google后的第一个任务（2005年4月）是追查一批机器死机原因并修复。如果确认是硬件原因，则转交给硬件技术人员维修。这个任务并没有看似那样的简单，因为我需在截止日期前处理超过20,000台机器。  第一台机器死机原因是：Google网络驱动补丁不断打印毫无意义的日志，导致文件系统的根目录写满，类似的一千台机器都是同样的问题。  我和同事沟通了解决这个问题的方案：编写一个脚本，ssh到所有异常机器，如果根目录已满，则清空/var/log中大文件日志，并重启syslog。我的同事对此方案不认可，他说最好找到根因并修复。如果掩盖了问题，在后续一段时间内，可能会引起更多严重性问题。  理论上，每台机器每小时的成本约为1美元。我的想法是，成本是运维工作很重要的衡量指标，应该高优让机器提供服务，利用起来。但我没有考虑的是：如果只是解决了这个表象，就没有机会去追查根因。  在高级工程师指导下，我翻阅了内核源码，找到导致此问题的可疑代码，并且记录了bug，帮助内核团队完善了他们的测试用例。从成本来看，解决这个网络补丁问题，每花费一小时，Google将为此付出1,000美元。  那天晚上就发布了新的内核版本，第二天我就把它升级到所有受影响的机器，内核团队在第二周更新了他们的测试用例。这个问题的处理，我很满意，因为找到了根因并成功修复，而不是每天上班后清理日志。琐事的度量运维工作是辛苦的。如果你做了一些工作减少了琐事，如何知道你的努力是成功的？许多SRE团队是结合经验和直觉来回答这个问题。经验和直觉会产生好的效果，但是我们还可以将方法上升到一个理论的维度。经验和直觉是因人而异、非客观的。根据场景的不同，琐事的定义也不同。比如，同一团队的不同成员会根据工作的投入产出比来判断一件事情是否可以定义为琐事。此外，为了减少琐事所做的工作可能会持续几个季度甚至几年的时间(本章的一些案例研究就证明了这一点)，在此期间团队的人员主要任务可能会发生改变。所以，为了保证减少琐事的工作能够长期进行，一般的，团队必须从几个确定的琐事中选择一个琐事来消灭它。我们应当将这件事上升为一个项目，并且需要建立起这个项目的长期的客观的度量机制以保证投入得到回报。在启动项目之前，重要的是分析成本与收益，并确认通过减少琐事所节省的时间(至少)与第一次开发和维护自动化解决方案所投入的时间成正比(图6-1)。从节省的时间与投入的时间的简单比较来看，那些看起来“无利可图”的项目可能仍然值得进行，因为自动化有许多间接或无形的好处。潜在的好处包括：  随着业务规模扩大，收益越明显  提高团队士气，减少团队流失和成员的厌倦情绪  更少的中断性工作，从而提高团队工作效率  提高流程清晰度和标准化  增强团队成员的技术技能和拥有更全面的职业发展  缩短新成员的培训时间  减少人为错误导致的问题  提高安全性  缩短用户投诉的响应时间 图 6-1 预测在减少琐事工作上花费的时间，并确保其收益大于投入 琐事的度量方法      识别它。第一本SRE书的第5章提供了如何识别琐事。最能够识别琐事的人取决于团队本身。理想情况下，SRE团队既是利益相关方，也是实际操作方。        选择适当的计量单位来量化人力成本。我们可以选择“分钟”或者“小时”这么一个客观和普遍能够理解的计量单位。务必还要考虑琐事转自动化的成本。有些人力成本具有分散性和碎片化的特征，所以我们从成员工作的内容来衡量更为合适。度量单位应该要能够很好的度量如下工作：为应用增加的补丁，完成的票证，手动生产环境的变更，电子邮件交换或者是一些对硬件的操作。总的来说，只要度量单位客观，一致且易于理解，它就可以作为工作的衡量标准。        在项目的整个周期内我们需要连续跟踪并记录度量的指标。我们可以使用工具或脚本来简化度量指标的测量过程，使得收集这些测量值不会产生额外的工作。  琐事分类法琐事，就像一座摇摇欲坠的桥梁或一座漏水的大坝，日复一日地隐藏在广阔无垠的大地之中。本节中的分类并不能够详尽无遗，但代表了一些常见的琐事类别。这些类别中有许多类似“正常”的工作，但是它们实际上就属于琐事。商业流程这可能是最常见的琐事来源。也许你的团队管理一些计算机资源——计算、存储、网络、负载平衡器、数据库等，以及为该资源提供支持的硬件资源。你需要处理用户登录、配置修改和计算机安全维护、软件更新以及扩缩容。你还需要最大限度地降低成本避免计算机资源的浪费。你的团队是计算机的人机界面，通常与为其需求提交票证的内部客户进行交互。你的组织甚至可能拥有多个票务系统和工作系统。票务系统属于“隐藏”一类的琐事，因为其驱动的业务流程通常是我们需要完成的目标。用户得到了他们想要的东西，并且因为琐事往往分散在整个团队中，所以琐事并不能明显地显现出来。在以票据驱动的任何地方，都有可能悄悄地积累这琐事。即使你没有明确的自动化流程，仍然需要执行流程的改进工作，例如简化流程，使其未来更容易做到自动化，同时更加容易管理。工作中断中断是一类为了保证系统运行的时间敏感类任务，简单理解为被其他紧急事情打断。例如，你可能需要通过手动释放磁盘空间或重新启动泄漏内存的应用程序来解决某些资源（磁盘，内存，I/O）的严重短缺。你可能正在提交更换硬盘驱动器，“踢”出无响应的系统或手动调整容量以满足当前或预期的负载请求。通常，中断会将注意力从更重要的工作上移开。流程监督在许多组织中，部署工具从发布到生产需要SRE进行监督。即使有自动化，全面的代码覆盖，代码审查和多种形式的自动化测试，这个过程并不总是顺利进行。根据工具和发布节奏，发布请求、回滚、紧急补丁以及重复或手动配置更改，发布仍产生琐事。服务迁移服务迁移也是我们经常要处理的一类事情。你可以手动或使用有限的脚本来执行此工作，而且希望只迁移一次。迁移有多种形式，包括有数据存储、云供应商、源代码控制系统、应用程序库和工具的更改。如果你手动迁移大规模的工程，迁移很可能涉及到“琐事”。对于大规模的迁移，你可能倾向于手动执行迁移，因为这是一次性的工作。并且我们甚至会将其视为“项目”的一部分而非“琐事”，但迁移工作的很多特征与“琐事”的特征是吻合的。从技术上讲，修改一个数据库的备份工具以便与另一个数据库可以协同工作是软件开发的范畴，但这项工作本质上只是重构代码，用一个接口替换另一个接口。这项工作是重复的，并且在很大程度上，备份工具的业务价值与之前是相同的。压缩成本和容量规划无论是拥有硬件还是使用基础架构提供商（云），压缩成本和容量规划通常是一些劳动密集型的工作。例如：  在计算、内存或IOPS（每秒输入/输出操作）等资源的未来规划中要确保成本效益和突发情况的扩容能力。这可能转化为采购订单，AWS预留实例或云/基础设施即服务合同协商。  应对（并从中恢复）关键的高流量事件，如产品发布或者遇到假期。  排查下游和上游服务水平和容量情况。  根据专有云服务产品的计费细节优化应用程序（适用于AWS的DynamoDB或适用于GCP的Cloud Datastore）。  重构工具以便更好地利用现有资源。  处理超预算的资源，无论是基础设施提供商的上游还是与下游客户之间。黑盒系统故障排除分布式微服务架构现在很常见。随着系统更加分散，出现了新的故障模式。团队可能没有能力来构建复杂的分布式跟踪，高可靠监控或详细的仪表盘。即使企业确实拥有这些工具，它们也可能不适用于所有系统。故障排除甚至可能需要登录到各个系统并使用脚本工具来对日志进行实时地查询分析。故障排除本身并不是坏事，但你应该把精力集中在新的故障模式上，而不是每周都发生的由脆弱系统架构导致的故障。随着可用度为“P”的新关键上游依赖性服务的上线，系统可用性将下降（1-P）倍。一个可用度为4个9的服务增加了9个关键的4个9的核心组件，现在就变为了是一个三个9的服务。琐事管理战略任何规模的生产系统，琐事管理都是至关重要的。一旦确定并量化了琐事，消除琐事的计划就要提上日程。这个工作可能需要数周才能完成，因此制定一个完善的计划是至关重要。首先，从源头上消除琐事是最佳的解决方案，但是对于源头上无法消除的琐事，则需要通过其他方式来消除。在我们深入研究两个案例之前，本节提供了此方面工作的通用性准则。正如下文的两个案例中提到的，琐事的细微差别是因团队而异。但无论如何，一些常见的准则是适用于任何规模或风格的组织。在后续案例中将以具体方式诠释每种策略。琐事的识别与度量采用数据驱动的方法来识别琐事，并配合客观的成本控制策略，获得此类项目最优的投入产出比。如果你的团队正在被琐事缠身，并将减少琐事作为了一个长期的项目。Google SRE团队根据多年的经验，在控制项目投入产出比方面是一个不错的借鉴。有关技术和指导，请参见第96页的“量化琐事”一节。让SRE从琐事中解脱出来减少琐事的最佳策略是从源头杜绝琐事。在进行系统设计和为生产环境制定流程之前，工程师要优化产品和系统来减少甚至消除琐事。真正了解生产环境痛点和知道导致系统出现琐事原因的那部分人正是SRE，因为只有他们和生产环境紧密联系。SRE应该在与产品开发团队合作的过程中，将自己的运维经验与产品开发团队共享从而开发出人机交互友好型的软件，从源头减少琐事，并且使产品具有更好的扩展性和弹性。拒绝琐事一个被琐事缠身的团队应该尽早的做出“消除琐事”决策。第一种策略是对琐事说“不”！对于每个琐事，量化它并以此为原则决定是否要做，但是根据Google的经验，这一种策略可能会适得其反。另一种策略是故意拖延这些琐事，直到我们可以通过批处理或并行处理来解决它。将琐事集中在一起一并处理它们，这种方式可以减少工作中的中断，并帮助你们识别琐事的特征，并将它们作为下一个消除目标。使用SLO减少琐事如第2章所述，服务系统应具有文档化的SLO。明确定义SLO才能使工程师做出明智的决策。例如，如果某项工作即使做也不会减少服务的错误预算，你就可以考虑忽略某项工作。随着服务的增长，专注于整体服务的可用性而不是单个设备的SLO，这样做是非常有利的，也是可持续的。有关编写有效SLO的指导，请参阅第2章。从部分自动化开始如果你的业务特别复杂，请将“部分自动化”方法视为实现“完全自动化”的临时步骤。在这种方法中，你的服务通常可以通过定义的API接收结构化数据。工程师也可以进行一些操作从而得到想要的结果。虽然这样做需要一些手动的操作，但是这种“幕后工程师”方法是逐步实现全自动化的前提。使用“客户端输入”来统一收集数据；通过确定的请求格式，你可以更容易的以编程的方式对请求进行处理。这种方法让客户也能够明白你需要的信息和指标，并在你完全理解系统服务之前避免使用大型的解决方案而产生的未知问题。提供一种自助的服务方法一旦你们提供了交互型界面的服务产品，请进一步的为用户提供自助式的服务方法。你可以提供Web表单、二进制、脚本、API，甚至只是告诉用户如何向服务的配置文件发出拉取请求的文档。例如，软件开发工程师要求SRE工程师为其开发工作配置新虚拟机，我们为他们提供一个简单的Web表单或脚本来触发配置，而不是让他们提交相关票证来进行这件事。如果发生了特殊的情况，我们也允许使用“票证”的方式替代自助的服务，这是可接受的。部分自动化是一个良好的开端，但服务SRE工程师应该始终要致力于尽可能让服务自动化起来。获得管理层和同事的支持在短期内，减少琐事的项目需要投入人力成本，反之会减少处理其他日常任务的人员数量。但长远来看，如果项目达到了减少琐事的目标，团队将更加健康，并有更多的时间进行更重要的工程改进。对于团队中的每个人来说，“减少琐事”作为一个共同的价值目标是很重要的。管理层的支持对于减少工程师的干扰是至关重要。制定琐事评估的客观指标来说明项目的推进情况可以让管理层更加支持项目的进行。减少琐事作为提高服务稳定性一部分要为减少琐事的项目创建一个强大的业务案例支持，将你的目标与其他业务目标相结合。如果有一个补充性的目标，例如，安全性、可扩展性或可靠性——这对客户来说是具有吸引力的，他们会更愿意放弃当前充满琐事的系统，转向更加亮眼的新系统。这样来看，减少琐事也可以提高用户服务的质量，这也是另一个角度来看待琐事的认识。从简单的琐事开始并持续改善，不要试图设计没有琐事的系统。面对一个充满琐事的系统，首先自动化一些高优先级的项目，然后通过评估这个项目所花费的时间来改进你的解决方案，总结获得的经验和教训。在项目开始之前，选择一个明确的指标，如MTTR（平均修复时间）来评估你的项目的进展和效果。提高系统的一致性从规模上看，多样化的生产环境是难以管理的。特殊的生产环境容易出错，管理能力会降低，事故的处理能力也会降低。你可以使用“宠物与牛”方法（https://www.engineyard.com/blog/pets-vs-cattle，译者注）来添加系统冗余并在你的生产环境中实施增加一致性的策略。是否选择“牛”取决于组织的需求和规模。将网络链路、交换机、机器、机架，甚至整个集群评估为可互换单元也是合理的。将设备转换为“牛”的理念可能会带来较高的初始成本，但会减少中长期的维护成本，增强灾难恢复能力和提高资源利用能力。为多个设备配置相同的接口意味着它们具有相同的配置，是可互换的，维护成本也就降低了。各种设备的界面一致（转移流量，恢复流量，执行关机等）使系统更加灵活和更加可扩展。Google鼓励各团队将不断发展的内部技术和工具进行统一，并有相应的鼓励机制。无论团队用什么样的方法，但他们不得不承认一些不受支持的工具或遗留的系统是产生琐事的根源。评估自动化带来的风险自动化可以节省人力成本，但是也会出现未知的错误，严重时会造成停机。一般情况下，防御性软件可以控制这类事情的发生。当管理级别的行为被自动化之后，防御性软件会显得至关重要。在执行前应对每项行为的安全性进行评估。在实施自动化时，我们建议采用以下做法：  防御性地处理用户输入，即使这个输入来自于上游的系统 ——换句话说，要对上下游的输入进行仔细的校验。  构建告警机制，使得工程师可以接收到相关告警以进行处理。安全措施可能与命令超时一样简单，也可能是对当前系统指标或当前中断次数的更复杂检查。因此，监控，报警和仪表系统应由机器和操作人员共同使用。  请注意，即使是简单的读取操作也可能会导致设备负载过高和触发服务中断。随着自动化的扩展，这些安全检查的工作量是可控的。  最大限度地减少因自动化安全检查不完整导致服务中断的影响。如果操作员遇到不安全的情况，自动化操作应该默认为人工操作。琐事自动化之后要做什么一旦你可以将一个工作自动化后，这个自动化的工作就值得更深层次的被发掘。进一步的将自动化的任务按照人工处理的流程优化下去。但请注意，自动化不应该让工程师认为任务不会出错。在完成上述优化后，你还可以尝试将自动化的工作分解为可单独实现的组件，并用于创建可组合的软件库，其他自动化项目可在以后重复使用。正如下文中的“数据中心维修案例”研究所示，自动化提供重新评估和简化人工工作流程的机会。使用开源和第三方工具有时你不必做所有的工作来减少琐事。像一次性迁移这样的工作可能自己无法建立定制型的工具，但你可能并不是第一个遇到这个任务的工程师。寻找第三方或开源库以降低开发成本，或者说，至少可以帮助你过渡到部分自动化。反馈并改进积极寻求反馈，这些反馈可以来自于工具、工作流程和自动化交互相关的其他人，这是非常重要的。你的用户将根据他们对底层系统的理解将你的工具在不同使用情景下进行使用。你的用户对这些工具越不熟悉，就越要积极地寻求用户的反馈。利用用户调查，用户体验（UX）和其他机制来了解你的工具被如何使用，并整合这些反馈，以便在未来实现更有效的兼容性。人的输入只是你应该考虑反馈中的一个方面。我们还可以根据延迟，错误率，返工率和节省的人工时间等指标（跨过流程中涉及的所有组）来衡量自动化任务的有效性。能够获得在自动化工作部署之前和之后两种状态的对比是最明确的衡量方式。  扩展：历史遗留系统  大多数SRE工程师在他们的工作中都会遇到过历史遗留系统。这些旧系统经常在用户体验，安全性、可靠性或可伸缩性方面有问题。他们倾向于将遗留系统看作一个神奇的黑匣子，因为系统“大部分组件是在工作中的”，但很少有人了解它们是如何工作的。贸然的调整它们是可怕的，也是昂贵的，并且保持它们的运行通常需要大量繁琐操作步骤。远离遗留系统通常遵循以下路径：      避免：我们可以为不去解决这个问题找到许多理由：可能是没有资源来替换这个系统；判断业务成本和风险发现不值得替换；可能没有找到商业上更好的解决方案。避免选择的是接受风险并从SRE转向系统管理。    封装/扩充：你可以使用SRE来构建一个抽象API的外壳，自动化，配置管理，监视和测试这些遗留系统，这些系统将卸载SA的工作。遗留系统仍然很难改变，但现在你至少可以识别它并在适当时有回滚策略。这种策略仍然可以避免，但这是将风险引入到的更好的系统中。这通常是准备增量替换的权宜之计。    替换/重构：替换遗留系统可能需要大量的决心、耐心、沟通成本和文档，最好是逐步进行。一种方法是定义遗留系统公共接口。此策略可帮助你使用发布的工程手段，将用户缓慢、安全地迁移到其他安全的架构中。通常，遗留系统的“规范”实际上只是通过其历史用途来定义，因此有助于构建生产大小的历史预期输入和输出数据集，以建立新系统不会偏离预期行为的信心（或正在以预期的方式发散）。    退出/保管所有权：最终，大多数客户或功能被迁移到一个或多个系统。这个迁移需要有激励措施，没有迁移的用户让他们自行维护历史遗留系统，并承担相应责任。  案例研究案例研究1：利用自动化减少数据中心的工作量  案例研究1中所应用的减少琐事的战略：      SRE工程师从琐事中解脱出来    从部分自动化开始    提高系统的一致性    使用SLO减少琐事    评估自动化带来的风险    反馈并改进    提供一种自助的服务方法  背景此案例来源于Google数据中心。与其他的数据中心类似，Google的计算机连接到交换机，交换机连接到路由器。流量通过链路流入和流出这些路由器，而链路又连接到互联网上的其他路由器。随着谷歌对互联网流量的要求越来越高，服务该流量所需的交换机数量也急剧增加。为了能够应对大流量的情况，我们的数据中心在规模和复杂性方面都有所增长。这种增长迫使数据中心改变了手动维修的旧方法。（从偶尔和有趣到频繁和沉闷的转变。）早期，谷歌在运行数据中心时，每个数据中心的网络拓扑都只有少量的网络设备，可以管理大量服务器的流量。单个网络设备故障可能会显著影响网络性能，但是一个小规模的工程师团队就可以处理设备的故障。早期，工程师调试故障设备并手动将流量切换到其他正常组件。而我们下一代的数据中心拥有更多的机器，并引入了折叠Clos拓扑结构的软件定义网络（SDN），交换机数量显著增加。图6-2展示的是一个小型数据中心Clos交换机网络的流量复杂情况。如果将这个比例放大，意味着设备数量更多，发生故障的组件也更多。虽然可以说，每个单独的故障对网络性能的影响比以前更小，但是大量的问题同时并发也会压倒工程师们。调试问题的过程同时也会引入大量新的问题，复杂的布局也让工程师感到困惑：需要检查哪些链接？需要更换哪个线卡？为什么是Stage 2开关，而不是Stage 1或Stage 3开关？关闭交换机会给用户带来哪些问题？图6-2. 一个小型Clos网络，Stage1 支持480台机器连接 修复故障的线卡是一个随着系统网络增长而任务量不断增长的琐事，因此我们将此作为“数据中心网络修复自动化”项目的第一阶段的目标。本案例阐述了我们如何在第一代线卡（名为Saturn）系统上开始自动化修复的过程，并以此为基础，我们讨论了如何对自动化工作进行改进以适应下一代线卡(Jupiter光纤网络)。如图6-3所示，在自动化项目开始之前，数据中心线卡修复工作需要工程师执行如下几个操作：  确定从故障交换机切走流量是否是安全的。  切走流量至其他交换机（“drain”操作）。  执行重启或修复（例如更换线卡）。  将流量切回至该交换机（“undrain”操作）。Drain，更换线卡，undrain的工作是不变和重复性质的，是“琐事”的典型范例。这些重复性的工作本身就会带来一些问题——例如，工程师在处理此类故障时会并行处理其他更有挑战性的工作，分心的工程师可能会意外地将未配置的交换机加入网络。  图6-3. 自动化之前的数据中心（Saturn）线卡修复工作流程：所有步骤都需要手动工作 问题陈述数据中心修复线卡问题具有以下几个维度：  团队规模增长的速度跟不上系统增长的速度（故障数量也在增长），使得我们无法快速解决问题以防止对系统带来负面影响。  人为错误一定会在重复执行的步骤中发生。  并非所有线卡故障的影响都是一致的。我们没办法对线卡故障划分优先级。  一些故障是暂时的，这时我们会选择直接重新启动线卡或重新安装交换机作为修复过程的第一步。并且，我们可以用编程方式捕获这些问题，如果它再次发生，则进行设备替换。  新的拓扑环境要求我们在采取行动之前手动评估隔离容量的风险。每次的人工风险评估都有可能带来人为错误，并可能带来严重影响。系统工程师和技术人员也没有好的方法来判断有多少设备和链接会受到修复过程的影响。我们要如何解决这个问题？为达到最好的效果，我们决定创建一个与现场技术人员配合使用的自动化框架，而不是把每个问题分配给工程师，让其进行风险评估，流量切换，维修和验证等人工操作。自动化的第一步：Jupiter光纤网络的修复自动化我们的最终目标是构建一个能够代替工程师分析和处理故障的网络设备故障检测系统。我们的程序是直接切换流量并告知工程师，而不是向工程师发送“线卡”故障的告警。新系统有一些值得注意的特点：  我们最好是利用现有工具。如图6-3所示，我们的告警已经可以检测到线卡上的问题; 所以我们可以配置告警以触发自动修复。新的工作流程还应改变工单系统，以便支持自动提交的维修请求。  我们建立自动风险评估的机制，以防止在流量切换期间意外的隔离设备，并在需要时触发安全机制。此机制可以杜绝人为错误。  我们编写程序用于跟踪告警以便作出不同的处理操作：第一次告警仅重启该线卡并重装了软件；第二次出现告警则直接请求更换线卡并告知供应商。执行自动化操作新的自动化工作流程（如图6-4所示）进行如下：  检测到有问题的线卡，并将故障特征添加到数据库中。  维修服务组件会解决问题并对交换机进行维修。该服务还会执行风险评估以确认操作不会隔离任何容量，然后：  a. 从故障交换机中切出流量。 b. 关闭线卡。 c. 如果这是第一次告警，则重新启动线卡，将流量恢复到此交换机。此时，工作流程已完成。 d．如果这是第二次失败，则工作流程进行到步骤3。  流程管理器检测到新案例并将其发送到故障维修池，供系统工程师处理。  系统工程师对故障做出响应，在UI界面中看到红色的“停止”（表示在开始修理之前需要切走流量），并分三步执行修复步骤： a. 系统工程师通过UI界面中的“准备组件”按钮启动流量切换。 b. 流量切换完成后表示交换机可操作。 c. 关闭交换机并维修线卡。  自动修复系统再次启动线卡。完成修复后，启动交换机，待初始化后，流程管理器会触发恢复操作，切回交换机流量并结算故障工单。 图6-4.具有自动化功能的Saturn线卡维修工作流程：只需按下按钮即可完成更换线卡等全部手动工作 新的自动化系统将团队从大量的琐事中解放出来，使他们有更多时间在其他地方开展更高效的项目：使用下一代Clos拓扑结构Jupiter。自动化项目的第二步：Saturn线卡修复与Jupiter线卡修复数据中心的容量需求几乎每12个月翻一番。因此，我们的下一代数据中心结构Jupiter比Google以前的任何数据中心的六倍还要大，所以故障的数量也会增加六倍多。Jupiter提出了自动化故障修复的挑战目标，这个目标的难度在于每层的数千个光纤链路和数百个线路卡都可能出现故障。幸运的是，随着潜在故障点的增加系统也会伴随增加更多的冗余，这有利于我们完成自动化任务。如图6-5所示，我们保留了系统的一些常规工作流程，并添加了一些重要的修改：  在自动切流量和关闭交换机之后，确定我们要更换的硬件，将硬件故障单发送给系统工程师。在这个过程中，切流量的行为是自动的，不需要系统工程师手动按下“预备按钮切流量开关”来完成。  我们添加了自动化，用于安装和推送组件更换后的配置。  我们启用自动化功能，以便在切回流量之前验证修复是否成功。  除非绝对必要，否则我们更关注的是如何恢复流量而不用人为介入。 图6-5.左图为Saturn线卡宕机自动化流程，右图为Jupiter线卡宕机自动化流程项目实现我们为Jupiter交换机上的所有的线卡故障采用了简单而统一的工作流程：操作通报，流量切换，开始修复。自动化执行如下：  检测到交换机故障，并将故障特征写到数据库。  维修程序开始修复交换机：停止使用交换机，并将停止原因写到数据库中。 a. 如果这是六个月内的第二次故障，请执行步骤4。 b. 否则，请执行步骤3。  尝试（通过两种不同的方法）重启交换机。  a. 如果重启成功，用自动化服务检查健康状态，然后安装并配置交换机使其投入使用；删除修复原因，删除数据库中的故障记录。 b. 如果健康检查失败，请升级给技术人员。  如果这是第二次故障告警，请将故障案例直接升级给技术人员，向其申请新的硬件设备。硬件更新后，用自动化服务检查健康状态，然后安装并配置交换机使其投入使用。删除修复原因，删除数据库中的故障记录。这种新的工作流程管理完全重写了以前的修复系统。同样的，我们要尽可能利用现有工具：  配置新交换机（安装和验证）的操作与验证已更换的交换机所需的操作相同。  快速部署新的硬件需要以编程的方式进行BERT和cable-audit的能力。在恢复使用之前，我们可以使用该程序在已经修复的链路上运行功能测试。这些测试需要能够识别错误链接以进一步提高修复的效果。下一步要提升的是自动缓解并修复Jupiter交换机线卡的内存错误。如图6-6所示，在开始自动化修复之前，此工作流程在很大程度上取决于工程师来判定故障是硬件导致还是软件导致，然后再停止使用，重启交换机等工作，并适时地安排修复。 图6-6. 自动化之前的Jupiter内存错误修复工作流程 我们的自动化过程不再尝试对内存错误进行故障排除从而达到简化修复工作流程的目的（请参阅第119页的“有时不完美的自动化就足够了”，了解为什么这样做是有意义的）。相反，我们处理内存错误的方式与处理线卡故障的方式相同。为了将自动化覆盖到内存错误引起的故障，我们只需在配置文件中添加一个特征，使其对新的故障类型起作用。 图6-7描述了内存错误的自动化工作流程。经验教训在我们致力于实现网络故障自愈的这些年里，我们学会了如何有效减少琐事。UIs 不该引入开销和复杂度替换一块Saturn-based线卡需要切走整个交换机的流量。等待备件更换以及工程师支持的时候，过早地执行全部切换操作意味着失去所有线卡的工作能力。我们在UI中增加一个“准备组件”的按钮，以允许技术人员在更换线卡前执行整个交换机的切换流量操作，从而消除了交换机不必要的停机时间（请参阅“按下准备按钮” 切出流量的开关“见图6-5）UI和维修工作的流程引入了许多非预期的问题  按下切走流量的按钮后，技术人员无法得到流量切换进度的反馈，只能在结果返回后才能进行下一步操作。  该按钮可能无法反馈真实的状态。造成的结果是，有时切流量开关出问题但并没有被维修，或者技术人员可能通过其他方式中断了进程但是并没有告知系统。  问题出现时，非自动化的组件反馈了一个通用的‘contact engineering’信息。经验不丰富的技术人员无法快速找到可以提供帮助的人，而联系上的工程师并不总能够立即解决问题。为快速对用户反馈以及因功能复杂性带来的回归问题进行响应，我们设计了更完善的工作流程，来保证按钮的安全性和可用性。不要依赖人的经验我们过分依赖有经验的数据中心技术人员来识别系统中的错误（例如，当程序认为可以安全地进行维修，但实际上交换机并没有完成流量切换的动作）。这些技术人员在没有自动化提示的情况下，还必须手动执行多项工作。经验是难以复制的。在一个复杂的情节中，技术人员在等待数据中心维修时，决定启动并发切换来快速进行“按下按钮并等待结果”的操作，从而导致了网络拥塞和用户可见的数据包丢失。我们的软件无法预测并阻止这种行为，因为我们并没有测试过这种自动化。设计可重复使用的组件尽可能避免采用集成化设计。使用组件来构建复杂的自动化工作流，每个组件处理一个独特且定义明确的任务。我们可以轻松地重复使用或调整早期Jupiter自动化的关键组件来用于下一代的软件设计，并且很容易针对已经存在的自动化项目增加新的功能。Jupiter类结构的连续变体可以采用早期已经完成的工作。不要过分分析问题我们过度分析了Jupiter线卡内存错误问题。我们试图进行精确的问题诊断，我们想区分软件错误（可通过重新启动修复）与硬件错误（需要更换卡），并识别影响流量的错误与未发生的错误。我们花费将近三年（2012-2015）的时间来收集超过650个离散内存错误的数据，然后才意识到这个分析是过头了，或者至少不应该阻塞我们自动化项目的开展。一旦我们决定对检测到的任何错误都采取必要的措施，就可以直接使用我们现有的自动化修复技术来实现简单的切换策略、重启以及为修复内存错误而重置交换机。如果问题再次出现，我们可以认为，故障很可能是基于硬件的，并立即要求更换组件。我们花费了整个项目四分之一的时间来收集数据，发现大多数的错误是暂时的 ——大多数交换机在重新启动和重新安装后都恢复了。我们不需要额外的数据来执行修复，因此为了实现这种自动化花费了三年是没有必要的。有时不完美的自动化就已经足够解除链路之前，通过BERT很容易确认链路状况，但BERT工具不支持网络管理链路。我们将这些链路添加到现有的链路修复自动化中，并允许跳过验证。我们很愿意绕过验证，因为链路并没有承载客户流量，如果验证结果很重要，我们可以稍后添加此功能。保证维修自动化项目的持续性和可继承性自动化项目可以有很长的生命周期，需要确保人员的流动不会干扰项目的连续性。 新人工程师应该接受现有系统的培训，以便他们能够修复错误。由于Jupiter线卡部件的短缺，Saturn-based系统在其目标寿命结束后很长一段时间内还是存在的，这要求我们日后在Saturn的生命周期中进行一些改进。自动化一旦被采用，在很长的一段时间内将会被依赖使用，并伴随着一些积极和消极的后果。如果可能，以灵活的方式设计你的自动化程序。不灵活的自动化会使系统变更变得难以实现。使用基于策略的自动化可以明确地将意图与通用实现引擎分离，从而使自动化更加可持续的发展。深入开展风险评估和防御措施为Jupiter构建新工具以评估执行切流操作前的风险，而后由于问题的复杂性，我们需要在更深层次的防御上引入二次检查。二次检查设定了受影响链路数量的上限，以及受影响设备的额外限制。一旦超过任一限定值，便会自动触发追踪bug以请求更进一步的检查。我们不断地调整这些限制，以减少误报。最初我们认为二次检查只是一项临时措施，但是在主要风险评估平稳后，该措施已被证明可用于识别由于停电和软件错误导致的维修问题（如请参阅SRE中“自动化：在规模上实现失效”）。失败预算和管理者支持修复自动化有时会失败，尤其是在首次使用时。管理者的支持对于保护项目，并鼓励团队坚持不懈是至关重要的。我们建议为通过自动化技术消除琐事项目设置错误预算。你还需要向外部的其他利益方解释：尽管存在故障风险，但自动化极其重要，并可以持续提高可靠性和效率。总结最终，复杂场景的自动化是真正需要解决的问题。在引入自动化系统之前要反复对系统进行评审——是否可以先简化系统和工作流？要关注自动化工作流程的各个方面，而不仅仅是造成琐事的那部分。和直接参与项目的人员共同开展测试工作，并积极寻求他们的反馈和帮助。如果他们在使用过程中出现操作问题，要想办法使工作界面更清晰，或者增加额外的安全检查。确保自动化不会带来额外的琐事——例如开启了不必要的工单以引起人的注意。给其他团队创造问题将增加自动化推进的难度。案例研究2：淘汰以文件为后端的Home directories  案例研究2中强调了减少琐事的方法：      考虑淘汰旧系统    将减少琐事作为一项工程    获得管理层和同事的支持    拒绝琐事    从部分自动化开始    提供一种自助的服务方法    从细微处开始然后改进    反馈并改进  背景在谷歌的早期，公司数据存储（CDS）SRE团队为所有Google员工提供home目录服务。与企业IT中常见的Active Directory漫游配置文件类似，Google员工可以跨工作站和平台使用相同的home目录。CDS团队还为共享存储空间中的跨团队协作提供“团队共享”服务。我们通过NFS / CIFS（或“文件管理器”）上的Netapp存储设备提供home目录和团队共享。这种存储系统是很昂贵的，但Google员工对此类服务的需求是必须的。问题陈述随着时间的推移，这些文件管理系统解决方案的优势被其他更好的存储解决方案所超越：我们的版本控制系统（Piper / Git-on-borg），Google Drive，Google Team Drive，Google云存储以及全球内部共享分布式ilesystem（x20）。这些替代方案的优越性体验在如下方面：  NFS / CIFS协议并不适用于在WAN上运行，这造成即使有几十毫秒的延迟，用户体验也会迅速降低。这也为远程工作人员或全球分布的团队带来了问题——因为数据只能存在于一个地方。  与替代品相比，原系统的设备运行和规模都是昂贵的。  要使NFS / CIFS协议与Google的Beyond Corp11网络安全模型兼容，需要做大量的工作。与本章最相关的是，home目录和团队共享会频繁的使用。存储配置的许多方面都是ticket驱动的。虽然这些工作流程通常是研发人员编写的，但它们代表了相当数量的CDS团队的工作成果。我们花了很多时间创建和配置共享，修改访问权限，解决最终用户问题，以及执行启动和调整以管理容量。除了配置、更新和备份之外，CDS还需要管理专用硬件的配置，机架和布线过程。由于延迟要求，我们经常不得不部署在远程办公室而不是在Google数据中心 – 这有时需要花费团队成员相当长的时间。我们决定做什么首先，收集数据：CDS团队开发了一个名为“Moonwalk”的工具来分析员工使用此的服务的场景。我们确定收集如下通用的指标，如每日活跃用户（DAU）和月活跃用户（MAU），并询问了诸如“哪些用户实际使用他们的home目录？”和“哪些人每天使用此系统？他们最常访问的文件是什么？“Moonwalk与用户调查相结合，验证了文件管理器当前服务的业务需求可以通过低运营开销和成本的可替代方案代替。另一个引人注目的原因促使我们放弃现有的文件系统：如果我们可以将大多数文件管理器用例迁移到G Suite / GCP，那么我们可以利用我们学到的经验来改进这些产品，从而为其他大型企业迁移到GSuite/ GCP提供支持。没有一种替代方案可以满足所有当前的文件管理器用例。然而，通过将问题转化为若干小的需求来寻找可替代系统，我们发现少数备选方案可以涵盖我们所有的使用场景。替代解决方案更专业，并且每个解决方案都带来比旧的解决方案更好的用户体验。例如：  x20  全局共享静态文件对于团队来说是很好的方式，比如二进制文件。  G Suite Team Drive  适用于办公文档协作，与NFS相比，用户更能容忍此延迟。  谷歌的巨像Colossus文件系统  比NFS更安全，更可靠地共享大型数据文件  Piper/Git-on-Borg  可以更好地同步dotfiles（工程师的个性化工具首选项）  一种新的“历史服务”工具  可以托管跨工作站命令行的历史记录在我们编制用例并找到替代方案时，旧文件系统的下线计划也已经开展设计与实施下线旧的文件管理系统是一项持续的、迭代的、需要多年的进行的工作。需要伴随多个子项目的开展：  Moira  home目录下线  Tekmor  迁移home目录用户的历史遗留数据  Migra  团队共享下线  Azog  下线home目录/共享基础架构和相关硬件 图6-8。Moira项目的四个阶段 本案例研究重点关注第一个项目Moira。后续项目的开展是在Moira的学习和开展的基础上开始的。如图6-8所示，Moira由四个阶段组成。关键组件Moonwalk虽然我们有关于用户共享（例如共享大小）的基本统计数据，但我们仍需要了解用户的工作流程，以帮助用户即使在一片反对声中仍然可以做出有利于业务发展的决策。我们建立了一个名为“Moonwalk”的系统来收集和反馈这些信息。Moonwalk存储了谁正在访问哪些文件以及何时使用BigQuery的数据，这使我们能够做出统计报告以便更好地了解用户。在BigQuery的帮助下，我们汇总了25亿个文件，共计300 TB的数据的用户访问模式。该数据来自于全球60个地理站点的124个NAS设备，共计600,000个磁盘卷，共收集了60,000名POSIX用户的使用信息。Moira Portal通过工单处理来完成home目录下线的想法，在我们庞大的用户基数面前看起来不太现实。我们需要在整个过程中（调查用户，告知项目下线原因，归档数据或迁移到替代系统）尽可能提供低接触服务（低接触服务是指这样的服务模式：销售服务人员在向顾客提供服务时，保持较少的面对面的接触机会。相对于高接触服务而言，低接触服务需要更多的机器和固定资产。因为通常需要由它们来自动完成顾客服务，如自动售货机、自动柜员机、自动加油机等，译者注）。我们的最终要求是：  描述项目的登录页面  不断更新对常见问题的解答  与当前用户共享关联状态和使用信息  提供请求，停用，存档，删除，扩展或重新激活共享的选项至此，我们的业务逻辑变得相当复杂——因为我们必须考虑许多用户场景。例如，用户可能会从Google离职，短暂离职，或者在诉讼状态（需要保留其拥有的数据）。图6-9提供了一个示例图，说明了其复杂性。 图6-9。基于用户场景的业务逻辑 为主门户网站提供支持的技术相对简单。基于Flask框架下用Python语言编写，它读取并写入Bigtable，并使用大量后台作业和调度程序来管理其工作。归档和迁移自动化我们需要大量的辅助工具来将门户网站和配置管理组合在一起，并与用户进行通信来进行用户查询。我们还需要使用沟通技巧来鉴别出适合进行数据迁移的用户。误报（错误地报告所需行动）或漏报（未通知用户您正在取走某些东西）都是不可接受的，这里发生错误将意味着失去用户可信度和带来客户服务的额外工作。我们与其他存储系统所有者合作——为新系统添加我们需要的功能。因此，随着项目的进展，不太成熟的替代品变得更适合了。我们还可以使用和扩展其他团队的工具。例如，我们使用其他团队内部开发的工具将数据从Google云端存储迁移到Google云端硬盘，作为门户网站自动存档功能的一部分。这项工作需要在整个项目期间进行长期的软件开发。我们构建并迭代了每个组件–Moonwalk报告管道，门户和自动化，以便更好地管理下线和归档共享，以响应下一阶段的要求和用户反馈。我们在第三阶段（差不多两年）才接近达到一个功能健全的系统。即便如此，我们还需要额外的工具来处理大约800名用户的“长尾”。这种低速和慢速的方法有一定的好处。因为它允许我们：  维持一个精炼的团队（平均三名CDS团队成员）  减少对用户工作流程的干扰  减少Techstop的琐事（谷歌内部技术支持组织）  根据需要构建工具，以避免将时间浪费在工程工作中与所有工程决策一样，存在如下权衡：项目将长期存在，因此团队在设计解决方案时必须忍受与文件管理器相关的琐事。该计划于2016年正式完成。在撰写本文时，我们已将home目录从65,000个减少到约50个（目前的Azog项目旨在淘汰这些最后用户并彻底下线文件管理系统的硬件。）我们的用户体验有所改善，CDS已停止运营成本高昂的硬件。经验教训虽然没有任何替代方案可以替代Google员工已使用14年之久的文件管理系统，但我们并非没必要进行批量更换。通过有效地将堆栈从通用但有限的文件系统解决方案升级到多个应用程序共同组成的解决方案，我们增加了系统的灵活性，以提高可扩展性、延迟包容度和安全性。Moira团队不得不预测各种用户的行为，并考虑不同阶段的可替代方案。我们必须围绕这些替代方案来调整我们的期望：总的来说，它们可以提供更好的用户体验，但实现这一目标并非是毫无痛苦的。我们学到了以下关于有效减少琐事的策略。发现旧系统的不足并下线昂贵的业务流程业务需求不断变化，新的解决方案不断涌现，因此定期评估旧的业务流程是值得的。正如我们在第101页的“琐事管理策略”中所讨论的那样，拒绝琐事（决定不执行）通常是消除它的最简单方法，即使这种方法并不总是快速或简单的。通过用户分析和业务理由来调整你的业务工作内容，而不仅仅是减少琐事。文件管理系统下线的主要业务理由归结为Beyond Corp安全模型的优势。因此，虽然Moira是减少CDS团队琐事的好方法，但强调下线系统的原因如果是考虑到了新系统诸多的安全优势，这些优势将带来更具吸引力的业务需求。构建自助服务接口我们为Moira建立了一个自定义门户（相对昂贵），但通常有更便宜的选择。Google的许多团队使用版本控制来管理和配置他们的服务，以拉取请求（称为更改列表或CL）的形式处理请求。这种方法几乎不需要服务团队的参与，但为我们提供了代码审查和持续部署的优势，便于验证、测试和部署内部服务配置更改。从人工支持的界面开始在几个方面，Moira团队采用了“幕后工程师”的方法，将自动化与工程师的人工操作相结合。共享请求在路由过程中出现bug，我们的自动化在处理请求时会及时更新。系统还会通知到终端用户，提醒他们解决类似的共性问题。工单可以作为自动化系统的应急的GUI：它们保存工作日志，更新利益相关者的数据，并在自动化出错时提供简单的人工干预机制。在我们的示例中，如果用户需要获得数据迁移工作的帮助，或者如果自动化无法处理其请求，则该错误会自动路由到SRE手动处理的队列中。零接触的自动化自动化系统要求请求合规。Moira的工程师选择重新调整我们的自动化，以专门处理共享的边缘场景请求，或者删除/修改不合格的共享以符合系统的期望。这使我们能够在大多数迁移过程中实现零接触的自动化。  有趣的事实：在谷歌，通过改变现实去适应代码而不是通过修改代码去适应现实的方式被称为“购买侏儒”。这句话源自一个关于Froogle的故事，Froogle是一个很早就开展的购物搜索引擎服务。在Froogle的早期阶段，发生过精确匹配搜索“跑鞋”关键字导致返回了garden gnome(花园侏儒, 穿着跑鞋）的严重错误。在几次尝试修复错误失败之后，有人注意到gnome不是批量生产的商品，而是一个带有“一口价”选项的eBay商品。他们购买了这个“花园侏儒”商品后，解决了这个返回错误搜索结果的问题（译者注：相比起修改代码，以更低的成本解决了问题）。（图6-10）。 图6-10. 不会消失的花园侏儒 推动新系统的使用寻找方法来推动新用户采用更好的替代方案。在这种情况下，Moira需要升级系统配置以便应对新的请求和下线旧的系统。在服务设置中，新系统使用最佳实践和用户如何配置系统也很重要。Google团队经常使用codelabs或cookbook为用户提供常见用例设置和指导如何使用他们的服务。因此，大多数用户入手都不需要额外的团队的指导。结论与生产服务运行相关的琐事会随着系统复杂性和规模的增长而线性增长。自动化通常是消除琐事的黄金法则，并且可以与其他策略相结合。即使一些琐事没必要完全自动化，你也可以通过部分自动化或改变业务流程等策略来减少操作的负担。本章中描述的消除琐事的模式和方法可以推广到其他各种大规模生产服务中。消除琐事可以节省工作时间，以便工程师专注于服务的更重要的方面，并允许团队将手动任务保持在最低限度。随着现代服务架构的复杂性和规模不断增加，此策略尤其重要。但是要注意，消除琐事并不总是最好的解决方案。如本章所述，你应该考虑成本，设计、改造和实施自动化解决方案都需要投入成本。一旦决定减少琐事，就必确立目标，进行投资回报率（ROI）分析，风险评估和迭代开发来确定是否减少了工作量。琐事通常是从小事开始积累的，并且可以迅速成长最终消耗整个团队的人力资源。SRE团队必须坚持不懈地消除琐事——因为即使减少琐事的项目看起来令人生畏，但其好处通常也是会超过成本的。我们所描述的每个项目都需要各自团队的坚持不懈和奉献精神，他们有时会面对质疑或者需要与制度进行斗争，并且总是面临竞争这种高优先级的任务。我们希望这些案例鼓励你识别工作中的琐事，量化它，然后努力消除它。即使今天不能开展一个大项目，你也可以从一个小概念开始，这可以帮助改变你的团队处理琐事的方式。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第五章 SLO报警]]></title>
      <url>/sre/2020/01/05/SLO%E6%8A%A5%E8%AD%A6/</url>
      <content type="text"><![CDATA[本章介绍如何在发生重要事件时将SLO转换为可进行配置的报警。我们的第一本SRE和本书都讨论了实施SLO。我们相信，拥有好的SLO可以衡量你平台可靠性，正如你的客户所经历的那样，可以为on-call人员该如何迅速做出响应提供最准确的提示。在这里，我们提供了有关如何将这些SLO转换为报警规则的具体指导，以便你在消耗过多的错误预算之前响应问题。我们的示例展示了一系列报警指标和逻辑的复杂实现；讨论他们的功能和缺点。虽然我们的示例使用的是简单的request-driven服务和Prometheus语法，但你可以应用到任何报警框架中。报警注意事项为了从服务质量指标（SLI）和错误预算生成报警，需要一种方法将这两个元素组合成一个特定的规则。 你的目标是通知重大事件：消耗大部分错误预算的事件。在评估报警策略时，请考虑以下属性：精确度检测到的事件比例很重要。 如果每一个报警对应一个重大事件，则精度为100％。请注意，报警可能会在低流量时段对非重要事件变得特别敏感（在第86页的“低流量服务和错误预算报警”中讨论）。召回率检测到重大事件的比例。如果每一个重要事件都会发出一次报警，则召回率为100％。检测时间在各种条件下发送报警通知需要多长时间。较长的检测时间会对错误预算产生负面影响。恢复时间解决问题后报警会持续多长时间。较长的恢复时间可能导致混淆或问题被忽略。重大事件的报警方法为SLO构建报警规则可能会变得非常复杂。在这里，我们提出了六种方法来配置重要事件的报警，以提高精度，得到一个可以同时控制精度、召回、检测时间和恢复时间这四个参数选项。以下每种方法都解决了不同的问题，有些方法最终同时解决多个问题。前三个不可行的方法对后三个可行报警策略的应用是十分有益的，方法6是最可行和最强烈推荐的选择。第一种方法实现简单但不充分，而最佳方法提供了一个完整的解决方案，可以在长期和短期内保护SLO。出于本节讨论的目的，“错误预算”和“错误率”适用于所有SLI，而不仅仅是名称中包含“错误”的SLI。在第20页的“测量内容：使用SLI”一节中，我们建议使用SLI来捕获正常事件与总事件的比率。错误预算给出允许的错误事件的数量，错误率=错误事件/总事件的比率。1. 目标错误率≥SLO阈值对于最简单的解决方案，你可以选择一个小的时间窗口（例如，10分钟），并在该窗口内的错误率超过SLO阈值时发出报警。例如，如果SLO在30天内为99.9％，则在前10分钟的错误率≥0.1％时发出报警：- alert: HighErrorRate  expr: job:slo_errors_per_request:ratio_rate10m{job="myjob"} &gt;= 0.001            这个10分钟的平均值是用Prometheus的记录法则计算出来的:    record: job:slo_errors_per_request:ratio_rate10m    expr:        sum(rate(slo_errors[10m])) by (job)             /         sum(rate(slo_requests[10m])) by (job)            如果你不从job中导出slo_errors和slo_requests，则可以通过重命名度量值来创建时间序列：        record: slo_errors        expr: http_errors当最近的错误率等于SLO时发出报警意味着系统检测到以下预算消耗：           告警窗口/SLO期限 图5-1 设有10分钟报警窗口和99.9％SLO的示例服务的检测时间图5-1 显示了设有10分钟报警窗口和99.9％SLO示例服务的检测时间和错误率之间的关系。 表5-1 显示了即时错误率过高时发出警报的优缺点            优点      缺点                  检测时间良好：总停机时间为0.6秒(10600.1%, 10：分钟；60：秒；0.1%：上文所计算得到的10分钟的平均值)。      精度很低：报警会触发许多不会威胁SLO的事件。10分钟的0.1％错误率会发出报警，而每月错误预算仅消耗0.02％。              此报警会触发任何威胁SLO的事件，表现出良好的召回率。      极端情况下，你每天最多可以收到144个报警，即使不需要对此采取任何措施，并且服务仍然符合SLO      2. 增加报警窗口我们可以通过更改报警窗口的大小重新构建前面的示例，以提高精度。 通过增加窗口大小，你可以在触发报警之前消耗更高的预算。为了保持报警的数量可控，你决定仅在事件消耗30天错误预算的5％（一个36小时的窗口）时才收到通知 ：- alert: HighErrorRate  expr: job:slo_errors_per_request:ratio_rate36h{job="myjob"} &gt; 0.001现在，检测时间是：表5-2 显示了在较大的时间窗口内错误率过高时发出报警的好处和缺点 表5-2 在较大的时间窗口内错误率过高时发出报警的优缺点:             优点      缺点                  检测时间仍然很好：完全停机需要2分10秒(36600.1%, 36：小时；60：分钟；0.1%：上文所计算得到的10分钟的平均值)      非常差的恢复时间：在100％停机的情况下，报警将在2分钟后触发，并在接下来的36小时内持续              比前一个示例更精确：通过确保错误率持续更长时间，报警可能会对错误预算构成重大威胁      由于存在大量数据点，因此在较长窗口上计算速率在存储器或I/O操作方面可能代价较大      图5-2显示，虽然在36小时内，错误率已降至可忽略不计的水平，但36小时的平均错误率仍高于阈值。 图5-2  36小时内的错误率 3. 增加报警持续时间大多数监控系统允许你将持续时间参数添加到报警规则，因此报警不会被触发，除非该值在一段时间内保持在阈值之上。你可能想使用此参数作为低成本方式增加更长的窗口： - alert: HighErrorRate   expr: job:slo_errors_per_request:ratio_rate1m{job="myjob"} &gt; 0.001   for: 1h表5-3显示了使用持续时间参数进行报警的优缺点。 表5-3 使用持续时间参数进行报警的优缺点             优点      缺点                  报警可以更高精度。在触发之前需要持续的错误率意味着报警更可能对应于重大事件。      召回率和检测时间不佳：由于持续时间不随事件严重程度而变化，因此在100%服务中断一小时后才会发出报警，0.2%服务中断也会有相同的检测时间。100％的中断将消耗30天预算的140％。即使度量标准暂时返回到SLO内的级别，持续时间计时器也将重置。 当SLI在满足于不满足SLO之间波动时可能永远不会发出报警。      由于表5-3中列出的原因，我们不建议将持续时间用作基于SLO的报警标准的一部分图5-3显示了在报警触发前持续10分钟的服务窗口内5分钟内的平均错误率。每隔10分钟出现的持续5分钟的错误高峰永远不会触发报警，但是总体上看出错率是35%。 图5-3 每隔10分钟出现100%的错误 每个峰值消耗了30天预算的近12％，但报警从未触发。4. 关于消耗率的报警要改进以前的解决方案，你需要创建具有良好检测时间和高精度的报警规则。为此， 你可以引入消耗速率以减小窗口大小，同时保持报警预算花费不变。消耗速率是指相对于SLO，服务消耗错误预算的速度。 图5-4显示了消耗率和错误预算之间的关系。示例服务使用了100%消耗率，这意味着它正在消耗错误预算，其速率使您在SLO的时间窗口结束时只剩下0的错误预（请参阅第一本书中的第4章）。 在30天的时间窗口内SLO为99.9％，持续的0.1％错误率正好可以在一个月内消耗完所有错误预算：消耗率为100%。 图5-4 相对于消耗率的错误预算 表5-4显示了消耗速率，相应的错误率以及耗尽SLO预算所需的时间。 表5-4 消耗率和耗尽错误预算所需的时间             Burn rate      Error rate for a 99.9% SLO      Time to exhaustion                  1      0.1%      30days              2      0.2%      15days              10      1%      3days              1000      100%      43minutes      通过将报警窗口定为一小时，并设定当消耗掉当月5％的错误预算时发出告警，你可以得到用于报警的消耗率阈值。对于基于消耗率的报警，报警触发所需的时间为：(（1 - SLO）/错误率）*报警窗口大小*消耗率报警触发时消耗的错误预算为：消耗率*报警窗口大小/SLO期限1小时的告警窗口消耗掉30天错误预算的5%时，错误预算的消耗率为36。报警规则现在变为：- alert: HighErrorRate  expr: job:slo_errors_per_request:ratio_rate1h{job="myjob"} &gt; 36 * 0.001表5-5 显示了基于消耗率的报警的优缺点。 表5-5 基于消耗率报警的优缺点             优点      缺点                  良好的精确度：此策略选择大部分错误预算支出以提醒发出报警。更短的时间窗口，计算起来代价较小。 检测时间好。更好的恢复时间：58分钟。      低召回率：35%（与上下文的36相对）的消耗率永远不会发出报警，但会在20.5小时内消耗掉所有30天的误差预算。重置时间：58分钟仍然太长      5. 多次消耗率报警你的报警逻辑可以使用多个消耗速率和时间窗口，并在消耗速率超过指定阈值时触发报警。 此选项保留了消耗率报警的好处，并确保你不会忽略较低（但仍然很重要）的错误率。为事件设置工单通知也是一个好主意，这些事件通常会被忽视，但如果不加以控制可能会耗尽你的错误预算 - 例如，三天内预算消耗率为10％。 这种错误率可以捕获重大事件，但由于预算消耗率提供了足够的时间来处理事件，因此你无需紧急通知某人。我们建议在一小时内将2％的预算消耗和6小时内的5％预算消耗作为紧急通知是合理起始数量，并在三天内将10％预算消耗作为故障工单报警的良好基准。适当的数字取决于服务和基本的报警负载。对于更繁忙的服务，并且根据周末和假日的待命责任oncall， 可能需要六小时窗口的工单提醒。表5-6显示了消耗的SLO预算百分比的相应消耗率和时间窗口。 表5-6 建议的时间窗口和消耗率，以消耗SLO预算的百分比             SLO budget consumption      Time window      Burn rate      Notification                  2%      1hour      14.4      Page              5%      6hours      6      Page              10%      3day      1      Ticket      报警配置可能类似于如下规则：    expr: (            job:slo_errors_per_request:ratio_rate1h{job="myjob"} &gt; (14.4*0.001)        or            job:slo_errors_per_request:ratio_rate6h{job="myjob"} &gt; (6*0.001)          )    severity: page    expr: job:slo_errors_per_request:ratio_rate3d{job="myjob"} &gt; 0.001    severity: ticket图5-5显示了根据错误率的检测时间和报警类型。 图5-5 错误率检测时间和报警类型 多个消耗速率允许你根据响应速度调整报警以提供适当的优先级。如果问题在几小时或几天内耗尽错误预算，则发送有效通知是合适的。否则，在下一个工作日处理基于工单的报警通知则更合适。表5-7列出了使用多种消耗率的优缺点。 表5-7 使用多种消耗率的优缺点             优点      缺点                  能够根据关键值调整监控配置以适应多种情况:错误率高时快速报警;如果错误率很低但持续，最终会发出报警。良好的精度，与所有固定预算的部分报警方法一样。 因为是三天的时间窗口，所以有很好的召回率。能够根据人们对防御SLO的反应速度来选择最合适的报警类型      更多数据、窗口大小和阈值需要管理和推理。 由于三天的窗口，更长的恢复时间。 如果所有条件均为真，则要避免触发多个报警，你需要实施报警屏蔽。 例如：5分钟内10％的预算支出也意味着5％的预算在6小时内消耗完，2％的预算消耗在1小时之内。此方案将触发三个通知，除非监控系统足够智能以防止它这样做      6. 多窗口，多消耗率报警我们可以在第五节中增强多消耗率报警，以便仅在我们仍在快速消耗预算时通知我们 - 从而减少误报的数量。 为此，我们需要添加另一个参数：一个较短的窗口，用于检查在触发报警时是否仍在消耗错误预算。一个好的方案是将短窗口设为长窗口持续时间的1/12，如图5-6所示。 该图显示了报警阈值。 在经历了10分钟的15％错误之后，短窗口平均值立即超过报警阈值，并且在5分钟后长窗口平均值超过阈值，此时报警开始触发。 错误停止后5分钟，短窗口平均值降至阈值以下，此时报警停止触发。 错误停止后60分钟，长窗口平均值降至阈值以下。 图 5-6. 报警用的长短窗口 例如，你可以在前一小时和前五分钟超过14.4倍消耗率时发送工单级报警。 只有在消耗了2％的预算后，此报警才会触发，但通过在五分钟后停止发送而不是一小时后显示更好的恢复时间：我们建议将表5-8中列出的参数作为基于SLO的报警配置的起点。 表 5-8. 99.9%的SLO报警配置推荐的参数             Serverity      Long window      Short window      Butn rate      budget consumption                  Page      1hour      5minutes      14.4      2%              Page      6hours      30minutes      6      5%              Ticket      3day      6hour      1      10%      我们发现基于了多消耗率的报警是实现基于SLO的报警的有效方式。表5-9显示了使用多种消耗率和窗口大小的优点和缺点。 表5-9 使用多种消耗率和窗口大小的优点和缺点             优点      缺点                  灵活的报警框架，允许你根据事件的严重性和组织的要求控制报警类型	要指定的参数很多，这可能使报警规则难以管理      良好的精度，与所有固定预算的部分报警方法一样。不错的召回率，因为有三天的窗口	有关管理报警规则的更多信息，请参阅第89页的“按比例报警”      低流量服务和错误预算报警当出现问题需要提供有意义的信息且请求率较高时，详细说明的多窗口、多点消耗方法很有效。但是，这些方法可能会导致接收请求率较低的系统出现问题。如果系统具有较少的用户数或自然的低流量时段（例如夜晚和周末），则可能需要更改你的方法。在低流量服务中自动区分不重要事件更加困难。 例如，如果系统每小时收到10个请求，则单个失败的请求会导致每小时错误率为10％。 对于99.9％的SLO，此请求构成1,000x消耗率并立即发出报警，因为它消耗了30天误差预算的13.9％。 此方案在30天内仅允许七个失败的请求。 单个请求可能会因大量短暂且令人厌倦的原因而失败，这些原因与大型系统中断一样，不一定能用成本效益的方式解决。最佳解决方案取决于服务的性质：单个请求失败的影响是什么？ 如果失败的请求是一次性的、高价值的、没有重试的请求，那么高可用性目标可能是合适的。从业务角度来看，调查每个失败的请求都是有意义的。但是，在这种情况下，报警系统会延迟通知错误。我们建议使用几个关键选项来处理低流量服务：  人工生成流量以补偿来自真实用户的信号不足。  将较小的服务组合成更大的服务以用于监控目的。  修改产品，以便：          – 需要更多请求才能将单个事件限定为失败。      – 单一故障的影响较小。      人工生成流量系统可以模拟用户活动以检查潜在错误和高延迟请求。在没有真实用户的情况下，你的监控系统可以检测到模拟错误和请求，因此你的值班工程师可以在影响太多实际用户之前对问题做出响应。人工流量提供更多信号，并允许你重用现有的监控逻辑和SLO值。你甚至可能已经拥有大部分必要的流量生成组件，例如黑盒探测器和集成测试。生成人工负载确实有一些缺点。大多数需要SRE支持的服务都很复杂，而且系统控制面很大。理想情况下，系统应进行设计和更改，以便使用人工流量进行监控。 即使是非常重要的服务，你也只能合成用户请求类型总数的一小部分。 对于有状态的服务，更多的状态会加剧这个问题。此外，如果问题影响真实用户但不影响人工流量，则成功的人工请求会隐藏真实的用户信号，因此你不会收到用户看到的错误通知。合并服务如果多个低流量服务对一个整体功能有贡献，则将它们的请求组合到单个更高级别的组中可以更精确地检测重要事件并且具有更少的误报。 要使这种方法起作用，服务必须以某种方式相关联 ——你可以组合构成同一产品的一部分的微服务，或者由同一个二进制文件处理的多个请求类型。组合服务的缺点是单个服务的完全失败可能不算是重大事件。 通过选择具有共享故障域的服务（例如公共后端数据库），可以增加故障影响整个组的可能性。 你仍然可以使用较长时间的报警，最终可以100%的捕获单个服务故障。进行服务和基础设施更改对重大事件发出报警旨在提供足够的通知，以便在耗尽整个错误预算之前缓解问题。 如果你无法将监控调整为对短暂事件不太敏感，并且生成人工流量不切实际，则可以考虑更改服务以减少单个失败请求对用户的影响。 例如，你可能：  修改客户端以使用指数退避和抖动进行重试。  设置捕获最终执行请求的回退路径，这可以在服务器或客户端上进行。这些更改对于高流量系统非常有用，但对于低流量系统更是如此：它们允许在错误预算中有更多的失败事件，更多的普通信号，以及更多的时间在事件变得重要之前对其做出反应。降低SLO或增加窗口你可能还想重新考虑单个故障对错误预算的影响是否准确反映了其对用户的影响。 如果少量错误导致你丢失错误预算，你是否真的需要寻找工程师来立即解决问题？ 如果没有，用户会对较低的SLO同样满意。 通过较低的SLO，工程师只会收到更大的持续中断报警通知。一旦你与服务的利益相关者协商降低SLO（例如，将SLO从99.9％降低到99％），实施更改非常简单：如果你已经有系统用于报告，监控和报警，则基于 SLO阈值，只需将新SLO值添加到相关系统即可。降低SLO确实有缺点：它涉及产品决策。 更改SLO会影响系统的其他方面，例如对系统行为的期望以及何时制定错误预算策略。 这些其他要求对于产品而言可能比避免一些低信号报警更重要。以类似的方式，增加用于报警逻辑的时间窗口确保触发页面的报警更加重要并且值得关注。在实践中，我们使用以下方法的某种组合来警告低流量服务：  在这样做时产生虚假流量是可能的并且可以实现良好的覆盖  修改客户端，以便短暂的故障不太可能导致用户影响  聚合共享某种故障模式的较小服务  设置SLO阈值与失败请求的实际影响相对应极端可用性目标具有极低或极高可用性目标的服务可能需要特别考虑。 例如，考虑具有90％可用性目标的服务。 表5-8表示了当在一个小时内消耗了2%的错误预算时的报警。因为100%的宕机只会在那个小时消耗掉1.4%的预算，所以这个报警永远不会触发。如果你的错误预算是在很长一段时间内设置的，那么你可能需要调整报警参数。对于具有极高可用性目标的服务，100％中断的耗尽时间非常短。 对于每月目标可用性为99.999％的服务，100％的中断将在26秒内耗尽其预算——这比许多监控服务的采集周期小很多，更不用说生成报警时通过电子邮件和短信等通知系统传递它的目的端时间了。 即使报警直接发送到自动解决方案系统，问题也可能完全消耗错误预算，然后才能得到缓解它。收到通知说你只剩下26秒的预算并不一定是一个坏策略；这对于保护SLO是没有用的。 防御这种可靠性的唯一方法是设计系统，使100％中断的可能性极低。 这样，你可以在消耗预算之前解决问题。 例如，如果你最初将此更改推广到仅有1％的用户，并以1％的相同速率消耗错误预算，那么现在你要43分钟才能耗尽错误预算。 有关设计此类系统的策略，请参阅第16章。大规模报警在扩展服务时，请确保报警同样可扩展。 你可能想为各个服务指定自定义报警参数。 如果你的服务包含100个微服务（或等效地，具有100种不同请求类型的单个服务），这种情况很快就会积累起无法衡量的工作和认知负载。在这种情况下，我们强烈建议不要为每项服务单独指定报警窗口和消耗率参数，因为这样做很快就会变得势不可挡。确定报警参数后，将它们应用于所有服务。管理大量SLO的一种技术是将请求类型分组到大致类似的可用性要求的桶中。 例如，对于具有可用性和延迟SLO的服务，可以将其请求类型分组到以下存储桶中：CRITICAL对于最重要的请求类型，例如用户登录服务时的请求。HIGH_FAST适用于具有高可用性和低延迟要求的请求。 这些请求涉及核心交互功能，例如当用户点击按钮以查看他们的广告库存本月赚了多少钱。HIGH_SLOW对于重要但对延迟不太敏感的请求，比如用户单击按钮生成过去几年所有广告活动的报告，并且不希望数据立即返回。LOW对于必须具有某些可用性，但是对于用户来说几乎不可见的中断的请求 —— 例如，轮询处理程序以查看可能长时间失败而不会对用户产生影响的帐户通知。NO_SLO对于用户完全不可见的功能 ——例如，暗启动或显式位于任何SLO之外的alpha功能。通过对请求进行分组而不是在所有请求类型上放置唯一可用性和延迟目标，可以将请求分组到五个存储桶中，如表5-10中的示例所示。 表5-10  根据类似的可用性要求和阈值请求类桶             Request class      Availability      Latency @ 90%      Latency@99%                  CRITICAL      99.99%      100 ms      200 ms              HIGH_Fast      99.9%      100 ms      200 ms              HIGH_SLOW      99.9%      1000 ms      5000 ms              LOW      99%      None      None              NO_SLO      None      None      None      这些存储桶提供了足够的保真度来保护用户的满意度，但与一个更复杂、管理成本更高的系统相比，它的工作量更小，而且可能更精确地反映用户体验。结论如果你设置的SLOs是有意义的、可理解的，并且可度量，那么你可以配置报警，只有在错误预算中存在可操作的、特定的威胁时才通知值班人员。用于警告重大事件的技术包括从错误率高于SLO阈值时发出报警，到使用多级消耗率和窗口大小。 在大多数情况下，我们认为多窗口、多消耗率报警技术是保护应用程序SLO的最佳方法。我们希望我们提供了为你自己的应用程序和组织做出正确配置决策时所需的环境和工具。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第四章 监控]]></title>
      <url>/sre/2020/01/04/%E7%9B%91%E6%8E%A7/</url>
      <content type="text"><![CDATA[监控涉及到多种类型的数据，包括监控指标，纯文本日志，结构化日志，分布式跟踪日志， event introspection。 以上各种数据都有它们各自的用处，但是本章主要讨论监控指标和结构化日志。根据我们的经验，这两种数据最适合SRE的基础监控需求。从根本上讲，监控系统应当能够透视系统的内部，当需要判断服务的健康状态和诊断服务问题时，这是最关键的需求。在第一版SRE的第6章中给出了一些基本的监控方法，并且提到SRE监控他们系统的主要目的有：  当达到阈值时触发报警  诊断和分析服务问题  展示系统的可视化信息  获取系统资源使用情况或服务健康状况的变化趋势，以便做长期计划  比较变更前后的系统变化或一个实验的两组样本的不同这些用例的不同重要程度能指导你在选择或构建一个监控系统时做出权衡。本章讨论Google如何管理监控系统，并提供一些如何选择和运行监控系统的指导意见监控策略的特征在选择监控系统时，理解那些你关心的功能并对它们进行一个优先级的排序很重要。如果你正在评估一个监控系统，本节提到的这些特性可以帮助你思考哪种方案最适合你。如果你已经有一个在运行的监控系统了，你可以考虑使用现有解决方案的一些别的特性。根据你的需求，一个监控系统可能就能解决你所有的问题，也可能你需要组合好几个监控系统。速度不同的组织对于数据的时效性和获取数据的速度有不同的要求。你需要用到数据的时候，数据就应该立马可用。数据的时效性影响的是当系统出错后多长时间监控系统才会通知你。另外，不及时的数据可能会导致因为错误的数据而采取不合适的行动。举个例子，关于事故响应，事故的发生时间和监控系统能够反映出结果的时间间隔如果太长，你可能会认为某一个改动没有产生什么不好的影响，或者你认为这个修改和某一个结果之间没有联系。超过4到5分钟才能获取的数据将会显著地影响你快速响应。如果你是基于速度在选择监控系统，那你需要首先确定对速度的需求。当你查询大量数据时，数据的获取速度通常都是个问题。如果需要汇总多个监控系统的数据，图形的加载需要费一些时间。监控系统如果从输入数据生成新的时间序列，则可以对一些通用查询进行预先计算，从而加速图形的加载。计算很多应用场景都要求支持各种复杂计算。至少，你会希望能从监控系统获取几个月时间跨度的数据。没有长期数据的视图，你很难判断像系统增长性这样的长期趋势。关于粒度，汇总数据对于制作增长计划很有效。详细地存储每一个指标会有助于回答这样的问题：这样的异常行为以前发生过吗？但是，数据可能会耗费昂贵的存储空间，或者难以检索。理想的事件或资源消耗的指标是递增的计数器。利用计数器，监控系统可以基于时间做计算——比如，报告每秒的访问量。如果在更长的时间范围做计算，你就可以实现implement the building blocks for SLO burn-based alerting (see Chapter 5).最后，支持种类更齐全的统计函数很有用，因为细微的操作可能会掩盖不好的行为。当记录访问延迟时，算数平均数只能告诉你访问比较慢，而支持百分比计算的监控系统能让你一眼就看出是50%,5%还是1%的访问太慢。如果你目前的监控系统不支持直接的百分比计算，你可以采取下面的替代方案：通过把每一个访问的时间相加然后除以访问数量，从而计算出平均访问时间每一个请求写入日志，然后对日志记录进行扫描或取样，从而计算出百分比你也可以把原始的监控指标写到另一个离线分析系统中，用于生成周报或月报，或者执行一些难以在监控系统中直接进行的复杂的计算。交互界面一个健壮的监控系统应该允许你简洁地在图形（graph）中显示时间序列数据，同时也能将数据结构化到表或各种类型的图表（chart）中。Dashborad是显示监控信息的主要的界面，所以选择显示格式很重要，要能最清晰地显示你所关心的数据。可以选择热力图、直方图和对数刻度图。你可能需要为同一数据提供不同的视图给不同的用户。高级管理人员希望看到的信息跟SRE的大不相同。针对使用者专门创建对他们来说有意义的dashborad。每一组dashborad，对同一类型的数据显示要保持一致，这样方便沟通。你可能需要实时图形化显示某一指标的不同聚合结果，比如分别根据机器类型、服务器版本或请求类型进行聚合。It’s a good idea for your team to be comfortable with performing ad hoc drill-downs on your data。根据不同的指标对你的数据进行切片，在需要的时候你可以查找数据之间的联系和模式。报警报警分级很有必要，不同的级别采取不同的响应机制。 给报警设置不同的级别很有用，你可能会开一个工单用于跟踪一个低级别故障，调查可能会持续了一个多小时；100%的错误则属于紧急情况，需要立即响应。报警屏蔽功能能避免不必要的分散值班工程师精力的干扰。比如：  当所有的服务器都出现同样的高故障率时，可以只针对全局的高故障率报警一次，不需要为每个服务器单独发送报警。  当你的服务所依赖的服务报警时，不需要为你的服务发出故障报警。不要忘记，一旦故障事件处理完了，记得恢复被屏蔽的故障报警。你还需要确保在事件结束后不再屏蔽警报。监控系统的可控控制程度决定了你应该使用第三方的监控服务，还是部署和运行自己的监控系统。Google内部开发了自己的监控系统，但是外面有很多开源或商业的监控系统可供选择。监控数据的来源选择何种监控系统也受将要使用的监控数据源的影响。这节讨论两种常用的数据源：日志和指标。还有些其它的有用的监控数据源这里没有讨论的，比如分布式跟踪和运行时introspection.指标是属性和事件的数字度量，通常间隔一段固定的时间产生多个数据点。日志是只能追加的事件记录。本章的讨论主要集中在结构化日志，相比纯文本日志结构化日志更易于复杂查询和聚合工具。Google基于日志的监控系统处理大量细粒度（highly granular）数据。事件发生到log可见之间不可避免的有些延迟。日志分析并不要求即时性，可以先经过一个批处理系统的处理，然后运行一些特定的查询，并在控制面板展示。比如，可以先使用Cloud Dataflow处理日志，BigQuery做查询，Data Studio做控制面板。而我们的基于指标的监控系统，从Google的各种服务处收集了大量的指标，能几乎实时地提供粗粒度的信息。基本上其它基于日志或指标的监控系统有着和Google的系统类似的特性，当然也有例外，比如也有实时日志处理系统，或者细粒度的指标等。我们的报警和控制面板通常使用指标数据。指标监控系统的实时性能让工程师快速地发现问题。我们倾向于使用日志监控系统查找问题发生的根本原因，指标常常无法提供这方面的信息。报表不要求实时性，我们经常用日志处理系统来生成详细的报表，因为日志几乎总是比指标产生更准确的数据。如果你的报警是基于指标的，可能会临时增加一些基于日志的报警，比如你需要在某个异常事件发生时收到报警。就算你有这样的需求我们仍然推荐基于指标的报警系统，其实你可以在某个特殊事件发生时将计数器指标加一，然后创建一个基于这个指标的报警。这样做的好处是把所有报警配置都放在一个地方，便于管理（详见“管理你的监控系统”）。案例接下来这些真实的例子解释了如何选择不同的监控系统。将信息从日志移到指标问题。对于App Engine的用户来说，HTTP状态码对于错误诊断来说非常重要，它存在于日志而不是指标中。指标控制面板只能显示一个总的错误率，无法包含错误相关的其它信息，如错误码或者错误发生的原因。因此，诊断一个问题需要这样做：  检查总体错误率的图表，找到错误发生的时间  读取日志文件，查找包含错误信息的日志记录  尝试在错误日志和错误图表之间建立联系日志记录无法体现出“数量”，因此很难从日志判断某一个错误是否频繁发生。日志还包含很多其它不相关的信息，让查找错误的根源变得很难。建议的解决方案。 App Engine开发组决定将HTTP状态码输出成一个指标（比如，requests_total{status=404} 或者 requests_total{status=500})。由于不同HTTP状态码的数量是有限的，这样做不会导致指标数据的数据量大小增长到一个不可接受的水平，但是这些数据可以用于图表和报警。结果。新的指标允许App Engine的开发组升级监控图表，分别显示不同的错误类型。用户则可以基于错误码快速判断可能发生的问题。同时，我们还能为客户端和服务端错误分别设置不同的报警阈值，让报警更加准确。优化日志和指标问题。Ads SRE组维护这近50个服务，由不同的语言和框架开发。SRE组将日志作为检验SLO（SLO compiance）的权威数据源。为了统计错误情况，为每个服务编写了专门的日志处理脚本。这里有一个日志处理脚本的例子：If the HTTP status code was in the range (500, 599)AND the 'SERVER ERROR' field of the log is populatedAND DEBUG cookie was not set as part of the requestAND the url did not contain '/reports'AND the 'exception' field did not contain 'com.google.ads.PasswordException'THEN increment the error counter by 1问题。脚本很难维护，并且用了一些指标监控系统没有的数据。因为报警由指标驱动，有时候报警可能跟用户无关的错误引发的。每一个报警都需要一个显式分类的步骤来判断它是否跟用户相关，这拖慢了响应速度。建议的解决方案。 SRE组开发了一个库，植入到业务处理系统中，如果判断出某一个错误会影响用户的请求，将判断的结果写入日志并且导出一个指标数据，提高日志和指标的一致性。如果指标显示某个服务返回了错误，日志包含那个错误以及一些请求相关的数据，帮助重现和诊断错误。日志中任何SLO相关的错误同时也会改变SLI指标，SRE组可以据此创建报警。结果。通过创建一个跨服务的统一控制接口，运维组重用了工具和报警逻辑，避免为不同的服务重复开发运维系统。去除了复杂的、服务特定的日志处理逻辑，所有的服务都从中受益，获得了扩展性的提升。一旦报警跟SLO直接绑定就变得清晰可执行了，因此错误报警显著减少为数据源保留日志问题。 在诊断生产环境中的问题时，运维组经常会查看受影响的实体ID，判断对用户的影响和问题的根源。在App Engine早期的时候，这样的调查工作需要用到只有日志中才有的数据。处理每个事故，运维组不得不执行一些一次性的查询，这就增加了事故恢复的时间——需要几分钟来编写正确的查询，然后花些时间查询日志。建议的解决方案。 起初，运维组讨论了是否应该用指标来代替日志。然而，实体ID可能有几百万种不同的值，要把它们做成指标不太可行。最终，运维组决定编写一个脚本来执行那些一次性的查询，并在报警邮件中说明需要运行哪个脚本。在需要的时候，运维人员可以直接把脚本拷贝到命令行执行。结果。运维组不再需要花太多精力管理一次性查询，获取结果的速度也更快了（尽管还没到指标查询那么快）。他们还有一个备用方案：报警发生时自动运行脚本，用一个小服务器定时查询日志，能获得半实时(semi-fresh)的数据。管理你的监控系统你的监控系统与你运行的任何其他服务一样重要。 因此，应该给予适当的关注。将配置视为代码将系统配置作为代码处理并存储在版本控制系统中是常见的做法，好处也很明显：更改历史记录，从特定更改到任务跟踪系统的链接，更简单的回滚和格式检查，以及强制执行的代码审查过程。我们强烈建议你将监控配置视为代码（有关配置的更多信息，请参阅第14章）。 支持文本缩进配置的监控系统比仅提供Web UI或CRUD样式API的系统更好。对于很多开源程序，这是标准的配置方法，它们只从配置文件读取信息。 一些第三方配置解决方案（如grafanalib）为传统UI配置增加了文本配置的方式。鼓励一致性大型公司会有多个工程团队使用监控系统，他们需要寻求一种良好的平衡：集中式的监控系统保证了一致性，但另一方面，各个团队可能希望自己能完全决定配置的设计。正确的解决方案取决于你的组织。 谷歌的方法随着时间的推移逐渐发展为基于单一框架的集中式监控服务。 说这套解决方案适用于我们有几个原因。 单一的框架使工程师在换团队时能够更容易上手，并使调试过程中的协作变得更加容易。 我们还提供集中式仪表盘服务，每个团队的仪表盘对于其它团队都是可发现和可访问的。 如果你很容易了解其他团队的仪表盘，则可以更快地调试你们的问题。如果可能，尽量让基本监控覆盖很容易做。 如果你的所有服务都导出一组一致的基本指标，则可以在整个组织中自动收集这些指标，并提供一组一致的仪表盘。 这也意味着任何新组件都自动具有基本监视功能。公司的许多团队 - 甚至是非工程团队 - 都可以使用这些监控数据。倾向于松耦合随着业务需求的变化，一年后您的生产系统看起来会有所不同。 同样，你的监控系统需要随着时间的推移而发展，因为它监控的服务会出现不同的故障模式。我们建议保持监控系统的组件松耦合。 你应该有稳定的接口来配置每个组件和传递监控数据。 但负责收集、存储、警告和可视化的组件应该相互独立。 稳定的接口使得更换任何给定组件更容易，如果你有更好的替代组件的话。将功能拆分为单个组件在开源世界中变得越来越流行。 十年前，像Zabbix这样的监控系统将所有功能集中到一个组件中。现在的设计通常将收集和规则评估（使用Prometheus服务器之类的解决方案）、长期时间序列存储（InfluxDB）、警报聚合（Alertmanager）和仪表盘（Grafana）等拆分开来。在本书撰写时，至少有两种流行用于检测软件和输出指标的开放标准：statsd度量聚合守护进程最初由Etsy编写，现在移植到大多数编程语言中。Prometheus一种开源监控解决方案，具有灵活的数据模型，支持指标标签和强大的直方图功能。 Prometheus正在被标准化为OpenMetrics，其他系统现在也采用Prometheus格式。独立的仪表盘系统可以使用多个数据源的数据，对服务状态进行集中的统一的展示。 谷歌最近在实践中看到了这一好处：我们的旧监控系统（Borgmon3）将仪表盘与报警规则放在同一配置中。在迁移到新系统（Monarch）时，我们决定将仪表盘移动到单独的服务（Viceroy）中。 由于Viceroy不是Borgmon或Monarch的组成部分，因此Monarch的功能要求较少。 由于用户可以使用Viceroy显示来自两个监控系统的数据，因此他们可以逐渐从Borgmon迁移到Monarch。有目的的指标第5章介绍了在系统的错误数阈值快接近时如何使用SLI指标进行监控和报警。 SLI指标是您在基于SLO的警报触发时要检查的第一个指标。 SLI指标应显示在服务仪表盘的显眼位置，最好位于其首页上。在调查SLO报警触发的原因时，你很可能无法从SLO仪表盘获得足够的信息。 这些仪表盘告诉你SLO被触发了，但不会告诉你为什么。 监控仪表盘还应显示其它哪些数据？我们发现了一些指定指标的指导意见。 指标应提供合理的监控，便于调查生产环境的问题，同时提供有服务相关的很多信息。预期的变化在诊断SLO报警时，你需要能够从告知你有影响用户的问题发生的报警指标切换到能让你知道问题根源的指标。 最近对服务进行的预期更改可能是错误的。添加一些能监视生产环境中的任何改动的指标。对于监控触发条件，我们有如下的建议：  监控二进制文件的版本。  监控命令行参数，尤其是在使用这些参数开启和禁用某些服务功能时。  如果配置数据动态推送到你的服务，请监视此动态配置的版本。如果系统中的任何部分未进行版本控制，你可以监控上次编译或打包的时间戳。当你尝试将服务中断与上线关联起来时，查看与报警链接的图表/仪表盘要比查看CI / CD（持续集成/持续交付）系统日志更容易。服务依赖即使你的服务没有更改，其任何依赖项都可能会更改或出现问题，因此你还应该监视来自直接依赖项的响应。将每一个服务依赖项返回的字节数、延迟和响应代码都输出。 在选择图标展示指标时，请牢记四个黄金信号。你可以给指标额外定义标签，通过响应代码，RPC（远程过程调用）方法名称和服务依赖项的名称对指标进行进一步细分。理想情况下，你可以检测较低级别的RPC客户端库以导出这些度量标准，而不是要求每个RPC客户端库导出它们.检测客户端库提供更高的一致性，并允许你免费监控新的依赖关系。你有时会遇到提供非常狭窄的API的依赖项，其中所有功能都可通过名为Get，Query或同样无用的单个RPC获得，并且实际命令被指定为此RPC的参数。 客户端库中的单个检测点与此类依赖关系不符：你将观察到延迟的高度变化和一些百分比的错误，这些错误可能会或可能不会表明此不透明API的某些部分完全失败。 如果这种依赖关系很重要，那么你有几个选项可以很好地监控它：  导出单独的度量标准以定制依赖关系，以便度量标准可以解压缩它们收到的请求以获取实际信号。  要求依赖项所有者执行重写以导出更广泛的API，该API支持跨单独的RPC服务和方法拆分的单独功能。资源容量目的是监视和跟踪服务所依赖的每种资源的使用情况。 某些资源具有你不能超过的硬限制，例如分配给你的应用程序的RAM，磁盘或CPU配额。 其他资源（如打开文件描述符，任何线程池中的活动线程，队列中的等待时间或写入的日志量）可能没有明确的硬限制，但仍需要管理。根据使用的编程语言不同，你还应该监视些其他资源：  对于Java：堆和元空间大小，以及根据垃圾收集类型不同而使用一些特殊指标  对于Go：协程的数量语言本身为跟踪这些资源提供了不同的支持。 除了如第5章所述警告重大事件之外，你可能还需要设置当某些特定资源接近耗尽时触发的报警，例如：当资源有硬性的上限时  当资源使用超过阈值会导致性能下降时  你应该对所有的资源都设置监控 - 即使是服务本身能很好地管理的资源。 这些指标对于容量和资源规划至关重要。服务流量状况最好能增加跟流量相关的指标或指标标签，以便仪表盘按状态代码显示详细的流量情况（除非你的服务用于SLI目的的指标已包含此信息）。以下是一些建议：  对于HTTP流量，监视所有响应代码，即使它们没有达到报警的级别，因为某些响应代码可能由不正确的客户端行为触发。  如果你对用户设定了频率速率限制或流量限制，监控系统应当统计有多少用户的请求因为流量限制被拒绝了。流量监控图表可以帮助你确定一个线上的改动在何时导致了显著的错误数量的变化。指定有目的指标每个输出的指标都应该有用它的目的性。 不要仅仅因为某些指标很容易产生就轻易地将它们输出。 相反，应该想想输出的这些指标会被如何使用。Metric design, or lack thereof, has implications。理想情况下，用于报警的指标只在系统出问题时发生显著的变化，而在系统正常运行时不会变化。 但是，调试用的指标没有这些要求 - 它们旨在告诉我们当报警触发时系统内部发生了什么。 好的调试指标能指示系统中可能导致问题的地方。 编写事后调查时，想一下还有其它哪些指标能帮助你更快地诊断问题。测试报警逻辑在理想情况下，监控和报警的代码应遵循与系统开发代码相同的测试标准。虽然Prometheus的开发人员正在讨论开发用于监控的单元测试，但目前广泛采用的监控系统还没有单元测试的支持。在Google，我们使用领域特定的语言测试我们的监控和警报，该语言允许我们创建合成时间序列（synthetic time series）。 然后，我们根据派生时间序列中的值，或特定报警的触发状态以及标签是否存在来编写测试断言。监控和报警通常是一个多阶段过程，因此需要多个单元测试集。 这个领域仍然有待发展，但如果你想在某个时候实施监控测试，我们建议采用三层方法，如图4-1所示。 图4-1：报警逻辑测试   二元报告：检查输出的标准的值是否在预期的某些条件下发生变化。  监控配置： 确保规则评估产生了预期的结果，并且特定条件会产生预期报警。  警报配置： 测试生成的报警是否按照报警的标签值路由到了预定目的地。如果你无法综合测试监控系统，或者你的监控的某一个阶段无法进行测试，可以考虑创建一个运行系统来输出一些公认的指标，例如请求数和错误数。 你可以据此来验证时间序列和报警。 你的报警规则很可能在设置之后的几个月或几年内都不会触发，你需要确信当指标超过某个阈值时，有意义的报警通知会发给正确的工程师。结论由于SRE角色负责生产系统的可靠性，SRE通常需要非常熟悉服务的监控系统及其功能。如果没有这方面的知识，SRE可能不知道在哪里查看监控，如何识别异常行为，或者如何在紧急情况下找到所需的信息。我们希望通过指出我们认为有用的监控系统功能及其为什么我们认为它们有用，可以帮助你评估监控策略和需求有多匹配，探索你可能能够利用的一些其他功能，并考虑你可能想要做出的改变。也许你会发现将一些指标和日志监控结合起来的策略很有用;具体如何结合取决于应用场景。注意收集的指标要有其目的性，可能是为了更好地进行容量规划，辅助调试或直接通知你发生了什么问题。一旦你有了监控系统，需要确保它可见且可用。 为此，我们还建议你测试你的监控设置。良好的监控系统能带来好的回报。好好想想什么样的监控系统最适合你的需求，不断地摸索直到找到最好的那个，这是一笔很值得的投资。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第三章 SLO工程案例学习]]></title>
      <url>/sre/2020/01/03/SLO%E6%A1%88%E4%BE%8B%E5%AD%A6%E4%B9%A0/</url>
      <content type="text"><![CDATA[  名次解释：      SLI：服务质量指标、该服务的某项服务质量的一个具体量化指标。例如：延迟、可用性    SLO：服务质量目标、服务的某个SLI的目标值/范围。例如：搜索请求的平均延迟 &lt; 100ms。    SLA：服务质量协议、服务与用户之间的一个明确的协议，描述达到/未达到SLO之后的后果。    错误预算： 1 - 可靠性目标  尽管SRE的许多原则都是在Google内部形成的，但它的原则早已存在于Google之外。许多Google SRE的标准已被业内多个组织实践应用。SLO是SRE模型的基础。自从我们组建了客户可靠性工程（CRE）团队——这是一组帮助Google Cloud Platform（GCP）客户构建更可靠的服务的经验丰富的SRE——几乎与每个客户交互都以SLO开始以SLO结束。我们在这里介绍了两个不同行业的公司事迹，概述了他们在与Google CRE团队合作时采纳SLO和基于错误预算的方法的过程。有关SLO和错误预算的讨论，请参阅本书的第2章和第一本书的第3章。Evernote的SLO故事Evernote是一款跨平台的APP，可帮助个人和团队创建、整合和共享信息。在全球拥有超过2.2亿用户，我们在平台内存储了超过120亿条信息——包括文本笔记、文件和附件/图像。在后台，Evernote服务由750个以上的MySQL实例支持。我们向Evernote引入了SLO的概念，并将其作为更广泛的技术改造的一部分，旨在提高工程速度，同时保持服务质量。我们的目标包括：将工程重点从数据中心中冗余的繁重工作转移到客户实际关心的产品工程工作上。为此，我们停止运行物理数据中心并转移到公有云。调整运维和软件工程师的工作模式，旨在保持整体服务质量的同时提高变更速度。改进我们对SLA的看法，以确保我们更加关注故障对庞大的客户群所造成的的影响。这些目标对许多行业的组织而言可能都很熟悉。虽然没有一种方法可以全面实现这些类型的变更，但希望我们分享的经验可以为面临类似挑战的人提供有价值的参考意见。为什么Evernote采用SRE模型？过渡开始阶段的Evernote的特点是传统的运维和开发分离：运维团队维护生产环境的稳定性，而开发团队的任务是为客户开发新的产品功能。这些目标通常是冲突的：开发团队 感觉被繁琐的流程所束缚，而运维团队又会因新代码在生产环境中引入新的问题变得不满。 当我们在这两个目标之间不断动摇时，运维和开发团队之间蔓延了一种不满和紧张的关系。我们希望达到一个双方都满意的节点，更好地平衡所涉及团队的不同需求。在五年多的时间里，我们尝试了各种方式解决这种传统二分法中的差距。在尝试了你编码，你运行的开发模式，以及你编码，我们为你运行的运维模式之后，我们转向了以SLO为中心的SRE方法。那么是什么促使Evernote向这个方向发展呢？在Evernote，我们将运维和开发的核心目标视为工程师专业化的独立发展方向。一个方向关注的是近乎7*24小时地持续为客户提供服务。另一个关注的是服务的扩展和发展，以满足客户未来的需求。近年来，这两个方向已经越来越接近，例如SRE和DevOps强调将软件开发应用于运维。（数据中心自动化和公有云的发展进一步推动了这种融合，这两者都为我们提供了一个可以完全由软件控制的数据中心。）另一方面，全栈所有权和持续部署也越来越多地应用于软件开发。SRE模型完全接受并包容了运维和开发间的差异，同时鼓励团队朝着共同的目标努力。它并不试图将运维工程师转变为应用程序开发人员，反之亦然。相反，它给出了一个共同的参考框架。根据我们的经验，由于使用错误预算/SLO方法的两个团队在交流时很少带着主观感情，所以在面对同样的情况时通常会做出类似的决定。SLO简介：正在进行的旅程旅程的第一步是从物理数据中心迁移到Google云平台。当Evernote服务在GCP上稳定运行后，我们就引入了SLO。我们的目标有两个：确保所有团队都在Evernote SLO的新框架内工作。将Evernote的SLO纳入我们与Google 云团队的合作中，他们现在负责我们的底层基础架构。由于在整体模型中加入了新的合作伙伴，因此我们需要确保迁移到GCP不会影响我们对用户的承诺。在使用SLO约9个月后，Evernote已经开始实践使用其SLO的第3版了！在深入了解SLO的技术细节之前，要先从客户的角度开始提问： 你可以提供哪些承诺？与大多数服务类似，Evernote具有许多功能和选项，用户可以通过各种创造性方式使用这些功能和选项。我们希望在一开始就关注最重要和最常见的客户需求：Evernote服务的可用性，以便用户能够访问和同步多个客户端的内容。我们的SLO之旅从这个目标开始。通过关注服务正常运行时间， 我们完成了接入SLO的第一步。使用这种方法，我们可以清楚地表达我们衡量的内容以及衡量方法。我们的第一份SLO文件包含以下内容：SLO的定义这是一个（服务、系统）可用时间的计算方法：为某些服务或者是方法，在月级别的统计周期内设定了99.95%的可用性。这个数据是我们基于内部客户支持团队、产品团队，尤其重要的是用户共同讨论得来的。我们特意选择将SLO和日历月而不是与滚动的时期进行关联，就是为了使我们在进行服务复查时保持专注有序。度量什么，以及如何度量它      度量指标   我们指定了一个服务终点，我们可以调用它来测试服务是否按预期运行。在我们的例子中，我们在服务中内置了一个状态页面，它可以运行我们的大部分堆栈并返回200状态代码（如果一切正常）。        如何度量   我们想要一个定期调用状态页面的探测器。我们希望探测器完全位于我们的环境之外并独立于我们的环境，因此我们可以测试所有组件，包括负载均衡。我们的目标是确保我们可以统计到GCP服务以及evernote应用任何、所有异常。但是，我们不希望随机网络问题触发误报。我们选择使用专门建立和运行此类探测器的第三方公司。我们选择了Pingdom，但市场上还有很多其他产品。我们按如下方式进行衡量：          探测频率：我们每分钟轮询一次前端节点。      探测器的位置：此设置是可配置的; 我们目前在北美和欧洲使用多个探测器      “down”的定义：如果一个探测器检测结果为失败，那么这个节点会被标记为疑似宕机，然后第二个基于不同地理位置独立部署的探测机会进行第二次确认。如果第二次检查同样也失败了，出于计算SLO的目的这个节点会被标记为宕机。只要探测请求持续显示错误，那么这个节点会被持续标记为宕机。      #### 如何从监控数据计算SLO   最后，我们仔细记录了我们如何根据从Pingdom收到的原始数据计算SLO。例如，我们指定了如何考虑维护窗口：我们无法假设我们所有的数亿用户都知道我们发布的维护窗口。因此，不知情的用户会将这些窗口视为通用和无法解释的停机时间，因此我们的SLO计算将维护视为停机时间。一旦我们定义了SLO，我们就必须使它发挥最大的价值。 我们希望SLO能够推动软件和运维方面的变革，让我们的客户更快乐并让他们满意。 怎么做到最好？我们用SLO中有关错误预算的思维为方法来分配下一步工作的需要的资源。举例来说，如果我们没有达成上个月的SLO，这会促使我们高优（对系统、服务）进行目标明确的加固、改进和修复。我们制定最简原则：evernote团队以及google团队共同进行月级别 的SLO目标复查。在这个会议上，我们复核SLO的表现并对所有服务中断行为进行深入研究。基于针对上个月的上述分析而不是根因分析，我们制定了一些改进措施。在整个过程中，我们的指导原则是“过犹不及”。即使在SLO还没有达到完美的时候，它也足以在此期间指导我们进行改进。一个“完美”的SLO应该可以衡量每一个与我们服务有关的潜在用户交互设计并且解释所有的边界行为。虽然字面上看起来这是个好主意，但是如果要实现起来却要花费数月的时间去改进服务（如果真的可以这到完美）。相反，我们选择了一个初始SLO，涵盖了大多数（但不是全部）用户交互，这是服务质量的良好代理。自从我们开始执行SLO以来，根据从服务复盘以及响应客户有感的宕机事件中得到的启示，我们对SLO做了两次修改。因为我们一开始就没有追求完美SLO，为了适应业务的发展我们乐于做出改变。除了evernote团队与google进行月级别SLO复盘之外，我们也设定了一个6个月的SLO复盘周期，这个周期可以使SLO的维护达到一个平衡：既不会频繁更新，也不会使之过时。在不断修订SLO的过程中，我们也意识到了，期望的衡量标准和可以达到的衡量标准之间的平衡是很重要的。自引入SLO以来，我们的运维和开发团队之间的关系有了微妙但显著的改善。现在团队对成功有了共同的衡量标准，那就是：取消对服务质量的人为解释使两个团队达成了共同的观点和标准。在此我们试着举一个例子，2017年当我们不得不在短期内推动多个版本的发布任务时，SLO为我们提供了共同基础。当我们发现一个复杂的bug时，产品开发团队要求我们将常规的周级别发布任务分配到多个独立的发布窗口，每个发布窗口都会对客户产生潜在的影响。通过对问题进行有针对性的SLO计算以及消除方案中的人为主观因素，我们可以更好的量化客户感受并且通过把发布窗口由5个降为2个从而达到了减少了客户痛点的目的。打破客户与云服务商之间的隔阂介于客户和云服务商之间的隔阂看起来是在所难免的。虽然google已经为运行evernote的GCP平台设定了SLO和SLA（服务等级协议），但是evernote有自己的SLO和SLA。期望两个技术团队会将彼此的SLA告知对方看起来是不现实的。evernote不希望存在这样的隔阂。当然我们也可以基于自己的SLO和底层的GCP平台的SLA建立起隔离域，相反从一开始我们就希望google可以理解性能表现对我们来说是多重要以及为什么这么重要。我们期望google和我们在目标上达成一致，让两家公司把evernote在可靠性方向的成败当作共同的职责。为了实现这一目标，我们需要一种方法可以：  达成一致的目标  确保我们的合作伙伴（在此指google）真正清楚我们最关心哪些指标  共担成败大多数服务商都为自己的云服务发布了SLO/SLA。虽然服务运行在此框架下很重要，但这并不能全面的反映我们的服务在云服务商的环境中运行的状况。例如，一个给定的云服务商可能在全球运行了数十万台虚拟机，他们为这些虚机的正常运行和可靠性负责。GCP承诺计算引擎（也就是虚机）可以达到99.95%的可靠性。即使当GCP SLO指标显示为绿色的时候（即可靠性高于99.95%），evernote的监控视图的表现可能完全不同：因为我们的虚机在GCP全球总量虚机中仅占有很小的比例，会使导致我们（服务所在）区域成为孤岛（或由于其他原因导致成为孤岛）的故障最终在全球级别的汇总中被忽略。为了修正这样的情况，我们将我们的SLO和未达成SLO的实时性能与goolge进行共享。因此，Google CRE团队和Evernote团队基于同样的性能仪表盘展开合作。这看起来似乎是一个很简单的观点，但最终被证明是一种相当有效的、可以形成真正以客户为中心的工作方法。因此，google会向我们提供更明确的环境运行情况通知，而不是那种泛泛的“x服务当前运行缓慢”的通知。举例来说，除了那种泛泛的“今天GCP负载均衡环境运行缓慢”之外，我们还会被告知这个问题已经对evernote的SLO造成了5%的影响。这种关系也有助于google内部团队了解他们的行为和决策是如何影响用户的。这种双向关系也为我们提供了一个非常有效的框架来应对重大事件。大多数情况下，P1-P5级别的工单和常规的支持渠道配合使用，产生了很好的效果，使我们能够提供稳定的服务，并与谷歌保持良好的合作关系。但众所周知，当你整个在线服务面临着拓展业务增长的压力的时候，P1级别的工单是不能满足要求的。这时，我们与CRE团队共享的SLO和（合作）关系得以实现。我们达成共识，如果SLO影响足够高，双方都会将该问题视为P1级别进行特殊处理。这就意味着evernote和google的cre团队经常要快速组织起一个可以共享的沟通渠道。Google CRE团队监控（管理）我们共同定义和商定的SLO，使我们在优先级和恰当响应方面保持同步。当前状态协调目标确保我们的合作伙伴（在本例中为Google）真正了解对我们重要的内容分享成功和失败在积极使用SLO大约九个月之后，Evernote已经在使用SLO实践的第三版了。下一个版本的SLO会以我们当前简单正常运行时间的SLO为基础进行改进。我们将关注单个API调用和客户端的指标/性能视图，以便更好地表示用户QoS。通过提供标准定义的QoS测量方法，SLO使Evernote更关注我们的服务是如何运行的。我们内部或者和谷歌进行以数据为驱动的对话，了解服务中断的影响，这能够推动服务改进，最终建立更强大的支持团队，使客户更满意。Home Depot的SLO故事Home Depot（THD）是全球最大的家居装饰零售商：我们在北美拥有2,200多家商店，每家商店都拥有超过35,000种产品（网站上有超过150万种产品）。 我们的基础架构托管各种软件应用程序，支持了近400,000名员工每年处理超过15亿的客户交易。这些商店由全球供应链和每年访问量超过20亿次电子商务网站紧密组成。最近为了提高我们软件开发的速度和质量，THD转向敏捷软件开发并改变了我们设计和管理软件的方式。我们从支持大型软件包开发的团队转变为小型独立的微服务架构开发团队。因此，我们的系统现在由一系列不断变更的微服务组成，这些微服务也是通过堆栈整合而成。我们向微服务转变的过程中，全栈所有权获得了新的“自由和责任文化”的补充。这种方法使开发人员可以自由地在需要时推送代码，同时也使他们为他们对服务的操作负责。对于这种共同所有权工作模式，运维和开发团队需要达成一种共识，即促进责任制和减少复杂性：SLO。相互依赖的服务需要知道如下信息：如果每项服务都能为这些问题提供明确的和一致的答案，那么团队就可以清楚地了解服务的依赖关系，从而达到更好地沟通，增强团队之间的信任和责任感。SLO文化项目在我们的服务模式开始转变之前，Home Depot没有SLO文化。监控工具和仪表盘特别多，但都分布在各处，并且不会随着时间的推移记录数据。我们并不总能查出服务中断的根因。我们通常从遇到的服务问题开始排查，直到我们发现问题为止，这浪费了无数个小时。如果服务需要计划停机时间，其依赖服务就会受不了。如果一个团队需要构建一个99.95%的服务，他们不确定有严格依赖的服务能否达到99.99%的标准。这些未知导致我们的软件开发团队和运维团队之间的疑惑和失望。我们需要通过建立SLO的共同文化来解决这些问题。因此，需要一个影响人员、流程和技术的总体战略。 我们的努力跨越了四个方面：  内部名词规定：  在THD（Home Depot）公司内部定义SLOs。 来说明如何以一致的方式来进行度量。福音主义在整个公司传播这个词。通过给销售提供培训资料，在公司进行路演、内部博客、宣传资料比如T恤和贴纸等方式，传播为什么SLO很重要。争取一些早期采用者来实施SLO并向其他人展示其价值。建立一个感兴趣的首字母缩略词（VALET;稍后讨论）以帮助传播这个想法。创建培训计划（FIRE学院：可靠性工程基础），对开发人员进行培训使其了解SLO和其他可靠性概念。自动化为了降低指标收集的难度，用一个指标收集平台去自动收集生产环境中的服务的服务等级指标。这些SLI以后可以更容易地转换为SLO。激励为所有开发经理制定年度目标，为其服务设置和衡量SLO。每个人达成共识很重要。我们还希望保持这个框架尽可能简单，以帮助这个想法更快地传播。为了开始，我们仔细研究了我们在各种服务中监控的指标，并发现了一些模式。每项服务都会监控某种形式的流量、延迟、错误和利用率指标，这些指标与Google SRE的四个黄金指标密切相关。此外，许多服务都可以从错误中明显监控正常运行时间或可用性。很遗憾，整体来看，并不是所有类型的采集项都统一添加了监控、统一了命名、或者有足够的监控数据。我们的服务都没有SLO。我们的生产系统与面向客户的SLO最接近的指标是（用户）支持数据。通过跟踪商店内咨询台接收到的支持电话数量，是我们评价部署在我们商店的应用可靠性的主要（大多数时候是唯一）方法。我们的第一套SLO我们不能对一个可度量系统的每个方面都创建SLOs，因此我们必须确定系统的哪些指标或SLIS应该具有SLOs。API调用的可用性和延迟我们决定对微服务之间的API调用设置可用性和延迟SLOs。例如，Cart微服务调用Inventory微服务。针对那些API调用，Inventory微服务发布了SLOs，Cart微服务（以及需要Inventory的其他微服务）可以获取这些SLOs并以此决定Inventory微服务是否能满足可靠性要求 基础设施利用/基础设施利用率。基础设施利用率THD团队通过不同的方式来衡量基础设施利用率，而最典型的衡量标准是分钟级别的实时基础设施利用率。我们基于某些原因并不会设置这种利用率SLOs。首先，微服务并非十分关注这个指标-只要服务可以承载流量，服务器正常运行、响应速度很快、不抛错误，且并不会耗尽容量，那么你的用户就不会真正关心利用率。此外，计划迁移服务到云端意味着资源利用率不是重点，这时我们要关注的是成本规划，而不是容量规划。（我们仍然需要监控利用率并执行容量规划，但不需要将其包括在我们的SLO框架内。）流量由于THD没有进行容量规划的传统，因此我们需要一种机制，该机制能让开发和运维团队就其服务可以承载的流量进行沟通。流量通常被定义为对服务的请求，但我们需要确定是否应该跟踪平均每秒请求数，每秒峰值请求数或报告时间段内的请求数。最终我们决定跟踪这三项，并给每项服务选择最合适的指标。我们讨论是否为流量设置SLO的原因在于这个指标是由用户行为决定的，而非我们可控的内部因素决定。我们要讨论是否为流量设置SLO，因为流量的衡量跟用户行为密切相关，我们可控的内部因素无法发挥决定作用。 最终我们认为，作为零售商，我们需要为应对黑色星期五这样的活动流量峰值增加服务的规模，并根据预期的峰值流量设置SLO。延迟我们给每个服务定义了延迟SLO并确定其最佳的衡量方式。这里我们只要求服务应该通过黑盒监控来补充我们常见的白盒性能监控，以捕获由网络或诸如缓存以及微服务外部代理失效等层面的问题。并且，我们认为，采用百分位数比算术平均值更合适。服务最少需要达到90％的目标，而面向用户的服务则最好达到95%或99%的目标。错误错误解释起来有点复杂。由于我们主要处理Web服务，因此我们必须将错误内容以及返回结果标准化。如果Web服务发生错误，我们自然会对HTTP响应代码进行标准化：  在服务的返回内容中，不应该用2xx来标记错误; 相反，一个错误应该抛出4xx或5xx。  由服务端问题（如内存不足）引起的错误应该抛出5xx错误。  客户端错误（如发送错误格式的请求）应该抛出4xx错误.一番考虑后，我们决定跟踪4xx和5xx错误，但仅使用5xx错误来设置SLOs。与定义其他相关SLO的方法类似，我们采用通用形式来定义错误SLO，以便不同环境中的不同应用都可以使用该SLO。例如，除HTTP错误外，定义一个批处理服务的错误，可能是该服务无法处理记录的个数。工单正如前面提到的，工单最初是我们评估大多数生产软件的主要方式。由于历史原因，在我们其他的SLOs中，我们决定继续跟踪工单。你可以将该指标视为类似于“软件操作级别”的指标。VALET我们将新的SLOs概括为一个更简易的缩略词：VALET。Volume 容量（流量) 服务可以处理多少业务量？Availability 可用性 需要的时候服务是否正在运行？Latency 延迟 使用时服务是否快速响应？Errors 错误 使用时服务是否会抛出错误？Tickets 工单   服务是否需要人为干预才能完成请求？推广SLOs凭借这样一个易于记忆的缩略词，我们开始在企业内部推广SLOs：  为何SLOs如此重要  SLOs是怎样与我们的“自由和责任”文化相契合的  应该衡量什么  如何处理结果因为开发人员现在要负责维护他们自己的软件，因此他们需要建立SLOs以体现他们开发和维护软件可靠性的能力，针对面向用户的服务，他们需要同服务使用者和产品经理进行交流。然而，他们中多数人并不熟悉诸如SLAs和SLOs这样的概念，因此他们需要接受VALET框架方面的培训。由于我们需要获得强有力的支持来推广SLOs，因此一开始我们可以面向高级领导者进行SLOs的推广讲解。然后逐个向开发团队讲述SLOs的价值观。我们鼓励团队从他们自定义的度量跟踪机制（通常是人为制定）转向VALET框架。为了保持这种推广态势，我们每周发送一份VALET格式的SLO报告给高层领导，这份报告结合了可靠性理念和从内部事件中吸取的经验。这也有助于构建业务指标，例如在VALET框架下，创建的采购订单（流量）或支付订单失败（错误）。我们还以多种方式扩展了我们的推广渠道：  我们建立了一个内部WordPress网站来托管有关VALET和可靠性的博客，并将其链接到相关资源。  我们组织内部技术讲座（包括Google SRE演讲嘉宾），讨论了通用可靠性概念以及如何使用VALET进行度量。  我们开展了一系列VALET培训研讨会（之后将演变为FiRE学院），并向所有想参加的人开放，这些研讨会持续了好几个月。  我们甚至制作了VALET笔记本电脑贴纸和文化衫，用来支持全面的内部推广活动。很快，公司里的每个人都知道了VALET这一概念，并且我们的SLOs新文化开始在公司占据主流。对开发负责人来讲，实施SLO甚至已正式成为其年度绩效评估指标。虽然大约有50项服务正在按周级别获取并报告其SLOs，但我们会将这些指标存储在电子表格中。虽然VALET的思想已经非常流行，但为了让其更广泛地被接纳，我们仍然需要自动化技术来进行数据的收集。自动化VALET数据收集虽然我们的SLO文化现在有了强大的立足点，但自动化VALET数据收集将加速SLO的应用。TPS报告我们构建了一个框架来自动捕获部署到新GCP环境的任何服务的VALET数据。我们将此框架称为TPS报告，这是我们用于数量和性能测试的术语（每秒交易次数），当然，也是为了满足多个管理者想要查看这些数据的想法。 我们在GCP的BigQuery数据库平台之上构建了TPS Reports框架。我们的Web服务前端生成的所有日志都被输入BigQuery以供TPS Reports处理。当然也包括来自各种监控系统的指标，例如Stackdriver的可用性指标。TPS报告将这些数据转换为任何人都可以查询的每小时VALET指标。新创建的服务自动注册到TPS报告中，因此可以立即查询。由于数据全部存储在BigQuery中，因此我们可以跨时间帧有效地报告VALET指标。我们使用此数据构建了各种自动报告和警报。 最有趣的集成是一个聊天机器人，让我们直接在商业聊天平台上报告服务的VALET。例如，任何服务都可以显示过去一小时的VALET，前一周的VALET，未达成SLO的服务以及聊天频道内的各种其他值得引起关注的数据。VALET服务我们的下一步是创建一个VALET应用程序来存储和报告SLO数据。因为SLO最适合用作趋势工具，所以该服务以每日、每周和每月粒度跟踪SLO。请注意，我们的SLO是一种趋势工具，我们可以将其用于错误预估，但不直接连接到我们的监控系统。相反，我们有各种不同的监控平台，每个平台都有自己的警报。这些监控系统每天汇总其SLO并发布到VALET服务以进行趋势分析。此设置的缺点是监控系统中设置的警报阈值未与SLO集成。 但是，我们可以根据需要灵活地更换监控系统。预计需要将VALET与未在GCP中运行的其他应用程序集成，我们创建了一个VALET集成层，该层提供API来收集聚合的VALET数据以生成服务日报。TPS Reports是第一个与VALET服务集成的系统，我们最终集成了各种本地应用程序平台（占在VALET中注册的服务的一半以上）。VALTE 仪表盘VALET仪表板（如图3-1所示）是我们用于可视化和报告此数据的UI，并且相对简单。 它允许用户： 图3-1  VALET仪表盘。 注册新服务。 这通常意味着将服务分配给一个或多个URL，这些URL可能已经收集了VALET数据。为五个VALET类别中的任何一个设置SLO目标。在每个VALET类别下添加新的指标类型。 例如，一个服务采集99%的请求所用的延迟，而另一个服务采集90%的请求所用（或两者）的延迟。或者，后端处理系统可以跟踪每日总量（一天内创建的采购订单），而客户服务的前端可以跟踪每秒交易的峰值。VALET仪表盘允许用户一次报告许多服务的SLO，并以多种方式对数据进行切片和切块。例如，团队可以查看过去一周未达到SLO的所有服务的统计信息。负责复盘服务性能的团队可以查看其所有服务及其所依赖的服务的延迟。VALET仪表盘将数据存储在一个简单的Cloud SQL数据库中，开发人员使用流行的商业报告工具来构建报告。这些报告成为开发人员新的最佳实践的基础：定期对其服务进行SLO审核（通常是每周或每月）。基于这些，开发人员可以创建操作项以使服务回归SLO，或者可能按照需要调整不符合实际的SLO。SLOs的扩散一旦SLOs融入到组织的集体思想中，并且具备了有效的自动化技术和报表，那么新的SLOs就可以快速实施。在年初跟踪了约50项服务的SLOs之后，到今年年底我们正在跟踪800项服务的SLOs，每月约有50项新服务在VALET注册。由于VALET允许我们在THD中推广SLO的应用，因此自动化开发这项工作是非常有意义的。但是，不具备这种自动化开发能力的公司也不用担心采用SLO会带来的麻烦。虽然自动化为THD提供了额外的收益，但一开始就编写SLO也收益颇多。将VALET应用于批处理应用程序当我们围绕SLO开发强大的报表时，我们发现了VALET的一些其他用途。 经过一些调整，批处理应用程序可以适用此框架，如下所示：数量已处理的记录数量可用性在一定时间内完成工作的频率（百分比）等待时间作业运行所需的时间错误 程序运行失败的记录工单 操作员必须手动修复数据和重新处理作业的次数在测试中使用VALET由于在发展SRE文化的同时，我们发现在临时环境中，VALET可以支持我们的破坏性测试（混沌工程）自动化。有了TPS Reports框架，我们就可以自动进行破坏性测试并记录对service’s VALET data造成的影响（希望没有影响）。未来展望通过800个（并且不断增长）服务来收集VALET数据，我们可以拥有大量有用的运营数据。我们对未来有几个期望。既然我们正在有效地收集SLO，我们希望使用这些数据来采取行动。我们的下一步是类似于Google的错误预算文化，当服务不在SLO时，团队停止推送新功能（除了提高可靠性相关的）。为了满足业务增长的需求，需要平衡SLO报告的生成频率（周级别或月级别）和SLO标准的更新频率。和许多采用错误预算的公司一样，我们正在权衡滚动窗口与固定窗口的优缺点。我们希望进一步优化VALET以跟踪详细的节点和服务的使用者。目前，即使特定服务具有多个节点，我们也只在整个服务中跟踪VALET。因此，很难区分不同的操作（例如，对目录的写入与对目录的读取；虽然我们对这些操作添加了单独的监控和报警，但不跟踪SLO）。同样，我们也很乐意为服务的不同消费者提供对应的VALET结果。虽然我们目前在Web服务层跟踪延迟SLO，但我们还希望跟踪最终用户的延迟SLO。此度量将捕获网络延迟和CDN缓存等因素如何影响页面开始呈现和完成呈现所需的时间。我们还想将VALET数据扩展到应用程序部署。具体来说，在将更改推广到下一个服务器、域或区域之前，我们希望自动化验证VALET是否在容差范围内。我们已经开始收集有关服务依赖性的信息，并且制作了一个可视化图表原型，该图表显示了我们在调用树中未触及到VALET指标的位置。 新兴的网格服务平台将简化这种分析。最后，我们坚信服务的SLO应该由服务的业务所有者（通常称为产品经理）根据其业务的重要性来设置。至少，我们希望业务所有者设置服务正常运行时间的最低要求，并将SLO用作产品管理和开发之间的共享目标。虽然技术人员发现VALET很直观，但对于产品经理来说，这个概念并不那么直观。我们正在努力使用与它们相关的术语来简化VALET的概念：我们既简化了正常运行时间的选择数量又提供了示例指标。我们还强调从一个级别转移到另一个级别所需的大量投入。以下是我们可能提供的简化VALET指标的示例：  99.5％：商店员工使用次数很少的应用程序或新服务。  99.9％：适用于THD的大多数非销售系统  99.95％：销售系统（或支持销售系统的服务）  99.99％：共享的基础设施服务以业务术语来衡量指标并在产品和开发之间共享可见目标（SLO），这种行为将大量减少公司常见的对可靠性的错误预期。概要向大公司介绍一个新流程，都需要一个好的策略、高管的支持、强大的传播、简单的采用模式以及最重要的耐心，更不用说是一个新文化了。像SLO这样的重大变革可能需要数年才能在公司中牢固地建立起来。我们想强调的是，Home Depot是一家传统企业;如果我们能够成功地引入这么大的变化，那么你也可以。你也不必一次完成这个任务。虽然我们逐步实施SLO，但制定全面的传播策略和明确的激励结构促进了快速转型：我们在不到一年的时间内获得了从0到800的SLO服务支持。结论SLO和错误预算为解决许多不同问题提供了强大的理论支持。这些来自Evernote和Home Depot的案例研究提供了非常真实的例子，说明如何实施SLO文化可以使产品开发和运维更紧密地结合在一起。这样做可以促进沟通并更好地为制定决策提供信息。它最终将为你的客户带来更好的体验 - 无论这些客户是内部、外部、人类还是其他服务。这两个案例研究强调实现SLO文化是一个持续的过程，而不是一次性修复或解决方案。虽然它们共享哲学基础，但THD和Evernote的度量风格、SLIs、SLOs和实现细节明显不同。这两个案例都补充了谷歌对SLOs的看法，说明了SLO实现不一定是Google所特有的。正如这些公司为自己独特的环境量身定制SLO一样，其他公司和组织也可以这样做。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第二章 实施SLO]]></title>
      <url>/sre/2020/01/02/%E5%AE%9E%E6%96%BDSLO/</url>
      <content type="text"><![CDATA[  名次解释：      SLI：服务质量指标、该服务的某项服务质量的一个具体量化指标。例如：延迟、可用性    SLO：服务质量目标、服务的某个SLI的目标值/范围。例如：搜索请求的平均延迟 &lt; 100ms。    SLA：服务质量协议、服务与用户之间的一个明确的协议，描述达到/未达到SLO之后的后果。    错误预算： 1 - 可靠性目标  SLO为服务可靠性设定了一个目标级别。它是可靠性决策的关键因素，所以是SRE实践的核心。无论从哪个角度来看，这都将是本书中最重要的一章。我们只有具备了一定的理论，设置初始的SLO并细化它们，这个过程才会变得简单。在第一本书第四章中介绍了有关SLO和SLI的相关理论，并对如何使用它们给出了一些建议。了解了SLO和错误预算这个概念之后，本章提供了一种方法让你开始SLO之旅，以及一些如何进一步迭代的建议。然后，我们将介绍如何使用SLO做出有效的业务决策，并探索一些更高级的使用场景。最后，我们介绍了一些不同场景下开展SLO的案例，以及在特定情况下开展更复杂SLO的指导方案。SRE需要SLO的原因即使在大型研发团队中，工程师也是稀缺资源，工程师的时间应投入到重要服务的核心问题上。工程师应该花时间在功能研发上以便赢得新的客户，还是花时间在提高服务可靠性和可伸缩性上以便让客户满意，这是很难找到平衡点的。谷歌认为一个深思熟虑的SLO是做出决策的关键，这些决策包括了可靠性相关工作，和确定工作优先级排序等内容。SRE的核心职责不仅仅是将“所有的事情”自动化并随时待命处理故障，他们的日常工作都将按照SLO来开展。确保SLO在短期内是合理的，并且可根据情况适时地调整。甚至可以说，如果没有SLO，就没有SRE。SLO更像一种工具，可以帮助工程师确定哪个工作优先级更高。 例如，考虑如下两个工作的优先级：将服务自动回滚和切换到备份站点。 通过计算这两个工作的“错误预算”值，我们可以确定哪个工作对用户更有利。有关详细信息，请参阅第37页上的“使用SLO和错误预算进行决策”部分，以及《Site Reliability Engineering》中的“拥抱风险”一章。入门作为建立基本SLO指标的起点，让我们来假设你的服务是某种形式的代码，它已经被编译和发布，并且运行在用户可以web访问的网络基础设施上。你的系统可能处于如下某个阶段：  起步阶段——尚未部署任何内容  在生产环境中，当出现问题时，系统的监控会通知您，但是没有正式的目标和没有错误预算的概念，也没有一个明确的正常运行时间  有SLO指标，但对其重要性理解不到位，或者不知道如何利用它来进行持续改进。  为了采用基于错误预算的站点可靠性工程方法，您需要达到以下状态：  服务的利益相关方认可此SLO  服务正常状态下可以达到SLO的要求  管理者认可此错误预算并在实际决策中发挥作用  有一个完善的SLO过程制定SLO的第一步是讨论SLO是什么，以及它应该包含哪些内容。SLO为服务客户设定了目标可靠性级别。 超过此阈值，几乎所有用户都应对你的服务感到满意（假设他们对服务的效用感到满意）。低于此阈值，用户可能会开始抱怨或停止使用该服务。最终，用户的快乐才是最重要的 - 快乐的用户使用服务，为您的组织创造收入，减少对您的客户支持团队的抱怨，并向他们的朋友推荐该服务。我们以可靠的服务让客户满意。顾客满意度是一个相当模糊的概念；我们无法精确衡量它。通常我们对它的了解很少，那么该如何开始呢?我们的经验表明，100％的可靠性是错误的目标：  服务即使使用冗余组件、自动健康检查和快速故障转移，也存在一个或多个组件同时失败的场景，服务的可靠性将低于100%。如果制定的SLO是100%，这件事将不可能实现。（运小白说：泰坦尼克号，有“”永不沉没“”的美誉，底仓有16个水密舱， 任何4个水密舱进水的情况下都不会沉没）  即使服务实现了100%的可靠性，但客户也不会体验到100％的可靠性。服务和客户之间的链路长且复杂，链路中的任何一个组件故障都会造成失败败。这也意味着当您的可靠性从99％提高到99.9％到99.99％时，每增加一个9都会增加额外的成本，但客户几乎感受不到。 （运小白说：搜索引擎搜索“运营商故障”即可感受到）  如果服务的可靠性是100%的，并希望保持这种可靠性，那么你永远无法更新或改进服务。最大的故障原因就是变化：推出新功能、应用安全补丁、部署新硬件以及扩大规模以满足客户需求都将影响100％的目标。 最终，服务将停滞不前，你的客户将转移到其他地方。（运小白说：对于节日期间没有促销活动的业务来讲，除去偶尔的硬件故障外，那是难得的平静期）  SLO为100％意味着你只有被动应对。除了对&lt;100％可用性做出反应之外，你实际上无法做任何事情，这是一定会发生的。 100％的可靠性不是工程师要追求的——它应该是运营团队的目标。（运小白说：运维和救火类似，如果消防人员的目标定位不能有任何小火苗，那消防人员估计就会疲于奔命了）一旦SLO目标低于100%，它就需要由组织中的某个人有权在迭代速率和可靠性之间进行权衡。在小型组织中，这可能是CTO；在更大的组织中，通常是产品所有者（或产品经理）。衡量标准:使用SLI一旦你认同100％是错误目标，多少才是正确的？ 在这里，服务质量指标发挥作用：我们引入SLI的概念，SLI是指服务的质量指标。虽然计算SLI有多种方法，我们建议SLI为：好的事件数量除以总事件数量。例如：  成功的HTTP请求数/总HTTP请求数（成功率）  在请求延迟小于100 ms 的成功请求数/总请求数  搜索结果数/搜索结果总数，包括那些正常降级的搜索结果  使用10分钟以上库存数据的产品搜索的“库存检查计数” 请求的数目/库存检查请求的总数  “良好用户分钟数” /“用户分钟数”这种形式的SLI有一些特别有用的属性。 SLI的范围从0％到100％，其中0％表示无效，100％表示无损。 我们发现这个比例是很直观的，这种风格很容易引入错误预算的概念：SLO是一个目标百分比，错误预算是100％减去SLO。 例如，如果您有99.9％的SLO成功率，且在四周内收到的300万个服务的请求，那么在此期间的错误预算为3,000（0.1％）。 如果单个中断导致1,500个错误，则该错误将占错误预算的50％。此外，使所有的SLI遵循一致的风格以便更好地利用工具：你可以编写报警逻辑、SLO分析工具、错误预算计算和报告，以期望得到相同的输入: 分子、分母和阈值。简化是一个额外的好处。在尝试首次制定SLI时，将SLI进一步划分为SLI规范和SLI实现是必要的：SLI规范：你认为对用户重要的服务结果的评估，与其测量方式无关。例如：加载小于100毫秒的主页请求比SLI实现：SLI规范及其测量方法。例如：  加载小于100毫秒的主页请求比，由服务器日志的延迟列进行测量，这种度量方式将遗漏未能到达后端的请求。 （运小白说：遗留有很多个地方都会发生，从用户侧到运营商，从运营商到IDC，从接入层到后端）  加载小于100毫秒的主页请求比，由在虚拟机中运行的浏览器中执行JavaScript的探测器测量。 当请求无法到达我们的网络时，此度量将捕获错误，但可能会遗漏仅影响用户子集的问题。（运小白说：例如部分地域/运营商的网络异常，仅通过该方案就无法发现）  加载小于100毫秒的主页请求比，通过在主页本身上使用JavaScript进行测量，并将其报告给专门的遥测记录服务。这个度量将更准确地捕获用户体验，尽管我们现在需要修改代码来捕获这些信息，并构建基础设施来进行记录 —— 但这是一个具有自身可靠性要求的规范。 （运小白说：俗称埋点，BAT均有使用，对访问速度优化，可用性监控，地址库优化等均能起到较好的效果）如你所见，单个SLI规范可能具有多个SLI实现，每个SLI实现在质量（它们如何准确地捕获用户体验），覆盖范围（它们如何捕获所有用户体验）和成本方面都具有自己的优缺点。您对SLI和SLO的第一次尝试不需要完全正确; 最重要的目标是获得适当的位置并加以测量，并建立反馈机制以便改进。 （我们将在本章的“持续改进SLO目标”中深入探讨这个主题。）在我们的第一本书中，我们建议不要根据当前的性能选择SLO，因为这可能会导致你执行不必要的严格SLO。虽然这个建议是正确的，但是如果你没有任何其他信息，并且有一个好的迭代过程(我们将在后面介绍)，那么你当前的性能是一个很好的起点。但是，当你优化SLO时，不要让当前性能被限制：客户也会期望服务在其SLO上执行，因此如果服务在不到10毫秒的时间内请求成功率为99.999％，任何基于该基线的退化可能让他们不开心。 （运小白说：当前的实际情况是一个参考，而非说目标制定必须以当前值为基础并高于当前值。而且，很多时候，单一目标是能上不能下的，你让用户习惯了这个响应速度，他就无法接受比这个基础值低的服务，这既是门槛也是压力。另外，对单一目标的不断追求，还需要考虑投入产出比。因此这个时候，可以参考下面的建议，从多个维度制定一组SLO。）要创建第一组SLO，您需要确定对您的服务至关重要的几个关键SLI规范。 可用性和延迟SLO非常常见; 新鲜度，耐用性，正确性，质量和覆盖范围SLO也有它们的位置（我们稍后会详细讨论它们）。（运小白说：大牛们对搜索服务的SLO总结为全，新，快，稳，准）如果你不知道从哪类SLI开始学习，那么从简单的开始:  选择一个要定义SLO的应用程序。如果产品包含许多应用程序，则可以在此之后添加这些应用程序。  在这种情况下，明确“用户”是谁。  考虑用户与系统交互的常见方式 - 常见任务和关键活动。  绘制系统的高级架构图; 显示关键组件、请求流、数据流和关键依赖项。将这些组件分组到下一节中列出的类别中(可能存在一些重叠和歧义; 运用你的直觉，不要让完美成为善意的敌人。） 你应该仔细考虑你选择什么作为你的SLI，但你也不应该过分复杂化。 特别是如果您刚刚开始SLI之旅，请选择相关但易于衡量的系统方面 ，以便可以随时进行迭代和优化。组件类型开始设置SLI的最简单方法是将系统抽象为几种常见的组件类型。然后，您可以使用我们为每个组件提供的SLI建议列表，来选择与您服务最相关的SLI:请求驱动用户创建某种类型的事件并期望响应。 例如: 这可以是HTTP服务，其中用户与浏览器或移动应用程序的API交互。管道一种系统，它将记录作为输入，对其进行转变，并将输出放在其他位置。 这可能是一个在单个实例上实时运行的简单过程，也可能是需要花费数小时的多阶段批处理过程。 例子包括：  一种定期从关系数据库中读取数据并将其写入分布式哈希表以优化服务的系统  一种将视频从一种格式转换为另一种格式的视频处理服务  一种从多个源读取日志文件以生成报告的系统  一种从远程服务器提取指标并生成时间序列和报警的监控系统存储接收数据(例如字节、记录、文件、视频)并使其在以后可以被检索的系统。案例一个简化过的手机游戏架构，如图2-1所示。在用户手机上运行应用程序与云中运行的HTTP API交互。API将状态更改并写入永久存储系统。一个管道定期运行这些数据，来生成今天、本周和所有时间的高分排行。这些数据被写入一个单独的排行榜数据存储，可以通过移动应用程序和网站获得结果。用户可以通过API和网站将游戏中使用的自定义头像上传到用户数据表。鉴于此设置，我们可以开始考虑用户如何与系统交互，以及采用哪种SLI衡量用户体验。这些SLI中有些可能存在重叠：请求服务具有正确性SLI，管道具有可用性SLI，并且持久性SLI可能被视为正确性SLI的变体。 我们建议选择少数（五个或更少）SLI类型，这些类型代表了客户最关键的功能。。为了捕获典型的用户体验和长尾，我们还建议使用多个等级的SLO。例如，如果90％的用户请求在100毫秒内返回，但剩下的10％用户需要10秒，这部分用户将不满意。 延迟SLO可以通过设置多个阈值来捕获此用户群：90％的请求快于100毫秒，99％的请求快于400毫秒。 这个原则适用于所有的SLI – 这些SLI的参数用来衡量用户的满意程度。表2-1为不同类型的服务提供了一些常用的SLI。表2-1 不同类型组件常用的SLI             服务类型      SLI类型      描述                  请求驱动      可用性      成功响应的请求比例。              请求驱动      延迟      比某些阈值快的请求比例。              请求驱动      质量      如果服务在过载或后端不可用时正常降级，则需要测量在未降级状态下提供服务的响应比例。 例如，如果用户数据存储不可用，但使用通用图像游戏仍可玩。              管道      新鲜度      最近更新的数据比例超过某个时间阈值。 理想情况下，此指标会计算用户访问数据的次数，以便最准确地反映用户体验。              管道      正确性      正确输出值的比例。              管道      覆盖范围      对于批处理，处理超过某个目标数据量的作业比例。对于流处理，在某个时间窗口内成功处理的传入记录比例。              存储      耐用性      可以成功读取的记录所占的比例。特别注意持久性SLI:用户想要的数据可能只是存储数据的一小部分。例如，如果你在过去10年里有10亿个记录，但是用户只需要今天的记录(但这些记录不可用)，那么即使他们的数据几乎都是可读的，他们也会不高兴。      从SLI理论到SLI实践第一次SLI实践可以考虑选择一个资源需求相对较少的项目。比如有如下几个项目可供选择：web日志服务器的SLI项目，这个项目我们不需要准备什么；对监控系统进行SLI项目实践，但是这需要几周的时间准备，而JavaScript的项目则会需要几个月的时间。在这种情况下请使用web服务器的日志来作为第一个SLI实践的工程。衡量SLI需要足够指标：可用性指标（成功率和失败率）; 慢请求延迟（请求的响应时间）。 这些指标可能需要你重新对Web服务器进行配置才能获得。 如果是基于云服务的Web，这些指标可以在监控仪表盘中看到。在这个案例中我可选择的SLI指标有很多，每个指标都有自己的优缺点。 以下部分详细介绍三种典型的SLI指标的应用。API和HTTP服务的可用性指标和慢请求延迟指标请求是否成功可以基于HTTP的返回码。5XX就代表请求失败，会降低服务的SLO，其他响应码代表成功。 可用性的SLI是指请求成功率；慢请求延迟的SLI是指在给定请求响应时间阈值下的请求成功率。SLI应该是具体明确并可测量的。总结“衡量标准:使用SLI”中的提供的潜在候选列表，SLI可以使用以下的一个或多个数据来源:  应用服务器日志  负载均衡监控  黑盒监控  客户端插件我们的例子采用负载均衡监控，因为这些指标已经是可用的，并且数据信息比采用“应用服务器日志”更真实反应用户体验的SLI。  （译者：采用负载均衡的数据，是因为接入层记录的耗时，是一个用户请求在整套系统所有模块处理耗时和所有网络传输耗时的总和，因此更加真实的反应用户的体验，且和客户端插件相比，实施成本相对较低。但该部分耗时，并不包含从用户端到IDC这段的耗时）管道数据延迟率，范围覆盖率和准确率使用管道系统管理一个排行榜时，它会记录一个包含有数据更新的时间戳标签。下面是我们进行SLI实践的例子：  在排行榜上周期性的运行一个进程用于查询有多少次记录被更新和总共有多少个记录。这两个指标同样重要。      在用户请求数据时默认为请求增加一个时间标签，排行榜服务收到客户端请求后会检查这个标签并将请求计数器+1， 如果数据超出了预定义的阈值，则将配置另一个用于记录超时的计数器数字+1。          （译者：在一个数据流中各个环节或者关键环节中添加时间戳后，可以在监控，性能优化，故障定位等多种场景中使用）      以上两个步骤的数据要求都在客户端实现 。这个指标与用户体验密切相关。为了计算我们覆盖率的SLI，我们的管道输出了它应该处理的记录数和它成功处理的记录数。此度量标准可能会遗漏由于管道配置错误而未记录的数据。我们采用如下方法来评估准确率：  将已知的数据作为输入写入系统，计算输出与期望值匹配率。  基于默认管道的输入输出结果作为基准，计算此管道在相同输入下的输出与前者匹配的程度（这个方法可能并不适合所有的管道系统）。我们的案例是为一个需要人工管理的数据库建立指标为准确率的SLI。所有的数据的输入都是合法的，通过管道系统输出结果， 计算输出的准确率。为了使指标能够很好的反应用户体验，我们需要确保人工输入的数据和用户真实数据是一致的。  （译者：这段看似简单，却是经验的分享。举一个具体的例子来让大家更深刻的理解，以计算服务为例，将已知的数据作为输入写入系统，你可以每分钟输入一个不变的数，然后让系统去计算一定时间的和值，从而度量计算服务的SLI。进阶的话，就是每分钟输入的是变化的数，从而计算和值，均值，最大值，最小值，那变化的数用什么呢，一般就是当前的分钟数）SLI的计算 图2-2展示的是用白盒监控系从示例程序的各个组件中收集指标的过程。 给出一个示例来说明我们是如何使用监控系统中的指标来计算启动器的SLO指标的，以便读者可以更好的理解。虽然我们在案例中只使用了可用性和慢查询延迟指标，但是同样的思路也适用于其他潜在的SLO指标的计算。系统使用度量标准的完整列表，请参阅附录a。我们的案例都使用普罗米修斯监控系统进行数据采集（Prometheus notation）。负载均衡指标后端的请求返回码为500的数量（“api” or “web”）:http_requests_total{host="api", status="500"}总延迟，作为累积直方图；每个柱状图（bucket）表示计算花费少于或等于该时间的请求数量:http_request_duration_seconds{host="api", le="0.1"}http_request_duration_seconds{host="api", le="0.2"}http_request_duration_seconds{host="api", le="0.4"}一般来说，计算得到慢请求数要比用直方图估计得到的慢请求数更加精准。但是，由于有些信息是拿不到的，所以最终使用监测系统提供的直方图。另一种方法是根据负载均衡配置中的各种慢请求阈值(例如，阈值为100毫秒和500毫秒)来计算慢请求数量。这种方式需要对监控的配置进行修改，所以会更复杂但是会更准确。http_request_duration_seconds{host="api", le="0.1"}http_request_duration_seconds{host="api", le="0.5"}计算SLI使用前面的指标，我们可以计算前七天的当前SLI，如表2-2所示。表2-2   过去七天的SLI计算              指标      计算方式                  可靠性      sum(rate(http_requests_total{host=”api”, status !~”5..” }[7d]))   /  sum(rate(http_requests_total{host=”api”}[7d])              延迟      histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[7d]))  histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[7d]))      利用SLI计算初始 SLO我们可以将这些SLI划分为可管理的数字（例如，两个重要的可用性数据，或最多50 ms的延迟）来获得我们的起始SLO。例如，超过四周，API指标显示：  总请求数: 3663253  总成功请求数: 3,557,865 (97.123%)  90%的延迟: &lt; 432 ms  99%的延迟: &lt; 891 ms我们为其他SLI重复此过程，并为API创建一个SLO，如表2-3所示。 表2-3  API的建 SLO              SLO类型      目标                  可靠性      97%              延迟      90%的请求 &lt; 450ms              延迟      99%的请求 &lt; 900ms      附录A提供了SLO文档的完整示例。 本文档包含SLI实现，为简洁起见，我们在此省略。根据所提出的SLI，我们可以计算这四周的错误预算，如表2-4所示。 表2-4    过去四周错误预算             SLO      允许失败数                  97%的可用性      09,897              90％的请求快于450ms      366,325              99％的请求快于900ms      36,632      选择合适的时间窗口可以在不同的时间间隔上定义SLO，并且可以使用滚动窗口或周期对齐窗口（例如，一个月）。选择时间窗口时需要考虑几个因素。滚动窗口与用户体验更紧密地联系在一起：如果你在一个月的最后一天发生大量中断，则你的用户在下个月的第一天不会突然忘记它。 我们建议将这段时间定义为整数周，以便它始终包含相同数量的周末。 例如，如果你使用30天的窗口，则某些时段可能包括四个周末，而其他时段包括五个周末。 如果周末流量与工作日流量明显不同，你的SLI可能会因为无趣的原因而有所不同。周期窗口与业务规划和项目工作更紧密地结合在一起。例如，你可以每个季度评估SLO，以确定下一个季度项目人员的重点工作。周期窗口还引入了一些不确定性因素:在季度中期，你不可能知道在本季度余下的时间里会收到多少请求。因此，在季度中期做出的决定必须推测系统将在本季度剩余时间内花费多少错误预算。更短的时间窗口可以让你更快地做出决策：如果你错过了前一周的SLO，那么小的更正 - 例如优先考虑相关错误 - 可以帮助避免未来几周的SLO违规。对于更具战略性的决策，更长的时间周期更好：例如，如果你只能选择三个大型项目中的一个，那么你最好转移到高可用性分布式数据库，自动执行部署和回滚过程，或者在另一个部署重复堆栈区。你需要超过一周的数据来评估大型多季度项目; 所需的数据量与建议修复它的工程量大致相当。我们发现为期四周的滚动窗口是一个很好的通用间隔。我们每周任务优先级总结和每季度的项目规划总结报告刚好补充这一时间段。如果数据源允许，则可以使用这个建议的SLO来计算在此期间的实际SLO性能：如果根据实际测量设置初始SLO，则按此设计。但我们也可以收集关于分布的有趣信息。在过去的四个星期内，有哪天我们的服务没有达到标准? 这些天与实际事件有关联吗? 在那些日子里，有没有(或者应该)采取一些行动来应对这些事件?如果没有日志、度量或任何其他历史性能来源，则需要配置数据源。例如，作为HTTP服务的基本解决方案，你可以设置远程监视服务，对HTTP服务定期的执行某种健康检查（ping或HTTP GET），并报告请求成功的数量。许多在线服务可以轻松实现这一解决方案。获得所有利益相关者同意为了使提议的SLO有用和有效，你需要让所有利益相关者同意它：  产品经理必须同意这个阈值 ——低于这个值的性能无法令人接受，需要花费时间来修复。  产品开发人员需要同意，如果错误预算已用尽，他们将采取一些措施来降低用户的风险，直到服务重新回到错误预算中（如第31页的“建立错误预算策略”中所述）。  负责维护这个SLO生产环境的团队已经同意并一致认为，不需要付出巨大的努力、过度的辛劳——这对团队和服务都是不利的。 一旦所有这些观点都达成一致，最难的部分就完成了。你已经开始了SLO之旅，剩下的步骤需要从这个起点迭代。你需要设置监控和报警来监控SLO，（请参阅第5章），以便工程师发现问题。建立错误预算策略获得SLO后，你可以使用SLO来获取错误预算。 要使用此错误预算，你需要一个策略，描述当你的服务超出预算时要执行的操作。获得所有关键的利益相关者(产品经理、开发团队和SRE)批准的错误预算策略，是对SLO是否适合目的良好测试:  如果SRE认为需要付出更多的工作才能保证SLO，那么他们可以提出放宽SLO的要求。  如果开发团队和产品经理认为，他们必须投入更多的资源来修复系统，这将导致特性发布速度低于可接受的水平，那么他们也可以争取放宽目标值。记住，降低SLO也会降低SRE响应的情况数量；产品经理需要对此做权衡。  如果产品经理认为，在错误预算策略提示任何人解决某个问题之前，SLO将给大量用户带来糟糕的体验，那么SLO可能不够紧凑。  如果所有三方都不同意执行错误预算策略，那么你需要迭代SLI和SLO，直到所有利益相关者都满意为止。决定如何前进，以及做出决定需要什么：更多的数据？更多的资源？还是对SLI或者SLO进行修改？当我们讨论强制执行错误预算时，我们的意思是一旦你耗尽了错误预算(或者接近于耗尽它)，你应该采取措施来恢复系统的稳定性要制定错误预算执行决策，你需要从书面策略开始。 此策略应涵盖服务在给定时间段内消耗全部的错误预算时必须采取的具体操作，并指定谁将采取这些操作。 共同所有者和行动包括：  开发团队将过去四周内与可靠性问题相关的bug放在了首位。  开发团队专注于可靠性问题，直到系统处于SLO范围内。 功能迭代可以推迟。  为了降低更多停机导致的风险，冻结生产系统的变更，直到有足够的错误预算来恢复变更。有时候，服务会消耗掉整个错误预算，但并不是所有利益相关者都同意制定错误预算策略是合适的。如果发生这种情况，你需要返回到错误预算策略审批阶段。记录SLO和错误预算策略一个SLO应记录在一个突出的位置，其他团队和利益相关者可以审查它。该文件应包括以下信息：  SLO的作者: 审核人（检查技术准确性）和审批人（谁做出了关于它是否是正确的SLO的商业决策）。  批准的日期，以及下次审核的日期。  为读者了解相关背景的简要说明。  SLO的细节：目标和SLI实现。  关于如何计算和使用错误预算的详细信息。  这些数字背后的基本原理，以及它们是否来自实验或观察数据。 即使SLO完全是临时的，也应记录这一事实，以便未来阅读文档的工程师不会根据临时数据做出错误的决定。 你查看SLO文档的频率取决于SLO文化的成熟度。在开始时，你应该经常审查SLO （例如每个月）。 一旦SLO变得更加符合实际，你可以降低评审频率为每季度或更低。制定错误预算策略，还应包括以下信息：  策略的制定人、审核人和审批人  批准的日期，以及下次审核的日期  编写说明文档  应对错误预算耗尽时采取的行动  如果在某种情况下商定的策略发生分歧，则将问题升级  让有经验的工程师对错误预算进行审核有关SLO文档和错误预算策略的示例，请参阅附录A。仪表盘和报表除了已发布的SLO和错误预算，及说明文档之外，还应有一个报表和仪表盘进行展示。（运小白说：通过仪表盘/大屏以及背后的存储系统，记录，展示和分析长期的SLO，从而才能帮助团队更好的发展，减少犯同样的错误）图2-3中的报表显示了几种服务的总体合规性：它们是否满足前一年的所有季度的SLO（括号中的数字表示满足的目标数量，以及目标总数），以及他们的SLI相对于上一季度和去年同一季度是否呈上升趋势或下降趋势。 图 2-3. SLO合规性报告 使用仪表盘来显示SLI的趋势也是很有用的。 这些仪表盘显示你是否以高于平常的速率消费预算，或者是否存在需要特别关注趋势。图2-4中的仪表盘显示了一个季度的错误预算，在该季度的中间部分，我们看到单个事件在两天内消耗了大约15%的错误预算。 图 2-4. 错误预算仪表盘 错误预算对于量化这些事件很有用——例如，“这次宕机消耗了我季度错误预算的30%”，或者“这是本季度排名前三的事件，根据它们消耗了多少错误预算来排序”。持续改进SLO目标每项服务都可以从持续改进中受益。 这是ITIL的核心服务目标之一。 例如： 在你提高SLO目标之前，你需要拥有用户对服务满意度的信息来源。 有很多选择：  人工发现的服务不可用次数、公共论坛上的帖子、故障单和投诉电话  社交媒体上的用户反馈  用插件定期对用户的满意度进行采样  调查问卷进行用户调查和采样最佳的方法取决于你的服务，我们建议从成本较低的渠道开始。让你的产品经理把可靠性纳入到他们与客户关于定价和功能的讨论中，这会是一个很好的开始。提高SLO质量记录人工检测到的服务不可用次数， 其他相关网站支持票数也可以计算在内，检查这些数据是否与错误预算的变化趋势相关。 同时检查这短时间内SLI和SLO的变化趋势。如果你擅长统计分析，Spearman相关系数是量化这种关系的有效方法。图2-5显示了每天增加的支持票的数量与当天错误预算的关系。虽然不是所有的支持票都与可靠性问题相关，但支持票与错误预算之间是存在相关性。我们看到两个异常值：一天只有5张票，损失了10%的错误预算；一天有40张票，没有损失任何错误预算。这两个异常值都需要进一步追查。 图 2-5. 每天增加的支持票的数量与当天错误预算的关系 如果支持票未在SLI或SLO中体现，或者用户关注的问题并没有在指标中体现，说明指标覆盖率存在问题。 这种情况完全正常，符合预期。 你的SLI和SLO应随着时间的推移而发生变化，因为服务的实际情况会发生变化， 不要畏惧对它们进行改进！如果你的SLO或SLI覆盖率不高，你可以采取多种方案：修正SLO如果你的SLI显示现在出问题了，但是你的SLO没有异常，你可能需要更加严格的SLO。  如果该时间段内发生的问题比较严重，通过SLI计算SLO应该出现异常的时间段。调整SLO之后，把这个新的SLO应用到SLI的历史数据上，看看这个调整会发现什么问题。如果发现严格的SLO会不断地对不重要的事件作出响应，那么这个修正毫无意义。  同样地，对于SLO误报的情况，考虑放宽SLO。如果在任一方向上修正SLO会导致误报或漏报，那么你还需要修正SLI实现。修正SLI实现有两种方法可以修正SLI实现: 要么将采集点更靠近用户以提高度量精准度；要么提高覆盖率，从而获得更高的用户交互比例。例如:  在负载均衡或客户端上测量成功率/延迟，而不是在服务器上测量。  更多的功能检测任务，或者在所有客户端通过JavaScript探测，而不仅仅是使用简单的HTTP GET请求来衡量可用性。制定一个高标准的SLO有时你需要更严格的SLO才能让用户满意，但改进产品以满足SLO需要一些时间。 如果你实施更严格的SLO，你将永久地脱离SLO并受到错误预算政策的约束。 在这种情况下，你可以将高标准的SLO作为期望值，与当前SLO一起进行追踪和对比。 通过这种方式，你可以掌握与高标准SLO之间的差距，却不会一直处于高压状态。迭代有许多不同的迭代方法，评审会议可以帮你找到许多潜在改进点。选择成本最低的方法，特别是在最初的几次迭代中，错误常常出现在贪图更快，更便宜方面;  这样做可以减少指标的不确定性，并帮助你确定是否需要更昂贵的指标。 根据需要进行多次迭代。使用SLO和错误预算进行决策一旦你制定了SLO，你就可以使用它们进行决策。当你没有达到SLO，也就是说已经用尽了错误预算，这时面对的首要问题是要做什么？如前所述，错误预算策略会告诉你应该做什么。 常见策略包括降级，直到服务再次处于SLO中；或者花费时间去处理问题以提高服务的可靠性。在特殊情况下，团队可以对外宣布处于紧急状态，取消所有外部需求，直到服务满足退出条件 （退出条件通常指服务处于SLO中，并且短时间内SLO不会出现问题）。我们可以使用改进监控，改进测试，消除系统的依赖关系，或重新调整架构以排除已知的故障类型等方法。你可以根据消耗错误预算的比例来确定事件的规模，并使用这些数据来识别最关键的故障，这些故障需要更深入的追查。例如，假设新版本API的发布导致100％  NullPointerExceptions，系统直到四小时后才可以恢复。检查服务的原始日志表明该问题导致了14,066个错误。 使用制定的97%的SLO和109,897个错误预算的标准来计算，这个故障使用了13%的错误预算。或者，数据库出现问题，而从备份数据恢复需要20小时。基于历史流量估算中断导致了72,000个错误，占错误预算的65%。想象一下，假设五年内只有一次服务器故障导致数据库异常，但通常每年会有两到三个版本被回退。 可以估计发布新版本导致的错误预算是数据库故障的两倍。 这些数字表明，投入资源来解决版本问题比调查服务器故障更有益处。如果服务运行完美且几乎不需要任何监督，并且做到了服务的故障管理和高级别的监督，那么你可以减少对此服务的SLO实施。因此，你可以将精力集中在其他需要更多SRE支持的系统上。表2-5  提供了基于三个关键维度决策矩阵:  SLO指标  维护服务所需要的工作量  客户对服务的满意程度表2-5   SLO决策矩阵             SLO      工作量      客户满意度      行动                         Met      Low      High      a.提高发布的可靠度和部署的速度      b.退出参与，并将工程重点放在需要更高可靠性的服务上              Met      Low      Low      收紧SLO                     Met      High      High      如果报警产生误报，则降低灵敏度。      否则，暂时放松SLO，减少琐事，并修复产品，或通过自动化处理故障来缓解              Met      High      Low      收紧SLO                     Missed      Low      High      放宽SLO                     Missed      Low      Low      增加报警灵敏度                     Missed      High      High      放宽SLO                     Missed      High      Low      减少琐事，修复产品或通过自动化处理故障来缓解             SLO进阶一旦你拥有成熟的SLO和错误预算的氛围，下一步要做的就是继续改进和完善如何度量服务的可靠性。模拟用户SLO最终应该以改善用户体验为中心。 因此，你应该以用户为中心制定SLO。你可以仿照用户典型流程来评估用户的体验 （典型流程是指一系列任务的集合，包括了用户体验核心部分，也是服务的重要方面）。 例如，对于在线购物体验，用户典型流程包括：（运小白说：大牛总结的电商典型流程是首页-搜索-商详-购物车-下单-支付）  搜索产品  添加购物车  完成购买这些肯定不能很好地映射到现有的SLI；每个任务都需要多个复杂的步骤，这些步骤可能在任何时候都会失败，并且从日志中推断这些操作的成功（或失败）非常困难。 （例如，如何确定用户在第三步失败了？可能他们只是被分散了注意力）。然而，你需要定位到故障发生的原因是什么，因为这是服务可靠性的一部分。一旦确定了用户最关心的问题，就可以通过监测典型流程来解决上述问题。 你可以通过将不同的日志事件连接在一起，使用高级JavaScript探测，使用客户端检测或使用其他一些过程来度量它们。 一旦你可以定位一个问题，它就变成了另一个SLI。你可以和现有的SLI和SLO一起追踪。 用户关键流程可以在不影响精度的情况下提高你的召回。###分级的重要性并不是所有的请求都是平等的。虽然来自app的HTTP请求——检查帐户通知(其中通知是由每日的管道生成的)对用户很重要，但广告客户与账单相关的请求更重要。我们需要一种方法来对请求进行分类，可以使用“bucketing”来完成此操作 - 也就是说，为SLI添加更多标签，然后对不通的标签制定不同的SLO指标。 表2-6显示了一个示例。表2-6  分级分配SLO             客户层      可用性SLO                  付费用户      99.99%              免费用户      99.9%      你还可以按照响应对请求进行分类，如表2-7所示。表2-7    按照响应进行分类             响应能力      延迟SLO                  交互式（即阻止页面加载的请求）      90％的请求在100毫秒内完成              CSV下载      90％的下载在5秒内开始      如果你可以为每个用户制定SLO，那么你就可以在任何时间内得到处于SLO合理范围内的用户数量。请注意，这个数字是有大量噪音——请求数量非常少的客户要么拥有100%的可用性（因为他们足够幸运地没有遇到故障）要么拥有非常低的可用性（因为他们经历的一个失败会是相当大的百分比，因为请求基数少 )。单个客户可能会因为一些低级的原因而无法满足他们的SLO。但是总的来说，跟踪这个指标是非常有用的。（运小白说：关于分级，我记忆中最深刻的是以前一个同事的总结，30%的资源，支持了10%的流量，提供了5%的收入，因此这类资源必须要优化）依赖关系建模大型系统有许多组件。单个系统可能有表示层、应用层、业务逻辑层和数据持久层。每一层都可能包含许多服务或微服务。虽然你最关心的是系统的SLO实现，但SLO也可以作为提高系统各组件间可靠度的有用方法。例如，系统某个组件被过度依赖，那么它的可靠性保障应尽可能放到最高级。相应组件的团队也应有SLO。如果某些组件可靠性存在客观限制，则SLO应该可以将该限制表现出来。如果这个组件不能满足系统的可靠性要求，要么改进它，要么使用其他组件代替他或进行主动防御（比如：添加缓存，预存储和计算，优雅降级等）。你也可以尝试用数学方法解决这些问题。例如：如果在单个区域内有一个可用性为99.90%的服务，但你需要99.95%的可用性，则在两个区域中部署该服务就可以解决这个需求。两个服务同时发生故障的概率非常低，此时服务的可用性为99.9999%。然而，这种情况的假设前提是两区域服务完全独立，但这几乎不可能。应用程序的两个实例将具有共同的依赖和故障模式，无论如何精心设计和管理，都可能会导致两个服务同时异常。除非将这些依赖项和故障模式都被枚举出来，否则任何此类计算都具有欺骗性。当故障是由其他团队负责的组件引起的，以下两种思路可以用于解决SLO的问题：  你的团队还应该继续开展发布新版本，不要把过多时间用于可靠性相关工作，因为不是你系统引起的问题  你应该制定故障隔离策略，以便最大程度地降低未来可能由此组件引起的服务故障的可能性，无论此组件故障的原因是什么第二种方法将使你的用户更快乐。你可以灵活地运用这个原则。根据停机和依赖关系的性质，冻结更改可能不实际。确定最适合你服务及其依赖项的决定，并将此决定记录在你的错误预算策略中。有关如何在实践中工作的示例，请参阅附录B中的错误预算策略示例。（运小白说：这个问题非常典型，大家都可能会碰到，我使用你的服务，你应该保障你服务承诺的可用性，而不应该是我来解决这个问题；本文给出了另外的一种思路，添加缓存，预存储和计算，优雅降级，多活，多机房部署等来保障自身服务的稳定性，因此下次遇到这类问题，希望大家可以尝试一下这些方式。另外，高内聚低耦合固然重要，但是也不要太过极端，觉得别人的东西都不靠谱，只有全部自己做才放心，很多时候，把一些依赖的服务放到手里独立部署，你觉得稳定性提升很多，其实，那只是集群拆分压力减小后的一种表象，平时很少出问题，因此你也会放松警惕，另外，加之业务众多，每个业务投入的精力也较为有限，一旦出现问题，通常难以应对）放宽SLO，进行试验如果你想对服务进行可靠性的相关试验以便了解指标（例如，增加页面加载时间的延迟）的变化对用户体验的影响程度(例如，完成购买的用户百分比)。我们建议，只有当你确信自己有足够的错误预算时，才进行这类操作和分析。由于延迟、可用性、客户、业务领域和竞争(或缺乏竞争)这些因素之间有许多微妙的相互作用。故意影响顾客体验的决策需要深思熟虑。虽然这种方法的影响听起来十分可怕，因为没有人想失去用户。但通过这种方法，你可以将得到的结论用于服务的改进，从而在未来让服务拥有更好的性能，从而获得更多的用户。这种方法还可以让你在统计学上获得关键业务度量(例如，销售额)和可靠性指标(例如，延迟)之间的关系。如果是这样，你就获得了非常有价值的数据，这些数据可以帮助你做成做出重大决策。这个尝试不应该是一次性的。随着你的服务的发展，你的客户的期望也会随之改变，确保它们之间的关系是实时有效的。这种尝试获得的关系也可能存在风险，因为你可能会误解你得到的数据。例如，如果你人为地将页面加载时间增加了50毫秒的延迟，但是并没有发现相应的损失，那么你可能会得出这样的结论: 延迟的SLO太严格了。然而，你的用户可能是不满意，只是缺乏可替代的产品，用户别无选择。一旦出现竞争对手，你的用户就会流失。一定要保数据的正确性，并采取适当的预防措施。结论本书的每个案例都有SLO理论的影子。既然你已经阅读了这一章，我们希望能够意识到，即使是形式化的SLO(它清楚地向用户传达了你的承诺)也提供了一个清晰的框架来分析你系统表现。在服务未能满足期望时，你还可以用此SLO确定可采取的补救措施。总结：  SLO是衡量服务可靠性的工具  错误预算是一种工具，它可以帮助你平衡可靠性和其他日常工作的精力，同时也是判定工作优先级的好方法  你应该立即使用SLO和错误预算有关SLO文档和错误预算策略的示例，请参阅附录 A和B。]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[第一章 SRE与DevOps之间的联系]]></title>
      <url>/sre/2020/01/01/SRE%E4%B8%8EDevops%E4%B9%8B%E9%97%B4%E7%9A%84%E8%81%94%E7%B3%BB/</url>
      <content type="text"><![CDATA[  《The Site Reliability Workbook — Practical Ways to Implement SRE》 中文版运维是一门很难的学科。 不仅因为没有解决如何很好地运行系统这种普遍问题，现存的最佳实践也是高度依赖环境且未被广泛采纳的；另外一个未解决的问题就是如何更好的管理运维团队。人们普遍认为，对这些问题的详细分析源于二战期间致力于改善盟军军事进程和产出的作战研究，但事实上，长期以来我们一直都在思考如何更好地运营。尽管有这么多的努力和想法，可靠的生产运维仍然是难以保障的,特别是在信息技术和软件可操作性领域， 例如: 企业通常将运维视为成本中心， 这使得对结果进行有意义的改进变得困难甚至不可能。 这种短视的方法还没有被广泛理解， 但对它的不满却已经引发了IT领域对如何组织工作方面的一场革命。这场革命源于试图解决一系列普遍问题， 并诞生了两个不同的解决方案: DevOps 和 SRE(Site Reli‐ability Engineering)。 尽管单从描述上看，他们是企业完全不同的两个方面，需要单独讨论，但事实上，它们的相似之处，要远比我们想象的多。但首先，我们需要来了解一下每种原则的背景。DevOps产生的背景DevOps是一套松散的实践，指南和文化，旨在打破IT开发，运维，网络和安全方面的孤立。 是由John Willis，Damon Edwards和Jez Humble提出，使用CA(L)MS表示：文化（Culture），自动化（Automation），精益（Lean， 如精益管理;也包含持续交付），测量（Measurement,）和分享（Sharing） – 这是一个记住DevOps哲学要点很有用的缩写。 而分享和合作是这一运动的重中之重。 在DevOps方法中，您可以改进某些内容（通常通过自动化实现）、测量结果，并与同事分享这些结果，以便整个组织得到改进。 所有CALMS原则都是由支持文化促进的。DevOps，Agile以及各种其他业务和软件工程技术，都是关于如何在现代世界中进行最佳实践的示例。DevOps哲学中的任何元素彼此都不易彼此分离，这是由基本设计来实现的。 但是，有一些关键的想法可以相对分开地讨论。不再孤岛关键一：不再孤岛 。有以下两种观点：  曾经流行将但却越来越过时的将运维和开发团队独立分开。  在许多情况下，极端的知识孤岛化、纯粹的局部优化的激励以及缺乏协作都是对商业十分不利的。事故是正常的关键二：事故不仅仅是由个人的孤立行动造成的，更是当问题不可避免地发生时，缺乏保障措施的结果。例如，一个糟糕的接口在不经意间助长了压力下的错误行为；如果出现（未知的）错误，系统缺陷将不可避免地导致失败；监控失效使得人们不可能知道是否出了问题，更不用说出了什么问题。一些传统观念强的企业，拥有开除犯错者并惩罚他们的文化。但这样做有其自身的恶果： 他会诱使人们混淆问题、掩盖真相和指责他人， 而所有这些最终没有任何价值。专注于恢复服务比阻止事故发生要更有价值。变更应该是循序渐进的第三个关键点是， 小而频繁的变更是最佳的。 一个比较激进的示例，是变更委员会每月开会讨论彻底修改大型机配置的计划，然而这种做法并不鲜见，所有变更必须由经验丰富的人员进行有效的规划，结果或多或少与最佳实践相悖。变更是有风险的，没错，但是正确的做法是将变更尽可能拆分成更小的组件或单元。然后，根据产品、设计和基础架构的变更，构建稳定的低风险变更管道。（Then you build a steady pipeline of low-risk change out of regular output from product, design, and infrastructure changes）这种策略，增加对小变更的自动化测试和异常变更的可靠回滚，就形成了管理变更的方法：持续集成(CI)和持续交付或部署(CD)。工具和文化是相互关联的工具是DevOps的一个重要组成部分，特别是强调正确管理变更的今天，变更管理依赖于高度定制化的工具。 但总的来说，DevOps的支持者十分强调组织文化 - 而不是工具 - 这是成功采用新工作方式的关键。 一个好的文化可以解决破碎的工具，但相反的情况很少适用。 俗话说， 文化能把战略当早餐吃(意味着文化的影响力远胜过策略)。 与运维一样，变更本身也很难。度量是至关重要的最后，度量在整个业务环境中尤为重要，例如，打破孤立和故障处理。 在上述的每种场景中，你可以通过客观的度量来确定正在发生事情的真实性，验证改变是否符合预期，并为不同职能部门达成一致的对话创建客观基础。 （这适用于商业和其他环境，例如On-call。）##SRE产生的背景SRE是由Google的工程副总裁Ben Treynor Sloss提出的术语（和相关的工作角色）。正如我们在上一节中所看到的，DevOps是运维和产品开发之间在整个生命周期互相协作的一系列广泛原则。SRE是一个工作角色，也是我们发现的一组实践（稍后介绍），以及一些激励这些实践的信念。如果您将DevOps看作一种哲学和工作方法，则可以认为SRE实现了DevOps描述的一些哲学，并且比“DevOps工程师”更接近于这个工作或角色的具体定义。因此，在某种程度上，SRE类实现了DevOps接口。与DevOps运动不同，DevOps运动起源于多家公司的领导者和从业者之间的合作，而SRE在整个行业广泛普及之前，则是由Google的SRE继承周围公司的大部分文化。 考虑到这一轨迹，整个SRE学科目前并没有像DevOps那样在文化上突然增长。 （当然，这并不能说明文化变革对在任意组织中进行SRE是否是必要的）SRE由以下具体原则定义。运维是一个软件问题SRE的基本原则是：做好运维是一个软件问题。 因此，SRE应使用软件工程来解决这一问题。 这涉及广泛的领域，涵盖了从流程和业务变更到同样复杂但更传统的软件问题的所有内容，例如重写堆栈以消除业务逻辑中的单点故障。通过SLOs进行管理SRE不会尝试提供100％的可用性。 正如我们的第一本书 《Site Reliability Engineering》中所讨论的，这是错误的目标， 原因有很多。 相反，产品团队和SRE团队为服务及其用户群选择适当的可用性目标，并管理服务达到该目标，选定这样的目标需要业务部门的强大协作。 SLOs也具有文化内涵：作为利益相关者之间的协作决策，SLO违规行为将团队无可厚非地带回到原点。###减少琐事对于SRE来说，任何手动的， 重复性的的运维任务都是令人憎恶的。 （这并不意味着我们没有任何此类任务：我们有很多这样的操作。我们只是不喜欢它们。）我们相信，如果机器可以执行所需的操作，那么通常应该让机器来执行。 这是一种区别(也是一种价值)，在其他组织中并不常见。在那里，琐事就是工作，而这就是你付钱让一个人去做的事情。而对于在谷歌环境下的SRE来说，琐事不是工作——它不可能是。任何在操作任务上花费的时间都意味着无法再投入到项目工作上——项目工作才能使我们的服务可靠和可扩展。然而，通过“the wisdom of production”，执行运维任务确实为决策提供了重要的参考。这项工作通过提供来自给定系统的实时反馈信息来保持稳定。（This work keeps us grounded by providing real-time feedback from a given system.）琐事的来源需要明确，这样可以最小化或消除它们。然而，如果你发现自己处于操作不足的状态，那么你可能需要更频繁地推动新特性和更改，以便工程师依旧熟悉你所支持的服务的工作方式。                                         The Wisdom of Production A note on “the wisdom of production”: by this phrase, we mean the wisdom you get from something running in production—the messy details of how it actually behaves, and how software should actually be designed, rather than a whiteboarded view of a service isolated from the facts on the ground. All of the pages you get, the tickets the team gets, and so on, are a direct connection with reality that should inform better system design and behavior.把今年的工作自动化在这个领域真正要做是，确定哪些工作基于什么样的条件，以什么样的方式要完成自动化。（The real work in this area is determining what to automate, under what conditions, and how to automate it.）在Google，经验丰富的SRE严格限制团队成员花费在琐事上的时间，与之相反的是他们会在产生持续价值的工程类工作中花费50%的时间。许多人认为这个限制是一个上限。 事实上，将它视为一种保证更为有用，一种明确的声明和启用机制，采用基于工程的方法来解决问题，而不是一遍又一遍地辛劳的解决问题。当我们考虑自动化和琐事时，基线和其如何发挥作用并不直观。（There is an unintuitive and interesting interaction between this benchmark and how it plays out when we think about automation and toil.） 随着时间的推移，一个SRE团队最终会将服务的大部分操作自动化，只留下无法自动化的（Murphy-Beyer效应）。 在其他条件相同的情况下，除非采取其他行动，否则SRE团队所做的事情就会受到影响。 在google你更倾向于通过不断新增服务来达到填满50%的工程设计时间的限制，或者你在自动化方向做的非常成功，以至于你可以去做一些完全不同的事情。通过降低故障成本来快速行动日益提高的可靠性只是SRE带来的众多收益中的一种，事实的确如此，它实际上提高了开发的产出。为什么呢？对于常见故障，减少故障平均修复时间（ Mean Time To Repair）会提高产品开发人员的速度，因为工程师不必在这些故障问题之后耗费时间和精力进行处理。这源于一个众所周知的事实，在一个产品的生命周期里，问题发现的越晚，修复它所付出的代价越高。SREs专门负责改善异常问题的过晚发现，为公司整体带来收益。与开发分享权限“应用程序开发”和“生产”（有时被称为Dev和Ops）之间的严格界限会适得其反。 如果项目事务处的职责划分和作为成本中心的分类，导致权力不平衡、尊重或薪酬方面的差异，则尤其如此。SREs往往倾向于关注生产而不是业务逻辑问题，但随着问题被他们用软件工程工具所解决，他们与产品开发团队分享技术栈。 通常，SREs在他们正在关注的服务的可用性，延迟，性能，效率，变更管理，监控，应急响应和容量规划方面具有特殊的专业知识。 那些特定的（通常定义明确的）能力是SRE对产品和产品的开发团队所做的贡献。理想情况下，产品开发和SRE团队应该对技术栈有一个整体的看法 - 前端，后端，库，存储，内核和物理机器 - 没有团队应该令人嫉妒的拥有着单个组件。事实证明，如果你“模糊线条”并使用SREs共苦JavaScript，或者产品开发人员对内核进行限定，你可以做得更多：知识如何进行更改，权限更加广泛，而激励小心翼翼地保护任何特定的功能这一想法都应摒弃。在《Site Reliability Engineering》这本书里,，我们没有明确表明Google中的产品开发团队默认拥有自己的服务。 SRE既不可用也不保证大部分服务，尽管如此，SRE原则仍然可以告知整个Google如何管理服务。 SRE团队与产品开发团队合作时的所有权模式最终也是一个共享模型。使用相同的工具，无论功能或职位工具是一个非常重要的行为决定因素，  在Google的环境中，SRE如果没有统一的代码库、软件和系统的各种工具、高度优化和专有的生产堆栈等是非常天真的。我们与DevOps分享这个绝对的假设：团队服务应该使用相同的工具，无论他们在组织中的角色如何。 没有好的方法来管理一个服务，当该服务具有一个用于SRE的工具，一个用于产品开发人员的工具，在不同情况下表现不同（并且可能具有灾难性）。 当拥有的分歧越多，公司从改进每个工具努力中的获益就越少。比较和对比从上面聊到的原则中，我们可以立即看到他们之间有很多共性：  DevOps和SRE都接受一种理念，即为了改进，变更是必要的（都接受对于提高而言，变更是必要的）。否则，就没有多少可操作的空间。  协作是DevOps工作的前沿和中心。 有效的分享所有权模式和合作伙伴关系是SRE发挥作用所必需的。 与DevOps一样， SRE也具有跨组织分享的强大价值，这样更容易打破团队之间的孤立。  变更的最佳实践是: 持续小而频繁的变更，大多数操作理想情况下应该是：自动化测试和部署。变更和可靠性之间的关键交互使得这对于SRE尤为重要。  正确的工具至关重要，工具在一定程度上决定了你的行为范围。然而，我们决不能过于关注是否使用某些特定工具实现某种操作；归根结底，面向系统管理的API是更为重要的哲学，它将比任何特定的实现都持久。  度量绝对是DevOps和SRE如何工作的关键。对于SRE, SLOs (服务质量目标) 决定着是否改善和优化服务。当然，如果没有度量( 以及在产品、基础设施/SRE和业务之间的跨团队合作)，就不可能有SLOs。对于DevOps，度量行为通常用于理解流程的输出是什么，反馈周期的持续时间是什么，等等。DevOps和SRE都是面向数据的东西， 无论是从专业角度还是从哲学角度。  管理生产服务的残酷现实意味着故障时有发生，您必须说明原因。SRE和DevOps都进行了无可厚非的故障复盘，以抵消争议。  最终，实施DevOps或SRE是一种整体行为; 两者都希望通过高度特定的方式共同合作，使整个团队（或单位或组织）更好。 对于DevOps和SRE，更好的速度就是产出。如你所见，DevOps和SRE之间有许多的共同点。然而，也存在着显著的差异。DevOps在某种意义上是一个更广泛的哲学和文化。因为它影响的变化范围比SRE更广，所以DevOps对上下文更敏感。 DevOps对于如何在一个具体层面上执行操作没有更详细的说明。例如，它不是关于服务的精确管理的规定。相反，它选择专注于在更广泛的组织中打破壁垒。这就很有价值。另一方面，SRE的职责定义相对狭窄，其职权范围通常是面向服务（面向最终用户）而非整体业务。 因此，它为如何有效运行系统的问题带来了自以为是的知识框架（包括错误预算等概念）。 虽然作为一个职业，SRE非常清楚激励措施及其影响，但它反过来却对孤立化和信息壁垒等主题保持沉默。 它将支持CI和CD，不一定是因为业务需要，而是因为所涉及的操作实践得到了改进。 或者，换句话说，SRE相信和DevOps一样的东西，但原因略有不同。组织环境与成功采纳的培养DevOps和SRE在其运行方式上存在非常大的概念重叠。 正如您所料，他们也有一组类似的条件必须在组织内成立，以便他们  a)首先可以实现，并且  b)从该实现中获得最大的好处。 正如托尔斯泰几乎从未说过的：有效的操作方法都是相似的，而失败的方法都有各自的失败之处。 激励机制可以部分解释这一点。如果组织的文化重视DevOps方法的好处并且愿意承担这些成本 - 通常表现为招聘困难，维持团队和责任，流动性所需的能量，以及用于补偿必要技能所增加的财务资源，这更为罕见 。然后该组织还必须确保激励措施是正确的，以实现这种方法的全部好处。具体而言，以下内容应在DevOps和SRE的环境中都应成立。教条，刚性的激励措施限制了你的成功许多公司无意中定义了破坏集体绩效的激励措施。为了避免这种错误，不要将激励机制局限于与发布相关或可靠性相关的结果。正如任何一位经济学家都能告诉你的那样，如果有一个数字衡量标准，人们总会找到一种方法，让它产生不好的效果，有时甚至是以一种完全出于善意的方式。相反，你应该允许其他人自由地找到正确的选择。正如前面所讨论的，DevOps或SRE通常可以作为产品团队的催化剂，允许其他软件组织以连续可靠的方式向客户提供功能。这种动态机制还解决了传统和分散的系统/软件组方法的一个持久性问题：设计和生产之间缺乏循环反馈。具有早期SRE参与的系统（理想情况下，在设计时）通常在部署后的生产中工作得更好，而不用管是谁负责管理服务。 （没有什么比丢失用户数据更能阻碍功能开发的进展。）最好自己解决这个问题; 不要责怪别人此外，要避免把生产事故或系统故障的责任推给其他组。在许多方面，推卸责任的动力是传统工程操作模型的核心问题，因为运维和软件团队允许出现单独的激励机制。不管怎样，考虑采用以下做法来反驳组织层面的指责:不仅仅只是允许，而是积极鼓励工程师在产品需要时改变代码和配置。还应允许这些团队在其任务范围内采取激进行动，从而消除采取缓慢行动的想法。支持事后总结。这样做排除了淡化或掩盖问题的动机。这一步骤对于充分理解产品并实际优化其性能和功能至关重要，并且依赖于前面提到的生产经验。允许对“运行困难并且不可挽救的”产品不进行支持。 支持暂停这种产品，直到产品开发在支持准备阶段和产品本身得到支持之后再修复该问题，从而节省每个人的时间。 根据您的背景，“运行困难并且不可挽救的”的含义可能会有所不同 - 这里的动态应该是相互理解的责任之一。 对其他组织的推迟可能会更为温和，“我们认为使用这种技能的人有更多的时间”，或者限制在“这些人员将会因为过多的操作工作而没有机会使用他们的工程技能。“在Google，直接撤销此类产品支持的做法已成为一种制度。将可靠性工作视为一个专门的角色在谷歌，SRE和产品开发是独立的组织。每个小组都有自己的重点、优先级和管理，而不需要对另一个小组发号施令。然而，当产品成功时，产品开发团队将有效地资助新员工SRE的提升。这样，产品开发与SRE团队的成功息息相关，就像SREs与产品开发团队的成功息息相关一样。SRE也很幸运地得到了管理层的大力支持，这使得工程师团队认可了“SRE”这一角色。尽管如此，你不需要有一个组织结构图来做不同的事情，但是你需要一个不同的实践社区。不管你是使用组织结构图还是使用非正式的机制，重要的是要认识到专业化会带来挑战。DevOps和SRE的实践者可以从一个同伴社区中获得支持和职业发展，以及一个用来奖励他们独特的技能和观点的职业阶梯。值得注意的是，Google采用的组织结构以及上述一些激励措施在某种程度上依赖于规模庞大的组织。 例如，如果您的20人创业公司只有一个（相对较小的）产品，那么允许运维退出支持没有多大意义。 仍然可以采用DevOps风格的方法，但是，如果您能做的仅仅只是帮助它成长，那么改善操作性差的产品的能力就会受到损害。不过，对于如何满足这些增长需求，与技术债务累积的速度相比，人们通常有比想象中更多的选择。何时可以替代但是，当您的组织或产品增长超过一定规模时，您可以在支持哪些产品或如何确定支持优先级方面行使更大的自由度。 如果很明显，对系统X的支持将比支持系统Y更快地发生，那么隐式条件可以发挥同样的作用,选择不支持服务的行为。在谷歌，SRE与产品开发的强大合作关系已被证明至关重要：如果您的组织存在这种关系，那么撤回（或提供）支持的决定可以基于有关的客观数据来比较运营特征，从而避免非生产性的交涉。SRE与产品开发之间的富有成效的关系也有助于避免产品开发团队在产品或功能准备就绪之前必须交付的组织反模式。相反，SRE可以与开发团队合作，在维护负担转移到具有最多专业知识的人员之前改进产品。争取平等的尊重：职业与薪酬最后，确保正确的职业激励措施到位：我们希望我们的DevOps/SRE组织能够像他们的产品开发伙伴一样受到尊重。因此，每个团队的成员应按大致相同的方法进行评级，并具有相同的薪酬激励。结论在IT运维整体领域的许多方面，DevOps和SRE在实践和理念上都非常接近。DevOps和SRE都需要讨论、管理支持、并从实际工作人员那里来获得重大进展。 实施其中任何一个都是一段旅程，而不是一个快速解决方案：rename-and-shame（重命名和羞耻的）做法是空洞的，不太可能带来收益。 鉴于它是对如何执行操作的更具见解性的实现，SRE对于如何在此过程中更早地更改您的工作实践有更具体的建议，尽管需要进行特定的调整。DevOps关注的范围更广了，因此很难对其进行推理并将其转化为具体的步骤，但恰恰是因为更广泛的关注，可能会遇到较弱的初始阻力。但是，每种方法的实践者都使用许多相同的工具、相同的方法来改变管理，以及相同的基于数据的决策思维方式。最终，我们都面临着同样的问题:生产，让它变得更好——不管我们被称为什么。对于那些有兴趣进一步阅读的人，以下建议可以帮助您更广泛地了解目前正在进行的运维革命的文化，业务和技术基础：  Site Reliability Engineering  Effective DevOps  The Phoenix Project  The Practice of Cloud System Administration: DevOps and SRE Practices for Web Services, Volume 2  Accelerate: The Science of Lean Software and DevOps]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[《SRE Google运维实践》介绍]]></title>
      <url>/sre/2020/01/01/SRE-Google%E8%BF%90%E7%BB%B4%E5%AE%9E%E8%B7%B5/</url>
      <content type="text"><![CDATA[  《The Site Reliability Workbook — Practical Ways to Implement SRE》 中文版Edited by:    Betsy Beyer, Niall Richard Murphy, David K. Rensin, Kent Kawahara and Stephen Thorne前言  The Site Reliability Workbook is the hands-on companion to the bestselling Site Reliability Engineeringbook and uses concrete examples to show how to put SRE principles and practices to work. This book contains practical examples from Google’s experiences and case studies from Google’s Cloud Platform customers. Evernote, The Home Depot, The New York Times, and other companies outline hard-won experiences of what worked for them and what didn’t.《The Site Reliability Workbook》操作手册 通过具体的案例来展示如何在工作中实践SRE。 本书包含了Google自身经历或是从Google’s Cloud Platform的客户案例。例如：Evernote、The Home Depot、The New York Times。  How to Read This Book  This book is the companion volume to Google’s first book, Site Reliability Engineering. To get the most out of this volume, we recommend that you have read, or can refer to, the first SRE book (available to read online for free at google.com/sre). The two works complement each other in the following ways:            The previous work was an introduction to principles and philosophy. This volume concentrates on how those principles are applied. (In a few areas—particu‐larly configuration management and canarying—we also cover some new ground to provide background for the practical treatment of other subjects.)              The earlier volume concentrated exclusively on how SRE is practiced at Google. This work includes perspectives from a number of other firms—from traditional enterprises (including The Home Depot and the New York Times) to digital natives (Evernote, Spotify, and others).              The first book didn’t directly refer to the larger operations community—especially DevOps—whereas this book speaks directly to how SRE and DevOps relate to each other.        This volume assumes that you will bounce between this volume and its predecessor.  You might, for example, read Chapter 4, “Service Level Objectives” in the first book and then read its implementation complement (Chapter 2) in this volume.  This book assumes that every chapter is just the starting point for a longer discussion and journey. Accordingly, this book is intended to be a conversation starter rather than the last word.  —The Editors  如何阅读本书  This book is the companion volume to Google’s first book, Site Reliability Engineer‐ing. To get the most out of this volume, we recommend that you have read, or can refer to, the first SRE book (available to read online for free at google.com/sre). The two works complement each other in the following ways:            The previous work was an introduction to principles and philosophy. This vol‐ume concentrates on how those principles are applied. (In a few areas—particu‐larly configuration management and canarying—we also cover some new ground to provide background for the practical treatment of other subjects.)              The earlier volume concentrated exclusively on how SRE is practiced at Google. This work includes perspectives from a number of other firms—from traditional enterprises (including The Home Depot and the New York Times) to digital natives (Evernote, Spotify, and others).              The first book didn’t directly refer to the larger operations community—espe‐ cially DevOps—whereas this book speaks directly to how SRE and DevOps relate to each other.        This volume assumes that you will bounce between this volume and its predecessor.  You might, for example, read Chapter 4, “Service Level Objectives” in the first book and then read its implementation complement (Chapter 2) in this volume.  This book assumes that every chapter is just the starting point for a longer discussion and journey. Accordingly, this book is intended to be a conversation starter rather than the last word.  —The Editors本书目录结构：第一章  SRE与DevOps之间的联系第一部分：基本原理第二章  SLO实施第三章  SLO工程案例学习第四章  监控第五章  SLO报警第六章  减少琐事第七章  简单化  第八章  On-Call第二部分： 实践第九章   故障响应第十章   故障总结：从失败中学习第十一章  应对过载第十二章  非抽象大系统设计介绍第十三章  数据处理管道第十四章  系统配置最佳实践第十五章  配置细节  第十六章  灰度发布（金丝雀部署）第三部分： 发展第十七章  从过载中识别和恢复   第十八章  SRE：参与模式第十九章  SRE：超出界限第二十章  SRE：团队生命周期第二十一章  SRE：组织变更管理SRE？  网站可靠性工程师（SRE）Site Reliability EngineeringGoogle的SRE具体会负责哪些事情？  SRE在Google不负责某个服务的上线、部署，SRE主要是保障服务的可靠性和性能，同时负责数据中资源分配，为重要服务预留资源，SRE并不负责某个业务逻辑的具体编写，主要负责在服务出现宕机等紧急事故时，可以快速作出响应，尽快恢复服务，减少服务掉线而造成的损失。SRE日常工作和职责包含哪些?  一般来说，SRE团队要承担以下几类职责：可用性改进、延迟优化、性能优化、效率优化、变更管理、监控、紧急事物处理以及容量规划与管理。  Tools Don’t create reliability. Humans do. But tools can help.  相关资料英文原版：the-site-reliability-workbook-next18.pdf悟冥：读《SRE：Google运维解密》一点思考SRE Google运维解密]]></content>
      <categories>
        
          <category> SRE </category>
        
      </categories>
      <tags>
        
          <tag> 《SRE-Google运维实践》 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
