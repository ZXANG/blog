<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-05-26T17:15:50+08:00</updated><id>http://localhost:4000/atom.xml</id><title type="html">Blog</title><subtitle>zxzxzxzx</subtitle><author><name>ZX</name></author><entry><title type="html">kafka相关运维案例</title><link href="http://localhost:4000/%E5%A4%A7%E6%95%B0%E6%8D%AE/2020/05/26/kafka%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E6%A1%88%E4%BE%8B/" rel="alternate" type="text/html" title="kafka相关运维案例" /><published>2020-05-26T00:00:00+08:00</published><updated>2020-05-26T00:00:00+08:00</updated><id>http://localhost:4000/%E5%A4%A7%E6%95%B0%E6%8D%AE/2020/05/26/kafka%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E6%A1%88%E4%BE%8B</id><content type="html" xml:base="http://localhost:4000/%E5%A4%A7%E6%95%B0%E6%8D%AE/2020/05/26/kafka%E7%9B%B8%E5%85%B3%E8%BF%90%E7%BB%B4%E6%A1%88%E4%BE%8B/">&lt;blockquote&gt;

  &lt;p&gt;版本：kafka_2.11-0.10.1.1&lt;br /&gt;
数据：1P+&lt;br /&gt;
规模：20+节点&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h1 id=&quot;__consumer_offsets-topic占用空间过大&quot;&gt;__consumer_offsets topic占用空间过大&lt;/h1&gt;

&lt;h2 id=&quot;现象&quot;&gt;现象：&lt;/h2&gt;
&lt;p&gt;一日kafka集群单节点磁盘报警，上服务器排查发现三个实例的三块盘均已使用85%，其余磁盘均使用40%左右，再次排查发现这三块盘中均是__consumer_offsets_43 这个partition占用将尽3T。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;线上集群未做raid，单实例上有12块盘，__consumer_offsets 共有3副本，因此3台机器均受到影响&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;__consumer_offsets-有什么用&quot;&gt;__consumer_offsets 有什么用？&lt;/h2&gt;
&lt;p&gt;0.9.0版本之后，kafka默认将consumer的offset信息记录在该系统topic里面。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;格式：[consumer group, topic name, partition] :: [offsetmetadata [offset value,  metadata],    committime value,         expiratintime value]   
示例：[test_consumer,  test_topic, 90]        :: [OffsetMetadata [68248895952,   NO_METADATA], CommitTime 1590481622713, ExpirationTime 1590568022713]   
     [消费者组,        topic名称,   分区]      :: [ offset元数据    [offset ,      nometadata ],  提交时间,                  过期时间 ]   

通过该命令可以查看最近100条__consumer_offsets数据

./kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server x.x.x.x:9092 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot;   --max-message 100 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;定位突增的数据&quot;&gt;定位突增的数据？&lt;/h2&gt;

&lt;p&gt;通过消费具体的partition来定位具体是哪个消费者组在提交offset。&lt;/p&gt;

&lt;h3 id=&quot;0900之后版本含&quot;&gt;0.9.0.0之后版本(含)&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/kafka-simple-consumer-shell.sh  --partition 20 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot; --broker-list x.x.x.x:9092 --topic __consumer_offsets --max-message 3000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;为什么会出现该现象&quot;&gt;为什么会出现该现象？&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;线上kafka集群默认配置了数据清楚策略，因此其余topic均按照保留时间进行删除，但 __consumer_offsets 是用来保存 kafka 其余topic消费offset信息的topic，如果log.cleaner.enable设置为false，是不进行数据清除的。&lt;/li&gt;
  &lt;li&gt;研发提交consumer offset方式不对&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;p&gt;__connsumer_offsets部分分区数据量异常的问题是由于以下两方面原因共同造成:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;__connsumer_offsets默认清理策略设置不当，导致过期历史数据无法正常清理。&lt;/li&gt;
  &lt;li&gt;部分应用消费方式不当，导致产生大量commit信息。&lt;/li&gt;
&lt;/ul&gt;</content><author><name>ZX</name></author><category term="ELK" /><summary type="html">版本：kafka_2.11-0.10.1.1 数据：1P+ 规模：20+节点 __consumer_offsets topic占用空间过大 现象： 一日kafka集群单节点磁盘报警，上服务器排查发现三个实例的三块盘均已使用85%，其余磁盘均使用40%左右，再次排查发现这三块盘中均是__consumer_offsets_43 这个partition占用将尽3T。 线上集群未做raid，单实例上有12块盘，__consumer_offsets 共有3副本，因此3台机器均受到影响 __consumer_offsets 有什么用？ 0.9.0版本之后，kafka默认将consumer的offset信息记录在该系统topic里面。 格式：[consumer group, topic name, partition] :: [offsetmetadata [offset value, metadata], committime value, expiratintime value] 示例：[test_consumer, test_topic, 90] :: [OffsetMetadata [68248895952, NO_METADATA], CommitTime 1590481622713, ExpirationTime 1590568022713] [消费者组, topic名称, 分区] :: [ offset元数据 [offset , nometadata ], 提交时间, 过期时间 ] 通过该命令可以查看最近100条__consumer_offsets数据 ./kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server x.x.x.x:9092 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot; --max-message 100 定位突增的数据？ 通过消费具体的partition来定位具体是哪个消费者组在提交offset。 0.9.0.0之后版本(含) /kafka-simple-consumer-shell.sh --partition 20 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot; --broker-list x.x.x.x:9092 --topic __consumer_offsets --max-message 3000 为什么会出现该现象？ 线上kafka集群默认配置了数据清楚策略，因此其余topic均按照保留时间进行删除，但 __consumer_offsets 是用来保存 kafka 其余topic消费offset信息的topic，如果log.cleaner.enable设置为false，是不进行数据清除的。 研发提交consumer offset方式不对 总结 __connsumer_offsets部分分区数据量异常的问题是由于以下两方面原因共同造成: __connsumer_offsets默认清理策略设置不当，导致过期历史数据无法正常清理。 部分应用消费方式不当，导致产生大量commit信息。</summary></entry><entry><title type="html">第一篇blog</title><link href="http://localhost:4000/something/2020/03/11/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E6%96%87/" rel="alternate" type="text/html" title="第一篇blog" /><published>2020-03-11T00:00:00+08:00</published><updated>2020-03-11T00:00:00+08:00</updated><id>http://localhost:4000/something/2020/03/11/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E6%96%87</id><content type="html" xml:base="http://localhost:4000/something/2020/03/11/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E6%96%87/">&lt;blockquote&gt;
  &lt;p&gt;如何搭建该网站！.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- more --&gt;

&lt;h2 id=&quot;准备工作&quot;&gt;准备工作&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;github pages&lt;/li&gt;
  &lt;li&gt;jekyll&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;具体过程&quot;&gt;具体过程&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;github pages 创建
  首先新建仓库， 需要以&lt;code class=&quot;highlighter-rouge&quot;&gt;username.github.io&lt;/code&gt;作为仓库名。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jekyll
  选择模版，可以在&lt;a href=&quot;http://jekyllthemes.org/&quot;&gt;Jekyll Themes&lt;/a&gt;选择自己喜欢的模版。我选择的是 &lt;a href=&quot;http://jekyllthemes.org/themes/jekyll-theme-next/&quot;&gt;Next&lt;/a&gt;
模版，之所以选择该模版，是因为可以按照&lt;a href=&quot;http://theme-next.simpleyyt.com/&quot;&gt;Next 使用文档&lt;/a&gt;一步一步进行操作，对于小白
来说比较友好。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;遇到问题&quot;&gt;遇到问题&lt;/h2&gt;
&lt;h3 id=&quot;jekyll安装-psmac-os&quot;&gt;jekyll安装， ps：mac os&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;ruby版本过低
  解决方案，安装rvm更新ruby，Rvm是一个命令行工具，可以管理多个版本的Ruby。&lt;a href=&quot;https://www.jianshu.com/p/f56addf0c870&quot;&gt;Mac使用RVM更新Ruby&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;权限问题
  使用gem遇到 write permissions for the /usr/bin directory；
    &lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;gem install &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; /usr/local/bin jekyll
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&lt;/p&gt;</content><author><name>ZX</name></author><category term="something" /><summary type="html">如何搭建该网站！. 准备工作 github pages jekyll 具体过程 github pages 创建 首先新建仓库， 需要以username.github.io作为仓库名。 jekyll 选择模版，可以在Jekyll Themes选择自己喜欢的模版。我选择的是 Next 模版，之所以选择该模版，是因为可以按照Next 使用文档一步一步进行操作，对于小白 来说比较友好。 遇到问题 jekyll安装， ps：mac os ruby版本过低 解决方案，安装rvm更新ruby，Rvm是一个命令行工具，可以管理多个版本的Ruby。Mac使用RVM更新Ruby 权限问题 使用gem遇到 write permissions for the /usr/bin directory； sudo gem install -n /usr/local/bin jekyll I</summary></entry><entry><title type="html">第二十一章 组织变更管理</title><link href="http://localhost:4000/sre/2020/01/21/SRE-%E7%BB%84%E7%BB%87%E5%8F%98%E6%9B%B4%E7%AE%A1%E7%90%86/" rel="alternate" type="text/html" title="第二十一章 组织变更管理" /><published>2020-01-21T00:00:00+08:00</published><updated>2020-01-21T00:00:00+08:00</updated><id>http://localhost:4000/sre/2020/01/21/SRE:%E7%BB%84%E7%BB%87%E5%8F%98%E6%9B%B4%E7%AE%A1%E7%90%86</id><content type="html" xml:base="http://localhost:4000/sre/2020/01/21/SRE-%E7%BB%84%E7%BB%87%E5%8F%98%E6%9B%B4%E7%AE%A1%E7%90%86/">&lt;p&gt;在第一本SRE手册的介绍中，Ben Treynor Sloss将SRE团队描述为“以快速创新和大量接受变革为特征”，并将组织变革管理作为SRE团队的核心职责。本章探讨理论如何在实践中应用于SRE团队。在回顾了一些关键的变革管理理论之后，我们探索了两个案例研究，它们展示了在Google中不同的变更管理风格是如何以具体的方式表现出来的。&lt;/p&gt;

&lt;p&gt;请注意，变更管理一词有两种解释：组织变更管理和变更控制。本章将变更管理作为所有方法的集合术语，用于准备和支持个人，团队和业务单位进行组织变革。我们不会在项目管理环境中讨论这个术语，它可以用来指代变更控制流程，例如变更审核或版本控制。&lt;/p&gt;

&lt;h2 id=&quot;sre拥抱变化&quot;&gt;SRE拥抱变化&lt;/h2&gt;
&lt;p&gt;2000多年前，希腊哲学家Heraclitus宣称变化是唯一不变的。这个公理今天仍然适用——特别是在技术方面，尤其是在快速发展的互联网和云计算领域。&lt;/p&gt;

&lt;p&gt;产品团队的存在是为了构建产品、发布功能和满足客户需求。在Google，大多数变化是快节奏的，遵循“启动和迭代”的方法。执行此类更改通常需要跨系统、产品和全球分布的团队进行协调。网站可靠性工程师经常处于这个复杂且快速变化的环境中，负责平衡变更中固有的风险与产品可靠性和可用性。错误预算（参见第2章）是实现这种平衡的主要机制。&lt;/p&gt;

&lt;h2 id=&quot;变更管理简介&quot;&gt;变更管理简介&lt;/h2&gt;
&lt;p&gt;自上世纪40年代Kurt Lewin在该领域的基础性工作以来，变更管理作为一个研究和实践领域不断发展。理论主要侧重于开发管理组织变革的框架。对特定理论的深入分析超出了本书的范围，但是为了在SRE领域内对它们进行语境化，我们简要介绍了一些常见理论以及每种理论如何适用于SRE类型的组织。虽然这些理论框架中隐含的正式流程尚未被SRE应用于Google，但通过这些框架的镜头考虑SRE活动有助于我们改进管理变革的方法。在讨论之后，我们将介绍一些案例研究，展示其中一些理论的元素如何适用于Google SRE领导的变更管理活动。&lt;/p&gt;

&lt;h3 id=&quot;lewin的三阶段模型&quot;&gt;Lewin的三阶段模型&lt;/h3&gt;
&lt;p&gt;Kurt Lewin用于管理变革的“不冻结—改变—冻结”模型是该领域中最古老的相关理论。这个简单的三阶段模型是一个管理过程审查的工具，以及由此产生的群体动态变化。阶段1需要说服一个需要改变的团体。一旦他们接受了改变的想法，第2阶段就会执行这一改变。最后，当变化大致完成时，第3阶段将新的行为和思想模式制度化。该模型的核心原则将该群体作为主要的动态工具，认为当群体计划、执行和完成任何变革期时，应将个人和群体互动作为一个系统来进行检验。因此，Lewin的工作对于在宏观层面规划组织变革最有用。&lt;/p&gt;

&lt;h3 id=&quot;mckinsey的7-s模型&quot;&gt;McKinsey的7-S模型&lt;/h3&gt;
&lt;p&gt;McKinsey的七个S代表结构、战略、系统、技能、风格、员工和共同价值观。 与Lewin的工作类似，该框架也是计划组织变革的工具集。 虽然Lewin的框架是通用的，但7-S的明确目标是提高组织效率。 两种理论的应用始于对当前目的和过程的分析。 但是，7-S还明确涵盖了业务要素（结构、战略、系统）和人员管理要素（共享价值观、技能、风格、员工）。 对于考虑从传统系统管理重点转向更全面的网络可靠性工程方法的团队，此模型可能非常有用。&lt;/p&gt;

&lt;h3 id=&quot;kotter领导变革的八步流程&quot;&gt;Kotter领导变革的八步流程&lt;/h3&gt;
&lt;p&gt;《时代》杂志将John P. Kotter于1996年出版的《引领变革》（Leading Change, Harvard Business School Press）一书评为有史以来最具影响力的25大商业管理书籍之一。 图21-1描述了Kotter变更管理流程中的八个步骤。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/21-1.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图21-1：Kotter的变更管理模型 [来源：](https://www.kotterinc.com/ 8-steps-process-for-leading-change/） &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Kotter的流程尤其与SRE团队和组织相关，只有一个小例外：在许多情况下（例如，即将推出的Waze案例研究），没有必要产生紧迫感。支持快速增长的产品和系统的SRE团队经常面临紧急的扩展、可靠性和运维挑战。组件系统通常由多个开发团队拥有，可能跨越多个组织单元; 扩展问题可能还需要与从物理基础架构到产品管理的团队进行协调。 由于SRE通常在出现问题时处于第一线，因此他们具有独特的动机来领导所需的更改，以确保产品24/7/365全天候可用。大部分SRE工作（隐含地）都采用了Kotter的流程来确保支持产品的持续可用性。&lt;/p&gt;

&lt;h3 id=&quot;prosci-adkar模型&quot;&gt;Prosci ADKAR模型&lt;/h3&gt;

&lt;p&gt;Prosci ADKAR模型侧重于平衡变更管理的业务和人员两个方面。 ADKAR是个人为成功组织变革必须达到的目标的首字母缩写：意识、愿望、知识、能力和强化。&lt;/p&gt;

&lt;p&gt;原则上，ADKAR提供了一个有用的，深思熟虑的，以人为中心的框架。但是，它对SRE的适用性是有限的，因为业务责任通常会带来相当大的时间限制。通过ADKAR的阶段反复进行并提供必要的培训或指导需要在通信方面进行调整和投资，这在全球分布的，以业务为重点的团队的背景下难以实施。也就是说，Google已成功使用ADKAR风格的流程来引入和构建对高级别更改的支持——例如，将全局组织变更引入SRE管理团队，同时保留本地实现细节的自主权。&lt;/p&gt;

&lt;h3 id=&quot;基于情感的模型&quot;&gt;基于情感的模型&lt;/h3&gt;
&lt;p&gt;桥梁过渡模型描述了人们对变化的情感反应。虽然它是人员管理者的有用管理工具，但它不是变更管理的框架或流程。同样，Kübler-Ross变化曲线描述了人们在面对变化时可能会感受到的情感范围。根据Elisabeth Kübler-Ross关于死亡和垂死的研究，它已被用于理解和预测员工对组织变革的反应。这两种模型都可以在变更期间保持高员工生产率，因为不快乐的人很少有生产力。&lt;/p&gt;

&lt;h3 id=&quot;戴明循环&quot;&gt;戴明循环&lt;/h3&gt;
&lt;p&gt;也称为Plan-Do-Check-Act（或PDCA）循环，统计学家Edward W. Deming的这一过程通常用于DevOps环境中以改进流程——例如，采用持续集成/持续交付技术。它不适合组织变革管理，因为它不包括变革的人性方面，包括动机和领导风格。戴明的重点是采用现有流程（机械的，自动化的或工作流的）并循环应用持续改进。我们在本章中提到的案例研究涉及更大的组织变革，其中迭代会适得其反：频繁、痛苦的组织结构变化会削弱员工的信心并对公司文化产生负面影响。&lt;/p&gt;

&lt;h3 id=&quot;这些理论如何应用于sre&quot;&gt;这些理论如何应用于SRE&lt;/h3&gt;
&lt;p&gt;没有一种变更管理模式适用于所有情况，因此Google SRE并未专门针对一种模式进行标准化也就不足为奇了。也就是说，这就是我们如何考虑将这些模型应用于SRE中的常见变更管理方案：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kotter的八步流程是SRE团队的变革管理模式，他们必须将变革视为核心责任&lt;/li&gt;
  &lt;li&gt;Prosci ADKAR模型是SRE管理层可能需要考虑的框架，用于协调全球分布式团队的变更。&lt;/li&gt;
  &lt;li&gt;所有单独的SRE经理都将受益于熟悉Bridges Transition Model和 Kübler-Ross Change Curve，它们提供了在组织变革时为员工提供支持的工具。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;既然我们已经介绍了这些理论，让我们看看两个案例研究，它们展示了变革管理在Google上的表现。&lt;/p&gt;

&lt;h2 id=&quot;案例研究1从临时变更到计划变更的缓和规模&quot;&gt;案例研究1：从临时变更到计划变更的缓和规模&lt;/h2&gt;
&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;
&lt;p&gt;Waze是Google于2013年收购的基于社区的导航应用程序。收购完成后，Waze进入了活跃用户、工程人员和计算基础架构的显著增长期，但在Google内部继续相对独立的运行。这种增长带来了许多技术和组织方面的挑战。&lt;/p&gt;

&lt;p&gt;Waze的自主权和创新精神使他们通过小组工程师的基层技术响应来应对这些挑战，而不是前一节讨论的正式模型所暗示的管理性，结构化的组织变革。然而，他们在整个组织和基础设施中传播变更的方法与Kotter的变更管理模型非常相似。本案例研究探讨了Kotter的流程（我们追溯应用）如何恰当地描述了Waze在收购后增长所面临的一系列技术和组织挑战。&lt;/p&gt;

&lt;h3 id=&quot;消息队列在保持可靠性的同时更换系统&quot;&gt;消息队列：在保持可靠性的同时更换系统&lt;/h3&gt;
&lt;p&gt;Kotter的模型以一种紧迫感开始了变革的周期。Waze的SRE团队需要在Waze的消息队列系统的可靠性严重退化，导致日益频繁和严重的停机时迅速而果断地采取行动。如图21-2所示，消息队列系统对于操作至关重要，因为Waze的每个组件（实时、地理编码、路由等）都使用它来与内部的其他组件进行通信。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/21-2.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图21-2：Waze组件之间的通信路径 &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;随着消息队列上的吞吐量显着增长，系统根本无法应对不断增长的需求。SRE需要手动干预以在越来越短的时间间隔内保持系统稳定性。在最糟糕的情况下，整个Waze SRE团队每周7天，每天24小时大部分时间在进行排障，最终每小时重新启动消息队列的一些组件，以保持消息流动，数千万用户满意。&lt;/p&gt;

&lt;p&gt;由于SRE还负责构建和发布所有Waze软件，因此这种操作负载对特性速度有明显影响——当SRE花费所有时间处理故障时，他们几乎没有时间支持新功能推出。通过强调情况的严重性，工程师说服Waze领导重新评估优先级并将一些工程师的时间用于可靠性工作。两个SRE和一名高级工程师的指导联盟聚集在一起形成了一个未来的战略愿景，SRE辛劳不再是保持信息流动所必需的。这个小团队评估了现成的消息队列产品，但很快就决定他们只能通过定制解决方案满足Waze的扩展和可靠性要求。&lt;/p&gt;

&lt;p&gt;如果没有某种方法在此期间维持操作，在内部开发此消息队列是不可能的。联盟从使用当前消息传递队列的团队中招募了一批志愿者开发人员，从而消除了这一障碍。每个团队都检查了他们的服务代码库，以确定减少他们发布的消息数量的方法。删除不必要的消息，并在旧队列的顶部扩展压缩层，可以减少系统上的一些负载。该团队还通过为一个特定组件构建专用消息队列来获得更多的操作空间，该组件负责超过30％的系统流量。这些措施产生了足够的临时操作缓冲，允许在两个月内组装和测试新消息传递系统的原型。&lt;/p&gt;

&lt;p&gt;即使没有迫在眉睫的服务崩溃的压力，迁移每秒处理数万条消息的消息队列系统也是一项艰巨的任务。但逐渐减少旧系统的负载可以减轻一些压力，为团队提供更长的时间窗口来完成迁移。为此，Waze SRE重建了消息队列的客户端库，以便他们可以使用其中一个或两个系统发布和接收消息，使用集中控制界面来切换流量。&lt;/p&gt;

&lt;p&gt;一旦新系统被证明有效，SRE就开始了迁移的第一阶段：他们发现了一些低流量，高重要性的消息流，消息传递中断对这些消息流来说是灾难性的。对于这些流，向两个消息传递系统写入将提供一个备份路径。有几次差点失败，当旧系统摇摇欲坠时，备用路径保持核心Waze服务的运行，提供了短期的胜利，证明了最初的投资是合理的。&lt;/p&gt;

&lt;p&gt;大规模迁移到新系统需要SRE与使用它的团队密切合作。该团队需要弄清楚如何最好地支持他们的用例以及如何协调流量切换。由于SRE团队自动化了迁移流量的过程，并且新系统默认支持更多用例，因此迁移率显著加快。&lt;/p&gt;

&lt;p&gt;Kotter的变革管理流程以实施变革而告终。最终，在采用新系统背后有足够的动力，SRE团队可以声明旧系统已弃用且不再受支持。几个季度后他们迁移了最后的一批消息队列。如今，新系统处理的负载超过前一个系统的1000倍，并且几乎不需要SRE的人工干预即可持续提供支持和维护。&lt;/p&gt;

&lt;h3 id=&quot;下一个变更周期改进部署过程&quot;&gt;下一个变更周期：改进部署过程&lt;/h3&gt;
&lt;p&gt;作为一个周期的变化过程是Kotter的关键见解之一。当涉及到SRE面临的技术变化类型时，有意义变化的周期性特征尤其明显。消除系统中的一个瓶颈常常会突出显示另一个瓶颈。随着每个变更周期的完成，由此产生的改进、标准化和自动化可以节省工程时间。工程团队现在有空间更仔细地检查他们的系统并识别更多的痛点，从而触发下一个变化周期。&lt;/p&gt;

&lt;p&gt;当Waze SRE最终能够从与消息传递系统相关的问题中退出时，一个新的瓶颈出现了，随之而来的是一种新的紧迫感：SRE对发行版本的唯一所有权明显地、严重地阻碍了开发速度。发布的手动性质需要大量的SRE投入时间。为了加剧已经不理想的情况，系统组件很大，而且由于发布成本很高，它们的频率相对较低。因此，每个版本都代表一个大的增量，这大大增加了一个重大缺陷需要回滚的可能性。&lt;/p&gt;

&lt;p&gt;由于Waze SRE没有一个方案的总体规划，因此逐步改进为更好的发布流程。为了精简系统组件，以便团队能够更快地迭代每个组件，Waze的一位高级开发人员创建了一个构建微服务的框架。这提供了一个标准的“电池包含”平台，使得工程组织可以很容易地将其组件分开。SRE与该开发人员一起工作，以包含一些重点关注可靠性的特性——例如，一个通用的控制界面和一组易于自动化的行为。因此，SRE可以开发一套工具来管理发布过程中以前昂贵的部分。其中一种工具通过将创建一个新的微服务所需的所有步骤与框架捆绑在一起来鼓励采用。&lt;/p&gt;

&lt;p&gt;这些工具一开始很简单，最初的原型是由一个SRE在几天内完成的。随着团队从它们的父组件中分离出更多的微服务，SRE开发的工具的价值在更广泛的组织中很快变得明显起来。SRE将精简后的组件投入生产的时间减少了，而单独发布新的微服务的成本要低得多。&lt;/p&gt;

&lt;p&gt;虽然发布过程已经有了很大的改进，但新微服务的激增意味着SRE的总体负担仍然令人担忧。工程领导不愿意承担发布过程的责任，直到发布不再那么繁重。&lt;/p&gt;

&lt;p&gt;作为回应，一个由SREs和开发人员组成的小联盟勾勒出了一个战略愿景，使用Spinnaker(一个开源、多云、持续交付平台，用于构建和执行部署工作流)转向持续部署策略。通过引导工具节省的时间，团队现在能够设计这个新系统，以支持一键构建和部署成百上千的微服务。新系统在各个方面都优于以前的系统，但是SRE仍然无法说服开发团队进行转换。这种不情愿是由两个因素驱动的：必须将自己的发行版推向生产的明显的抑制因素，加上对发布过程的可见性不强所导致的变更厌恶。&lt;/p&gt;

&lt;p&gt;Waze SRE通过展示新流程如何增加价值来消除这些采用障碍。该团队构建了一个集中式仪表盘，显示二进制文件的发布状态以及微服务框架导出的一些标准指标。开发团队可以很轻松地将他们的发布与这些指标中的变化联系起来，这使他们相信部署是成功的。SRE与一些面向系统的志愿者开发团队密切合作，将服务转移到Spinnaker。&lt;/p&gt;

&lt;p&gt;这些胜利证明了新的系统不仅能够满足它的需求，而且能够在原有的发布过程之外增加价值。此时，工程领导为所有团队设定了一个目标，即使用新的Spinnaker部署管道来执行发布。为了促进迁移，Waze SRE为具有复杂需求的团队提供了组织范围内的Spinnaker培训和咨询会议。当早期采用者熟悉新系统后，他们的积极经历引发了加速采用的连锁反应。他们发现，与等待SRE推送他们的版本相比，这个新的流程更快，痛苦也更少。现在，工程师开始对没有移动的依赖项施加压力，因为他们是加快开发速度的障碍——而不是SRE团队!&lt;/p&gt;

&lt;p&gt;如今，超过95%的Waze的服务使用Spinnaker进行持续部署，并且可以在极少人工参与的情况下将更改推到生产环境中。虽然Spinnaker并不是一种万能的解决方案，但是如果使用微服务框架构建了一个新的服务，那么配置一个发布管道是很简单的，因此新的服务有强烈的动机对这个解决方案进行标准化。&lt;/p&gt;

&lt;h3 id=&quot;经验总结&quot;&gt;经验总结&lt;/h3&gt;
&lt;p&gt;Waze在消除技术变更瓶颈方面的经验，对于其他尝试工程主导技术或组织变更的团队来说，包含了许多有用的经验。首先，改变管理理论不是浪费时间！通过Kotter过程的镜头来观察这个开发和迁移过程可以证明模型的适用性。当时，Kotter模型更正式的应用可能有助于简化和指导变更的过程。&lt;/p&gt;

&lt;p&gt;从基层发起的变更需要SRE和研发团队之间的密切合作，以及行政领导的支持。创建一个小的、集中的团队，成员来自组织的各个部分——sre、开发人员和管理人员——是团队成功的关键。类似的合作对实现这一变更至关重要。随着时间的推移，这些特设小组能够而且应该发展成更正式和更结构化的合作，在这种合作中，SREs自动参与设计讨论，并能够就在整个产品生命周期中在生产环境中构建和部署健壮的应用程序的最佳实践提供建议。&lt;/p&gt;

&lt;p&gt;增量更改更容易管理。直接跳到“完美”的解决方案是一个非常大的步骤，不能一下子全部执行（如果你的系统即将崩溃，更不用说可能是不可行的），而且“完美”的概念可能会随着更改过程中新信息的出现而演进。迭代方法可以演示早期的胜利，帮助组织接受变更的远景 并证明进一步的投资是合理的。另一方面，如果早期的迭代没有显示出价值，那么当你不可避免地放弃变更时，你将浪费更少的时间和资源。因为增量式的改变不是一下子就能发生的，所以有一个总体计划是非常宝贵的。用宽泛的术语描述目标，要灵活，并确保每次迭代都朝着目标前进。&lt;/p&gt;

&lt;p&gt;最后，有时你当前的解决方案不能支持你的战略远景的需求。构建新事物需要大量的工程成本，但如果项目将你推离了局部的最大值，并且能够实现长期的增长，那么这是值得的。作为一个思想实验，随着业务和组织在未来几年的增长，找出系统和工具中可能出现的瓶颈。如果你怀疑任何元素没有横向扩展，或者对于核心业务度量（如每日活跃用户）具有超线性（或者更糟，是指数增长），那么你可能需要考虑重新设计或替换它们。&lt;/p&gt;

&lt;p&gt;Waze开发的一种新的内部消息队列系统表明，一小群有决心的工程师有可能进行变革，从而提高服务可靠性。将Kotter的模型映射到变更上表明，对变更管理策略的一些考虑可以帮助提供成功的公式，即使是在小型的、工程主导的组织中。而且，正如下一个案例研究也表明的那样，当变革促进标准化技术和过程时，整个组织可以获得相当大的效率收益。&lt;/p&gt;

&lt;h2 id=&quot;案例研究2sre中的通用工具采用&quot;&gt;案例研究2：SRE中的通用工具采用&lt;/h2&gt;
&lt;h3 id=&quot;背景-1&quot;&gt;背景&lt;/h3&gt;
&lt;p&gt;SREs对于他们可以用来管理生产的软件持有不同的看法。多年的经验，观察什么做得好，什么做得不好，以及通过事后分析的视角来审视过去，让SREs有了深刻的背景和强烈的直觉。在SRE中，指定、构建和试实施软件以自动化今年的工作是核心价值。特别是，Google SRE最近将我们的工作重点放在了横向软件上。大量用户和开发人员采用了相同的解决方案，这就形成了一个良性循环，减少了重新开发。否则可能不进行交互的团队将共享使用相同软件自动化的实践和策略。&lt;/p&gt;

&lt;p&gt;这个案例研究基于组织的发展，而不是对系统扩展或可靠性问题的响应（如Waze案例研究中所讨论的）。因此，Prosci ADKAR模型（如图21-3所示）比Kotter的模型更适合，因为它识别了在变更期间显式的组织/人员管理特征和技术考虑。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/21-2.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图21-3：变更管理的Prosci ADKAR模型 &lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&quot;问题陈述&quot;&gt;问题陈述&lt;/h3&gt;
&lt;p&gt;几年前，Google SRE发现自己使用了多个独立的软件解决方案，可以在多个问题空间中解决大致相同的问题：监控、发布和部署、事件响应、容量管理等等。&lt;/p&gt;

&lt;p&gt;这种最终状态出现的部分原因是为SRE构建工具的人员与他们的用户及其需求是分离的。工具开发人员并不总是对问题陈述或整个生产环境有一个当前的视图——生产环境以新的方式以非常快的速度变化，因为新的软件、硬件和用例几乎每天都被引入到生活中。此外，工具的使用者是多种多样的，有时还存在正交需求（“这种推出必须是快速的；近似是正确的，相对而言，这个展示必须是100%正确的；可以慢慢进行”）。&lt;/p&gt;

&lt;p&gt;因此，这些长期项目都没有完全满足任何人的需求，每个项目的特点都是不同级别的开发工作、功能完整性和持续的支持。那些等待大用例的人——一个非特定的、全能的未来解决方案——等了很长时间，感到沮丧，并使用他们自己的软件工程技术来创建他们自己的利基解决方案。那些有更小、更具体需求的人不愿意采用一种更广泛的、不适合他们的解决方案。更通用的解决方案的长期、技术和组织效益是显而易见的，但是客户、服务和团队并没有因为等待而得到人员配备或奖励。为了是这种情况更加复杂，大客户团队和小客户团队的需求会随着时间而改变。&lt;/p&gt;

&lt;h3 id=&quot;我们决定做什么&quot;&gt;我们决定做什么&lt;/h3&gt;
&lt;p&gt;为了将此场景扩展为一个具体的问题空间，我们问自己：如果所有Google SREs都可以使用一个通用的监控引擎和一组仪表盘，这些仪表盘易于使用，并且支持各种各样的用例，而不需要自定义，那会怎么样?&lt;/p&gt;

&lt;p&gt;同样，我们可以将这种思维模型扩展到发布和推广、事件响应、容量管理等等。如果一个产品的初始配置捕获了大量的方法来满足我们的大部分功能需求，那么随着时间的推移，我们一般的和高深的解决方案将变得不可避免。在某种程度上，与生产交互的工程师的临界数量将超过他们使用的任何解决方案，并自行选择迁移到一组通用的、受良好支持的工具和自动化中，放弃他们定制的工具和相关的维护成本。&lt;/p&gt;

&lt;p&gt;Google的SRE很幸运，它的许多工程师都有软件工程背景和经验。他们是专家，对具体问题有自己的看法——从负载均衡到发布工具到事件管理和响应——以虚拟团队的形式工作，由共同的长期愿景自行选择。这些工程师将把他们的愿景转化为实际的软件，最终被所有的SRE和所有的Google所采用，作为生产的基本功能。&lt;/p&gt;

&lt;p&gt;为了回到ADKAR的变更管理模型，到目前为止所讨论的步骤——识别问题和确认机会——是ADKAR启动意识步骤的典型例子。Google SRE领导团队同意需求（愿望），并有足够的知识和能力来快速设计解决方案。&lt;/p&gt;

&lt;h3 id=&quot;设计&quot;&gt;设计&lt;/h3&gt;
&lt;p&gt;我们的首要任务是集中讨论一些我们认为是核心的主题，这将极大地受益于一致的愿景：交付适合大多数用例的解决方案和采用计划。从65个以上的项目列表开始，我们花了几个月的时间收集客户需求，验证路线图，进行市场分析，最终将我们的工作范围确定在少数经过审查的主题。&lt;/p&gt;

&lt;p&gt;我们最初的设计围绕这些主题创建了一个虚拟的SRE专家团队。这个虚拟团队将为这些横向项目贡献很大比例的时间，大约80%。80%的时间和一个虚拟团队背后的想法是，确保我们在没有与生产持续接触的情况下，不设计或构建解决方案。然而，我们（也许可以预见）发现了这种方法的一些痛点:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;协调一个虚拟团队是非常困难的，这个团队的重点是在多个时间区域内定期随叫随到。在运行一个服务和构建一个软件之间，有很多状态需要交换。&lt;/li&gt;
  &lt;li&gt;从收集共识到代码审查的所有内容都受到缺乏中心位置和公共时间的影响。&lt;/li&gt;
  &lt;li&gt;横向项目的人员最初必须来自现有的团队，他们现在处理自己项目的工程资源更少了。即使在Google，委派员工来支持系统与委派员工来构建面向未来的基础设施之间也存在矛盾。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有了足够的数据，我们意识到我们需要重新设计我们的方法，并选择更熟悉的集中式模型。最重要的是，我们取消了团队成员在项目工作和值班职责之间分配80/20时间的要求。大多数SRE软件开发现在都是由拥有大量on-call经验的高级工程师组成的小组来完成的，但他们都是专注于基于这些经验构建软件的。我们也通过招募或调动工程师来集中这些团队。小组（6-10人）的开发在一个房间内更有效率（然而，这个论点并不适用于所有的小组——例如，远程SRE团队）。我们仍然可以通过视频会议、电子邮件和传统的出差来达到收集整个Google工程组织的需求和观点的目标。&lt;/p&gt;

&lt;p&gt;所以我们的设计演变实际上出现在一个熟悉的地方——小型、灵活、大多是本地、快速发展的团队——但更加强调选择和构建自动化和工具，以供60%的Google工程师采用（我们确定这个数字是对“几乎每个人都在Google”的目标）。成功意味着Google大部分人都在使用SRE为管理其生产环境而构建的工具。&lt;/p&gt;

&lt;p&gt;ADKAR模型在以人为中心的知识和能力阶段之间映射了变更项目的实现阶段。这个案例研究证实了这种映射。我们有许多敬业、才华横溢、知识渊博的工程师，但我们通过关注客户需求，产品路线图和交付承诺，要求那些专注于SRE问题的人员像产品软件开发工程师一样行事。我们需要重新考虑这个更改的实现，以使工程师能够展示他们关于这些新属性的能力。&lt;/p&gt;

&lt;h3 id=&quot;实现监控&quot;&gt;实现：监控&lt;/h3&gt;
&lt;p&gt;为了回到上一节中提到的监控空间，第一本SRE手册中的第31章描述了Viceroy-Google SRE如何创建一个适合所有人的监控仪表盘解决方案，解决了完全不同的定制解决方案的问题。几个SRE团队一起创建并运行最初的迭代，随着Viceroy成长为Google的实际监控和仪表盘解决方案，一个专门的集中式SRE开发团队承担了项目的所有权。&lt;/p&gt;

&lt;p&gt;但是，即使Viceroy框架将SRE统一在一个共同的框架下，由于团队构建了特定于其服务的复杂自定义仪表盘，因此需要进行大量重复工作。虽然Viceroy提供了一种标准的托管方法来设计和构建数据的可视化显示，但仍然需要每个团队决定显示哪些数据以及如何组织这些数据。&lt;/p&gt;

&lt;p&gt;现在集中化的软件开发团队开始了第二个并行工作，提供通用仪表板，在较低级别的“自定义”系统之上构建了一个固定的零配置系统。这个零配置系统提供了一套标准的综合监控显示，它基于一个给定的服务被组织为少数流行的样式之一的假设。随着时间的推移，大多数服务都迁移到使用这些标准仪表板，而不是投资于自定义布局。如果需要，非常大的、独特的或其他特殊的服务仍然可以在托管系统中部署自定义视图。&lt;/p&gt;

&lt;p&gt;回到ADKAR模型，Google监控工具的整合始于基层工作，由此带来的运营效率提升提供了可量化的基础（意识和愿望），以启动更广泛的努力：SRE自筹资金的软件开发团队为所有Google构建生产管理工具。&lt;/p&gt;

&lt;h3 id=&quot;经验总结-1&quot;&gt;经验总结&lt;/h3&gt;
&lt;p&gt;设计相互依赖的部件的迁移通常比空白页设计更复杂。但在现实生活中，最困难的工程工作最终是将许多小型/受限系统演变成更少、更通用的系统——而不会干扰许多客户所依赖的已经在运行的服务。与此同时，除了现有的系统之外，新的小型系统也在不断增加——其中一些系统最终发展成为大型系统而让我们感到惊讶。大型设计重新开始，只有支持真正必要的约束，才有吸引力，但系统和团队的迁移是迄今为止最困难的工作。&lt;/p&gt;

&lt;p&gt;设计横向软件需要大量听取潜在最终用户的意见，在许多方面，构建和采用的任务看起来很像产品经理的角色。为了使这一努力取得成功，我们必须确保我们吸收并优先考虑优先事项。满足客户需求——SREs和其他生产用户的需求——也是成功的关键因素。必须承认，向通用工具的转移仍然是一项正在进行的工作。我们对构建共享技术的团队的结构和人员进行了迭代，以更好地满足客户需求，我们还增加了产品管理和用户体验人才(解决了缺失的知识)。&lt;/p&gt;

&lt;p&gt;在过去的一两年里，我们在Google的许多团队中看到了这些SRE设计和构建的产品。我们已经了解到，要想取得成功，迁移（从旧的、碎片化的、专门的解决方案）的成本相对于新的通用解决方案的净收益而言较小。否则，迁移本身就会成为采用的障碍。我们继续与构建这些产品的单个团队合作，以加强团队交付的通用解决方案满足客户所需的行为。&lt;/p&gt;

&lt;p&gt;我们在横向软件开发项目中发现的一个共同主题是，无论新软件和产品有多好，从已经在工作的东西迁移到新东西的迁移成本总是被认为非常高。尽管有更容易管理和不太具体的深入知识的诱惑，从熟悉的地方迁移（尽管有缺点和辛苦）的成本通常是一个障碍。此外，个别工程师也经常有类似的内部独白：“我没有改进或改变系统；我把一个工件换成另一个工件。ADKAR将这种阻力描述为“知识——能力差距”。在人性方面，为了认识和接受变革，人们需要时间、指导和新工具和技能方面的培训。在技术方面，实现变更需要理解采用成本，并包括将这些成本最小化的工作作为启动过程的一部分。&lt;/p&gt;

&lt;p&gt;因此，对于团队、个人和公司来说，迁移成本必须接近于零（“只需重新编译，您就可以获得新的东西”），而好处也必须明确（“现在你可以免受$foo漏洞的伤害”）。&lt;/p&gt;

&lt;p&gt;SRE通常用于以“尽力而为”的方式构建我们承诺的产品，这意味着我们给产品的时间量适合我们正在做的其他事情之间的裂缝（管理主要服务，容量规划，处理中断，等等）。因此，我们的执行不是很可靠；无法预测什么时候可以使用某个特性或服务。延伸开来，我们产品的消费者对最终结果的信任度就降低了，因为我们的产品总是会被推迟，并且有一个轮流的产品经理和个体工程师组成。当各个SREs或SRE团队为自己的使用构建工具时，重点是解决个别问题，以降低为支持的系统维护SLOs的成本。为了在Google中为大多数用例构建通用工具，我们需要将重点转移到衡量这项工作在产品采用方面的成功与否。&lt;/p&gt;

&lt;p&gt;由于我们的组织文化和丰富的资源，我们以自下而上而不是自上而下的方式来处理这个项目。我们没有强制用户迁移到我们的新监控系统，而是通过证明我们的新产品比现有的解决方案更好来赢得用户。&lt;/p&gt;

&lt;p&gt;随着时间的推移，我们了解到我们如何执行我们的开发过程将告知潜在的内部用户如何感知最终结果。只有当生产经验丰富的工程师100%致力于构建软件时，这些项目才能获得真正的吸引力，其计划和支持与Google的其他软件开发相同。透明地构建通用软件，像clockwork一样，具有良好的通信（“我们将在Y 日期之前完成X”），极大地提高了迁移到新系统的速度。人们已经信任这个新系统，因为他们可以观察到它是如何从早期发展起来的。从一开始，人们对香肠制作过程的理解就比我们预想的更加重要。我们最初的想法是“如果你创造出伟大的东西，人们会自然而然地涌向它”，但这并不是真的。相反，这些项目必须明确定义，事先做好宣传，针对大量的用户案例（首先针对最暴躁的采用者）进行评估，比现有的选择有更好的跳跃式发展，并且可以毫不费力地采用。&lt;/p&gt;

&lt;p&gt;普通工具采用的消费者越多，除了编写代码之外，你实际花费的时间就越多。回想起来，这听起来可能很明显，但是清晰的最终目标、可信的日期、定期的更新以及与消费者的持续接触是至关重要的。通常持怀疑态度的消费者会问：“如果我当前的一次性shell脚本运行良好，我真的需要这个吗?”采用通用软件或流程类似于可靠性作为一项特性——你可以构建世界上最好的东西，但是如果人们不采用它（或者如果它不可靠就不能使用它），那么它对任何人都没有用处。当涉及到构建和采用通用工具和实践时，制定一个采用计划——从拥护者到beta测试人员，从执行发起人到专门的工程师，他们都明白最小化采用障碍的重要性——既是最终目标，也是起点。&lt;/p&gt;

&lt;p&gt;这是因为采用会带来网络效应：随着普通软件工具的规模和范围的扩大，对这些工具的逐步改进对组织来说更有价值。随着工具价值的增加，致力于它们的开发工作也会增加。这些开发工作中的一部分自然用于进一步降低迁移成本，鼓励更多的采用。广泛采用鼓励以一致的、类似于产品的方式构建组织范围内的改进，并证明配备完整的团队以支持长期的工具是合理的。这些工具应该具有快速开发、特性稳定性、通用控制界面和可自动化api的特点。&lt;/p&gt;

&lt;p&gt;在衡量此类工作的影响时，我们可以提出类似以下问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;新产品开发人员能够以多快的速度构建和管理世界级服务？&lt;/li&gt;
  &lt;li&gt;通过常见的工具和实践启用，一个领域中的SRE可以多容易地转移到另一个领域?&lt;/li&gt;
  &lt;li&gt;使用相同的原语可以管理多少服务，如端到端用户体验与单独服务？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些都是度量影响的可能且非常有价值的方法，但是我们的第一个度量必须是采用。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;正如Waze和横向软件案例研究所展示的那样，即使在一家公司内，SRE变更管理也可能需要处理各种问题空间和组织环境。因此，可能没有任何一种正式的变更管理模型可以巧妙地应用于任何给定组织可能处理的变更范围。然而，这些框架，特别是Kotter的八步过程和Prosci ADKAR模型，可以为即将发生的变化提供有用的见解。在像SRE这样动态的环境中，任何必要的更改都有一个共同点，那就是不断的重新评估和迭代。虽然许多变化可能以基层的方式有机地开始，但随着变化的成熟，大多数变化可以从结构化的协调和计划中获益。&lt;/p&gt;</content><author><name>ZX</name></author><category term="《SRE-Google运维实践》" /><summary type="html">在第一本SRE手册的介绍中，Ben Treynor Sloss将SRE团队描述为“以快速创新和大量接受变革为特征”，并将组织变革管理作为SRE团队的核心职责。本章探讨理论如何在实践中应用于SRE团队。在回顾了一些关键的变革管理理论之后，我们探索了两个案例研究，它们展示了在Google中不同的变更管理风格是如何以具体的方式表现出来的。 请注意，变更管理一词有两种解释：组织变更管理和变更控制。本章将变更管理作为所有方法的集合术语，用于准备和支持个人，团队和业务单位进行组织变革。我们不会在项目管理环境中讨论这个术语，它可以用来指代变更控制流程，例如变更审核或版本控制。 SRE拥抱变化 2000多年前，希腊哲学家Heraclitus宣称变化是唯一不变的。这个公理今天仍然适用——特别是在技术方面，尤其是在快速发展的互联网和云计算领域。 产品团队的存在是为了构建产品、发布功能和满足客户需求。在Google，大多数变化是快节奏的，遵循“启动和迭代”的方法。执行此类更改通常需要跨系统、产品和全球分布的团队进行协调。网站可靠性工程师经常处于这个复杂且快速变化的环境中，负责平衡变更中固有的风险与产品可靠性和可用性。错误预算（参见第2章）是实现这种平衡的主要机制。 变更管理简介 自上世纪40年代Kurt Lewin在该领域的基础性工作以来，变更管理作为一个研究和实践领域不断发展。理论主要侧重于开发管理组织变革的框架。对特定理论的深入分析超出了本书的范围，但是为了在SRE领域内对它们进行语境化，我们简要介绍了一些常见理论以及每种理论如何适用于SRE类型的组织。虽然这些理论框架中隐含的正式流程尚未被SRE应用于Google，但通过这些框架的镜头考虑SRE活动有助于我们改进管理变革的方法。在讨论之后，我们将介绍一些案例研究，展示其中一些理论的元素如何适用于Google SRE领导的变更管理活动。 Lewin的三阶段模型 Kurt Lewin用于管理变革的“不冻结—改变—冻结”模型是该领域中最古老的相关理论。这个简单的三阶段模型是一个管理过程审查的工具，以及由此产生的群体动态变化。阶段1需要说服一个需要改变的团体。一旦他们接受了改变的想法，第2阶段就会执行这一改变。最后，当变化大致完成时，第3阶段将新的行为和思想模式制度化。该模型的核心原则将该群体作为主要的动态工具，认为当群体计划、执行和完成任何变革期时，应将个人和群体互动作为一个系统来进行检验。因此，Lewin的工作对于在宏观层面规划组织变革最有用。 McKinsey的7-S模型 McKinsey的七个S代表结构、战略、系统、技能、风格、员工和共同价值观。 与Lewin的工作类似，该框架也是计划组织变革的工具集。 虽然Lewin的框架是通用的，但7-S的明确目标是提高组织效率。 两种理论的应用始于对当前目的和过程的分析。 但是，7-S还明确涵盖了业务要素（结构、战略、系统）和人员管理要素（共享价值观、技能、风格、员工）。 对于考虑从传统系统管理重点转向更全面的网络可靠性工程方法的团队，此模型可能非常有用。 Kotter领导变革的八步流程 《时代》杂志将John P. Kotter于1996年出版的《引领变革》（Leading Change, Harvard Business School Press）一书评为有史以来最具影响力的25大商业管理书籍之一。 图21-1描述了Kotter变更管理流程中的八个步骤。 图21-1：Kotter的变更管理模型 [来源：](https://www.kotterinc.com/ 8-steps-process-for-leading-change/） Kotter的流程尤其与SRE团队和组织相关，只有一个小例外：在许多情况下（例如，即将推出的Waze案例研究），没有必要产生紧迫感。支持快速增长的产品和系统的SRE团队经常面临紧急的扩展、可靠性和运维挑战。组件系统通常由多个开发团队拥有，可能跨越多个组织单元; 扩展问题可能还需要与从物理基础架构到产品管理的团队进行协调。 由于SRE通常在出现问题时处于第一线，因此他们具有独特的动机来领导所需的更改，以确保产品24/7/365全天候可用。大部分SRE工作（隐含地）都采用了Kotter的流程来确保支持产品的持续可用性。 Prosci ADKAR模型 Prosci ADKAR模型侧重于平衡变更管理的业务和人员两个方面。 ADKAR是个人为成功组织变革必须达到的目标的首字母缩写：意识、愿望、知识、能力和强化。 原则上，ADKAR提供了一个有用的，深思熟虑的，以人为中心的框架。但是，它对SRE的适用性是有限的，因为业务责任通常会带来相当大的时间限制。通过ADKAR的阶段反复进行并提供必要的培训或指导需要在通信方面进行调整和投资，这在全球分布的，以业务为重点的团队的背景下难以实施。也就是说，Google已成功使用ADKAR风格的流程来引入和构建对高级别更改的支持——例如，将全局组织变更引入SRE管理团队，同时保留本地实现细节的自主权。 基于情感的模型 桥梁过渡模型描述了人们对变化的情感反应。虽然它是人员管理者的有用管理工具，但它不是变更管理的框架或流程。同样，Kübler-Ross变化曲线描述了人们在面对变化时可能会感受到的情感范围。根据Elisabeth Kübler-Ross关于死亡和垂死的研究，它已被用于理解和预测员工对组织变革的反应。这两种模型都可以在变更期间保持高员工生产率，因为不快乐的人很少有生产力。 戴明循环 也称为Plan-Do-Check-Act（或PDCA）循环，统计学家Edward W. Deming的这一过程通常用于DevOps环境中以改进流程——例如，采用持续集成/持续交付技术。它不适合组织变革管理，因为它不包括变革的人性方面，包括动机和领导风格。戴明的重点是采用现有流程（机械的，自动化的或工作流的）并循环应用持续改进。我们在本章中提到的案例研究涉及更大的组织变革，其中迭代会适得其反：频繁、痛苦的组织结构变化会削弱员工的信心并对公司文化产生负面影响。 这些理论如何应用于SRE 没有一种变更管理模式适用于所有情况，因此Google SRE并未专门针对一种模式进行标准化也就不足为奇了。也就是说，这就是我们如何考虑将这些模型应用于SRE中的常见变更管理方案： Kotter的八步流程是SRE团队的变革管理模式，他们必须将变革视为核心责任 Prosci ADKAR模型是SRE管理层可能需要考虑的框架，用于协调全球分布式团队的变更。 所有单独的SRE经理都将受益于熟悉Bridges Transition Model和 Kübler-Ross Change Curve，它们提供了在组织变革时为员工提供支持的工具。 既然我们已经介绍了这些理论，让我们看看两个案例研究，它们展示了变革管理在Google上的表现。 案例研究1：从临时变更到计划变更的缓和规模 背景 Waze是Google于2013年收购的基于社区的导航应用程序。收购完成后，Waze进入了活跃用户、工程人员和计算基础架构的显著增长期，但在Google内部继续相对独立的运行。这种增长带来了许多技术和组织方面的挑战。 Waze的自主权和创新精神使他们通过小组工程师的基层技术响应来应对这些挑战，而不是前一节讨论的正式模型所暗示的管理性，结构化的组织变革。然而，他们在整个组织和基础设施中传播变更的方法与Kotter的变更管理模型非常相似。本案例研究探讨了Kotter的流程（我们追溯应用）如何恰当地描述了Waze在收购后增长所面临的一系列技术和组织挑战。 消息队列：在保持可靠性的同时更换系统 Kotter的模型以一种紧迫感开始了变革的周期。Waze的SRE团队需要在Waze的消息队列系统的可靠性严重退化，导致日益频繁和严重的停机时迅速而果断地采取行动。如图21-2所示，消息队列系统对于操作至关重要，因为Waze的每个组件（实时、地理编码、路由等）都使用它来与内部的其他组件进行通信。 图21-2：Waze组件之间的通信路径 随着消息队列上的吞吐量显着增长，系统根本无法应对不断增长的需求。SRE需要手动干预以在越来越短的时间间隔内保持系统稳定性。在最糟糕的情况下，整个Waze SRE团队每周7天，每天24小时大部分时间在进行排障，最终每小时重新启动消息队列的一些组件，以保持消息流动，数千万用户满意。 由于SRE还负责构建和发布所有Waze软件，因此这种操作负载对特性速度有明显影响——当SRE花费所有时间处理故障时，他们几乎没有时间支持新功能推出。通过强调情况的严重性，工程师说服Waze领导重新评估优先级并将一些工程师的时间用于可靠性工作。两个SRE和一名高级工程师的指导联盟聚集在一起形成了一个未来的战略愿景，SRE辛劳不再是保持信息流动所必需的。这个小团队评估了现成的消息队列产品，但很快就决定他们只能通过定制解决方案满足Waze的扩展和可靠性要求。 如果没有某种方法在此期间维持操作，在内部开发此消息队列是不可能的。联盟从使用当前消息传递队列的团队中招募了一批志愿者开发人员，从而消除了这一障碍。每个团队都检查了他们的服务代码库，以确定减少他们发布的消息数量的方法。删除不必要的消息，并在旧队列的顶部扩展压缩层，可以减少系统上的一些负载。该团队还通过为一个特定组件构建专用消息队列来获得更多的操作空间，该组件负责超过30％的系统流量。这些措施产生了足够的临时操作缓冲，允许在两个月内组装和测试新消息传递系统的原型。 即使没有迫在眉睫的服务崩溃的压力，迁移每秒处理数万条消息的消息队列系统也是一项艰巨的任务。但逐渐减少旧系统的负载可以减轻一些压力，为团队提供更长的时间窗口来完成迁移。为此，Waze SRE重建了消息队列的客户端库，以便他们可以使用其中一个或两个系统发布和接收消息，使用集中控制界面来切换流量。 一旦新系统被证明有效，SRE就开始了迁移的第一阶段：他们发现了一些低流量，高重要性的消息流，消息传递中断对这些消息流来说是灾难性的。对于这些流，向两个消息传递系统写入将提供一个备份路径。有几次差点失败，当旧系统摇摇欲坠时，备用路径保持核心Waze服务的运行，提供了短期的胜利，证明了最初的投资是合理的。 大规模迁移到新系统需要SRE与使用它的团队密切合作。该团队需要弄清楚如何最好地支持他们的用例以及如何协调流量切换。由于SRE团队自动化了迁移流量的过程，并且新系统默认支持更多用例，因此迁移率显著加快。 Kotter的变革管理流程以实施变革而告终。最终，在采用新系统背后有足够的动力，SRE团队可以声明旧系统已弃用且不再受支持。几个季度后他们迁移了最后的一批消息队列。如今，新系统处理的负载超过前一个系统的1000倍，并且几乎不需要SRE的人工干预即可持续提供支持和维护。 下一个变更周期：改进部署过程 作为一个周期的变化过程是Kotter的关键见解之一。当涉及到SRE面临的技术变化类型时，有意义变化的周期性特征尤其明显。消除系统中的一个瓶颈常常会突出显示另一个瓶颈。随着每个变更周期的完成，由此产生的改进、标准化和自动化可以节省工程时间。工程团队现在有空间更仔细地检查他们的系统并识别更多的痛点，从而触发下一个变化周期。 当Waze SRE最终能够从与消息传递系统相关的问题中退出时，一个新的瓶颈出现了，随之而来的是一种新的紧迫感：SRE对发行版本的唯一所有权明显地、严重地阻碍了开发速度。发布的手动性质需要大量的SRE投入时间。为了加剧已经不理想的情况，系统组件很大，而且由于发布成本很高，它们的频率相对较低。因此，每个版本都代表一个大的增量，这大大增加了一个重大缺陷需要回滚的可能性。 由于Waze SRE没有一个方案的总体规划，因此逐步改进为更好的发布流程。为了精简系统组件，以便团队能够更快地迭代每个组件，Waze的一位高级开发人员创建了一个构建微服务的框架。这提供了一个标准的“电池包含”平台，使得工程组织可以很容易地将其组件分开。SRE与该开发人员一起工作，以包含一些重点关注可靠性的特性——例如，一个通用的控制界面和一组易于自动化的行为。因此，SRE可以开发一套工具来管理发布过程中以前昂贵的部分。其中一种工具通过将创建一个新的微服务所需的所有步骤与框架捆绑在一起来鼓励采用。 这些工具一开始很简单，最初的原型是由一个SRE在几天内完成的。随着团队从它们的父组件中分离出更多的微服务，SRE开发的工具的价值在更广泛的组织中很快变得明显起来。SRE将精简后的组件投入生产的时间减少了，而单独发布新的微服务的成本要低得多。 虽然发布过程已经有了很大的改进，但新微服务的激增意味着SRE的总体负担仍然令人担忧。工程领导不愿意承担发布过程的责任，直到发布不再那么繁重。 作为回应，一个由SREs和开发人员组成的小联盟勾勒出了一个战略愿景，使用Spinnaker(一个开源、多云、持续交付平台，用于构建和执行部署工作流)转向持续部署策略。通过引导工具节省的时间，团队现在能够设计这个新系统，以支持一键构建和部署成百上千的微服务。新系统在各个方面都优于以前的系统，但是SRE仍然无法说服开发团队进行转换。这种不情愿是由两个因素驱动的：必须将自己的发行版推向生产的明显的抑制因素，加上对发布过程的可见性不强所导致的变更厌恶。 Waze SRE通过展示新流程如何增加价值来消除这些采用障碍。该团队构建了一个集中式仪表盘，显示二进制文件的发布状态以及微服务框架导出的一些标准指标。开发团队可以很轻松地将他们的发布与这些指标中的变化联系起来，这使他们相信部署是成功的。SRE与一些面向系统的志愿者开发团队密切合作，将服务转移到Spinnaker。 这些胜利证明了新的系统不仅能够满足它的需求，而且能够在原有的发布过程之外增加价值。此时，工程领导为所有团队设定了一个目标，即使用新的Spinnaker部署管道来执行发布。为了促进迁移，Waze SRE为具有复杂需求的团队提供了组织范围内的Spinnaker培训和咨询会议。当早期采用者熟悉新系统后，他们的积极经历引发了加速采用的连锁反应。他们发现，与等待SRE推送他们的版本相比，这个新的流程更快，痛苦也更少。现在，工程师开始对没有移动的依赖项施加压力，因为他们是加快开发速度的障碍——而不是SRE团队! 如今，超过95%的Waze的服务使用Spinnaker进行持续部署，并且可以在极少人工参与的情况下将更改推到生产环境中。虽然Spinnaker并不是一种万能的解决方案，但是如果使用微服务框架构建了一个新的服务，那么配置一个发布管道是很简单的，因此新的服务有强烈的动机对这个解决方案进行标准化。 经验总结 Waze在消除技术变更瓶颈方面的经验，对于其他尝试工程主导技术或组织变更的团队来说，包含了许多有用的经验。首先，改变管理理论不是浪费时间！通过Kotter过程的镜头来观察这个开发和迁移过程可以证明模型的适用性。当时，Kotter模型更正式的应用可能有助于简化和指导变更的过程。 从基层发起的变更需要SRE和研发团队之间的密切合作，以及行政领导的支持。创建一个小的、集中的团队，成员来自组织的各个部分——sre、开发人员和管理人员——是团队成功的关键。类似的合作对实现这一变更至关重要。随着时间的推移，这些特设小组能够而且应该发展成更正式和更结构化的合作，在这种合作中，SREs自动参与设计讨论，并能够就在整个产品生命周期中在生产环境中构建和部署健壮的应用程序的最佳实践提供建议。 增量更改更容易管理。直接跳到“完美”的解决方案是一个非常大的步骤，不能一下子全部执行（如果你的系统即将崩溃，更不用说可能是不可行的），而且“完美”的概念可能会随着更改过程中新信息的出现而演进。迭代方法可以演示早期的胜利，帮助组织接受变更的远景 并证明进一步的投资是合理的。另一方面，如果早期的迭代没有显示出价值，那么当你不可避免地放弃变更时，你将浪费更少的时间和资源。因为增量式的改变不是一下子就能发生的，所以有一个总体计划是非常宝贵的。用宽泛的术语描述目标，要灵活，并确保每次迭代都朝着目标前进。 最后，有时你当前的解决方案不能支持你的战略远景的需求。构建新事物需要大量的工程成本，但如果项目将你推离了局部的最大值，并且能够实现长期的增长，那么这是值得的。作为一个思想实验，随着业务和组织在未来几年的增长，找出系统和工具中可能出现的瓶颈。如果你怀疑任何元素没有横向扩展，或者对于核心业务度量（如每日活跃用户）具有超线性（或者更糟，是指数增长），那么你可能需要考虑重新设计或替换它们。 Waze开发的一种新的内部消息队列系统表明，一小群有决心的工程师有可能进行变革，从而提高服务可靠性。将Kotter的模型映射到变更上表明，对变更管理策略的一些考虑可以帮助提供成功的公式，即使是在小型的、工程主导的组织中。而且，正如下一个案例研究也表明的那样，当变革促进标准化技术和过程时，整个组织可以获得相当大的效率收益。 案例研究2：SRE中的通用工具采用 背景 SREs对于他们可以用来管理生产的软件持有不同的看法。多年的经验，观察什么做得好，什么做得不好，以及通过事后分析的视角来审视过去，让SREs有了深刻的背景和强烈的直觉。在SRE中，指定、构建和试实施软件以自动化今年的工作是核心价值。特别是，Google SRE最近将我们的工作重点放在了横向软件上。大量用户和开发人员采用了相同的解决方案，这就形成了一个良性循环，减少了重新开发。否则可能不进行交互的团队将共享使用相同软件自动化的实践和策略。 这个案例研究基于组织的发展，而不是对系统扩展或可靠性问题的响应（如Waze案例研究中所讨论的）。因此，Prosci ADKAR模型（如图21-3所示）比Kotter的模型更适合，因为它识别了在变更期间显式的组织/人员管理特征和技术考虑。 图21-3：变更管理的Prosci ADKAR模型 问题陈述 几年前，Google SRE发现自己使用了多个独立的软件解决方案，可以在多个问题空间中解决大致相同的问题：监控、发布和部署、事件响应、容量管理等等。 这种最终状态出现的部分原因是为SRE构建工具的人员与他们的用户及其需求是分离的。工具开发人员并不总是对问题陈述或整个生产环境有一个当前的视图——生产环境以新的方式以非常快的速度变化，因为新的软件、硬件和用例几乎每天都被引入到生活中。此外，工具的使用者是多种多样的，有时还存在正交需求（“这种推出必须是快速的；近似是正确的，相对而言，这个展示必须是100%正确的；可以慢慢进行”）。 因此，这些长期项目都没有完全满足任何人的需求，每个项目的特点都是不同级别的开发工作、功能完整性和持续的支持。那些等待大用例的人——一个非特定的、全能的未来解决方案——等了很长时间，感到沮丧，并使用他们自己的软件工程技术来创建他们自己的利基解决方案。那些有更小、更具体需求的人不愿意采用一种更广泛的、不适合他们的解决方案。更通用的解决方案的长期、技术和组织效益是显而易见的，但是客户、服务和团队并没有因为等待而得到人员配备或奖励。为了是这种情况更加复杂，大客户团队和小客户团队的需求会随着时间而改变。 我们决定做什么 为了将此场景扩展为一个具体的问题空间，我们问自己：如果所有Google SREs都可以使用一个通用的监控引擎和一组仪表盘，这些仪表盘易于使用，并且支持各种各样的用例，而不需要自定义，那会怎么样? 同样，我们可以将这种思维模型扩展到发布和推广、事件响应、容量管理等等。如果一个产品的初始配置捕获了大量的方法来满足我们的大部分功能需求，那么随着时间的推移，我们一般的和高深的解决方案将变得不可避免。在某种程度上，与生产交互的工程师的临界数量将超过他们使用的任何解决方案，并自行选择迁移到一组通用的、受良好支持的工具和自动化中，放弃他们定制的工具和相关的维护成本。 Google的SRE很幸运，它的许多工程师都有软件工程背景和经验。他们是专家，对具体问题有自己的看法——从负载均衡到发布工具到事件管理和响应——以虚拟团队的形式工作，由共同的长期愿景自行选择。这些工程师将把他们的愿景转化为实际的软件，最终被所有的SRE和所有的Google所采用，作为生产的基本功能。 为了回到ADKAR的变更管理模型，到目前为止所讨论的步骤——识别问题和确认机会——是ADKAR启动意识步骤的典型例子。Google SRE领导团队同意需求（愿望），并有足够的知识和能力来快速设计解决方案。 设计 我们的首要任务是集中讨论一些我们认为是核心的主题，这将极大地受益于一致的愿景：交付适合大多数用例的解决方案和采用计划。从65个以上的项目列表开始，我们花了几个月的时间收集客户需求，验证路线图，进行市场分析，最终将我们的工作范围确定在少数经过审查的主题。 我们最初的设计围绕这些主题创建了一个虚拟的SRE专家团队。这个虚拟团队将为这些横向项目贡献很大比例的时间，大约80%。80%的时间和一个虚拟团队背后的想法是，确保我们在没有与生产持续接触的情况下，不设计或构建解决方案。然而，我们（也许可以预见）发现了这种方法的一些痛点: 协调一个虚拟团队是非常困难的，这个团队的重点是在多个时间区域内定期随叫随到。在运行一个服务和构建一个软件之间，有很多状态需要交换。 从收集共识到代码审查的所有内容都受到缺乏中心位置和公共时间的影响。 横向项目的人员最初必须来自现有的团队，他们现在处理自己项目的工程资源更少了。即使在Google，委派员工来支持系统与委派员工来构建面向未来的基础设施之间也存在矛盾。 有了足够的数据，我们意识到我们需要重新设计我们的方法，并选择更熟悉的集中式模型。最重要的是，我们取消了团队成员在项目工作和值班职责之间分配80/20时间的要求。大多数SRE软件开发现在都是由拥有大量on-call经验的高级工程师组成的小组来完成的，但他们都是专注于基于这些经验构建软件的。我们也通过招募或调动工程师来集中这些团队。小组（6-10人）的开发在一个房间内更有效率（然而，这个论点并不适用于所有的小组——例如，远程SRE团队）。我们仍然可以通过视频会议、电子邮件和传统的出差来达到收集整个Google工程组织的需求和观点的目标。 所以我们的设计演变实际上出现在一个熟悉的地方——小型、灵活、大多是本地、快速发展的团队——但更加强调选择和构建自动化和工具，以供60%的Google工程师采用（我们确定这个数字是对“几乎每个人都在Google”的目标）。成功意味着Google大部分人都在使用SRE为管理其生产环境而构建的工具。 ADKAR模型在以人为中心的知识和能力阶段之间映射了变更项目的实现阶段。这个案例研究证实了这种映射。我们有许多敬业、才华横溢、知识渊博的工程师，但我们通过关注客户需求，产品路线图和交付承诺，要求那些专注于SRE问题的人员像产品软件开发工程师一样行事。我们需要重新考虑这个更改的实现，以使工程师能够展示他们关于这些新属性的能力。 实现：监控 为了回到上一节中提到的监控空间，第一本SRE手册中的第31章描述了Viceroy-Google SRE如何创建一个适合所有人的监控仪表盘解决方案，解决了完全不同的定制解决方案的问题。几个SRE团队一起创建并运行最初的迭代，随着Viceroy成长为Google的实际监控和仪表盘解决方案，一个专门的集中式SRE开发团队承担了项目的所有权。 但是，即使Viceroy框架将SRE统一在一个共同的框架下，由于团队构建了特定于其服务的复杂自定义仪表盘，因此需要进行大量重复工作。虽然Viceroy提供了一种标准的托管方法来设计和构建数据的可视化显示，但仍然需要每个团队决定显示哪些数据以及如何组织这些数据。 现在集中化的软件开发团队开始了第二个并行工作，提供通用仪表板，在较低级别的“自定义”系统之上构建了一个固定的零配置系统。这个零配置系统提供了一套标准的综合监控显示，它基于一个给定的服务被组织为少数流行的样式之一的假设。随着时间的推移，大多数服务都迁移到使用这些标准仪表板，而不是投资于自定义布局。如果需要，非常大的、独特的或其他特殊的服务仍然可以在托管系统中部署自定义视图。 回到ADKAR模型，Google监控工具的整合始于基层工作，由此带来的运营效率提升提供了可量化的基础（意识和愿望），以启动更广泛的努力：SRE自筹资金的软件开发团队为所有Google构建生产管理工具。 经验总结 设计相互依赖的部件的迁移通常比空白页设计更复杂。但在现实生活中，最困难的工程工作最终是将许多小型/受限系统演变成更少、更通用的系统——而不会干扰许多客户所依赖的已经在运行的服务。与此同时，除了现有的系统之外，新的小型系统也在不断增加——其中一些系统最终发展成为大型系统而让我们感到惊讶。大型设计重新开始，只有支持真正必要的约束，才有吸引力，但系统和团队的迁移是迄今为止最困难的工作。 设计横向软件需要大量听取潜在最终用户的意见，在许多方面，构建和采用的任务看起来很像产品经理的角色。为了使这一努力取得成功，我们必须确保我们吸收并优先考虑优先事项。满足客户需求——SREs和其他生产用户的需求——也是成功的关键因素。必须承认，向通用工具的转移仍然是一项正在进行的工作。我们对构建共享技术的团队的结构和人员进行了迭代，以更好地满足客户需求，我们还增加了产品管理和用户体验人才(解决了缺失的知识)。 在过去的一两年里，我们在Google的许多团队中看到了这些SRE设计和构建的产品。我们已经了解到，要想取得成功，迁移（从旧的、碎片化的、专门的解决方案）的成本相对于新的通用解决方案的净收益而言较小。否则，迁移本身就会成为采用的障碍。我们继续与构建这些产品的单个团队合作，以加强团队交付的通用解决方案满足客户所需的行为。 我们在横向软件开发项目中发现的一个共同主题是，无论新软件和产品有多好，从已经在工作的东西迁移到新东西的迁移成本总是被认为非常高。尽管有更容易管理和不太具体的深入知识的诱惑，从熟悉的地方迁移（尽管有缺点和辛苦）的成本通常是一个障碍。此外，个别工程师也经常有类似的内部独白：“我没有改进或改变系统；我把一个工件换成另一个工件。ADKAR将这种阻力描述为“知识——能力差距”。在人性方面，为了认识和接受变革，人们需要时间、指导和新工具和技能方面的培训。在技术方面，实现变更需要理解采用成本，并包括将这些成本最小化的工作作为启动过程的一部分。 因此，对于团队、个人和公司来说，迁移成本必须接近于零（“只需重新编译，您就可以获得新的东西”），而好处也必须明确（“现在你可以免受$foo漏洞的伤害”）。 SRE通常用于以“尽力而为”的方式构建我们承诺的产品，这意味着我们给产品的时间量适合我们正在做的其他事情之间的裂缝（管理主要服务，容量规划，处理中断，等等）。因此，我们的执行不是很可靠；无法预测什么时候可以使用某个特性或服务。延伸开来，我们产品的消费者对最终结果的信任度就降低了，因为我们的产品总是会被推迟，并且有一个轮流的产品经理和个体工程师组成。当各个SREs或SRE团队为自己的使用构建工具时，重点是解决个别问题，以降低为支持的系统维护SLOs的成本。为了在Google中为大多数用例构建通用工具，我们需要将重点转移到衡量这项工作在产品采用方面的成功与否。 由于我们的组织文化和丰富的资源，我们以自下而上而不是自上而下的方式来处理这个项目。我们没有强制用户迁移到我们的新监控系统，而是通过证明我们的新产品比现有的解决方案更好来赢得用户。 随着时间的推移，我们了解到我们如何执行我们的开发过程将告知潜在的内部用户如何感知最终结果。只有当生产经验丰富的工程师100%致力于构建软件时，这些项目才能获得真正的吸引力，其计划和支持与Google的其他软件开发相同。透明地构建通用软件，像clockwork一样，具有良好的通信（“我们将在Y 日期之前完成X”），极大地提高了迁移到新系统的速度。人们已经信任这个新系统，因为他们可以观察到它是如何从早期发展起来的。从一开始，人们对香肠制作过程的理解就比我们预想的更加重要。我们最初的想法是“如果你创造出伟大的东西，人们会自然而然地涌向它”，但这并不是真的。相反，这些项目必须明确定义，事先做好宣传，针对大量的用户案例（首先针对最暴躁的采用者）进行评估，比现有的选择有更好的跳跃式发展，并且可以毫不费力地采用。 普通工具采用的消费者越多，除了编写代码之外，你实际花费的时间就越多。回想起来，这听起来可能很明显，但是清晰的最终目标、可信的日期、定期的更新以及与消费者的持续接触是至关重要的。通常持怀疑态度的消费者会问：“如果我当前的一次性shell脚本运行良好，我真的需要这个吗?”采用通用软件或流程类似于可靠性作为一项特性——你可以构建世界上最好的东西，但是如果人们不采用它（或者如果它不可靠就不能使用它），那么它对任何人都没有用处。当涉及到构建和采用通用工具和实践时，制定一个采用计划——从拥护者到beta测试人员，从执行发起人到专门的工程师，他们都明白最小化采用障碍的重要性——既是最终目标，也是起点。 这是因为采用会带来网络效应：随着普通软件工具的规模和范围的扩大，对这些工具的逐步改进对组织来说更有价值。随着工具价值的增加，致力于它们的开发工作也会增加。这些开发工作中的一部分自然用于进一步降低迁移成本，鼓励更多的采用。广泛采用鼓励以一致的、类似于产品的方式构建组织范围内的改进，并证明配备完整的团队以支持长期的工具是合理的。这些工具应该具有快速开发、特性稳定性、通用控制界面和可自动化api的特点。 在衡量此类工作的影响时，我们可以提出类似以下问题： 新产品开发人员能够以多快的速度构建和管理世界级服务？ 通过常见的工具和实践启用，一个领域中的SRE可以多容易地转移到另一个领域? 使用相同的原语可以管理多少服务，如端到端用户体验与单独服务？ 这些都是度量影响的可能且非常有价值的方法，但是我们的第一个度量必须是采用。 结论 正如Waze和横向软件案例研究所展示的那样，即使在一家公司内，SRE变更管理也可能需要处理各种问题空间和组织环境。因此，可能没有任何一种正式的变更管理模型可以巧妙地应用于任何给定组织可能处理的变更范围。然而，这些框架，特别是Kotter的八步过程和Prosci ADKAR模型，可以为即将发生的变化提供有用的见解。在像SRE这样动态的环境中，任何必要的更改都有一个共同点，那就是不断的重新评估和迭代。虽然许多变化可能以基层的方式有机地开始，但随着变化的成熟，大多数变化可以从结构化的协调和计划中获益。</summary></entry><entry><title type="html">第二十章 SRE：团队生命周期</title><link href="http://localhost:4000/sre/2020/01/20/SRE-%E5%9B%A2%E9%98%9F%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/" rel="alternate" type="text/html" title="第二十章 SRE：团队生命周期" /><published>2020-01-20T00:00:00+08:00</published><updated>2020-01-20T00:00:00+08:00</updated><id>http://localhost:4000/sre/2020/01/20/SRE:%E5%9B%A2%E9%98%9F%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F</id><content type="html" xml:base="http://localhost:4000/sre/2020/01/20/SRE-%E5%9B%A2%E9%98%9F%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/">&lt;p&gt;本书的前言就设定了一个目标，即“消除SRE只能在谷歌场景中实现”。本章给出了一个从无人值守到成熟SRE组织的路线图。无论你的SRE团队中处于什么阶段或位置，本章都将帮助你如何发展SRE团队。&lt;/p&gt;

&lt;p&gt;针对SRE的不同阶段，本章讨论了SRE理论。虽然SRE根据自己团队的规模、性质和地理分布而有所不同，但我们描述的SRE理论和实践适用于许多不同类型的团队。&lt;/p&gt;

&lt;h2 id=&quot;没有sre的sre实践&quot;&gt;没有SRE的SRE实践&lt;/h2&gt;

&lt;p&gt;即使没有SRE，也可以使用SLO。如第2章所述，SLO是SRE实践的基础。因此，SRE的第一条理论：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h4 id=&quot;理论1sre需要slo评估影响&quot;&gt;理论1：SRE需要SLO评估影响。&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;用SLO来评估服务性能，将会引导你的业务决策。&lt;/p&gt;

&lt;p&gt;即使没有SRE，如下SRE的实践也可以实现。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;承认你不需要100%的可靠。&lt;/li&gt;
  &lt;li&gt;设置合理的SLO目标，此SLO应衡量对用户最重要的可靠性。&lt;/li&gt;
  &lt;li&gt;同意有助于保护用户体验的错误预算政策，使用错误预算来帮助指导：
–减少停机等之类的管理措施以此来保障你的系统达到可靠状态。
–更长期的工作优先顺序，使系统更可靠，使用更少的错误预算。&lt;/li&gt;
  &lt;li&gt;测量SLO并承诺遵循错误预算策略。这一承诺需要得到公司领导层的同意。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;即使团队没有SRE，为关键客户服务设置SLO并实施错误预算是应该的，只是因为隐含的100％SLO意味着团队只能被动反应。此SRE理论允许你就如何确保应用程序的可靠性做出数据知情决策。&lt;/p&gt;

&lt;h2 id=&quot;开始一个sre角色&quot;&gt;开始一个SRE角色&lt;/h2&gt;

&lt;h3 id=&quot;找到你的第一个sre&quot;&gt;找到你的第一个SRE&lt;/h3&gt;
&lt;p&gt;有可能你的第一个SRE员工不会有明确的SRE经验。我们发现以下几个方面与SRE的角色有关，因此适合在面试中进行交谈：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;运维&lt;/code&gt;  &lt;br /&gt;
在生产中运行应用程序提供了非常宝贵的见解，否则很难获得。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;软件工程&lt;/code&gt;&lt;br /&gt;
SRE需要了解他们支持的软件，并有权改进它。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;监控系统&lt;/code&gt;&lt;br /&gt;
SRE原则要求可以衡量和解释的SLO，生产自动化扩展操作需要自动化。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;生产自动化&lt;/code&gt;&lt;br /&gt;
扩展操作需要自动化。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;系统架构&lt;/code&gt;&lt;br /&gt;
扩展应用程序需要良好的架构。&lt;/p&gt;

&lt;p&gt;你的第一个SRE可能会在速度和可靠性目标之间处于一个困难和模糊的位置。他们需要有弹性和灵活性，以便在实现产品开发和维护客户体验之间提供适当的平衡。&lt;/p&gt;

&lt;h3 id=&quot;安排你的第一个sre&quot;&gt;安排你的第一个SRE&lt;/h3&gt;
&lt;p&gt;一旦雇佣了你的第一个SRE，你现在需要决定将他们嵌入到你的团队中。你有三个主要的选择:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在产品开发团队中&lt;/li&gt;
  &lt;li&gt;在运维团队中&lt;/li&gt;
  &lt;li&gt;在一个横向角色中，跨多个团队进行咨询&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在阅读本章之后，我们建议你评估这三个选项的利弊，考虑：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;你自己的角色和影响范围&lt;/code&gt;。&lt;br /&gt;
如果你能够有效地影响产品开发团队，那么在运维或横向工作中嵌入一个SRE可以帮助尽早解决生产问题。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;你面临的直接挑战&lt;/code&gt;。&lt;br /&gt;
如果挑战需要实际工作来减轻技术问题或业务风险，那么将SRE嵌入到运维或产品团队中可能是有利的。这样做可以消除团队孤岛，便于团队成员之间的沟通。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;你期望在未来12个月内面临的挑战&lt;/code&gt;。&lt;br /&gt;
例如，如果你关注的是发布，那么将SRE嵌入到产品开发团队中可能是有意义的。如果你关注的是基础架构的更改，那么将SRE嵌入到运维团队中可能更有意义。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;你计划如何改变你的团队&lt;/code&gt;。&lt;br /&gt;
如果你计划转向集中式的SRE团队，那么你可能不希望在产品开发团队中首先嵌入SRE——以后可能很难将他们从这些团队中删除。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;你已确定为第一个SRE的人&lt;/code&gt;。  &lt;br /&gt;
根据他们的背景和技能来决定第一个SRE在哪里最有生产力。&lt;/p&gt;

&lt;p&gt;在确定哪种方法最适合你时，尝试使用不同的模型可能是有意义的。但是，我们强烈建议长期坚持使用一个稳定且连贯的模型；否则，不稳定性将破坏SRE的有效性。&lt;/p&gt;

&lt;h3 id=&quot;引导你的第一个sre&quot;&gt;引导你的第一个SRE&lt;/h3&gt;

&lt;p&gt;你的第一个SRE的首要任务是加快服务速度。为了产生积极影响，SRE需要了解服务的当前问题、所需的工作（参见第6章）以及将系统保持在SLO中所需的工程。如果你的组织尚未按照理论1拥有SLO和错误预算，那么你的第一个SRE需要执行设计和实现这些工具所需的工程。基于这点，第二条SRE理论：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;理论2：SRE必须有时间做明天比今天更好的事情。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果没有这个原则，辛劳只会随着服务使用的增加而增加，系统也会相应地变得更大、更复杂。运维责任和项目工作之间的健康平衡是非常重要的——如果繁重的工作变得过于繁重，有才华的工程师就会离开团队。有关SRE团队如何获得这种平衡的更多指导，请参阅第17章。&lt;/p&gt;

&lt;p&gt;最初的项目工作可能集中于以下之一:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;改进监控，以便在出现问题时更好地了解系统。&lt;/li&gt;
  &lt;li&gt;解决在最近的事后调查中发现的任何高优先级的行动（见第10章）。&lt;/li&gt;
  &lt;li&gt;实现自动化，以减少运行服务所需的特定工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;至关重要的是，SRE有一个独特的角色，他们的项目有利于整个团队。留意SRE工作进展不顺利的迹象：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;S他们的工作组合与其他工程工作难以区分。&lt;/li&gt;
  &lt;li&gt;S如果你的第一个SRE是在一个产品开发团队中，那么他们所做的工作超出了他们的职责范围，或者他们是唯一一个在服务配置更改方面工作的人。&lt;/li&gt;
  &lt;li&gt;SLO没有受到重视，SRE也没有在衡量和维护客户体验方面取得进展。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;分布式sre&quot;&gt;分布式SRE&lt;/h3&gt;
&lt;p&gt;如果你没有离散的SRE团队，那么为分布式SRE构建一个社区是很重要的。这个社区应该提倡SRE的独特作用，并在团队之间推动以可靠性为中心的技术或实践的一致变化。如果没有社交分组，个体SRE可能会感到非常孤立。&lt;/p&gt;

&lt;h2 id=&quot;你的第一个sre团队&quot;&gt;你的第一个SRE团队&lt;/h2&gt;
&lt;p&gt;你可以通过多种方式组建一个SRE团队。我们在Google中使用的方法，从最小到最复杂，包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;S创建一个新团队作为主要项目的一部分&lt;/li&gt;
  &lt;li&gt;建立横向SRE团队&lt;/li&gt;
  &lt;li&gt;转换现有团队（例如，运维团队）
最适合你的方法是因地制宜。一个团队需要足够的SRE来处理运行服务所需的运维任务。处理这种工作量使我们想到我们的第三个理论：&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;理论3：SRE团队有能力调节工作负载。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在大型SRE团队之外，团队可能无法从第一天起就接受这个概念。这一原则易于解释，但很难有组织地付诸实施。它也是我们三个原则中最微妙的一条，也需要一些梳理。下面的部分将介绍如何构建团队，使用Tuckman的表现模型：形成、攻坚、规范和表演四个阶段。&lt;/p&gt;

&lt;h3 id=&quot;形成&quot;&gt;形成&lt;/h3&gt;
&lt;p&gt;你组建的团队应该具备以下经验和专业知识：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;修改应用软件以提高可靠性和性能。&lt;/li&gt;
  &lt;li&gt;编写软件，来达到如下目的：
  –产品中问题的的发现和快速解决
  –自动化手动操作&lt;/li&gt;
  &lt;li&gt;建立并使用强大的软件实践和标准来促进长期的可维护性。&lt;/li&gt;
  &lt;li&gt;采用有条不紊和谨慎的方法进行操作。&lt;/li&gt;
  &lt;li&gt;了解系统架构（分布式系统设计和操作）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;理想情况下，你的团队将准备采用一种新的工作方式，并在技能上与其他团队建立的个人关系之间取得平衡。如果可能的话，我们建议你通过内部转移为团队提供支持。这可以减少团队的启动和运行所需的时间。&lt;/p&gt;

&lt;h4 id=&quot;创建一个新的团队作为主要项目的一部分&quot;&gt;创建一个新的团队作为主要项目的一部分&lt;/h4&gt;
&lt;p&gt;你可以为一个大的项目创建一个新的SRE团队，这个团队大到足以证明新的人员编制是合理的，并且已经将可靠性和操作能力确定为项目风险。示例可能包括新服务的创建或技术的重大更改（例如，服务迁移到公共云）。&lt;/p&gt;

&lt;h4 id=&quot;组建横向sre团队&quot;&gt;组建横向SRE团队&lt;/h4&gt;
&lt;p&gt;在这种方法中（在我们第一本书的第27章中有详细的记录），一个SRE小组在多个团队之间进行咨询。这个团队还可能建立配置管理、监视和警报的最佳实践和工具。&lt;/p&gt;

&lt;h4 id=&quot;正确地转换团队角色&quot;&gt;正确地转换团队角色&lt;/h4&gt;
&lt;p&gt;你可以将现有的团队转换为SRE团队。现有的团队可能不是产品开发团队；典型的候选人包括：操作团队、使用流行开源组件的团队。如果没有首先应用SRE实践和原则，要小心避免将团队从“运维”重新命名为“SRE”！如果你的重命名工作失败了，你的组织将来可能会对整个SRE概念造成毒害。&lt;/p&gt;

&lt;h3 id=&quot;攻坚&quot;&gt;攻坚&lt;/h3&gt;
&lt;p&gt;新组建的团队一开始就需要考虑协作的问题：团队成员需要互相配合，也需要与其他团队合作。&lt;/p&gt;

&lt;p&gt;你可以使用任何策略来促进这种凝聚力。在Google，我们已经成功地提供了一个定期论坛来学习和讨论SRE实践，并反思团队的表现。例如，你可能会定期举办一场电视午餐，在那里你会播放一段来自SREcon的视频，或者是一个读书俱乐部，在那里你可以提前阅读一些相关内容，然后讨论如何应用它。&lt;/p&gt;

&lt;p&gt;在此阶段，鼓励你的新SRE团队进行扩展。你的新SRE应该乐于说出不适合你的组织的SRE实践，以及是否值得进行更改以使它们适合你的组织。&lt;/p&gt;

&lt;h4 id=&quot;风险和缓解&quot;&gt;风险和缓解&lt;/h4&gt;
&lt;p&gt;在SRE旅程的初期阶段，团队可能会以多种方式失败。接下来，我们将介绍一些风险和可能的缓解策略，这些策略根据新团队的组成进行了细分。你可以针对每种风险使用一个或多个缓解策略。&lt;/p&gt;

&lt;h4 id=&quot;新团队作为重大项目的一部分&quot;&gt;新团队作为重大项目的一部分&lt;/h4&gt;
&lt;p&gt;风险&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;团队:
    &lt;ul&gt;
      &lt;li&gt;一次承担太多服务的责任，会让自己过于分散。——一个经常处理报警的团队没有时间以更持久的方式处理风险。&lt;/li&gt;
      &lt;li&gt;试图理解SRE原则和如何实现它们变得过于内省。结果，它未能实现预期目标。——例如，团队可能会忙于开发完美的SLO定义，同时忽略了服务的需求。&lt;/li&gt;
      &lt;li&gt;没有彻底检查其工作。因此，服务管理恢复到以前的行为。——团队每天有100个工单。由于这些工单并不需要立即干预，因此被忽略。&lt;/li&gt;
      &lt;li&gt;放弃SRE原则和实践，以满足产品里程碑。——保护SLO的可靠性改进（例如架构更改）可能永远不会实施，因为它们会推迟开发时间。&lt;/li&gt;
      &lt;li&gt;由于与新SRE团队失去影响力或权力而与现有团队发生冲突而分散注意力。&lt;/li&gt;
      &lt;li&gt;没有必要的技能广度，所以只提供了必要的部分改进。——例如，如果不能进行编程，SREs可能无法测量产品的可靠性。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缓解措施&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;团队：
    &lt;ul&gt;
      &lt;li&gt;从事单一重要服务开始。&lt;/li&gt;
      &lt;li&gt;尽可能早地参与项目，最好是在设计阶段。&lt;/li&gt;
      &lt;li&gt;对设计有投入，特别关注于定义SLO和分析设计中固有的可靠性风险。&lt;/li&gt;
      &lt;li&gt;与产品开发团队合作，致力于可靠性和与现有操作平台集成的特性。&lt;/li&gt;
      &lt;li&gt;在第一天不需要承担运维责任。相反，这种责任最初由产品开发团队或项目团队承担。这可能是一个需要管理层支持的重大文化变革。&lt;/li&gt;
      &lt;li&gt;就服务必须满足的条件与SRE达成明确的协议(参见《现场可靠性工程》第32章)。&lt;br /&gt;
  &lt;strong&gt;此外：&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;如果项目涉及到迁移，团队应该对当前和未来的环境有充分的了解。如果你的团队成员需要从外部招聘，请考虑具有软件工程和未来环境知识的候选人。&lt;/li&gt;
      &lt;li&gt;继续将新员工的数量控制在团队的三分之一以下，这样培训工作就不会压倒现有的团队成员。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;横向sre团队&quot;&gt;横向SRE团队&lt;/h4&gt;
&lt;p&gt;风险
    团队被视为一个新的“门控”组织，不做真正的工作，也不增加真正的价值。&lt;/p&gt;

&lt;p&gt;缓解措施&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;团队：
    &lt;ul&gt;
      &lt;li&gt;由具有相关专业知识的受人尊敬的工程师组成。&lt;/li&gt;
      &lt;li&gt;进行项目工作，集中于交付工具(用于监视、警报、推出、最佳实践、检查列表)。这些工具应该至少对另外两个团队有短期的有益影响。&lt;/li&gt;
      &lt;li&gt;传达成功和利益。应该庆祝一个能够实现效率突破，自动化工作，或永久消除系统不可靠性的来源的SRE团队。&lt;/li&gt;
      &lt;li&gt;将自己视为推动者，而非看门人。专注于解决方案，而不仅仅是问题。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;一个团队转换到位&quot;&gt;一个团队转换到位&lt;/h4&gt;
&lt;p&gt;风险&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;团队：
    &lt;ul&gt;
      &lt;li&gt;认识到转换过程是自动取代人类的失业之旅的开始。&lt;/li&gt;
      &lt;li&gt;不支持对SRE团队的更改。&lt;/li&gt;
      &lt;li&gt;他们没有足够的能力来改变团队的日常活动。&lt;/li&gt;
      &lt;li&gt;几个月后，他们的日常工作毫无益处。&lt;/li&gt;
      &lt;li&gt;适用于不支持脚本或自动化的系统。&lt;/li&gt;
      &lt;li&gt;没有软件工程技能来自动化他们当前的工作量。&lt;/li&gt;
      &lt;li&gt;不具备向SRE发展所需的技能，或者对获得技能的兴趣。
缓解措施&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;团队：
    &lt;ul&gt;
      &lt;li&gt;确保高层领导对变革的支持。&lt;/li&gt;
      &lt;li&gt;重新协商责任，以创建实现变革所需的空间。&lt;/li&gt;
      &lt;li&gt;非常谨慎地管理变更的沟通。&lt;/li&gt;
      &lt;li&gt;在整个过渡过程中能够获得强大的个人和技术支持。&lt;/li&gt;
      &lt;li&gt;直面对失业的担忧。在许多环境中，自动化消除了部分工作，但不包括整个工作；虽然这可能是走向失业的一步，但它至少有一个优点，那就是腾出时间去做一些比非自动化劳动更好的事情(也更适合未来的雇主)。&lt;/li&gt;
      &lt;li&gt;可以避免运维过载，并具有更大的影响。如果工程师减少了繁重的工作量，需要一个更小的团队，那么他们的经验应该在组织的其他地方得到高度重用。如果他们的经验不能在公司内部使用，那么在其他地方找工作应该会有优势。&lt;/li&gt;
      &lt;li&gt;接受培训以获得SRE需要的技能。你的产品开发团队可以提供产品培训，而SRE定位可以利用这本书和其他外部资源。&lt;/li&gt;
      &lt;li&gt;改变绩效评估的方式——评估团队和个人的指标。前者应与SLO和采用其他SRE做法相一致；后者应该与SRE技能的证据相一致。&lt;/li&gt;
      &lt;li&gt;向团队中添加一个有经验的SRE或开发人员。&lt;/li&gt;
      &lt;li&gt;具有识别和引入新的开源或基于云的监控和警报系统以实现自动化的自由度（预算或时间）。确定现有系统是否足够是早期的优先事项。&lt;/li&gt;
      &lt;li&gt;定期审查内部和利益相关方的进展情况。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;规范化&quot;&gt;规范化&lt;/h3&gt;

&lt;p&gt;规范化需要克服405页“风险和缓解”中提出的问题，并就组织的SRE团队的最佳实践达成广泛一致。团队需要就可接受的工作量水平、适当的警报阈值以及重要的和相关的SRE实践达成一致。团队还需要充分主动地识别服务前的挑战，并制定中长期目标来改进服务。&lt;/p&gt;

&lt;p&gt;团队应该在规范化成熟度达到以下水平：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SLO和错误预算已经到位，错误预算政策在重大事件发生后执行。领导对SLO测量感兴趣。&lt;/li&gt;
  &lt;li&gt;值班的轮换是建立和可持续的(参见第8章)。on-call工程师可以对他们待命时间进行补偿。在重大事件中，有足够的工具，文档，和培训来支持任何团队成员。&lt;/li&gt;
  &lt;li&gt;有文档记录，有禁止事项，有管理。因此，SRE完成了有影响力的项目，提高了可靠性和效率。&lt;/li&gt;
  &lt;li&gt;事后分析文化已经确立。(参见第十章)。&lt;/li&gt;
  &lt;li&gt;团队展示了第一章列出的大部分原则。&lt;/li&gt;
  &lt;li&gt;当团队解决了405页“攻坚”中列出的初始问题时，他们会抓住他们所学到的知识并防止重复的问题。该团队定期进行演练，如不幸之轮或DiRT(灾难恢复测试)。(有关on-call培训的更多信息，请参阅我们第一本书的第11章和本书的第18章。)&lt;/li&gt;
  &lt;li&gt;产品开发团队从持续参与值班循环中获益。&lt;/li&gt;
  &lt;li&gt;团队为他们的利益相关者制作定期报告(例如，季度报告)，涵盖了报告期间的重点、亮点和关键指标。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;与产品开发团队建立健康的关系是许多缓解策略的基础。团队应该根据组织的计划周期一起计划工作。&lt;/p&gt;

&lt;p&gt;在继续下一步之前:停下来庆祝这一成功，写一篇回顾你到目前为止的经历。&lt;/p&gt;

&lt;h3 id=&quot;执行&quot;&gt;执行&lt;/h3&gt;

&lt;p&gt;SRE团队的经验应该赢得更广泛的尊重和关注，并为战略的制定奠定基础。在Tuckman的performance model的最后阶段你应该期望:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;成为架构设计和变更的顾问&lt;/code&gt;&lt;br /&gt;
    从最初的设计阶段开始，SRE应该为软件的构建和结构可靠性定义模式。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;主观能动性&lt;/code&gt;&lt;br /&gt;
    团队应始终如一地应用原则3，以实现系统的整体健康。&lt;/p&gt;

&lt;h4 id=&quot;产品架构方面&quot;&gt;产品架构方面&lt;/h4&gt;
&lt;p&gt;所有重大服务的变更，产品开发团队应该向SRE团队寻求意见。&lt;/p&gt;

&lt;p&gt;例如，SRE团队会在新服务体系结构设计早期介入以减少日后进行高成本改造的几率。产品开发和SRE团队需要认识到他们在架构决策方面上观点的不同，但是目的都是要达到良好的产品设计。SRE的参与在如下方面可以为产品增加价值:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;提高可靠性、可伸缩性和可操作性&lt;/li&gt;
  &lt;li&gt;更好地重用现有模式&lt;/li&gt;
  &lt;li&gt;更简单的迁移(如果需要的话)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;自动调节工作负载&quot;&gt;自动调节工作负载&lt;/h4&gt;
&lt;p&gt;尽管随着时间的推移，产品架构负责人应该以某种有机的方式出现，但是SRE团队必须明确地向其伙伴维护原则3。要做到这一点，需要强有力的团队领导能力和高层管理人员的明确承诺。管理自己的工作负载的能力确保了SRE团队作为一个工程团队的地位，该工程团队与产品开发团队一样，在组织最重要的服务上工作。&lt;/p&gt;

&lt;p&gt;在实践中，SRE团队如何确定自己的工作负载取决于与SRE接口的团队。在谷歌中，SRE团队通常与不同的产品开发团队进行交互。在这种情况下，关系具有以下特点:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SRE团队选择是否和何时上线服务(参见站点可靠性工程第32章)。&lt;/li&gt;
  &lt;li&gt;在运维超负荷的情况下，团队可以通过以下方式减少工作量:&lt;br /&gt;
  –降低SLO&lt;br /&gt;
  –将运营工作转移到另一个团队(如产品开发团队)&lt;/li&gt;
  &lt;li&gt;如果在约定的辛劳限制下无法在SLO上运行服务，SRE团队可以将服务交还给产品开发团队。&lt;/li&gt;
  &lt;li&gt;SRE参与不是永久的——它通过系统问题的解决和服务可靠性的提升来满足自身发展的需要。如果一个SRE团队已经解决了一个服务稳定性的问题，那么你需要:&lt;br /&gt;
  –有意识地为SRE团队寻求其他靠性挑战。&lt;br /&gt;
  –有意识地决定将服务交还给产品开发团队。&lt;br /&gt;
  否则，随着SRE转向其他领域，团队可能会面临人员流失的风险。造成的缓慢流血可能会危及生产。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;并不是所有的SRE团队都有合作的产品开发团队。一些SRE团队还负责开发他们运行的系统。一些SRE团队将第三方软件、硬件或服务打包(例如，开源包、网络设备等)，并将这些资产转换为内部服务。在这种情况下，您没有将工作转移回另一个团队的选项。相反，考虑以下策略:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果服务不符合其SLO，停止与特性相关的项目工作，转而支持以可靠性为中心的项目工作。&lt;/li&gt;
  &lt;li&gt;如果在约定的工作量限制下无法在SLO上运行服务，请减少懒惰——除非管理层提供更多的能力(人员或基础设施)来处理这种情况。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;组建更多的sre团队&quot;&gt;组建更多的SRE团队&lt;/h2&gt;
&lt;p&gt;一旦你的第一个SRE团队开始步入正轨，基于如下的原因我们可能还要建设另一个SRE团队：&lt;/p&gt;

&lt;h5 id=&quot;服务的复杂性&quot;&gt;服务的复杂性&lt;/h5&gt;
&lt;p&gt;随着服务复杂度的提升，单个SRE团队无法有效的支持服务的运维工作。你可能希望将团队分成专门处理服务部分的子团队。&lt;/p&gt;

&lt;h5 id=&quot;sre上线&quot;&gt;SRE上线&lt;/h5&gt;
&lt;p&gt;如果你的第一个SRE团队取得了成功并有明显的不同，那么在更多的服务中采用这种方法是必要的。&lt;/p&gt;

&lt;h5 id=&quot;在地理上分离&quot;&gt;在地理上分离&lt;/h5&gt;
&lt;p&gt;你想要在不同的时区将团队分成两部分，并改为12小时on-call的轮班制。&lt;/p&gt;

&lt;p&gt;当创建一个新的SRE团队时，我们建议执行以下操作：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;阅读其他团队成立后的总结报告。找出重复做得好的事情，修复并探索那些做得不好的事情。&lt;/li&gt;
  &lt;li&gt;将现有的SEE团队成员加入到新的团队中，这些SRE新团队的骨干，以便应对挑战和风险。根据我们的经验，要找到合格的SRE候选人是很困难的，所以在新员工的帮助下快速发展团队通常是不现实的。&lt;/li&gt;
  &lt;li&gt;标准化建立团队和入职服务的框架(见第18章)。&lt;/li&gt;
  &lt;li&gt;慢慢改变值班的职责。例如：
  –为了避免核心on-call工程师离职，让团队成员在一个过渡时期内为他们以前的团队系统值班。
  –在团队分离后，等待三到六个月的时间来分离值班轮换。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;服务复杂性&quot;&gt;服务复杂性&lt;/h3&gt;

&lt;h4 id=&quot;如何分割&quot;&gt;如何分割&lt;/h4&gt;
&lt;p&gt;如果一个服务对于单个团队来说过于复杂而难以管理，那么有很多方法可以将工作分开。考虑以下选项来简化团队成员的认知负荷：&lt;/p&gt;

&lt;h5 id=&quot;结构分割&quot;&gt;结构分割&lt;/h5&gt;
&lt;p&gt;例如，计算、存储和网络；前端和后端；前端和数据库；客户端和服务器；前端和管道。&lt;/p&gt;

&lt;h5 id=&quot;代码分割&quot;&gt;代码分割&lt;/h5&gt;
&lt;p&gt;SRE原则不依赖于编程语言。但是，如果你的SRE深入到源代码中，那么沿着这些代码进行拆分可能会有一些好处。&lt;/p&gt;

&lt;h5 id=&quot;管理分割&quot;&gt;管理分割&lt;/h5&gt;
&lt;p&gt;如果你所领导组织的工程跨越多个办公室，你可能希望将SRE团队的布置与应用程序开发联系起来。&lt;/p&gt;

&lt;h4 id=&quot;隐患&quot;&gt;隐患&lt;/h4&gt;
&lt;p&gt;当一个团队分裂时，有时新的团队中不会为原来团队所拥有的组件承担责任。为了减轻这种风险，你可以：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;指定一个团队对第二团队章程之外的所有事情负责。&lt;/li&gt;
  &lt;li&gt;任命一个高级SRE在两个团队中担任一个全面的技术领导角色。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sre上线-1&quot;&gt;SRE上线&lt;/h3&gt;
&lt;p&gt;如果你最初的SRE团队成功了，那你的组织可能需要更多的SRE团队。我们建议对获得SRE支持的服务进行仔细的优先排序。考虑以下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;优先考虑可靠性对财务或声誉有很大影响的服务。影响越大，优先级越高。&lt;/li&gt;
  &lt;li&gt;定义最小可行的服务集，这些服务集是为了使产品能够正常工作而需要提供的。对这些服务进行优先级排序，并确保其他服务优雅地降级。&lt;/li&gt;
  &lt;li&gt;服务不应该成为SRE的优先级，因为它不可靠。在与业务最相关的领域，SRE应该在战术上得到应用。你也不希望在SREs投入使用之前让开发人员忽略可靠性。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;地理分割&quot;&gt;地理分割&lt;/h3&gt;
&lt;p&gt;正如我们第一本书的第11章所述，Google通常在不同大洲的姐妹SRE团队中工作。我们这样做有很多原因：&lt;/p&gt;

&lt;h5 id=&quot;服务可靠性&quot;&gt;服务可靠性&lt;/h5&gt;
&lt;p&gt;如果一个重大事件(如自然灾害)阻止一个团队工作运维服务，另一个团队可以继续支持服务。&lt;/p&gt;

&lt;h5 id=&quot;值班压力&quot;&gt;值班压力&lt;/h5&gt;
&lt;p&gt;将值班轮班分成12小时轮班，为值班的工程师提供了适当的休息时间。&lt;/p&gt;

&lt;h5 id=&quot;招聘和留住人才&quot;&gt;招聘和留住人才&lt;/h5&gt;
&lt;p&gt;与正常工作日重叠的值班轮班，扩大了我们可以招募到SRE工程师的基础，并强调了我们角色中的工程部分。&lt;/p&gt;

&lt;h5 id=&quot;生产期限&quot;&gt;生产期限&lt;/h5&gt;
&lt;p&gt;随着文档、培训和标准化的需求变得越来越重要，跨两个办公室划分服务职责通常会促进成熟度的提高。&lt;/p&gt;

&lt;p&gt;如果你的组织足够幸运，已经在多个大洲拥有了工程团队，我们建议配备多站点SRE团队。在不同于开发团队的办公室中有一个SRE团队是可行的，但是根据我们的经验，主机托管为健康和健壮的团队间对话提供了好处。否则，SREs就很难理解服务如何发展或技术基础设施如何使用，产品开发人员也就很难对基础设施的改进感到乐观。&lt;/p&gt;

&lt;h4 id=&quot;位置团队之间应该跨多少时区&quot;&gt;位置：团队之间应该跨多少时区?&lt;/h4&gt;
&lt;p&gt;假设你有一些选择，时区分隔是决定两支队伍位置时的一个重要考虑因素。不幸的是，目标是相互排斥的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;尽量减少值班人员在正常办公时间以外的工作时间&lt;/li&gt;
  &lt;li&gt;最大化两个团队在线时的重叠时间，这样他们就可以定期互动&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据我们的经验，在相隔6至8个小时的时区工作的员工团队工作得很好，避免了12点到6点的值班轮班。你可以使用&lt;a href=&quot;https://www.timeanddate.com/worldclock/meeting.html&quot;&gt;https://www.timeanddate.com/worldclock/meeting.html&lt;/a&gt;等在线资源来可视化不同位置来减少重叠。&lt;/p&gt;

&lt;h4 id=&quot;人员和项目建立团队&quot;&gt;人员和项目：建立团队&lt;/h4&gt;
&lt;p&gt;当你在地理上划分团队时，新办公室中的第一个SRE团队将为未来的SRE团队设置规范。如果你能识别出一个或多个愿意在临时或长期的基础上从原来的站点迁移来建立SRE实践、招募和培训新团队的SRE人员，你成功的可能性就会大大提高。新团队还应该承担一个高价值的项目，促进团队内部的协作，并需要与姐妹团队进行交互。&lt;/p&gt;

&lt;h4 id=&quot;平均在办公室之间分配工作避免夜班&quot;&gt;平均：在办公室之间分配工作，避免“夜班”&lt;/h4&gt;
&lt;p&gt;通常，两个姐妹的SRE团队中的一个与产品开发团队(我们将其称为“Office 1”)相关联(或者至少在同一个时区)。如果是这种情况，要保持警惕，以确保没有被配置的团队(“office2”)不会变成一个与产品开发团队几乎没有联系的夜班，承担过多的工作量，或者只分配给不太有趣或影响不大的项目。&lt;/p&gt;

&lt;p&gt;这两个办公室的工作量会有一些自然的差异：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;你的服务可能每天都有高峰，在高峰期间会有一个办公室内的人员随时待命。因此，这两个站点的on-call体验将有所不同。&lt;/li&gt;
  &lt;li&gt;开发过程将以特定的节奏生成新版本。一个办公室人员可能会承担更多的与推出和回滚相关的负担。&lt;/li&gt;
  &lt;li&gt;Office 1在工作日更容易被产品开发团队的问题打断。&lt;/li&gt;
  &lt;li&gt;Office 1更容易承担与主要版本相关的项目工作。相反，Office 2更容易承担与即时产品目标脱钩的项目工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;你可以使用以下方法来维持平衡：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;平衡办公室之间值班的工作量。分配较大比例的报警及较小比例的工单到办公室。&lt;/li&gt;
  &lt;li&gt;将开发区域与特定办公室的SRE团队联系起来，这可以是短期(例如，根据项目)或长期(例如，根据服务)的。否则，产品开发团队很可能会依赖于Office 1，而无法有效地与Office 2中的SREs打交道。&lt;/li&gt;
  &lt;li&gt;将更高比例的内部服务改进项目(这些项目可能需要较少的产品开发团队参与)分配给Office 2。&lt;/li&gt;
  &lt;li&gt;在两个办公室之间公平地传播最有趣、最有影响力的项目。&lt;/li&gt;
  &lt;li&gt;在两个办公室之间保持相似的团队规模和资历组合。&lt;/li&gt;
  &lt;li&gt;将项目分散到两个站点，有意促进两个办公室SREs之间的交互。虽然从一个办公室运行一个主要项目可能会获得一些效率，但是将两个站点的项目分开有助于传播知识并在办公室之间建立信任。&lt;/li&gt;
  &lt;li&gt;允许工程师定期去其他办公室。这可以创造更好的和谐关系，从而，愿意与对方合作。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;工作地点三个地点怎么样&quot;&gt;工作地点：三个地点怎么样?&lt;/h4&gt;

&lt;p&gt;我们试图将SRE团队分成三个站点，结果导致了各种问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不可能有一个所有SREs都能参加的跨办公室生产会议(见我们第一本书的第31章)。&lt;/li&gt;
  &lt;li&gt;很难在三个办公室之间确保知识、能力和操作响应的一致性。&lt;/li&gt;
  &lt;li&gt;如果所有on-call的工作都是在办公时间内完成的，那么自动化低级工作和低价值页面的动机就会减少。在工作时间做一个解决简单问题的英雄是很有趣的。但如果它有一定的个人成本，确保它不再发生的动机是尖锐和直接的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;工时机两队应该同时首发吗&quot;&gt;工时机：两队应该同时首发吗?&lt;/h4&gt;
&lt;p&gt;你可以使用以下任何一种模型来组建姐妹团队：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;两半同时开始。&lt;/li&gt;
  &lt;li&gt;首先建立与产品开发团队合作的网站。这允许SREs更早地参与到产品生命周期中。&lt;/li&gt;
  &lt;li&gt;首先建立一个不与产品开发团队合作的站点，或者，如果一个服务已经投入生产一段时间，SRE团队和产品开发团队可以共享on-call。&lt;/li&gt;
  &lt;li&gt;根据合适的人选在合适的时间开始做出改变。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;财务差旅预算&quot;&gt;财务：差旅预算&lt;/h4&gt;
&lt;p&gt;为团队两部分之间的高质量交互创造机会是非常重要的。尽管视频会议对日常会议很有效，但我们发现，定期面对面的交流有助于促进健康的人际关系和信任。我们建议：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;每个SRE，产品开发经理，和技术领导在站点1访问站点2每年(至少)，反之亦然。&lt;/li&gt;
  &lt;li&gt;在站点1中担任管理或技术领导角色的每个SRE每年至少访问站点2两次，反之亦然。&lt;/li&gt;
  &lt;li&gt;所有SREs至少每年召开一次会议。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;领导能力共同拥有一项服务&quot;&gt;领导能力：共同拥有一项服务&lt;/h4&gt;
&lt;p&gt;如果你有多个SRE站点，那么可能每个办公室都有决策者。这些聚会应该定期面对面和通过视频会议。只有建立牢固的个人关系，他们才能：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;讨论团队面临的挑战的解决方案。&lt;/li&gt;
  &lt;li&gt;解决意见分歧，同意共同前进的道路。&lt;/li&gt;
  &lt;li&gt;为对方的团队辩护(防止“我们与他们对抗”的心态)。&lt;/li&gt;
  &lt;li&gt;支持彼此团队的健康发展。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;运行多个团队的实践建议&quot;&gt;运行多个团队的实践建议&lt;/h2&gt;
&lt;p&gt;当你的组织积累了更多的SREs和SRE团队时，新的挑战就会出现。例如，你必须:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;确保你为SREs提供他们需要的职业机会。&lt;/li&gt;
  &lt;li&gt;鼓励操作和工具的一致性。&lt;/li&gt;
  &lt;li&gt;处理那些不适合完全参与SRE的服务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本节描述了我们在Google中为处理这些问题而采用的一些实践。根据你的组织的具体情况，有些或许多组织可能也为你工作。&lt;/p&gt;

&lt;h3 id=&quot;任务控制&quot;&gt;任务控制&lt;/h3&gt;
&lt;p&gt;Google的任务控制计划使产品开发团队的工程师有机会在SRE团队中工作六个月。我们通常会将这些工程师与他们专业领域截然不同的SRE团队进行匹配。软件工程师接受生产系统和实践方面的培训，并最终随叫随到。6个月后，一些工程师决定留在SRE；其他人返回到他们的老团队，对生产环境和SRE实践有了更好的认识。SRE团队从额外的工程资源中获益，并对培训材料和文档中的漏洞和错误获得有价值的见解。&lt;/p&gt;

&lt;h3 id=&quot;sre交换&quot;&gt;SRE交换&lt;/h3&gt;
&lt;p&gt;Google的SRE交换计划让SRE与不同的SRE团队一起工作一周。来访的SRE将观察主队的工作方式，并与主队分享可能对主队有用的来自主队的实践。在交流结束时，来访的SRE会写一份旅行报告，描述他们的一周，他们的观察，以及他们对两个团队的建议。这个程序在Google很有用，因为我们的SRE团队是高度专业化的。&lt;/p&gt;

&lt;h3 id=&quot;培训&quot;&gt;培训&lt;/h3&gt;
&lt;p&gt;培训对于SRE操作系统的能力至关重要。虽然大多数培训是在团队中进行的(参见第8章第150页的“培训路线图”)，但是考虑为所有SREs建立一个标准的培训课程。在Google，所有新的SREs参加SRE EDU，一个沉浸式的为期一周的培训，介绍了几乎所有SREs工作的关键概念，工具和平台。这提供了所有新SREs的基本知识水平，并简化了特定于团队和特定于服务的培训目标。几个月后，SRE EDU团队还运行了第二系列课程，介绍了用于管理重大事件的常用工具和流程。我们的绩效管理流程特别认可为本次培训提供便利的SREs人员。&lt;/p&gt;

&lt;h3 id=&quot;横向项目&quot;&gt;横向项目&lt;/h3&gt;
&lt;p&gt;因为SRE团队与一组服务紧密结合，所以对于团队来说，构建专有的解决方案来应对他们遇到的挑战是一种诱惑——例如，监控、软件推出和配置工具。这可能导致跨团队工作的重大重复。虽然允许许多解决方案竞争“市场”采用是有价值的，但在某些时候，将标准的解决方案聚合在一起是有意义的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;满足大多数团队的需求&lt;/li&gt;
  &lt;li&gt;提供一个稳定的、可扩展的平台，在此基础上构建下一层创新&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Google通过使用横向团队来完成这些工作，横向团队通常由经验丰富的SREs人员组成。这些横向团队构建并运行标准解决方案，并与其他SRE团队合作以确保顺利采用。(有关横向软件开发的更多信息，请参阅第21章第432页的“案例研究2：SRE中的通用工具采用”。)&lt;/p&gt;

&lt;h3 id=&quot;sre流动性&quot;&gt;SRE流动性&lt;/h3&gt;
&lt;p&gt;Google尽最大努力确保工程师积极地想成为各自团队的一员。为此，我们确保SREs能够（并意识到他们能够）在团队之间进行转移。假设没有性能问题，SREs可以自由地转移到其他人员开放的SRE团队。SREs也通过了我们软件工程师职位的招聘标准，他们可以自由地转到产品开发团队(参见http://bit.ly/2xyQ4aD)。&lt;/p&gt;

&lt;p&gt;这种流动性水平对于个人和团队来说是非常健康的，原因有很多：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;工程师能够识别并占据感兴趣的角色。&lt;/li&gt;
  &lt;li&gt;如果个人情况发生变化，on-call的职责变得不切实际，SREs可以在要求较少on-call职责的团队中探索机会。他们可以通过与其他团队交谈和查看团队值班的统计数据来获得这些信息。&lt;/li&gt;
  &lt;li&gt;在团队之间移动的SREs扩大了他们加入的团队的经验。&lt;/li&gt;
  &lt;li&gt;SREs在办公室之间流动有助于建立或保持不同办公室之间的文化一致性。&lt;/li&gt;
  &lt;li&gt;SREs不会被强迫去做不健康的服务，或者为那些不支持个人发展的经理工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个策略还有一个副作用，就是让你的SRE经理专注于健康快乐的服务和团队。&lt;/p&gt;

&lt;h3 id=&quot;团建&quot;&gt;团建&lt;/h3&gt;
&lt;p&gt;除了保持地理上分散的团队健康所需的旅行（见第417页的“财务：旅行预算”一节），考虑以下方面的资金：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;建立公司内部感兴趣的社区，包括来自多个办公室的SREs。这类团体可以通过电子邮件和视频会议进行广泛的合作，但至少每年面对面交流一次。&lt;/li&gt;
  &lt;li&gt;参加并出席全行业的SRE和与SRE相关的会议，以拓宽知识，了解其他组织如何处理类似问题，并希望得到启发和激励。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;启动协调工程小组&quot;&gt;启动协调工程小组&lt;/h3&gt;
&lt;p&gt;正如我们第一本书的第27章所描述的，启动协调工程(LCE)团队可以将SRE原则应用到更广泛的产品开发团队中——这些团队构建的服务不需要引起值得SRE参与的注意级别。就像其他的SRE团队一样，LCE团队应该积极地参与日常操作的自动化。例如，开发标准工具和框架使产品开发团队能够在生产环境中设计、构建和启动他们的服务。&lt;/p&gt;

&lt;h3 id=&quot;卓越生产&quot;&gt;卓越生产&lt;/h3&gt;
&lt;p&gt;随着组织中SRE团队数量的增长，将出现许多最佳实践。每个SRE团队的发展都是不同的，因此评估它们需要深入了解多个团队的高级SREs。&lt;/p&gt;

&lt;p&gt;在Google，我们定期进行名为Production Excellence的服务评估。高级SRE领导定期检查每个SRE团队，评估他们的一些标准度量(例如，工单负载、错误预算使用、项目完成、bug关闭率)。该评论既赞扬出色的表现，也为表现不佳的团队提供建议。&lt;/p&gt;

&lt;p&gt;经验丰富的SRE可用于评估细微差别。例如，将团队合并或拆分导致的项目完成率下降与真正的团队性能问题相比，是一项具有挑战性的工作。如果一个团队有被淹没的风险，评审员可以也应该利用他们的组织地位来支持团队的领导来纠正这种情况。&lt;/p&gt;

&lt;h3 id=&quot;sre资金和招聘&quot;&gt;SRE资金和招聘&lt;/h3&gt;

&lt;p&gt;在Google，我们使用两种做法来确保每个SRE都贡献了显著的价值：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;大部分SRE资金来源于产品开发团队的资金来源。与测试或安全类似，可靠性是产品开发的核心支柱，并为此提供资金支持。&lt;/li&gt;
  &lt;li&gt;根据我们的经验，SREs的供应总是小于需求。这一动态确保我们定期审查和优先考虑得到SRE支持的服务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;简而言之，你应该有比组织想要的更少的SREs，并且只有足够的SREs来完成他们的专业工作。&lt;/p&gt;

&lt;p&gt;在Google中，产品开发团队中SREs与工程师的比例从1:5左右(例如，低级基础设施服务)到1:50左右(例如，使用标准框架构建大量微服务的面向消费者的应用程序)。许多服务在这一范围的中间，比率约为1:10。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;我们相信任何规模的组织都可以通过以下三个原则来实施SRE实践：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SRE需要带有结果的SLOs。&lt;/li&gt;
  &lt;li&gt;SRE必须有时间让明天比今天好。&lt;/li&gt;
  &lt;li&gt;SRE团队有能力调整他们的工作量。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;自从Google开始公开谈论SRE，它已经从Google特有的生产实践发展成为许多公司的专业实践。这些原则经常被证明是正确的——无论是在我们多年的大规模直接经验中，还是在我们最近与客户一起采用SRE实践的经验中。因为我们已经看到这些实践在Google内部和外部都起作用，我们认为这些建议应该在不同类型和规模的组织中被证明是有用的。&lt;/p&gt;</content><author><name>ZX</name></author><category term="《SRE-Google运维实践》" /><summary type="html">本书的前言就设定了一个目标，即“消除SRE只能在谷歌场景中实现”。本章给出了一个从无人值守到成熟SRE组织的路线图。无论你的SRE团队中处于什么阶段或位置，本章都将帮助你如何发展SRE团队。 针对SRE的不同阶段，本章讨论了SRE理论。虽然SRE根据自己团队的规模、性质和地理分布而有所不同，但我们描述的SRE理论和实践适用于许多不同类型的团队。 没有SRE的SRE实践 即使没有SRE，也可以使用SLO。如第2章所述，SLO是SRE实践的基础。因此，SRE的第一条理论： 理论1：SRE需要SLO评估影响。 用SLO来评估服务性能，将会引导你的业务决策。 即使没有SRE，如下SRE的实践也可以实现。 承认你不需要100%的可靠。 设置合理的SLO目标，此SLO应衡量对用户最重要的可靠性。 同意有助于保护用户体验的错误预算政策，使用错误预算来帮助指导： –减少停机等之类的管理措施以此来保障你的系统达到可靠状态。 –更长期的工作优先顺序，使系统更可靠，使用更少的错误预算。 测量SLO并承诺遵循错误预算策略。这一承诺需要得到公司领导层的同意。 即使团队没有SRE，为关键客户服务设置SLO并实施错误预算是应该的，只是因为隐含的100％SLO意味着团队只能被动反应。此SRE理论允许你就如何确保应用程序的可靠性做出数据知情决策。 开始一个SRE角色 找到你的第一个SRE 有可能你的第一个SRE员工不会有明确的SRE经验。我们发现以下几个方面与SRE的角色有关，因此适合在面试中进行交谈： 运维 在生产中运行应用程序提供了非常宝贵的见解，否则很难获得。 软件工程 SRE需要了解他们支持的软件，并有权改进它。 监控系统 SRE原则要求可以衡量和解释的SLO，生产自动化扩展操作需要自动化。 生产自动化 扩展操作需要自动化。 系统架构 扩展应用程序需要良好的架构。 你的第一个SRE可能会在速度和可靠性目标之间处于一个困难和模糊的位置。他们需要有弹性和灵活性，以便在实现产品开发和维护客户体验之间提供适当的平衡。 安排你的第一个SRE 一旦雇佣了你的第一个SRE，你现在需要决定将他们嵌入到你的团队中。你有三个主要的选择: 在产品开发团队中 在运维团队中 在一个横向角色中，跨多个团队进行咨询 在阅读本章之后，我们建议你评估这三个选项的利弊，考虑： 你自己的角色和影响范围。 如果你能够有效地影响产品开发团队，那么在运维或横向工作中嵌入一个SRE可以帮助尽早解决生产问题。 你面临的直接挑战。 如果挑战需要实际工作来减轻技术问题或业务风险，那么将SRE嵌入到运维或产品团队中可能是有利的。这样做可以消除团队孤岛，便于团队成员之间的沟通。 你期望在未来12个月内面临的挑战。 例如，如果你关注的是发布，那么将SRE嵌入到产品开发团队中可能是有意义的。如果你关注的是基础架构的更改，那么将SRE嵌入到运维团队中可能更有意义。 你计划如何改变你的团队。 如果你计划转向集中式的SRE团队，那么你可能不希望在产品开发团队中首先嵌入SRE——以后可能很难将他们从这些团队中删除。 你已确定为第一个SRE的人。 根据他们的背景和技能来决定第一个SRE在哪里最有生产力。 在确定哪种方法最适合你时，尝试使用不同的模型可能是有意义的。但是，我们强烈建议长期坚持使用一个稳定且连贯的模型；否则，不稳定性将破坏SRE的有效性。 引导你的第一个SRE 你的第一个SRE的首要任务是加快服务速度。为了产生积极影响，SRE需要了解服务的当前问题、所需的工作（参见第6章）以及将系统保持在SLO中所需的工程。如果你的组织尚未按照理论1拥有SLO和错误预算，那么你的第一个SRE需要执行设计和实现这些工具所需的工程。基于这点，第二条SRE理论： 理论2：SRE必须有时间做明天比今天更好的事情。 如果没有这个原则，辛劳只会随着服务使用的增加而增加，系统也会相应地变得更大、更复杂。运维责任和项目工作之间的健康平衡是非常重要的——如果繁重的工作变得过于繁重，有才华的工程师就会离开团队。有关SRE团队如何获得这种平衡的更多指导，请参阅第17章。 最初的项目工作可能集中于以下之一: 改进监控，以便在出现问题时更好地了解系统。 解决在最近的事后调查中发现的任何高优先级的行动（见第10章）。 实现自动化，以减少运行服务所需的特定工作。 至关重要的是，SRE有一个独特的角色，他们的项目有利于整个团队。留意SRE工作进展不顺利的迹象： S他们的工作组合与其他工程工作难以区分。 S如果你的第一个SRE是在一个产品开发团队中，那么他们所做的工作超出了他们的职责范围，或者他们是唯一一个在服务配置更改方面工作的人。 SLO没有受到重视，SRE也没有在衡量和维护客户体验方面取得进展。 分布式SRE 如果你没有离散的SRE团队，那么为分布式SRE构建一个社区是很重要的。这个社区应该提倡SRE的独特作用，并在团队之间推动以可靠性为中心的技术或实践的一致变化。如果没有社交分组，个体SRE可能会感到非常孤立。 你的第一个SRE团队 你可以通过多种方式组建一个SRE团队。我们在Google中使用的方法，从最小到最复杂，包括： S创建一个新团队作为主要项目的一部分 建立横向SRE团队 转换现有团队（例如，运维团队） 最适合你的方法是因地制宜。一个团队需要足够的SRE来处理运行服务所需的运维任务。处理这种工作量使我们想到我们的第三个理论： 理论3：SRE团队有能力调节工作负载。 在大型SRE团队之外，团队可能无法从第一天起就接受这个概念。这一原则易于解释，但很难有组织地付诸实施。它也是我们三个原则中最微妙的一条，也需要一些梳理。下面的部分将介绍如何构建团队，使用Tuckman的表现模型：形成、攻坚、规范和表演四个阶段。 形成 你组建的团队应该具备以下经验和专业知识： 修改应用软件以提高可靠性和性能。 编写软件，来达到如下目的： –产品中问题的的发现和快速解决 –自动化手动操作 建立并使用强大的软件实践和标准来促进长期的可维护性。 采用有条不紊和谨慎的方法进行操作。 了解系统架构（分布式系统设计和操作）。 理想情况下，你的团队将准备采用一种新的工作方式，并在技能上与其他团队建立的个人关系之间取得平衡。如果可能的话，我们建议你通过内部转移为团队提供支持。这可以减少团队的启动和运行所需的时间。 创建一个新的团队作为主要项目的一部分 你可以为一个大的项目创建一个新的SRE团队，这个团队大到足以证明新的人员编制是合理的，并且已经将可靠性和操作能力确定为项目风险。示例可能包括新服务的创建或技术的重大更改（例如，服务迁移到公共云）。 组建横向SRE团队 在这种方法中（在我们第一本书的第27章中有详细的记录），一个SRE小组在多个团队之间进行咨询。这个团队还可能建立配置管理、监视和警报的最佳实践和工具。 正确地转换团队角色 你可以将现有的团队转换为SRE团队。现有的团队可能不是产品开发团队；典型的候选人包括：操作团队、使用流行开源组件的团队。如果没有首先应用SRE实践和原则，要小心避免将团队从“运维”重新命名为“SRE”！如果你的重命名工作失败了，你的组织将来可能会对整个SRE概念造成毒害。 攻坚 新组建的团队一开始就需要考虑协作的问题：团队成员需要互相配合，也需要与其他团队合作。 你可以使用任何策略来促进这种凝聚力。在Google，我们已经成功地提供了一个定期论坛来学习和讨论SRE实践，并反思团队的表现。例如，你可能会定期举办一场电视午餐，在那里你会播放一段来自SREcon的视频，或者是一个读书俱乐部，在那里你可以提前阅读一些相关内容，然后讨论如何应用它。 在此阶段，鼓励你的新SRE团队进行扩展。你的新SRE应该乐于说出不适合你的组织的SRE实践，以及是否值得进行更改以使它们适合你的组织。 风险和缓解 在SRE旅程的初期阶段，团队可能会以多种方式失败。接下来，我们将介绍一些风险和可能的缓解策略，这些策略根据新团队的组成进行了细分。你可以针对每种风险使用一个或多个缓解策略。 新团队作为重大项目的一部分 风险 团队: 一次承担太多服务的责任，会让自己过于分散。——一个经常处理报警的团队没有时间以更持久的方式处理风险。 试图理解SRE原则和如何实现它们变得过于内省。结果，它未能实现预期目标。——例如，团队可能会忙于开发完美的SLO定义，同时忽略了服务的需求。 没有彻底检查其工作。因此，服务管理恢复到以前的行为。——团队每天有100个工单。由于这些工单并不需要立即干预，因此被忽略。 放弃SRE原则和实践，以满足产品里程碑。——保护SLO的可靠性改进（例如架构更改）可能永远不会实施，因为它们会推迟开发时间。 由于与新SRE团队失去影响力或权力而与现有团队发生冲突而分散注意力。 没有必要的技能广度，所以只提供了必要的部分改进。——例如，如果不能进行编程，SREs可能无法测量产品的可靠性。 缓解措施 团队： 从事单一重要服务开始。 尽可能早地参与项目，最好是在设计阶段。 对设计有投入，特别关注于定义SLO和分析设计中固有的可靠性风险。 与产品开发团队合作，致力于可靠性和与现有操作平台集成的特性。 在第一天不需要承担运维责任。相反，这种责任最初由产品开发团队或项目团队承担。这可能是一个需要管理层支持的重大文化变革。 就服务必须满足的条件与SRE达成明确的协议(参见《现场可靠性工程》第32章)。 此外： 如果项目涉及到迁移，团队应该对当前和未来的环境有充分的了解。如果你的团队成员需要从外部招聘，请考虑具有软件工程和未来环境知识的候选人。 继续将新员工的数量控制在团队的三分之一以下，这样培训工作就不会压倒现有的团队成员。 横向SRE团队 风险 团队被视为一个新的“门控”组织，不做真正的工作，也不增加真正的价值。 缓解措施 团队： 由具有相关专业知识的受人尊敬的工程师组成。 进行项目工作，集中于交付工具(用于监视、警报、推出、最佳实践、检查列表)。这些工具应该至少对另外两个团队有短期的有益影响。 传达成功和利益。应该庆祝一个能够实现效率突破，自动化工作，或永久消除系统不可靠性的来源的SRE团队。 将自己视为推动者，而非看门人。专注于解决方案，而不仅仅是问题。 一个团队转换到位 风险 团队： 认识到转换过程是自动取代人类的失业之旅的开始。 不支持对SRE团队的更改。 他们没有足够的能力来改变团队的日常活动。 几个月后，他们的日常工作毫无益处。 适用于不支持脚本或自动化的系统。 没有软件工程技能来自动化他们当前的工作量。 不具备向SRE发展所需的技能，或者对获得技能的兴趣。 缓解措施 团队： 确保高层领导对变革的支持。 重新协商责任，以创建实现变革所需的空间。 非常谨慎地管理变更的沟通。 在整个过渡过程中能够获得强大的个人和技术支持。 直面对失业的担忧。在许多环境中，自动化消除了部分工作，但不包括整个工作；虽然这可能是走向失业的一步，但它至少有一个优点，那就是腾出时间去做一些比非自动化劳动更好的事情(也更适合未来的雇主)。 可以避免运维过载，并具有更大的影响。如果工程师减少了繁重的工作量，需要一个更小的团队，那么他们的经验应该在组织的其他地方得到高度重用。如果他们的经验不能在公司内部使用，那么在其他地方找工作应该会有优势。 接受培训以获得SRE需要的技能。你的产品开发团队可以提供产品培训，而SRE定位可以利用这本书和其他外部资源。 改变绩效评估的方式——评估团队和个人的指标。前者应与SLO和采用其他SRE做法相一致；后者应该与SRE技能的证据相一致。 向团队中添加一个有经验的SRE或开发人员。 具有识别和引入新的开源或基于云的监控和警报系统以实现自动化的自由度（预算或时间）。确定现有系统是否足够是早期的优先事项。 定期审查内部和利益相关方的进展情况。 规范化 规范化需要克服405页“风险和缓解”中提出的问题，并就组织的SRE团队的最佳实践达成广泛一致。团队需要就可接受的工作量水平、适当的警报阈值以及重要的和相关的SRE实践达成一致。团队还需要充分主动地识别服务前的挑战，并制定中长期目标来改进服务。 团队应该在规范化成熟度达到以下水平： SLO和错误预算已经到位，错误预算政策在重大事件发生后执行。领导对SLO测量感兴趣。 值班的轮换是建立和可持续的(参见第8章)。on-call工程师可以对他们待命时间进行补偿。在重大事件中，有足够的工具，文档，和培训来支持任何团队成员。 有文档记录，有禁止事项，有管理。因此，SRE完成了有影响力的项目，提高了可靠性和效率。 事后分析文化已经确立。(参见第十章)。 团队展示了第一章列出的大部分原则。 当团队解决了405页“攻坚”中列出的初始问题时，他们会抓住他们所学到的知识并防止重复的问题。该团队定期进行演练，如不幸之轮或DiRT(灾难恢复测试)。(有关on-call培训的更多信息，请参阅我们第一本书的第11章和本书的第18章。) 产品开发团队从持续参与值班循环中获益。 团队为他们的利益相关者制作定期报告(例如，季度报告)，涵盖了报告期间的重点、亮点和关键指标。 与产品开发团队建立健康的关系是许多缓解策略的基础。团队应该根据组织的计划周期一起计划工作。 在继续下一步之前:停下来庆祝这一成功，写一篇回顾你到目前为止的经历。 执行 SRE团队的经验应该赢得更广泛的尊重和关注，并为战略的制定奠定基础。在Tuckman的performance model的最后阶段你应该期望: 成为架构设计和变更的顾问 从最初的设计阶段开始，SRE应该为软件的构建和结构可靠性定义模式。 主观能动性 团队应始终如一地应用原则3，以实现系统的整体健康。 产品架构方面 所有重大服务的变更，产品开发团队应该向SRE团队寻求意见。 例如，SRE团队会在新服务体系结构设计早期介入以减少日后进行高成本改造的几率。产品开发和SRE团队需要认识到他们在架构决策方面上观点的不同，但是目的都是要达到良好的产品设计。SRE的参与在如下方面可以为产品增加价值: 提高可靠性、可伸缩性和可操作性 更好地重用现有模式 更简单的迁移(如果需要的话) 自动调节工作负载 尽管随着时间的推移，产品架构负责人应该以某种有机的方式出现，但是SRE团队必须明确地向其伙伴维护原则3。要做到这一点，需要强有力的团队领导能力和高层管理人员的明确承诺。管理自己的工作负载的能力确保了SRE团队作为一个工程团队的地位，该工程团队与产品开发团队一样，在组织最重要的服务上工作。 在实践中，SRE团队如何确定自己的工作负载取决于与SRE接口的团队。在谷歌中，SRE团队通常与不同的产品开发团队进行交互。在这种情况下，关系具有以下特点: SRE团队选择是否和何时上线服务(参见站点可靠性工程第32章)。 在运维超负荷的情况下，团队可以通过以下方式减少工作量: –降低SLO –将运营工作转移到另一个团队(如产品开发团队) 如果在约定的辛劳限制下无法在SLO上运行服务，SRE团队可以将服务交还给产品开发团队。 SRE参与不是永久的——它通过系统问题的解决和服务可靠性的提升来满足自身发展的需要。如果一个SRE团队已经解决了一个服务稳定性的问题，那么你需要: –有意识地为SRE团队寻求其他靠性挑战。 –有意识地决定将服务交还给产品开发团队。 否则，随着SRE转向其他领域，团队可能会面临人员流失的风险。造成的缓慢流血可能会危及生产。 并不是所有的SRE团队都有合作的产品开发团队。一些SRE团队还负责开发他们运行的系统。一些SRE团队将第三方软件、硬件或服务打包(例如，开源包、网络设备等)，并将这些资产转换为内部服务。在这种情况下，您没有将工作转移回另一个团队的选项。相反，考虑以下策略: 如果服务不符合其SLO，停止与特性相关的项目工作，转而支持以可靠性为中心的项目工作。 如果在约定的工作量限制下无法在SLO上运行服务，请减少懒惰——除非管理层提供更多的能力(人员或基础设施)来处理这种情况。 组建更多的SRE团队 一旦你的第一个SRE团队开始步入正轨，基于如下的原因我们可能还要建设另一个SRE团队： 服务的复杂性 随着服务复杂度的提升，单个SRE团队无法有效的支持服务的运维工作。你可能希望将团队分成专门处理服务部分的子团队。 SRE上线 如果你的第一个SRE团队取得了成功并有明显的不同，那么在更多的服务中采用这种方法是必要的。 在地理上分离 你想要在不同的时区将团队分成两部分，并改为12小时on-call的轮班制。 当创建一个新的SRE团队时，我们建议执行以下操作： 阅读其他团队成立后的总结报告。找出重复做得好的事情，修复并探索那些做得不好的事情。 将现有的SEE团队成员加入到新的团队中，这些SRE新团队的骨干，以便应对挑战和风险。根据我们的经验，要找到合格的SRE候选人是很困难的，所以在新员工的帮助下快速发展团队通常是不现实的。 标准化建立团队和入职服务的框架(见第18章)。 慢慢改变值班的职责。例如： –为了避免核心on-call工程师离职，让团队成员在一个过渡时期内为他们以前的团队系统值班。 –在团队分离后，等待三到六个月的时间来分离值班轮换。 服务复杂性 如何分割 如果一个服务对于单个团队来说过于复杂而难以管理，那么有很多方法可以将工作分开。考虑以下选项来简化团队成员的认知负荷： 结构分割 例如，计算、存储和网络；前端和后端；前端和数据库；客户端和服务器；前端和管道。 代码分割 SRE原则不依赖于编程语言。但是，如果你的SRE深入到源代码中，那么沿着这些代码进行拆分可能会有一些好处。 管理分割 如果你所领导组织的工程跨越多个办公室，你可能希望将SRE团队的布置与应用程序开发联系起来。 隐患 当一个团队分裂时，有时新的团队中不会为原来团队所拥有的组件承担责任。为了减轻这种风险，你可以： 指定一个团队对第二团队章程之外的所有事情负责。 任命一个高级SRE在两个团队中担任一个全面的技术领导角色。 SRE上线 如果你最初的SRE团队成功了，那你的组织可能需要更多的SRE团队。我们建议对获得SRE支持的服务进行仔细的优先排序。考虑以下几点： 优先考虑可靠性对财务或声誉有很大影响的服务。影响越大，优先级越高。 定义最小可行的服务集，这些服务集是为了使产品能够正常工作而需要提供的。对这些服务进行优先级排序，并确保其他服务优雅地降级。 服务不应该成为SRE的优先级，因为它不可靠。在与业务最相关的领域，SRE应该在战术上得到应用。你也不希望在SREs投入使用之前让开发人员忽略可靠性。 地理分割 正如我们第一本书的第11章所述，Google通常在不同大洲的姐妹SRE团队中工作。我们这样做有很多原因： 服务可靠性 如果一个重大事件(如自然灾害)阻止一个团队工作运维服务，另一个团队可以继续支持服务。 值班压力 将值班轮班分成12小时轮班，为值班的工程师提供了适当的休息时间。 招聘和留住人才 与正常工作日重叠的值班轮班，扩大了我们可以招募到SRE工程师的基础，并强调了我们角色中的工程部分。 生产期限 随着文档、培训和标准化的需求变得越来越重要，跨两个办公室划分服务职责通常会促进成熟度的提高。 如果你的组织足够幸运，已经在多个大洲拥有了工程团队，我们建议配备多站点SRE团队。在不同于开发团队的办公室中有一个SRE团队是可行的，但是根据我们的经验，主机托管为健康和健壮的团队间对话提供了好处。否则，SREs就很难理解服务如何发展或技术基础设施如何使用，产品开发人员也就很难对基础设施的改进感到乐观。 位置：团队之间应该跨多少时区? 假设你有一些选择，时区分隔是决定两支队伍位置时的一个重要考虑因素。不幸的是，目标是相互排斥的： 尽量减少值班人员在正常办公时间以外的工作时间 最大化两个团队在线时的重叠时间，这样他们就可以定期互动 根据我们的经验，在相隔6至8个小时的时区工作的员工团队工作得很好，避免了12点到6点的值班轮班。你可以使用https://www.timeanddate.com/worldclock/meeting.html等在线资源来可视化不同位置来减少重叠。 人员和项目：建立团队 当你在地理上划分团队时，新办公室中的第一个SRE团队将为未来的SRE团队设置规范。如果你能识别出一个或多个愿意在临时或长期的基础上从原来的站点迁移来建立SRE实践、招募和培训新团队的SRE人员，你成功的可能性就会大大提高。新团队还应该承担一个高价值的项目，促进团队内部的协作，并需要与姐妹团队进行交互。 平均：在办公室之间分配工作，避免“夜班” 通常，两个姐妹的SRE团队中的一个与产品开发团队(我们将其称为“Office 1”)相关联(或者至少在同一个时区)。如果是这种情况，要保持警惕，以确保没有被配置的团队(“office2”)不会变成一个与产品开发团队几乎没有联系的夜班，承担过多的工作量，或者只分配给不太有趣或影响不大的项目。 这两个办公室的工作量会有一些自然的差异： 你的服务可能每天都有高峰，在高峰期间会有一个办公室内的人员随时待命。因此，这两个站点的on-call体验将有所不同。 开发过程将以特定的节奏生成新版本。一个办公室人员可能会承担更多的与推出和回滚相关的负担。 Office 1在工作日更容易被产品开发团队的问题打断。 Office 1更容易承担与主要版本相关的项目工作。相反，Office 2更容易承担与即时产品目标脱钩的项目工作。 你可以使用以下方法来维持平衡： 平衡办公室之间值班的工作量。分配较大比例的报警及较小比例的工单到办公室。 将开发区域与特定办公室的SRE团队联系起来，这可以是短期(例如，根据项目)或长期(例如，根据服务)的。否则，产品开发团队很可能会依赖于Office 1，而无法有效地与Office 2中的SREs打交道。 将更高比例的内部服务改进项目(这些项目可能需要较少的产品开发团队参与)分配给Office 2。 在两个办公室之间公平地传播最有趣、最有影响力的项目。 在两个办公室之间保持相似的团队规模和资历组合。 将项目分散到两个站点，有意促进两个办公室SREs之间的交互。虽然从一个办公室运行一个主要项目可能会获得一些效率，但是将两个站点的项目分开有助于传播知识并在办公室之间建立信任。 允许工程师定期去其他办公室。这可以创造更好的和谐关系，从而，愿意与对方合作。 工作地点：三个地点怎么样? 我们试图将SRE团队分成三个站点，结果导致了各种问题： 不可能有一个所有SREs都能参加的跨办公室生产会议(见我们第一本书的第31章)。 很难在三个办公室之间确保知识、能力和操作响应的一致性。 如果所有on-call的工作都是在办公时间内完成的，那么自动化低级工作和低价值页面的动机就会减少。在工作时间做一个解决简单问题的英雄是很有趣的。但如果它有一定的个人成本，确保它不再发生的动机是尖锐和直接的。 工时机：两队应该同时首发吗? 你可以使用以下任何一种模型来组建姐妹团队： 两半同时开始。 首先建立与产品开发团队合作的网站。这允许SREs更早地参与到产品生命周期中。 首先建立一个不与产品开发团队合作的站点，或者，如果一个服务已经投入生产一段时间，SRE团队和产品开发团队可以共享on-call。 根据合适的人选在合适的时间开始做出改变。 财务：差旅预算 为团队两部分之间的高质量交互创造机会是非常重要的。尽管视频会议对日常会议很有效，但我们发现，定期面对面的交流有助于促进健康的人际关系和信任。我们建议： 每个SRE，产品开发经理，和技术领导在站点1访问站点2每年(至少)，反之亦然。 在站点1中担任管理或技术领导角色的每个SRE每年至少访问站点2两次，反之亦然。 所有SREs至少每年召开一次会议。 领导能力：共同拥有一项服务 如果你有多个SRE站点，那么可能每个办公室都有决策者。这些聚会应该定期面对面和通过视频会议。只有建立牢固的个人关系，他们才能： 讨论团队面临的挑战的解决方案。 解决意见分歧，同意共同前进的道路。 为对方的团队辩护(防止“我们与他们对抗”的心态)。 支持彼此团队的健康发展。 运行多个团队的实践建议 当你的组织积累了更多的SREs和SRE团队时，新的挑战就会出现。例如，你必须: 确保你为SREs提供他们需要的职业机会。 鼓励操作和工具的一致性。 处理那些不适合完全参与SRE的服务。 本节描述了我们在Google中为处理这些问题而采用的一些实践。根据你的组织的具体情况，有些或许多组织可能也为你工作。 任务控制 Google的任务控制计划使产品开发团队的工程师有机会在SRE团队中工作六个月。我们通常会将这些工程师与他们专业领域截然不同的SRE团队进行匹配。软件工程师接受生产系统和实践方面的培训，并最终随叫随到。6个月后，一些工程师决定留在SRE；其他人返回到他们的老团队，对生产环境和SRE实践有了更好的认识。SRE团队从额外的工程资源中获益，并对培训材料和文档中的漏洞和错误获得有价值的见解。 SRE交换 Google的SRE交换计划让SRE与不同的SRE团队一起工作一周。来访的SRE将观察主队的工作方式，并与主队分享可能对主队有用的来自主队的实践。在交流结束时，来访的SRE会写一份旅行报告，描述他们的一周，他们的观察，以及他们对两个团队的建议。这个程序在Google很有用，因为我们的SRE团队是高度专业化的。 培训 培训对于SRE操作系统的能力至关重要。虽然大多数培训是在团队中进行的(参见第8章第150页的“培训路线图”)，但是考虑为所有SREs建立一个标准的培训课程。在Google，所有新的SREs参加SRE EDU，一个沉浸式的为期一周的培训，介绍了几乎所有SREs工作的关键概念，工具和平台。这提供了所有新SREs的基本知识水平，并简化了特定于团队和特定于服务的培训目标。几个月后，SRE EDU团队还运行了第二系列课程，介绍了用于管理重大事件的常用工具和流程。我们的绩效管理流程特别认可为本次培训提供便利的SREs人员。 横向项目 因为SRE团队与一组服务紧密结合，所以对于团队来说，构建专有的解决方案来应对他们遇到的挑战是一种诱惑——例如，监控、软件推出和配置工具。这可能导致跨团队工作的重大重复。虽然允许许多解决方案竞争“市场”采用是有价值的，但在某些时候，将标准的解决方案聚合在一起是有意义的： 满足大多数团队的需求 提供一个稳定的、可扩展的平台，在此基础上构建下一层创新 Google通过使用横向团队来完成这些工作，横向团队通常由经验丰富的SREs人员组成。这些横向团队构建并运行标准解决方案，并与其他SRE团队合作以确保顺利采用。(有关横向软件开发的更多信息，请参阅第21章第432页的“案例研究2：SRE中的通用工具采用”。) SRE流动性 Google尽最大努力确保工程师积极地想成为各自团队的一员。为此，我们确保SREs能够（并意识到他们能够）在团队之间进行转移。假设没有性能问题，SREs可以自由地转移到其他人员开放的SRE团队。SREs也通过了我们软件工程师职位的招聘标准，他们可以自由地转到产品开发团队(参见http://bit.ly/2xyQ4aD)。 这种流动性水平对于个人和团队来说是非常健康的，原因有很多： 工程师能够识别并占据感兴趣的角色。 如果个人情况发生变化，on-call的职责变得不切实际，SREs可以在要求较少on-call职责的团队中探索机会。他们可以通过与其他团队交谈和查看团队值班的统计数据来获得这些信息。 在团队之间移动的SREs扩大了他们加入的团队的经验。 SREs在办公室之间流动有助于建立或保持不同办公室之间的文化一致性。 SREs不会被强迫去做不健康的服务，或者为那些不支持个人发展的经理工作。 这个策略还有一个副作用，就是让你的SRE经理专注于健康快乐的服务和团队。 团建 除了保持地理上分散的团队健康所需的旅行（见第417页的“财务：旅行预算”一节），考虑以下方面的资金： 建立公司内部感兴趣的社区，包括来自多个办公室的SREs。这类团体可以通过电子邮件和视频会议进行广泛的合作，但至少每年面对面交流一次。 参加并出席全行业的SRE和与SRE相关的会议，以拓宽知识，了解其他组织如何处理类似问题，并希望得到启发和激励。 启动协调工程小组 正如我们第一本书的第27章所描述的，启动协调工程(LCE)团队可以将SRE原则应用到更广泛的产品开发团队中——这些团队构建的服务不需要引起值得SRE参与的注意级别。就像其他的SRE团队一样，LCE团队应该积极地参与日常操作的自动化。例如，开发标准工具和框架使产品开发团队能够在生产环境中设计、构建和启动他们的服务。 卓越生产 随着组织中SRE团队数量的增长，将出现许多最佳实践。每个SRE团队的发展都是不同的，因此评估它们需要深入了解多个团队的高级SREs。 在Google，我们定期进行名为Production Excellence的服务评估。高级SRE领导定期检查每个SRE团队，评估他们的一些标准度量(例如，工单负载、错误预算使用、项目完成、bug关闭率)。该评论既赞扬出色的表现，也为表现不佳的团队提供建议。 经验丰富的SRE可用于评估细微差别。例如，将团队合并或拆分导致的项目完成率下降与真正的团队性能问题相比，是一项具有挑战性的工作。如果一个团队有被淹没的风险，评审员可以也应该利用他们的组织地位来支持团队的领导来纠正这种情况。 SRE资金和招聘 在Google，我们使用两种做法来确保每个SRE都贡献了显著的价值： 大部分SRE资金来源于产品开发团队的资金来源。与测试或安全类似，可靠性是产品开发的核心支柱，并为此提供资金支持。 根据我们的经验，SREs的供应总是小于需求。这一动态确保我们定期审查和优先考虑得到SRE支持的服务。 简而言之，你应该有比组织想要的更少的SREs，并且只有足够的SREs来完成他们的专业工作。 在Google中，产品开发团队中SREs与工程师的比例从1:5左右(例如，低级基础设施服务)到1:50左右(例如，使用标准框架构建大量微服务的面向消费者的应用程序)。许多服务在这一范围的中间，比率约为1:10。 结论 我们相信任何规模的组织都可以通过以下三个原则来实施SRE实践： SRE需要带有结果的SLOs。 SRE必须有时间让明天比今天好。 SRE团队有能力调整他们的工作量。 自从Google开始公开谈论SRE，它已经从Google特有的生产实践发展成为许多公司的专业实践。这些原则经常被证明是正确的——无论是在我们多年的大规模直接经验中，还是在我们最近与客户一起采用SRE实践的经验中。因为我们已经看到这些实践在Google内部和外部都起作用，我们认为这些建议应该在不同类型和规模的组织中被证明是有用的。</summary></entry><entry><title type="html">第十九章 SRE：超出界限</title><link href="http://localhost:4000/sre/2020/01/19/SRE-%E8%B6%85%E5%87%BA%E7%95%8C%E9%99%90/" rel="alternate" type="text/html" title="第十九章 SRE：超出界限" /><published>2020-01-19T00:00:00+08:00</published><updated>2020-01-19T00:00:00+08:00</updated><id>http://localhost:4000/sre/2020/01/19/SRE:%E8%B6%85%E5%87%BA%E7%95%8C%E9%99%90</id><content type="html" xml:base="http://localhost:4000/sre/2020/01/19/SRE-%E8%B6%85%E5%87%BA%E7%95%8C%E9%99%90/">&lt;p&gt;距离我们开始在Google上练习SRE已有14年了。 回想起来，当时的一些成果似乎是显而易见的，而其他发展则令人震惊。 我们出版第一本SRE书的两年以来特别有趣。 现在正在实施SRE的公司数量以及我们在会议和客户的谈论中关于它的时间已经超出了我们之前的想象。&lt;/p&gt;

&lt;p&gt;特别是这种变化 – 围绕SRE的非谷歌生态系统的快速扩张 - 是最令人兴奋的，但它使得预测SRE行业的未来变得更加困难。 尽管如此，我们自己在谷歌的SRE工作中，开始看到一些可能为行业未来提供概述信息的趋势。 本章代表了我们分享 自己以及全球SRE同事所看到的，以及迄今为止所努力得出的结论。&lt;/p&gt;

&lt;h2 id=&quot;真理不言而喻&quot;&gt;真理不言而喻&lt;/h2&gt;
&lt;p&gt;对未来有任何意义的唯一方法就是从基本的原则开始，然后继续前进。接下来的事情应该是没有争议的。其他的就没那么多了。然而，在任何情况下，这些原则都是基于我们在世界上看到的真实事物。&lt;/p&gt;

&lt;h3 id=&quot;可靠性是最重要的特征&quot;&gt;可靠性是最重要的特征&lt;/h3&gt;
&lt;p&gt;当我们断言“可靠性是任何系统最重要的特征”时，人们通常不会进行反驳，只要我们小心地指出“可靠性”通常覆盖很广的领域。&lt;/p&gt;

&lt;p&gt;很容易找出充足的证据：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果一个系统不可靠，用户就不会信任它。&lt;/li&gt;
  &lt;li&gt;如果用户不信任一个系统，当有其他的选择时，他们不会使用它。&lt;/li&gt;
  &lt;li&gt;由于所有软件系统都受网络效应控制，如果一个系统没有任何用户，那么它就一文不值。&lt;/li&gt;
  &lt;li&gt;你就是衡量标准，因此请仔细选择您的指标。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;决定你的可靠性是用户而不是监控&quot;&gt;决定你的可靠性是用户，而不是监控，&lt;/h3&gt;
&lt;p&gt;系统的价值与它的用户息息相关，因此可靠性的唯一衡量标准的关键就是用户体验的可靠性。如果你的用户怀疑是你的平台造成了他们的故障，在这时告诉他们“我们的监控一切正常，因此问题一定出现在你们那边”，不会让用户的情绪好转，用户体验到你的系统不稳定，当你和你的竞争对手之间做出选择时，客户会想起这一点。（这种现象被称为峰值规则）&lt;/p&gt;

&lt;p&gt;你的监控，日志和报警只有帮助你赶在客户之前发现问题的情况下才有价值。&lt;/p&gt;

&lt;h3 id=&quot;如果你运行一个平台那么可靠性就是合伙人&quot;&gt;如果你运行一个平台，那么可靠性就是合伙人&lt;/h3&gt;
&lt;p&gt;如果其他人使用你系统的唯一方式是通过可视化用户界面（例如，网页），并且你的系统仅由真人（而不是机器）使用，那么你用户体验的可靠性几乎只与你作为一名SRE所从事的保障系统可靠性的工作有关。&lt;/p&gt;

&lt;p&gt;但是，一旦你添加了一个API，并且你的一些“用户”实际上是其他机器，那么你的运行平台的规则就已经改变了。&lt;/p&gt;

&lt;p&gt;当您的产品充当平台时，用户体验的可靠性并不局限于您的选择。 可靠性就成为一种合作关系。 如果您的用户在您的平台上构建或运行的系统永远不会达到99％以上的可靠性 - 即使您以99.999％的可靠性运行您的平台 - 那么他们的最佳案例体验是98.99901％。&lt;/p&gt;

&lt;p&gt;这些用户的选择直接影响他们的体验，并与您的服务相关联。你可能不会喜欢，但他们会让你对他们所经历的一切负责，即使这不是你的错。&lt;/p&gt;

&lt;h3 id=&quot;任何重要的东西最终都会成为一个平台&quot;&gt;任何重要的东西最终都会成为一个平台&lt;/h3&gt;
&lt;p&gt;由于系统的价值随着使用它的人数的增加而增加，因此你需要找到访问其他大型已建立的用户池的方法。当您吸引更多的用户时，其他软件系统也想要接触您的用户。&lt;/p&gt;

&lt;p&gt;这是其他公司开始让他们的机器通过API与您的机器通信的时候。如果您的系统非常流行，那么集成是您的发展中不可避免的一步。&lt;/p&gt;

&lt;p&gt;即使您决定不关心其他用户社区，并决定永远不会创建机器可使用的API，您仍然无法避免这种未来。 其他人会简单地把您的UI包装到机器API中并使用它。 唯一的区别是你无法控制结果。&lt;/p&gt;

&lt;p&gt;一旦您的系统成为大量用户的网关，它就变得很有价值。 APIs – 官方或非官方的 – 将成为您未来的一部分。&lt;/p&gt;

&lt;h3 id=&quot;当你的客户遇到困难时你必须放慢速度&quot;&gt;当你的客户遇到困难时，你必须放慢速度&lt;/h3&gt;

&lt;p&gt;当你的客户遇到困难时，他们的挫败会变成对你的摩擦。即使您没有传统的支持模式(故障工单、电子邮件、电话等)，您仍然会花时间通过StackOverflow，甚至Twitter、Facebook和其他社交平台来处理问题和回复投诉。&lt;/p&gt;

&lt;p&gt;无论你投入到帮助用户度过难关的精力有多少，你都不能投入于改进你的系统。我们已经看到许多团队(和公司)允许他们的时间慢慢地被中断/修复客户问题所占用——留下一个不断减少的创新预算。这些团队被辛劳所消耗。&lt;/p&gt;

&lt;p&gt;一旦进入这种状态，就很难发现(见第6章)。你可能在读这篇文章的时候会想，哎呀，我只是内部平台团队的一员。这对我不适用!&lt;/p&gt;

&lt;p&gt;我们很抱歉地通知您，这对您来说是加倍适用的!在您的案例中，您的客户是您公司系统的消费者。&lt;/p&gt;

&lt;p&gt;这就引出了下一个结论。&lt;/p&gt;

&lt;p&gt;你需要和你的客户一起练习SRE&lt;/p&gt;

&lt;p&gt;如果你想让你的客户使用你的平台来设计和运行可靠的系统，你必须教会他们如何操作。是的，这也包括你的内部客户。仅仅因为您在内部平台团队工作并不意味着您可以逃离这个动态过程——事实上，您最有可能首先遇到它。&lt;/p&gt;

&lt;p&gt;即使您可以将这些信息完美地提炼成高度伸缩的一对多表单(书籍、博客帖子、架构图、视频等)，您仍然需要一种方法来确定要包含哪些内容和培训。随着你平台的成长和完善，这些经验教训将会改变。您总是需要一种方法来防止这些资源变得陈旧。&lt;/p&gt;

&lt;p&gt;学习这些经验的最好方法就是和你的用户一起“do SRE”。&lt;/p&gt;

&lt;p&gt;这并不一定意味着您需要为用户的系统创建页面调度程序，但您确实需要承担通常导致页面调度程序切换的大部分工作（意味着系统已满足某些最低可行的可靠性要求）， 至少是您用户的代表性样本。&lt;/p&gt;

&lt;h2 id=&quot;怎样--和你的用户一起实践sre&quot;&gt;怎样:  和你的用户一起实践SRE&lt;/h2&gt;
&lt;p&gt;与用户一起实践SRE的想法似乎有点令人生畏，你读这本书的原因可能是你自己都不知道该如何去做。不过不同担心，两者可以同时进行，实际上，前者可以帮助你加速后者。&lt;/p&gt;

&lt;p&gt;下面是我们要遵循的步骤，它对我们很有帮助，并且我们认为也同样会对你有所帮助。&lt;/p&gt;

&lt;h3 id=&quot;步骤一-slos-and-slis-are-how-you-speak&quot;&gt;步骤一: SLOs and SLIs Are How You Speak&lt;/h3&gt;

&lt;p&gt;你希望你的用户认为你的系统是可靠的。否则，你就有可能失去他们。因此，你应该非常关心他们是如何形成这些观点的。它们度量什么？它们是如何度量？最重要的是，这些度量对用户做出了什么承诺？&lt;/p&gt;

&lt;p&gt;如果您的用户度量SLIs并对SLOs保持警惕，并且与你共享这些度量值，您的生活会好得多。否则，你会花费很多的精力在这样的对话中:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;用户：API调用X通常需要时间T，但现在需要时间U.我认为你们出现了一些问题。 请仔细研究并立即回复我。&lt;/p&gt;

  &lt;p&gt;你：这种表现符合我们的预期，一切看起来都很正常。 如果API调用X确实需要这么长时间，这有问题吗？&lt;/p&gt;

  &lt;p&gt;用户：我不清楚。 这个过程通常不需要这么长时间，所以中间发生了一些变化，我们对这种变化感到担忧。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;这场对话将会循环下去，并且永远不会有一个满意的结果。你要么花费大量时间去说服你的用户这不是他们应该关心的，要么您将花费大量时间在这个变化产生的根本原因上，以便你可以说服你的用户他们没必要关心。在任何一种情况下，你都花费了很多精力，而这些精力本可以用在其他地方。&lt;/p&gt;

&lt;p&gt;这个问题的根本原因是用户没有使用SLO来确定他们是否应该关心他们所看到的性能。 他们只是注意到一个无法解决的问题，你的用户将不可避免地发明一个而不会告诉你，直到你不满足它！ 你更喜欢这个对话：&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;用户: 我们对应用程序FOO的SLO消耗得太快，应用程序处于危险之中。SLIs的 X和Y都呈现断崖式下跌，它们都依赖于你的API X。&lt;/p&gt;

  &lt;p&gt;你：好的。让我看一下API X是如何在我的系统中执行的/或它的具体表现。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;这是一个更有效的对话，因为：&lt;/p&gt;

&lt;p&gt;（a）它只会在SLO受到威胁时才会发生。&lt;/p&gt;

&lt;p&gt;（b）它依赖于相互理解的度量（SLIs）和目标（SLOs）。&lt;/p&gt;

&lt;p&gt;如果你使用SRE实践来运行你的系统，那么你在内部说的是SLOs。如果你的用户也讲SLO，你的日子会更好过，你的用户也会更舒心，因为这会让你们更容易对话。&lt;/p&gt;

&lt;p&gt;我们建议你做一个简单的练习，让你与用户的工作关系变得更好: 与用户坐下来，解释一下SLOs、SLIs和错误预算——尤其是如何在团队中实践它们。然后帮助他们用这些术语描述他们在你的平台上构建的关键应用程序。&lt;/p&gt;

&lt;h3 id=&quot;步骤二-审核监控和构建共享仪表板&quot;&gt;步骤二: 审核监控和构建共享仪表板&lt;/h3&gt;
&lt;p&gt;一旦您的用户为他们的应用程序选择了一些基本的SLOs，下一个问题就是他们是否度量了正确的东西来确认他们是否达到了这些目标。您应该帮助他们确定他们使用的度量是否合适。&lt;/p&gt;

&lt;p&gt;根据我们的经验，您的用户度量（和报警）的事物中有多达一半对他们的SLOs没有任何影响。 当你向他们指出这一点时，你的生活将变得更好，他们会关闭令人讨厌的报警。 这对他们来说意味着更少的页面，对你而言也是如此！&lt;/p&gt;

&lt;p&gt;其余的度量是有用的候选SLIs。帮助您的用户聚合这些度量数据，以计算他们的SLOs。&lt;/p&gt;

&lt;p&gt;一旦开始这个练习，您很快就会很快知道SLOs的一部分已经被发现——没有相关的度量方法来说明这些维度的任何有用之处。您还应该帮助客户覆盖他们SLOs的这些部分。&lt;/p&gt;

&lt;p&gt;现在，你的客户可以开始在你的平台上谈论他们的应用程序的SLO性能了。&lt;/p&gt;

&lt;p&gt;最后，与客户构建一组共享的SLO仪表板。您应该能够看到他们的应用程序SLOs，并且应该共享您所拥有的任何与他们体验您的系统性能相关的信息。您的目标是，当您的客户因为他们的SLO似乎受到威胁而联系您时，您都不必交换太多额外的信息。所有这些信息都应该在共享的监控中。&lt;/p&gt;

&lt;h3 id=&quot;步骤三-测量和协商&quot;&gt;步骤三: 测量和协商&lt;/h3&gt;
&lt;p&gt;一旦你把测量数据整理出来，你应该收集一两个月的数据。准备好面对你的客户可能会突然觉醒的可能性。他们认为应用程序运行在“五个9”(99.999%;每个人都认为他们得到了五个9)的情况下，如果与他们闪亮的新SLOs相比，可能只有99.5%-99.9%。&lt;/p&gt;

&lt;p&gt;在最初的震撼消失之后，是指出他们的用户并不是一直在大喊大叫的好时机，所以他们可能从来不需要他们真正没有得到的5个9。&lt;/p&gt;

&lt;p&gt;问题的关键在于，他们的用户对应用程序的性能有多满意?如果他们的用户满意，并且没有证据表明提高性能或可靠性会增加用户的采用/保留/使用，那么您的目的就达到了。你应该定期问自己这个问题，以确保你的预算和优先事项是正确的。(有关此主题的更深入的讨论，请参阅第2章。)&lt;/p&gt;

&lt;p&gt;如果客户认为他们仍然需要做得更好，那就继续下一步。&lt;/p&gt;

&lt;h3 id=&quot;步骤四-设计评审和风险分析&quot;&gt;步骤四: 设计评审和风险分析&lt;/h3&gt;
&lt;p&gt;与客户坐下来，真正了解他们的应用程序是如何设计和操作的。他们是否有隐藏的单点故障（SPOFs）？他们有部署和回滚的预案吗？基本上，对你自己的内部应用再进行同样的练习。&lt;/p&gt;

&lt;p&gt;接下来，根据每个项目消耗的错误预算的大小对您找到的问题进行排名。(阅读更多关于如何在Google云平台博客上执行此操作的信息。)，注意客户选择修复哪些项目以“赚取他们想要的9”(例如，从99.5%调整到99.9%)。&lt;/p&gt;

&lt;p&gt;您从这些评论中所学到的知识将告诉您：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;您的客户如何使用您的平台&lt;/li&gt;
  &lt;li&gt;这样做会造成什么样的可靠性错误？&lt;/li&gt;
  &lt;li&gt;当他们试图改进时，会如何进行权衡。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此练习还将帮助您的客户围绕他们当前应用程序应该具有的可靠性来设定切合实际的期望。 他们的期望会影响他们的看法，因此恰当地设定期望只会有助于赢得和保持他们的信任。&lt;/p&gt;

&lt;h3 id=&quot;步骤五-练习练习再练习&quot;&gt;步骤五: 练习,练习,再练习&lt;/h3&gt;
&lt;p&gt;最后一步是为您的客户创建一些操作严谨性。 模拟故障（不幸之轮练习，故障与恢复测试，纸质游戏日等）。&lt;/p&gt;

&lt;p&gt;在团队之间建立健康的肌肉记忆，以便在危机期间进行有效的沟通。 这是建立信任，降低MTTR以及了解一些奇怪操作极少cases好方法，您可以将其作为增强功能集成到平台功能中。&lt;/p&gt;

&lt;p&gt;当故障发生后，不要只与您的客户分享您的结论。 实际上进行一些故障复盘。 这样做也将建立信任并教给你一些宝贵的经验教训。&lt;/p&gt;

&lt;h3 id=&quot;需要考虑和训练的&quot;&gt;需要考虑和训练的&lt;/h3&gt;
&lt;p&gt;在一小部分客户之外，很快就不可能执行以上这些步骤。请不要尝试将此模型扩展到每个人身上。相反，你应该做一些有原则的决定来决定如何做出选择。以下是一些常见的方法:&lt;/p&gt;
&lt;h4 id=&quot;收入范围&quot;&gt;收入范围&lt;/h4&gt;
&lt;p&gt;选择占你收入XX%的最小客户数量。如果你的收入主要集中在几个大客户身上，那么这可能是你的正确选择。&lt;/p&gt;
&lt;h4 id=&quot;功能范围&quot;&gt;功能范围&lt;/h4&gt;
&lt;p&gt;选择覆盖平台特性XX%以上的最小客户数量。如果你运行一个高度多样化的平台，有很多客户做着不同的事情，那么这种方法将帮助你避免意外。&lt;/p&gt;
&lt;h4 id=&quot;工作范围&quot;&gt;工作范围&lt;/h4&gt;
&lt;p&gt;您的平台的使用可能由几个不同的用例或客户类型主导。 也许这些类型的客户中没有一个是占主导地位的，但您可以轻松地将他们分类成不同的群组。 在这种情况下，从每个群组中抽取一个或两个客户是获得平台覆盖率并发现用例之间的操作差异的好方法。&lt;/p&gt;

&lt;p&gt;无论你选择什么方法，坚持下去。 混合和匹配使用会使您的利益相关者感到困惑，并迅速压垮您的团队&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;
&lt;p&gt;在过去的几年里，SRE的职业和角色已广泛传播到谷歌之外。 尽管我们从未预料到这一点，但我们仍然为之激动不已。 我们或许可以说一些关于我们如何认为该学科将在谷歌内部发展的值得信赖的话，但在外界，这是一个“令人不安又刺激”的主张。&lt;/p&gt;

&lt;p&gt;我们非常确定的一点是，当您将SRE原则应用到您的组织中时，您将跨越许多与我们相同的拐点(有些我们没有!)—包括需要在您客户的终点和您的起点之间模糊界限。&lt;/p&gt;

&lt;p&gt;在这样的操作深度下与个别客户打交道，对我们来说是一个很有价值的新领域，我们仍在这条道路上走得很远。(你可以在线关注谷歌云平台博客。)然而，我们走得越远，我们就越确信这是你们也需要经历的。&lt;/p&gt;</content><author><name>ZX</name></author><category term="《SRE-Google运维实践》" /><summary type="html">距离我们开始在Google上练习SRE已有14年了。 回想起来，当时的一些成果似乎是显而易见的，而其他发展则令人震惊。 我们出版第一本SRE书的两年以来特别有趣。 现在正在实施SRE的公司数量以及我们在会议和客户的谈论中关于它的时间已经超出了我们之前的想象。 特别是这种变化 – 围绕SRE的非谷歌生态系统的快速扩张 - 是最令人兴奋的，但它使得预测SRE行业的未来变得更加困难。 尽管如此，我们自己在谷歌的SRE工作中，开始看到一些可能为行业未来提供概述信息的趋势。 本章代表了我们分享 自己以及全球SRE同事所看到的，以及迄今为止所努力得出的结论。 真理不言而喻 对未来有任何意义的唯一方法就是从基本的原则开始，然后继续前进。接下来的事情应该是没有争议的。其他的就没那么多了。然而，在任何情况下，这些原则都是基于我们在世界上看到的真实事物。 可靠性是最重要的特征 当我们断言“可靠性是任何系统最重要的特征”时，人们通常不会进行反驳，只要我们小心地指出“可靠性”通常覆盖很广的领域。 很容易找出充足的证据： 如果一个系统不可靠，用户就不会信任它。 如果用户不信任一个系统，当有其他的选择时，他们不会使用它。 由于所有软件系统都受网络效应控制，如果一个系统没有任何用户，那么它就一文不值。 你就是衡量标准，因此请仔细选择您的指标。 决定你的可靠性是用户，而不是监控， 系统的价值与它的用户息息相关，因此可靠性的唯一衡量标准的关键就是用户体验的可靠性。如果你的用户怀疑是你的平台造成了他们的故障，在这时告诉他们“我们的监控一切正常，因此问题一定出现在你们那边”，不会让用户的情绪好转，用户体验到你的系统不稳定，当你和你的竞争对手之间做出选择时，客户会想起这一点。（这种现象被称为峰值规则） 你的监控，日志和报警只有帮助你赶在客户之前发现问题的情况下才有价值。 如果你运行一个平台，那么可靠性就是合伙人 如果其他人使用你系统的唯一方式是通过可视化用户界面（例如，网页），并且你的系统仅由真人（而不是机器）使用，那么你用户体验的可靠性几乎只与你作为一名SRE所从事的保障系统可靠性的工作有关。 但是，一旦你添加了一个API，并且你的一些“用户”实际上是其他机器，那么你的运行平台的规则就已经改变了。 当您的产品充当平台时，用户体验的可靠性并不局限于您的选择。 可靠性就成为一种合作关系。 如果您的用户在您的平台上构建或运行的系统永远不会达到99％以上的可靠性 - 即使您以99.999％的可靠性运行您的平台 - 那么他们的最佳案例体验是98.99901％。 这些用户的选择直接影响他们的体验，并与您的服务相关联。你可能不会喜欢，但他们会让你对他们所经历的一切负责，即使这不是你的错。 任何重要的东西最终都会成为一个平台 由于系统的价值随着使用它的人数的增加而增加，因此你需要找到访问其他大型已建立的用户池的方法。当您吸引更多的用户时，其他软件系统也想要接触您的用户。 这是其他公司开始让他们的机器通过API与您的机器通信的时候。如果您的系统非常流行，那么集成是您的发展中不可避免的一步。 即使您决定不关心其他用户社区，并决定永远不会创建机器可使用的API，您仍然无法避免这种未来。 其他人会简单地把您的UI包装到机器API中并使用它。 唯一的区别是你无法控制结果。 一旦您的系统成为大量用户的网关，它就变得很有价值。 APIs – 官方或非官方的 – 将成为您未来的一部分。 当你的客户遇到困难时，你必须放慢速度 当你的客户遇到困难时，他们的挫败会变成对你的摩擦。即使您没有传统的支持模式(故障工单、电子邮件、电话等)，您仍然会花时间通过StackOverflow，甚至Twitter、Facebook和其他社交平台来处理问题和回复投诉。 无论你投入到帮助用户度过难关的精力有多少，你都不能投入于改进你的系统。我们已经看到许多团队(和公司)允许他们的时间慢慢地被中断/修复客户问题所占用——留下一个不断减少的创新预算。这些团队被辛劳所消耗。 一旦进入这种状态，就很难发现(见第6章)。你可能在读这篇文章的时候会想，哎呀，我只是内部平台团队的一员。这对我不适用! 我们很抱歉地通知您，这对您来说是加倍适用的!在您的案例中，您的客户是您公司系统的消费者。 这就引出了下一个结论。 你需要和你的客户一起练习SRE 如果你想让你的客户使用你的平台来设计和运行可靠的系统，你必须教会他们如何操作。是的，这也包括你的内部客户。仅仅因为您在内部平台团队工作并不意味着您可以逃离这个动态过程——事实上，您最有可能首先遇到它。 即使您可以将这些信息完美地提炼成高度伸缩的一对多表单(书籍、博客帖子、架构图、视频等)，您仍然需要一种方法来确定要包含哪些内容和培训。随着你平台的成长和完善，这些经验教训将会改变。您总是需要一种方法来防止这些资源变得陈旧。 学习这些经验的最好方法就是和你的用户一起“do SRE”。 这并不一定意味着您需要为用户的系统创建页面调度程序，但您确实需要承担通常导致页面调度程序切换的大部分工作（意味着系统已满足某些最低可行的可靠性要求）， 至少是您用户的代表性样本。 怎样: 和你的用户一起实践SRE 与用户一起实践SRE的想法似乎有点令人生畏，你读这本书的原因可能是你自己都不知道该如何去做。不过不同担心，两者可以同时进行，实际上，前者可以帮助你加速后者。 下面是我们要遵循的步骤，它对我们很有帮助，并且我们认为也同样会对你有所帮助。 步骤一: SLOs and SLIs Are How You Speak 你希望你的用户认为你的系统是可靠的。否则，你就有可能失去他们。因此，你应该非常关心他们是如何形成这些观点的。它们度量什么？它们是如何度量？最重要的是，这些度量对用户做出了什么承诺？ 如果您的用户度量SLIs并对SLOs保持警惕，并且与你共享这些度量值，您的生活会好得多。否则，你会花费很多的精力在这样的对话中: 用户：API调用X通常需要时间T，但现在需要时间U.我认为你们出现了一些问题。 请仔细研究并立即回复我。 你：这种表现符合我们的预期，一切看起来都很正常。 如果API调用X确实需要这么长时间，这有问题吗？ 用户：我不清楚。 这个过程通常不需要这么长时间，所以中间发生了一些变化，我们对这种变化感到担忧。 这场对话将会循环下去，并且永远不会有一个满意的结果。你要么花费大量时间去说服你的用户这不是他们应该关心的，要么您将花费大量时间在这个变化产生的根本原因上，以便你可以说服你的用户他们没必要关心。在任何一种情况下，你都花费了很多精力，而这些精力本可以用在其他地方。 这个问题的根本原因是用户没有使用SLO来确定他们是否应该关心他们所看到的性能。 他们只是注意到一个无法解决的问题，你的用户将不可避免地发明一个而不会告诉你，直到你不满足它！ 你更喜欢这个对话： 用户: 我们对应用程序FOO的SLO消耗得太快，应用程序处于危险之中。SLIs的 X和Y都呈现断崖式下跌，它们都依赖于你的API X。 你：好的。让我看一下API X是如何在我的系统中执行的/或它的具体表现。 这是一个更有效的对话，因为： （a）它只会在SLO受到威胁时才会发生。 （b）它依赖于相互理解的度量（SLIs）和目标（SLOs）。 如果你使用SRE实践来运行你的系统，那么你在内部说的是SLOs。如果你的用户也讲SLO，你的日子会更好过，你的用户也会更舒心，因为这会让你们更容易对话。 我们建议你做一个简单的练习，让你与用户的工作关系变得更好: 与用户坐下来，解释一下SLOs、SLIs和错误预算——尤其是如何在团队中实践它们。然后帮助他们用这些术语描述他们在你的平台上构建的关键应用程序。 步骤二: 审核监控和构建共享仪表板 一旦您的用户为他们的应用程序选择了一些基本的SLOs，下一个问题就是他们是否度量了正确的东西来确认他们是否达到了这些目标。您应该帮助他们确定他们使用的度量是否合适。 根据我们的经验，您的用户度量（和报警）的事物中有多达一半对他们的SLOs没有任何影响。 当你向他们指出这一点时，你的生活将变得更好，他们会关闭令人讨厌的报警。 这对他们来说意味着更少的页面，对你而言也是如此！ 其余的度量是有用的候选SLIs。帮助您的用户聚合这些度量数据，以计算他们的SLOs。 一旦开始这个练习，您很快就会很快知道SLOs的一部分已经被发现——没有相关的度量方法来说明这些维度的任何有用之处。您还应该帮助客户覆盖他们SLOs的这些部分。 现在，你的客户可以开始在你的平台上谈论他们的应用程序的SLO性能了。 最后，与客户构建一组共享的SLO仪表板。您应该能够看到他们的应用程序SLOs，并且应该共享您所拥有的任何与他们体验您的系统性能相关的信息。您的目标是，当您的客户因为他们的SLO似乎受到威胁而联系您时，您都不必交换太多额外的信息。所有这些信息都应该在共享的监控中。 步骤三: 测量和协商 一旦你把测量数据整理出来，你应该收集一两个月的数据。准备好面对你的客户可能会突然觉醒的可能性。他们认为应用程序运行在“五个9”(99.999%;每个人都认为他们得到了五个9)的情况下，如果与他们闪亮的新SLOs相比，可能只有99.5%-99.9%。 在最初的震撼消失之后，是指出他们的用户并不是一直在大喊大叫的好时机，所以他们可能从来不需要他们真正没有得到的5个9。 问题的关键在于，他们的用户对应用程序的性能有多满意?如果他们的用户满意，并且没有证据表明提高性能或可靠性会增加用户的采用/保留/使用，那么您的目的就达到了。你应该定期问自己这个问题，以确保你的预算和优先事项是正确的。(有关此主题的更深入的讨论，请参阅第2章。) 如果客户认为他们仍然需要做得更好，那就继续下一步。 步骤四: 设计评审和风险分析 与客户坐下来，真正了解他们的应用程序是如何设计和操作的。他们是否有隐藏的单点故障（SPOFs）？他们有部署和回滚的预案吗？基本上，对你自己的内部应用再进行同样的练习。 接下来，根据每个项目消耗的错误预算的大小对您找到的问题进行排名。(阅读更多关于如何在Google云平台博客上执行此操作的信息。)，注意客户选择修复哪些项目以“赚取他们想要的9”(例如，从99.5%调整到99.9%)。 您从这些评论中所学到的知识将告诉您： 您的客户如何使用您的平台 这样做会造成什么样的可靠性错误？ 当他们试图改进时，会如何进行权衡。 此练习还将帮助您的客户围绕他们当前应用程序应该具有的可靠性来设定切合实际的期望。 他们的期望会影响他们的看法，因此恰当地设定期望只会有助于赢得和保持他们的信任。 步骤五: 练习,练习,再练习 最后一步是为您的客户创建一些操作严谨性。 模拟故障（不幸之轮练习，故障与恢复测试，纸质游戏日等）。 在团队之间建立健康的肌肉记忆，以便在危机期间进行有效的沟通。 这是建立信任，降低MTTR以及了解一些奇怪操作极少cases好方法，您可以将其作为增强功能集成到平台功能中。 当故障发生后，不要只与您的客户分享您的结论。 实际上进行一些故障复盘。 这样做也将建立信任并教给你一些宝贵的经验教训。 需要考虑和训练的 在一小部分客户之外，很快就不可能执行以上这些步骤。请不要尝试将此模型扩展到每个人身上。相反，你应该做一些有原则的决定来决定如何做出选择。以下是一些常见的方法: 收入范围 选择占你收入XX%的最小客户数量。如果你的收入主要集中在几个大客户身上，那么这可能是你的正确选择。 功能范围 选择覆盖平台特性XX%以上的最小客户数量。如果你运行一个高度多样化的平台，有很多客户做着不同的事情，那么这种方法将帮助你避免意外。 工作范围 您的平台的使用可能由几个不同的用例或客户类型主导。 也许这些类型的客户中没有一个是占主导地位的，但您可以轻松地将他们分类成不同的群组。 在这种情况下，从每个群组中抽取一个或两个客户是获得平台覆盖率并发现用例之间的操作差异的好方法。 无论你选择什么方法，坚持下去。 混合和匹配使用会使您的利益相关者感到困惑，并迅速压垮您的团队 结论 在过去的几年里，SRE的职业和角色已广泛传播到谷歌之外。 尽管我们从未预料到这一点，但我们仍然为之激动不已。 我们或许可以说一些关于我们如何认为该学科将在谷歌内部发展的值得信赖的话，但在外界，这是一个“令人不安又刺激”的主张。 我们非常确定的一点是，当您将SRE原则应用到您的组织中时，您将跨越许多与我们相同的拐点(有些我们没有!)—包括需要在您客户的终点和您的起点之间模糊界限。 在这样的操作深度下与个别客户打交道，对我们来说是一个很有价值的新领域，我们仍在这条道路上走得很远。(你可以在线关注谷歌云平台博客。)然而，我们走得越远，我们就越确信这是你们也需要经历的。</summary></entry><entry><title type="html">第十八章 SRE：参与模式</title><link href="http://localhost:4000/sre/2020/01/18/SRE-%E5%8F%82%E4%B8%8E%E6%A8%A1%E5%BC%8F/" rel="alternate" type="text/html" title="第十八章 SRE：参与模式" /><published>2020-01-18T00:00:00+08:00</published><updated>2020-01-18T00:00:00+08:00</updated><id>http://localhost:4000/sre/2020/01/18/SRE:%E5%8F%82%E4%B8%8E%E6%A8%A1%E5%BC%8F</id><content type="html" xml:base="http://localhost:4000/sre/2020/01/18/SRE-%E5%8F%82%E4%B8%8E%E6%A8%A1%E5%BC%8F/">&lt;p&gt;我们的第一本书的第32章，描述了SRE团队分析和提高服务可靠性的技术和方法。其中包括：生产成熟度评审（PRR）、早期参与和持续改进。&lt;/p&gt;

&lt;p&gt;简而言之，SRE的目标是在保证产品可靠性的前提下，最大限度的提高开发团队的项目进度。这对用户和公司而言都是有益的。但是，即使最好的SRE团队所能完成的工作也是有限的，并且当范围太大且过于复杂时，SRE模型就不那么的有效了。当前，小公司拥有微服务的个数通常比单个SRE团队能处理的要多。鉴于生产环境较大，并且无法涵盖所有服务，SRE团队必须将注意力集中在能够获得最佳效果的地方。产品开发和SRE团队可以一起确定正确的关注目标。&lt;/p&gt;

&lt;p&gt;本章采用某SRE团队的视角，该团队准备为新服务提供支持。我们着眼于如何与负责该服务的开发和产品团队一起有效地提供服务。虽然SRE通常“参与”一个或多个服务，但“参与”所涉及的内容远不止服务本身——它侧重于理解开发和产品团队的目标，并找到支持他们的正确方法。&lt;/p&gt;

&lt;p&gt;以下的大多数讨论适用各种组织规模。虽然我们经常使用团队这个词，但理论上“团队”也可以从单人开始（尽管会很忙）。无论团队规模如何，主动定义SRE的角色以及管理与产品开发的沟通和协作十分重要。&lt;/p&gt;

&lt;h2 id=&quot;服务生命周期&quot;&gt;服务生命周期&lt;/h2&gt;

&lt;p&gt;正如《Google SRE运维解密》的前言所述，SRE团队对服务可靠性的贡献贯穿于服务生命周期的所有阶段。在任何SRE为服务提供on-call之前，他们对于生产知识和经验的应用，都可以大大提高服务的可靠性。&lt;/p&gt;

&lt;p&gt;图18-1显示了服务生命周期中SRE参与的理想情况。但是，SRE团队可能在服务生命周期的任何阶段参与服务。例如，如果开发团队计划将SRE所支持的服务进行替换，则SRE可能很早就会参与新服务。又或者，服务可用数月或数年，且现在面临可靠性或可伸缩性的挑战时，SRE团队可能会正式参与该服务。本节提供有关SRE团队如何在每个阶段实现自身价值的方针。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/18-1.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图18-1: 服务生命周期中SRE的参与程度 &lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&quot;阶段1架构和设计&quot;&gt;阶段1：架构和设计&lt;/h3&gt;
&lt;p&gt;SRE可以以多种方式影响软件系统的体系结构和设计：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;提供开发团队在构建新产品时可以采用的最佳实践，例如单点故障自我恢复的能力。&lt;/li&gt;
  &lt;li&gt;(基于经验）记录特定基础设施系统的注意事项，以便开发人员可以正确的选择并使用构建模块，避免已知陷阱。&lt;/li&gt;
  &lt;li&gt;参与前期讨论，详细讨论具体架构和设计选择，并在目标原型的帮助下验证假设。&lt;/li&gt;
  &lt;li&gt;加入开发团队参与开发工作。&lt;/li&gt;
  &lt;li&gt;协调部分服务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;到了开发周期的后期，是很难修复由架构选型导致的错误的。SRE在早期参与有助于避免在系统与实际用户交互时需要进行高成本的重新设计，或根据服务增长进行扩展。&lt;/p&gt;

&lt;h3 id=&quot;阶段2积极发展&quot;&gt;阶段2：积极发展&lt;/h3&gt;
&lt;p&gt;随着产品在积极开发过程中完成，SRE便可以开始“生产化”服务——使其成型并投入生产。生产化通常包括容量规划，为冗余设置额外资源，规划尖峰和过载处理，实施负载均衡，以及实施可持续运维实践，如监控，报警和性能调优。&lt;/p&gt;

&lt;h3 id=&quot;阶段3有限的可用性&quot;&gt;阶段3：有限的可用性&lt;/h3&gt;
&lt;p&gt;随着服务向Beta发展，用户数量，用例的多样性，使用强度以及可用性和性能需求都会增加。在此阶段，SRE可以帮助衡量和评估可靠性。我们建议在常见可用性（GA）之前先定义SLO，以便服务团队客观的衡量服务的可靠性。产品团队可以选择撤回无法达到目标可靠性的产品。&lt;/p&gt;

&lt;p&gt;在此阶段，SRE团队还可以通过构建容量模型，为即将到来的启动阶段获取资源以及自动化调整和弹性调整扩展系统。SRE需要确保合适的监控范围，帮助即将到来的的服务创建与其SLO相匹配的报警配置。&lt;/p&gt;

&lt;p&gt;服务使用情况一直在变化，且SRE团队仍需要了解服务如何工作以及如何管理其故障模式，所以团队在事件响应和运维操作期间的工作量仍是增加的。我们建议开发人员和SRE团队能共同承担此项工作。这样，开发团队就可以获得服务的运维操作经验，且SRE可以获得常见的服务经验。运维工作和事件管理将在GA之前告知系统变更并发布服务所有者需要进行的变更。&lt;/p&gt;

&lt;h3 id=&quot;第4阶段一般可用性&quot;&gt;第4阶段：一般可用性&lt;/h3&gt;
&lt;p&gt;在此阶段，该服务已通过生产准备审核（详细信息请参阅《Google SRE运维解密》中的第32章），并被所有用户接受。虽然SRE通常执行大部分的操作工作，但为了保险起见，开发人员团队需要继续完成所有操作和事件响应工作的小部分内容。可以在on-call轮值中安排一名开发人员，帮助开发人员持续跟踪业务负载。&lt;/p&gt;

&lt;p&gt;在GA的早期阶段，由于开发人员专注于服务的成熟以及发布第一批新功能，因此需要进行轮值来了解实际负载下的系统属性。在GA的后期阶段，开发人员主要提供小的新增功能以及一些bug修复，其中的一些功能和bug恢复需求来源于操作需求和已发生的生产事件。&lt;/p&gt;

&lt;h3 id=&quot;第5阶段弃用&quot;&gt;第5阶段：弃用&lt;/h3&gt;
&lt;p&gt;没有系统能一直运行。如果有更好的替代系统，那么现有系统将对新用户关闭，所有工作都侧重于将用户从现有系统转换到新系统中。在没有开发团队参与的情况下，SRE将运维现有系统，并支持开发和运维工作的过渡。&lt;/p&gt;

&lt;p&gt;虽然减少了现有系统所需的SRE工作量，但SRE实际上是同时支持两个完整系统，所以需要适当调整人员以及人员配置。&lt;/p&gt;

&lt;h3 id=&quot;第6阶段被遗弃&quot;&gt;第6阶段：被遗弃&lt;/h3&gt;
&lt;p&gt;一旦服务被遗弃，通常，开发团队将接手运维工作。在此过程中，SRE会尽力提供支持。对于具有内部用户的服务，SRE将服务管理权限移交给这些用户。本章提供了两个案例研究，说明SRE如何将服务归还给开发团队。&lt;/p&gt;

&lt;h3 id=&quot;第7阶段停止支持&quot;&gt;第7阶段：停止支持&lt;/h3&gt;
&lt;p&gt;没有用户且服务已关闭时。SRE会帮助删除生产配置和文档中引用服务的部分。&lt;/p&gt;

&lt;h2 id=&quot;建立联系&quot;&gt;建立联系&lt;/h2&gt;
&lt;p&gt;服务不是凭空存在的：需要SRE团队与构建服务的开发团队以及确定发展方向的产品团队合作。本节介绍了与这些团队建立和维持良好工作关系的方法和策略。&lt;/p&gt;

&lt;h3 id=&quot;交流业务和生产优先事项&quot;&gt;交流业务和生产优先事项&lt;/h3&gt;
&lt;p&gt;你在帮助别人之前肯定需要了解其需求。同理，SRE也需要了解产品开发人员期望SRE参与实现的目标。在与开发团队合作时，SRE应深入了解产品和业务目标，了解自身角色以及如何参与帮助开发人员实现这些目标。&lt;/p&gt;

&lt;p&gt;团队需要定期就业务和生产优先事项进行沟通。理想情况下，SRE和开发领导团队应该作为一个整体进行工作，定期开会交流技术和优先级问题。SRE领导甚至可以加入产品开发领导团队。&lt;/p&gt;

&lt;h3 id=&quot;识别风险&quot;&gt;识别风险&lt;/h3&gt;

&lt;p&gt;由于SRE团队专注于系统可靠性，能很好的识别潜在风险。由于中断开发的成本和功能流对产品和工程师很重要，因此要尽可能准确的衡量这些风险的可能性和潜在影响。&lt;/p&gt;

&lt;h3 id=&quot;目标一致&quot;&gt;目标一致&lt;/h3&gt;

&lt;p&gt;开发人员和SRE团队都很关注可靠性、可用性、性能、可扩展性、效率、功能和发布速度。然而，SRE的主要目标和动力是为了支持服务在新功能发布后的长期可靠性。&lt;/p&gt;

&lt;p&gt;根据我们的经验，开发人员和SRE团队既可以通过维护自身团队的目标来达到平衡，也可以通过支持对方团队的目标实现平衡。SRE可以设立明确的目标来支持开发团队的发布上线，并确保所有已审批通过的版本上线成功。例如，SRE可能会表明：“我们将尽可能快的支持你安全发布上线”，其中“安全”通常意味着保持在错误预算范围内。开发人员应该投入一定的时间去修复或预防一些有损可靠性的事情上：解决设计和实施层面的在线服务问题，解决遗留技术问题，尽早在新功能开发时让SRE参与设计。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h3 id=&quot;-共同目标纽约时报的sre-&quot;&gt;&lt;center&gt; 共同目标：纽约时报的SRE &lt;/center&gt;&lt;/h3&gt;

  &lt;p&gt;作者：Surya Prashanth Sanagavarapu (New York Times)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;当涉及到云迁移，生产过渡期或向容器部署应用时，我们对SRE资源的需求会很大。此外，SRE团队还有自身积压的工作要解决。面对有限的资源，SRE团队的成功在于合理的安排互不兼容的事务的优先级。虽然雇佣SRE是解决SRE时间需求的一种方式，但并非每个团队都有额外的成本、足够的经验或时间。&lt;/p&gt;

  &lt;p&gt;“纽约时报”SRE职能的核心使命是为产品开发团队提供工具和流程,最大程度的支持新闻编辑室的应用的可靠性和弹性，从而为读者提供高质量的新闻报道。我们采用了共享目标模型，在减少自身工作积压和团队合作之间获取平衡。&lt;/p&gt;

  &lt;p&gt;在与团队合作之前，我们会审核当前季度/年度的总体积压，明确定义工作项目和类别。例如，我们的待办事项可能包括：&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;通过点击应用的服务状态按钮，添加自动化设置基础监控和报警。&lt;/li&gt;
    &lt;li&gt;实施更可靠和/或更快的构建管道。&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;当有团队向SRE寻求帮助时，我们确定请求优先级时考虑的因素之一是参与进去是否有助于减少我们的工作积压。&lt;/p&gt;

  &lt;h4 id=&quot;定义参与度&quot;&gt;定义参与度&lt;/h4&gt;

  &lt;p&gt;我们的SRE根据两种不同的模型与产品开发团队合作：&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;全职模型&lt;/li&gt;
    &lt;li&gt;相对简短和受限制项目的兼职模型&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;我们根据SRE团队的参与度定义参与模型。对于全职参与，我们更愿意将SRE嵌入产品开发团队，这样有助于提供时间和精力来减轻产品开发团队的负担。随着开发人员SRE技能和能力提高的同时，SRE和产品团队有更多的时间来了解彼此。对于长期合作，我们优先考虑最适合我们公司战略的应用&lt;/p&gt;

  &lt;p&gt;在定义参与范围时，我们尝试衡量团队或应用与SRE实践相关的成熟度。我们发现，在考虑SRE实践和原则时，每个团队处于不同的水平。我们正努力使用应用成熟度模型来提供帮助。&lt;/p&gt;

  &lt;h4 id=&quot;设定共同的目标和期望&quot;&gt;设定共同的目标和期望&lt;/h4&gt;

  &lt;p&gt;对于任务的最后期限和完成度而言设定正确的目标十分重要。为此，我们按照以下原则工作：&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;我们强调，应用所有者（非SRE）直接负责对应用进行更改。&lt;/li&gt;
    &lt;li&gt;SRE参与是为了公司范围的利益。任何新的自动化或工具都应该同时改进整个公司使用的常用工具和自动化，避免一次性的脚本开发。&lt;/li&gt;
    &lt;li&gt;SRE应该让开发人员团队提前了解可能会引入的新流程（例如，负载测试）。&lt;/li&gt;
    &lt;li&gt;参与应用准备评审（ARR）和生产就绪程度评审（PRR），如《Google SRE运维解密》第32章所述。ARR和PRR的拟议变更必须优先由开发人员和SRE共同考虑。&lt;/li&gt;
    &lt;li&gt;SRE不是传统的运维工程师。他们不支持手动工作，例如运行部署作业。&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;我们会与开发团队一起明确目标，并将目标划分为一个个里程碑。如果你是一家基于敏捷开发的公司，你可以撰写描述或综述。SRE团队可以将这些目标映射到他们的待办事项中。&lt;/p&gt;

  &lt;p&gt;设定目标时我们的共同模式是：&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;确定参与范围。&lt;br /&gt;
   示例1：在下一季度，我希望团队的所有成员都能够处理GKE/GAE部署，熟悉生产环境，并能够处理生产故障。&lt;br /&gt;
   示例2：在下一季度，我希望SRE与开发团队合作，在扩展和监控方面保证应用稳定性，针对故障有运行手册和自动化任务。&lt;/li&gt;
    &lt;li&gt;确定并明确标出最终结果成功案例。&lt;br /&gt;
   示例：参与后，产品开发团队可以在不升级的情况下处理Google Kubernetes Engine的服务故障。&lt;/li&gt;
  &lt;/ol&gt;

  &lt;h4 id=&quot;冲刺和沟通&quot;&gt;冲刺和沟通&lt;/h4&gt;

  &lt;p&gt;任何与产品开发团队的合作都始于发布和计划会议。在发布之前，我们的SRE团队会审核应用架构和我们的共同目标，验证在给定时间范围内预期结果是否切合实际。相互参与可以从创建描述和综述的联合计划会议开始。&lt;/p&gt;

  &lt;p&gt;这种参与的流程可能是：&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;查看应用架构。&lt;/li&gt;
    &lt;li&gt;定义共享目标。&lt;/li&gt;
    &lt;li&gt;举行启动和计划会议。&lt;/li&gt;
    &lt;li&gt;进入开发周期以达到里程碑。&lt;/li&gt;
    &lt;li&gt;进行回顾来获得参与方的反馈。&lt;/li&gt;
    &lt;li&gt;进行生产就绪程度评审。&lt;/li&gt;
    &lt;li&gt;进入开发周期以达到里程碑。&lt;/li&gt;
    &lt;li&gt;计划、执行发布。&lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;我们要求团队定义反馈方法并就反馈频率达成一致。SRE和开发团队都需要有关工作和非工作的反馈。为了让这一举措获得成功，我们发现通过协商提供持续的循环反馈是有效的——例如，每两周一次进行审查或与团队经理确认。如果相互参与不起作用，我们也不希望团队回避并减少接触。&lt;/p&gt;

  &lt;h4 id=&quot;衡量影响力&quot;&gt;衡量影响力&lt;/h4&gt;

  &lt;p&gt;为了确保SRE从事高价值的工作，对SRE参与工作的影响力进行衡量十分重要。为了方便SRE确定最有效的方法，我们还衡量每个合作团队的成熟度级别。我们与Google客户可靠性团队（CRE）团队合作，并在开始参与之前与产品工程团队的负责人进行时间点评估。&lt;/p&gt;

  &lt;p&gt;时间点评估包括遍历成熟度矩阵，衡量服务的成熟度，依据SRE关注的各个方面开展（如《Google SRE运维解密》第32章所述），并就功能区域的各个方面达成一致，如可观察性、容量规划、变更管理和事件响应处理。在进一步了解团队的优劣和盲点之后，有助于更好的确定SRE参与度。&lt;/p&gt;

  &lt;p&gt;在SRE完成工作且开发团队可以自行发布之后，我们会再次评估衡量SRE参与的价值。如果我们有一个成熟度模型，我们会根据模型进行衡量，看看参与度是否会带来更高的成熟度。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;设定基本规则&quot;&gt;设定基本规则&lt;/h3&gt;

&lt;p&gt;在Google，每个SRE团队都有两个主要目标：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;短期&lt;/code&gt;&lt;br /&gt;
   通过提供可用、可按需扩展、操作稳定的系统来满足产品的业务需求，立足于系统的可维护性。
&lt;code class=&quot;highlighter-rouge&quot;&gt;长期&lt;/code&gt;&lt;br /&gt;
   将服务的运维操作优化到不需要持续人工投入的水平，这样SRE团队可以继续开展下一个高价值的工作。&lt;/p&gt;

&lt;p&gt;为此，各小组就某些合作原则达成一致，例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;业务工作的定义（和硬性限制）。&lt;/li&gt;
  &lt;li&gt;通过商定和衡量服务SLO来明确开发人员和SRE团队工程工作的优先级。你可以在没有SLO的情况下工作，但我们的经验，项目开始时还未确定SLO及工作优先级意味着在后面的工作中将回溯到此步骤。有关如何在没有SLO的情况下理想地进行工程工作，请参阅第427页的“案例研究1：将Waze从AdHoc扩展到计划变更”。&lt;/li&gt;
  &lt;li&gt;商定季度错误预算，确定发布速度和其他安全系数，例如处理意外使用增长的超额服务容量。&lt;/li&gt;
  &lt;li&gt;为确保持续存在的问题得到关注并确定修复根本原因的优先级，开发人员需要参与日常运维中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;计划与执行&quot;&gt;计划与执行&lt;/h3&gt;

&lt;p&gt;为确保SRE团队在优化和降低运维成本的同时达到预期和产品目标，需要主动规划和协调执行。我们建议在两个（相邻）阶段进行规划：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在开发人员的领导下，确定产品和服务的优先级，并发布年度企划图。&lt;/li&gt;
  &lt;li&gt;定期审查和更新路线图，并得出与路线图一致的目标（季度或其他）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;路线图确保每个团队拥有清晰、高效工作的长期时间线。可能会有充分的理由（例如，开发组织变化太快）来放弃路线图。但在稳定的环境下，缺乏路线图可能是SRE团队与其他团队合并，将服务管理工作移交回开发团队，甚至是解散的信号。&lt;/p&gt;

&lt;p&gt;与开发领导层保持持续的战略对话有助于快速确定工作重点，讨论SRE为业务增加价值的新机会，或停止对产品而言没有成本效益的工作。&lt;/p&gt;

&lt;p&gt;路线图可以专注于改进产品，还可以解决如何应用和改进常见的SRE技术和流程以降低运维成本。&lt;/p&gt;

&lt;h2 id=&quot;保持持续有效的关系&quot;&gt;保持持续有效的关系&lt;/h2&gt;
&lt;p&gt;健康有效的关系需要不断的努力，本节简述了对我们而言效果非常好的策略。&lt;/p&gt;

&lt;h3 id=&quot;投入时间共同努力&quot;&gt;投入时间共同努力&lt;/h3&gt;
&lt;p&gt;投入时间相互协作这种简单的行为有助于SRE和开发人员更有效的协作。我们建议SRE定期与开发人员当面沟通确保其运维的服务稳定性。SRE还可以定期与其他SRE团队沟通，这些团队运维的服务可以向本团队负责的服务提供流量或提供服务使用的通用基础架构。因为团队已经彼此了解并且设定了如何启动和管理升级的期望目标，这样，在故障或意见分歧期间，SRE团队可以自信且迅速的升级事件。&lt;/p&gt;

&lt;h3 id=&quot;保持开放的沟通渠道&quot;&gt;保持开放的沟通渠道&lt;/h3&gt;
&lt;p&gt;除了之前提到的团队日常沟通之外，我们还发现了一些更加正式的信息交换方法，这些方法在参与过程中十分有效。&lt;/p&gt;

&lt;p&gt;SRE可以与产品领导进行季度“生产状态”谈话，帮助他们了解应该在何处投入资源以及SRE如何帮助他的产品或服务。类似的，开发人员可以定期向SRE团队提供“产品状态”，或者让SRE参与开发团队的执行演示。向SRE团队概述了开发团队在上季度所取得的成就（并让SRE了解他们自己的工作要如何实现）。还提供了产品未来几个季度的最新信息，以及让产品负责人了解SRE在哪些方面发挥了作用。&lt;/p&gt;

&lt;h3 id=&quot;定期执行服务评估&quot;&gt;定期执行服务评估&lt;/h3&gt;

&lt;p&gt;作为服务的未来决策者，SRE和负责该服务的开发团队每年至少应该见面一次。也许很难更频繁的开会-例如，可能涉及洲际旅行。在会议期间，我们通常会分享未来12-18个月的路线图，并讨论新项目和发布会。
SRE团队有时会进行回顾讨论团队想要停止做什么，继续做什么以及开始做什么。项目可以出现在多个区域且这些意见都是有效的。最好的结果通常是全团队都参与的，所以需要积极促进这些会议。这些会议产生的细节可以推动重大的服务变更，因而被评为服务会议中最有用的会议。&lt;/p&gt;

&lt;h3 id=&quot;当规则开始变化时要重新评估&quot;&gt;当规则开始变化时要重新评估&lt;/h3&gt;

&lt;p&gt;如果之前协商的部分（参见379页的“设置基本规则”）开始回滚，开发人员和SRE都需要更改优先级以使服务恢复正常。我们发现，根据紧急程度，意味着可能发生以下任何一种情况：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;团队指定的工程师必须放弃低优先级任务，专注于回滚。&lt;/li&gt;
  &lt;li&gt;两个团队都号称“可靠性黑客马拉松”，但通常团队的优先级是在黑客马拉松之上的。&lt;/li&gt;
  &lt;li&gt;停止功能开发，两个团队的多数成员都专注于解决回滚问题。&lt;/li&gt;
  &lt;li&gt;技术领导层确定产品的可靠性存在严重风险，团队要“全力以赴”的响应。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;根据你的slo和错误预算调整优先级&quot;&gt;根据你的SLO和错误预算调整优先级&lt;/h3&gt;

&lt;p&gt;指定明确的SLO有助于团队安排工作优先级。如果服务存在丢失SLO或存在用完错误预算的风险，那么两个团队的高优先级工作应该是使服务恢复安全。他们可以通过战术措施（例如，超额配置以解决与流量相关的性能回滚）和更具战略性的软件修复（例如优化，缓存和优雅降级）来降级此类情况。
如果服务在SLO内且剩余错误预算充足，我们建议使用备用错误预算来提高功能迭代速度，而不是在服务改进上花费过多的精力。&lt;/p&gt;

&lt;h3 id=&quot;妥善处理错误&quot;&gt;妥善处理错误&lt;/h3&gt;
&lt;p&gt;人总会犯错。和我们的事后文化一致，我们不会责怪某个人，而是专注于系统行为。你的情况可能和我们不一样，但以下策略也可以作为参考。&lt;/p&gt;

&lt;h4 id=&quot;三思而后行&quot;&gt;三思而后行&lt;/h4&gt;
&lt;p&gt;如果可能，请勿在疲惫或情绪高涨时进行后续对话。在高压力时，人们很容易误解书面交流如电子邮件中的语气。读者会记住这些词语让他们产生何种感受的，当你在异地进行通信时，通常应该进行视频聊天，这样你可以看面部表情，听到的词语语调也可以帮忙消除原本可能产生的歧义。&lt;/p&gt;

&lt;h4 id=&quot;当面或尽可能近的解决问题&quot;&gt;当面（或尽可能近的）解决问题&lt;/h4&gt;
&lt;p&gt;仅通过代码审查或文档交互很难让人集中注意力。当另一个团队的行为或决定与我们预期的不一致时，我们会和他们讨论并询问为何没有达到预期。&lt;/p&gt;

&lt;h4 id=&quot;要乐观&quot;&gt;要乐观&lt;/h4&gt;
&lt;p&gt;要感谢别人积极主动的行为。做起来可能很简单-例如，在代码审查，设计审查和故障场景培训期间，我们要求工程师介绍出彩的内容。你可能注意到优秀的代码注释或感谢人们愿意花时间投入设计审核。&lt;/p&gt;

&lt;h4 id=&quot;了解沟通的差异&quot;&gt;了解沟通的差异&lt;/h4&gt;
&lt;p&gt;不同的团队对如何传播信息有不同的预期，了解这些差异有助于加强团队的关系。&lt;/p&gt;

&lt;h2 id=&quot;将sre扩展到更大的环境&quot;&gt;将SRE扩展到更大的环境&lt;/h2&gt;
&lt;p&gt;目前为止，我们讨论的场景涉及一个SRE团队，一个开发团队和一个服务。较大的公司，甚至是使用微服务模型的小公司，可能需要扩展部分或全部团队规模。&lt;/p&gt;

&lt;h3 id=&quot;单个sre团队支持多项服务&quot;&gt;单个SRE团队支持多项服务&lt;/h3&gt;
&lt;p&gt;由于SRE需要专业技能并且是稀缺资源，因此Google通常将SRE与开发人员的比率保持在&amp;lt;10%。因此，一个SRE团队通常与其产品领域（PA）中的多个开发团队合作。&lt;/p&gt;

&lt;p&gt;如果SRE的数量不足以支持需要面对的服务数，是，那么SRE团队可以将精力集中到一项服务，或者集中在开发人员较少的一些服务上。&lt;/p&gt;

&lt;p&gt;根据我们的经验，如果这些服务具有以下特征，你可以将有限的SRE资源应用到多个服务中：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;服务是单一产品的一部分。提供了用户体验的端到端所有权以及与用户的一致性。&lt;/li&gt;
  &lt;li&gt;服务建立在相似的技术栈上。可以最大限度的减少认知负担，有效的重用技术技能。&lt;/li&gt;
  &lt;li&gt;服务由同一开发团队或少数相关开发团队构建。这样可以最大限度的减少关联数量，便于商定优先级。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;构建多个sre团队环境&quot;&gt;构建多个SRE团队环境&lt;/h3&gt;
&lt;p&gt;如果你的公司足够大，拥有多个SRE团队，或许还有多个产品，那么你需要选择SRE和产品组相关联的合适的架构。&lt;/p&gt;

&lt;p&gt;在Google，我们支持复杂的开发人员组织。如图18-2所示，每个PA由多个产品组组成，每个产品组包含多个产品。SRE组织以层次结构的方式影响开发人员组织，每个级别都有共享的优先级和最佳实践。当一个组中的所有团队或PA中的所有组都共享相同或相似的特定业务目标，且每个产品组都有产品领导和SRE领导时，这个模型都是有效的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/18-2.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图18-2. 大规模的开发者与SRE团队关系图（每个产品领域） &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;如果你的组织有多个SRE团队，你需要以某种方式对其进行分组。我们发现有两种主要的分组方式：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将团队分组到产品中，这样他们就不必与太多不同的开发团队协调。&lt;/li&gt;
  &lt;li&gt;将团队分组到技术栈中（例如，“存储”或“网络”）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了防止在开发人员重新开发的期间SRE团队的流失，我们建议根据技术而不是开发人员PA报告架构来组织SRE团队。例如，许多支持存储系统的团队都以相同的方式构建和运行。即使是来自开发组织的不同部分，将技术型产品组中的存储系统分组可能会更有意义。&lt;/p&gt;

&lt;h3 id=&quot;使sre团队结构适应不断变化的环境&quot;&gt;使SRE团队结构适应不断变化的环境&lt;/h3&gt;
&lt;p&gt;如果你需要调整SRE团队的结构来响应不断变化的PA需求，那么我们建议你根据服务需求以及工程和运维负载来创建，拆分（切分），合并和解散SRE团队。每个SRE团队都应该有一个清晰的章程来反映他们的服务，技术和运维。当一个SRE团队拥有太多服务时，我们宁愿将现有团队分成多个团队来传递企业文化并发展现有领导层，而不是从头开始建立新的团队。类似这种的变化不可避免会对现有团队造成破坏，因此我们建议你仅在必要时对团队进行重组。&lt;/p&gt;

&lt;h3 id=&quot;运行有凝聚力的分布式sre团队&quot;&gt;运行有凝聚力的分布式SRE团队&lt;/h3&gt;
&lt;p&gt;如果你需要确保全天候保持业务连续性，并且拥有全球性的服务，那么可以通过在全球范围内建立你的SRE团队来提供均匀覆盖。如果你拥有多个全球分布的团队，我们建议根据邻接以及服务和共享技术的相似性来协调团队。独立的团队通常效率较低，且容易受到团队外部重组的影响-我们只有在业务明确需要他们并且考虑了其他所有选项后才会建立这样的团队。&lt;/p&gt;

&lt;p&gt;许多公司没有足够的全球覆盖资源，但即使你只是在建筑物之间分布（不考虑洲际），创建和维护两个地方的团队也是有必要的。&lt;/p&gt;

&lt;p&gt;通过创建、维护组织标准来推动规划和执行以及培养和维护共享的团队文化十分重要。为此，可以定期让整个团队聚在一起-例如，每12-18个月举办一次全员参与的峰会。&lt;/p&gt;

&lt;p&gt;有时，对团队的个人而言，拥有某些特定职责是没有意义的-例如，从备份中执行定期测试还原或实施跨公司技术任务。在团队分布式站点间平衡这些责任时，请记住以下策略：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将个人职责分配给单个站点，但要定期轮换（例如，每年）。&lt;/li&gt;
  &lt;li&gt;分担各站点之间的责任，积极努力的平衡参与度和工作量。&lt;/li&gt;
  &lt;li&gt;不要常年将责任锁定在某个站点。我们发现这种配置的成本最终会超过收益。虽然这个站点可以很好的履行职责，但会培养“我们与他们”的心态，有碍知识的分享，并给业务带来连续性的风险。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所有这些策略都需要站点之间维持战术和策略沟通。&lt;/p&gt;

&lt;h2 id=&quot;关系结束&quot;&gt;关系结束&lt;/h2&gt;
&lt;p&gt;SRE参与不一定是无限期的。SRE通过有影响力的工程工作提供价值，如果工作不再具有影响力（即，SRE参与的价值消失），或者大部分工作不再在工程（或运维）层面，你可能需要重新审视当前参与的SRE。一般而言，独立的SRE团队倾向从过度辛劳的团队转变成更有趣的工程工作团队。&lt;/p&gt;

&lt;p&gt;在团队级别，如果SRE不再提供足够的业务价值来抵偿成本的话，你可能会归还服务。例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果服务已经优化到不再需要SRE持续参与的水平&lt;/li&gt;
  &lt;li&gt;服务的重要性或相关性已经降低&lt;/li&gt;
  &lt;li&gt;如果服务已达到使用寿命&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下案例研究展示了两个Google SRE参与模式的结束方式。第一个结果基本上是积极的结果，而另一个的结果则比较微妙。&lt;/p&gt;

&lt;h3 id=&quot;案例研究1ares&quot;&gt;案例研究1：Ares&lt;/h3&gt;

&lt;p&gt;Google的Abuse SRE和CommonAbuse Tool（CAT）团队为大多数Google产品提供了反滥用保护，并与面向客户的产品合作以确保用户安全。Abuse SRE团队应用工程工作来降低CAT的运维负担，以便开发人员能够直接支持其用户。这些用户是Google运维CAT所捍卫的资源，他们对CAT的功效及其对问题或新威胁的响应时间有着很高的预期。&lt;/p&gt;

&lt;p&gt;有效的反滥用战斗需要保持持续的关注，能快速的适应变化，面对新的威胁和攻击时具有灵活性。通常SRE的目标是可靠性和有计划的功能开发，这些要求是与之冲突的。CAT团队通常需要快速开发并为受到攻击的资源部署新的保护措施。但是，Abuse SRE推迟了所要求的的变更，针对每个变更都要求对整个生产系统的影响进行更深入的分析。团队和审查之间协商的时间限制加剧了这种紧张局势。&lt;/p&gt;

&lt;p&gt;为了改善这种状况，Abuse SRE和CAT领导层开展了一个持续全年度的项目，在CAT内部建立了一个专门的基础设施团队。新成立的“Ares”团队有权统一Google资源的反滥用基础设施。该团队由CAT工程师组成，他们拥有生产基础知识和构建运行大型服务的经验。团队启动了一项交换计划，将生产管理知识从Abuse SRE转移到CAT基础设施团队成员。&lt;/p&gt;

&lt;p&gt;Abuse SRE团队告诉Ares团队，在生产中启动新服务最简单的方法（当你已经运行大型分布式服务时）是最小化服务所带来的额外认知负荷。为减少这种认知负荷，系统应尽可能是同构的。一起部署和管理生产服务集合意味着可以共享相同的发布结构，容量规划，访问存储的子服务等。根据这一建议，Ares重新设计了整个反滥用堆栈，应用模块化概念转向了微服务模型。他们还构建了一个新层，为开发人员提供抽象化，这样就不必担心监控，日志记录和存储等较低级别的生产细节。&lt;/p&gt;

&lt;p&gt;现在，Ares团队开始管理新的反滥用基础设施，看上去更像是CAT的SRE团队。同时，Abuse SRE专注于整个反滥用基础设施的生产部署和高效的日常运维。
Ares工程师和AbuseSRE之间的协作带来了以下改进：&lt;/p&gt;

&lt;p&gt;现在，Ares团队开始管理新的防滥用基础设施，看上去更像是CAT的SRE团队。同时，Abuse SRE专注于整个防滥用基础设施的生产部署和高效的日常运维。
Ares工程师和Abuse SRE之间的协作带来了以下改进：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;由于CAT团队现在拥有“内部”生产专家，他们本身也是反滥用战斗的专家，Abuse SRE不再需要审查新的功能变更。大大缩短了新功能的开发时间。与此同时，由于新的基础设施抽象了生产管理细节，CAT团队的开发人员的开发速度也有了提高。&lt;/li&gt;
  &lt;li&gt;由于大多数请求不需要更改基础架构，因此Abuse SRE团队对CAT团队提出的新需求也少了很多。又因为基础设施很少需要更改，该团队对新功能影响的评估也比之前简单。当需要更改基础架构时，Abuse SRE只需要清楚对基础架构的影响，而不用了解具体的功能。&lt;/li&gt;
  &lt;li&gt;由于现在产品集成相当于功能发布，所以需要与反滥用基础架构集成的产品有更快更加可预测的转变时间。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在该项目结束时，Abuse SRE不再直接支持CAT，而是专注于底层基础设施。这并没有影响CAT的可靠性，也没有使CAT团队承担额外的运维工作；相反，这加快了CAT的整体发展速度。&lt;/p&gt;

&lt;p&gt;目前，Ares通过大量Google资源来保护用户。自团队成立以来，SRE和产品开发合作一起就基础设施如何在生产中发挥作用进行决策。正是由于Ares的努力才使得这样的伙伴关系成为可能，Ares创造了一种共同的使命感。&lt;/p&gt;

&lt;h3 id=&quot;案例研究2数据分析通道&quot;&gt;案例研究2：数据分析通道&lt;/h3&gt;

&lt;p&gt;有时维持SRE运维关系的成本高于SRE提供的价值。这种情况下，通过解散SRE团队来结束这种关系是可行的 。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;注1：Google HR在这类转换中为员工提供新机会&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;随着时间的推移这种关系的价值在减小，但很难确定终止合作的时间点。Google的两个支持重点收入数据分析通道的团队就面临这一挑战。在经过十年的合作之后，确定分离的方法是十分重要的。回想起来，我们能够确定团队互动的几种模式，这些模式是我们需要重新考虑SRE团队和产品团队间关系的重要指标。&lt;/p&gt;

&lt;h4 id=&quot;数据挖掘&quot;&gt;数据挖掘&lt;/h4&gt;

&lt;p&gt;在衰退的前三年，所有相关方都认识到他们的主要数据分析通道正在遇到扩展的限制。当时，开发团队决定规划新系统，并让少数工程师专门投入此项工作。随着此项工作的融合合并，有必要为现有系统开发大型，复杂或有风险的特性来支持新系统的工作。随着时间的推移，产生了两个重要的影响：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对新项目采用了非正式规则：如果项目的复杂度或修改现有系统以适应项目涉及到的风险太高，那么最好在新系统中进行规划。&lt;/li&gt;
  &lt;li&gt;随着资源转向开发新系统，即使对现有系统进行相对保守的变更也变得十分困难。但此时对现有系统的使用量仍在快速增加。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;沟通失败&quot;&gt;沟通失败&lt;/h4&gt;

&lt;p&gt;在保持现有系统正常运行的同时设计，构建，启动替换系统对任何工程团队而言都是一项挑战。压力自然的落在同时关注着新、旧系统的人，以及需要做出优先级决策的团队身上。当团队在组织结构上是分离的，这些困难可能更加复杂-例如，一个专注于维护和运维现有系统的SRE团队和一个致力于下一代系统的开发团队。&lt;/p&gt;

&lt;p&gt;在整个周期中，为了维护和保持团队间良好的工作关系，定期，开放和合作的沟通十分重要。在这个例子中，沟通不畅导致了团队间工作关系的不和谐。&lt;/p&gt;

&lt;h4 id=&quot;解散&quot;&gt;解散&lt;/h4&gt;

&lt;p&gt;花费了一段时间才意识到SRE和开发团队完全脱节是不可取的。最终，最简单的解决方案是消除组织障碍，让开发团队完全把控新旧系统的优先级工作。在旧系统完全淘汰之前，预计两个系统将同时存在18-24个月。&lt;/p&gt;

&lt;p&gt;将SRE和产品开发功能整合到一个团队中可以使高层管理人员最大限度的响应他们的问责领域。同时，团队可以决定如何平衡运维需求和速度。虽然解散两个SRE团队并不是件愉快的事，但这样做解决了在何处投入精力的问题。&lt;/p&gt;

&lt;p&gt;尽管开发团队不可避免会有额外的运维负担，但是重新调整旧系统的所有权给对服务更了解的人员有助于更快的解决运维问题。该团队可以更深入的了解故障的潜在原因，能更高效的排查故障和解决问题。但是，开发团队在短期内接手所支持服务的运维工作时，不可避免会产生一些负面影响。SRE团队的最后工作是尽可能的分享运维知识，帮助开发团队顺利承担这项工作。&lt;/p&gt;

&lt;p&gt;如果工作关系更健康-团队合作可以有效的解决问题-SRE能在短期内将生产工作交付给开发团队。在系统重新稳定并强健能够满足预期的增长需求后，SRE通常会重新承担系统运维的责任。SRE和开发团队要主动直接解决问题并找出需要重置的工作内容。SRE的一部分工作是在面对不断变化的业务需求时帮助开发进行优化开发，寻找解决挑战性问题的解决方案。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;SRE团队参与的模式会改变服务生命周期的各个阶段。本章对每个阶段都提供了具体建议。Google和纽约时报SRE团队的例子表明，有效管理参与度和指定出色的技术设计决策同样重要。有时SRE的参与应该达到一个自然的终止点。Ares和数据分析通道团队的案例研究提供了如何实现这点的示例，以及如何很好的结束参与关系。&lt;/p&gt;

&lt;p&gt;在谈及SRE和产品开发团队之间建立有效关系的最佳实践时，关键在于定期和开放式沟通共享目标和方向。你可以通过多种方式扩展SRE团队，但这些关系管理原则应该始终如一。为了保持SRE参与的长期成功，协调团队目标，理解彼此的目标与捍卫SLO同样重要。&lt;/p&gt;</content><author><name>ZX</name></author><category term="《SRE-Google运维实践》" /><summary type="html">我们的第一本书的第32章，描述了SRE团队分析和提高服务可靠性的技术和方法。其中包括：生产成熟度评审（PRR）、早期参与和持续改进。 简而言之，SRE的目标是在保证产品可靠性的前提下，最大限度的提高开发团队的项目进度。这对用户和公司而言都是有益的。但是，即使最好的SRE团队所能完成的工作也是有限的，并且当范围太大且过于复杂时，SRE模型就不那么的有效了。当前，小公司拥有微服务的个数通常比单个SRE团队能处理的要多。鉴于生产环境较大，并且无法涵盖所有服务，SRE团队必须将注意力集中在能够获得最佳效果的地方。产品开发和SRE团队可以一起确定正确的关注目标。 本章采用某SRE团队的视角，该团队准备为新服务提供支持。我们着眼于如何与负责该服务的开发和产品团队一起有效地提供服务。虽然SRE通常“参与”一个或多个服务，但“参与”所涉及的内容远不止服务本身——它侧重于理解开发和产品团队的目标，并找到支持他们的正确方法。 以下的大多数讨论适用各种组织规模。虽然我们经常使用团队这个词，但理论上“团队”也可以从单人开始（尽管会很忙）。无论团队规模如何，主动定义SRE的角色以及管理与产品开发的沟通和协作十分重要。 服务生命周期 正如《Google SRE运维解密》的前言所述，SRE团队对服务可靠性的贡献贯穿于服务生命周期的所有阶段。在任何SRE为服务提供on-call之前，他们对于生产知识和经验的应用，都可以大大提高服务的可靠性。 图18-1显示了服务生命周期中SRE参与的理想情况。但是，SRE团队可能在服务生命周期的任何阶段参与服务。例如，如果开发团队计划将SRE所支持的服务进行替换，则SRE可能很早就会参与新服务。又或者，服务可用数月或数年，且现在面临可靠性或可伸缩性的挑战时，SRE团队可能会正式参与该服务。本节提供有关SRE团队如何在每个阶段实现自身价值的方针。 图18-1: 服务生命周期中SRE的参与程度 阶段1：架构和设计 SRE可以以多种方式影响软件系统的体系结构和设计： 提供开发团队在构建新产品时可以采用的最佳实践，例如单点故障自我恢复的能力。 (基于经验）记录特定基础设施系统的注意事项，以便开发人员可以正确的选择并使用构建模块，避免已知陷阱。 参与前期讨论，详细讨论具体架构和设计选择，并在目标原型的帮助下验证假设。 加入开发团队参与开发工作。 协调部分服务。 到了开发周期的后期，是很难修复由架构选型导致的错误的。SRE在早期参与有助于避免在系统与实际用户交互时需要进行高成本的重新设计，或根据服务增长进行扩展。 阶段2：积极发展 随着产品在积极开发过程中完成，SRE便可以开始“生产化”服务——使其成型并投入生产。生产化通常包括容量规划，为冗余设置额外资源，规划尖峰和过载处理，实施负载均衡，以及实施可持续运维实践，如监控，报警和性能调优。 阶段3：有限的可用性 随着服务向Beta发展，用户数量，用例的多样性，使用强度以及可用性和性能需求都会增加。在此阶段，SRE可以帮助衡量和评估可靠性。我们建议在常见可用性（GA）之前先定义SLO，以便服务团队客观的衡量服务的可靠性。产品团队可以选择撤回无法达到目标可靠性的产品。 在此阶段，SRE团队还可以通过构建容量模型，为即将到来的启动阶段获取资源以及自动化调整和弹性调整扩展系统。SRE需要确保合适的监控范围，帮助即将到来的的服务创建与其SLO相匹配的报警配置。 服务使用情况一直在变化，且SRE团队仍需要了解服务如何工作以及如何管理其故障模式，所以团队在事件响应和运维操作期间的工作量仍是增加的。我们建议开发人员和SRE团队能共同承担此项工作。这样，开发团队就可以获得服务的运维操作经验，且SRE可以获得常见的服务经验。运维工作和事件管理将在GA之前告知系统变更并发布服务所有者需要进行的变更。 第4阶段：一般可用性 在此阶段，该服务已通过生产准备审核（详细信息请参阅《Google SRE运维解密》中的第32章），并被所有用户接受。虽然SRE通常执行大部分的操作工作，但为了保险起见，开发人员团队需要继续完成所有操作和事件响应工作的小部分内容。可以在on-call轮值中安排一名开发人员，帮助开发人员持续跟踪业务负载。 在GA的早期阶段，由于开发人员专注于服务的成熟以及发布第一批新功能，因此需要进行轮值来了解实际负载下的系统属性。在GA的后期阶段，开发人员主要提供小的新增功能以及一些bug修复，其中的一些功能和bug恢复需求来源于操作需求和已发生的生产事件。 第5阶段：弃用 没有系统能一直运行。如果有更好的替代系统，那么现有系统将对新用户关闭，所有工作都侧重于将用户从现有系统转换到新系统中。在没有开发团队参与的情况下，SRE将运维现有系统，并支持开发和运维工作的过渡。 虽然减少了现有系统所需的SRE工作量，但SRE实际上是同时支持两个完整系统，所以需要适当调整人员以及人员配置。 第6阶段：被遗弃 一旦服务被遗弃，通常，开发团队将接手运维工作。在此过程中，SRE会尽力提供支持。对于具有内部用户的服务，SRE将服务管理权限移交给这些用户。本章提供了两个案例研究，说明SRE如何将服务归还给开发团队。 第7阶段：停止支持 没有用户且服务已关闭时。SRE会帮助删除生产配置和文档中引用服务的部分。 建立联系 服务不是凭空存在的：需要SRE团队与构建服务的开发团队以及确定发展方向的产品团队合作。本节介绍了与这些团队建立和维持良好工作关系的方法和策略。 交流业务和生产优先事项 你在帮助别人之前肯定需要了解其需求。同理，SRE也需要了解产品开发人员期望SRE参与实现的目标。在与开发团队合作时，SRE应深入了解产品和业务目标，了解自身角色以及如何参与帮助开发人员实现这些目标。 团队需要定期就业务和生产优先事项进行沟通。理想情况下，SRE和开发领导团队应该作为一个整体进行工作，定期开会交流技术和优先级问题。SRE领导甚至可以加入产品开发领导团队。 识别风险 由于SRE团队专注于系统可靠性，能很好的识别潜在风险。由于中断开发的成本和功能流对产品和工程师很重要，因此要尽可能准确的衡量这些风险的可能性和潜在影响。 目标一致 开发人员和SRE团队都很关注可靠性、可用性、性能、可扩展性、效率、功能和发布速度。然而，SRE的主要目标和动力是为了支持服务在新功能发布后的长期可靠性。 根据我们的经验，开发人员和SRE团队既可以通过维护自身团队的目标来达到平衡，也可以通过支持对方团队的目标实现平衡。SRE可以设立明确的目标来支持开发团队的发布上线，并确保所有已审批通过的版本上线成功。例如，SRE可能会表明：“我们将尽可能快的支持你安全发布上线”，其中“安全”通常意味着保持在错误预算范围内。开发人员应该投入一定的时间去修复或预防一些有损可靠性的事情上：解决设计和实施层面的在线服务问题，解决遗留技术问题，尽早在新功能开发时让SRE参与设计。 共同目标：纽约时报的SRE 作者：Surya Prashanth Sanagavarapu (New York Times) 当涉及到云迁移，生产过渡期或向容器部署应用时，我们对SRE资源的需求会很大。此外，SRE团队还有自身积压的工作要解决。面对有限的资源，SRE团队的成功在于合理的安排互不兼容的事务的优先级。虽然雇佣SRE是解决SRE时间需求的一种方式，但并非每个团队都有额外的成本、足够的经验或时间。 “纽约时报”SRE职能的核心使命是为产品开发团队提供工具和流程,最大程度的支持新闻编辑室的应用的可靠性和弹性，从而为读者提供高质量的新闻报道。我们采用了共享目标模型，在减少自身工作积压和团队合作之间获取平衡。 在与团队合作之前，我们会审核当前季度/年度的总体积压，明确定义工作项目和类别。例如，我们的待办事项可能包括： 通过点击应用的服务状态按钮，添加自动化设置基础监控和报警。 实施更可靠和/或更快的构建管道。 当有团队向SRE寻求帮助时，我们确定请求优先级时考虑的因素之一是参与进去是否有助于减少我们的工作积压。 定义参与度 我们的SRE根据两种不同的模型与产品开发团队合作： 全职模型 相对简短和受限制项目的兼职模型 我们根据SRE团队的参与度定义参与模型。对于全职参与，我们更愿意将SRE嵌入产品开发团队，这样有助于提供时间和精力来减轻产品开发团队的负担。随着开发人员SRE技能和能力提高的同时，SRE和产品团队有更多的时间来了解彼此。对于长期合作，我们优先考虑最适合我们公司战略的应用 在定义参与范围时，我们尝试衡量团队或应用与SRE实践相关的成熟度。我们发现，在考虑SRE实践和原则时，每个团队处于不同的水平。我们正努力使用应用成熟度模型来提供帮助。 设定共同的目标和期望 对于任务的最后期限和完成度而言设定正确的目标十分重要。为此，我们按照以下原则工作： 我们强调，应用所有者（非SRE）直接负责对应用进行更改。 SRE参与是为了公司范围的利益。任何新的自动化或工具都应该同时改进整个公司使用的常用工具和自动化，避免一次性的脚本开发。 SRE应该让开发人员团队提前了解可能会引入的新流程（例如，负载测试）。 参与应用准备评审（ARR）和生产就绪程度评审（PRR），如《Google SRE运维解密》第32章所述。ARR和PRR的拟议变更必须优先由开发人员和SRE共同考虑。 SRE不是传统的运维工程师。他们不支持手动工作，例如运行部署作业。 我们会与开发团队一起明确目标，并将目标划分为一个个里程碑。如果你是一家基于敏捷开发的公司，你可以撰写描述或综述。SRE团队可以将这些目标映射到他们的待办事项中。 设定目标时我们的共同模式是： 确定参与范围。 示例1：在下一季度，我希望团队的所有成员都能够处理GKE/GAE部署，熟悉生产环境，并能够处理生产故障。 示例2：在下一季度，我希望SRE与开发团队合作，在扩展和监控方面保证应用稳定性，针对故障有运行手册和自动化任务。 确定并明确标出最终结果成功案例。 示例：参与后，产品开发团队可以在不升级的情况下处理Google Kubernetes Engine的服务故障。 冲刺和沟通 任何与产品开发团队的合作都始于发布和计划会议。在发布之前，我们的SRE团队会审核应用架构和我们的共同目标，验证在给定时间范围内预期结果是否切合实际。相互参与可以从创建描述和综述的联合计划会议开始。 这种参与的流程可能是： 查看应用架构。 定义共享目标。 举行启动和计划会议。 进入开发周期以达到里程碑。 进行回顾来获得参与方的反馈。 进行生产就绪程度评审。 进入开发周期以达到里程碑。 计划、执行发布。 我们要求团队定义反馈方法并就反馈频率达成一致。SRE和开发团队都需要有关工作和非工作的反馈。为了让这一举措获得成功，我们发现通过协商提供持续的循环反馈是有效的——例如，每两周一次进行审查或与团队经理确认。如果相互参与不起作用，我们也不希望团队回避并减少接触。 衡量影响力 为了确保SRE从事高价值的工作，对SRE参与工作的影响力进行衡量十分重要。为了方便SRE确定最有效的方法，我们还衡量每个合作团队的成熟度级别。我们与Google客户可靠性团队（CRE）团队合作，并在开始参与之前与产品工程团队的负责人进行时间点评估。 时间点评估包括遍历成熟度矩阵，衡量服务的成熟度，依据SRE关注的各个方面开展（如《Google SRE运维解密》第32章所述），并就功能区域的各个方面达成一致，如可观察性、容量规划、变更管理和事件响应处理。在进一步了解团队的优劣和盲点之后，有助于更好的确定SRE参与度。 在SRE完成工作且开发团队可以自行发布之后，我们会再次评估衡量SRE参与的价值。如果我们有一个成熟度模型，我们会根据模型进行衡量，看看参与度是否会带来更高的成熟度。 设定基本规则 在Google，每个SRE团队都有两个主要目标： 短期 通过提供可用、可按需扩展、操作稳定的系统来满足产品的业务需求，立足于系统的可维护性。 长期 将服务的运维操作优化到不需要持续人工投入的水平，这样SRE团队可以继续开展下一个高价值的工作。 为此，各小组就某些合作原则达成一致，例如： 业务工作的定义（和硬性限制）。 通过商定和衡量服务SLO来明确开发人员和SRE团队工程工作的优先级。你可以在没有SLO的情况下工作，但我们的经验，项目开始时还未确定SLO及工作优先级意味着在后面的工作中将回溯到此步骤。有关如何在没有SLO的情况下理想地进行工程工作，请参阅第427页的“案例研究1：将Waze从AdHoc扩展到计划变更”。 商定季度错误预算，确定发布速度和其他安全系数，例如处理意外使用增长的超额服务容量。 为确保持续存在的问题得到关注并确定修复根本原因的优先级，开发人员需要参与日常运维中。 计划与执行 为确保SRE团队在优化和降低运维成本的同时达到预期和产品目标，需要主动规划和协调执行。我们建议在两个（相邻）阶段进行规划： 在开发人员的领导下，确定产品和服务的优先级，并发布年度企划图。 定期审查和更新路线图，并得出与路线图一致的目标（季度或其他）。 路线图确保每个团队拥有清晰、高效工作的长期时间线。可能会有充分的理由（例如，开发组织变化太快）来放弃路线图。但在稳定的环境下，缺乏路线图可能是SRE团队与其他团队合并，将服务管理工作移交回开发团队，甚至是解散的信号。 与开发领导层保持持续的战略对话有助于快速确定工作重点，讨论SRE为业务增加价值的新机会，或停止对产品而言没有成本效益的工作。 路线图可以专注于改进产品，还可以解决如何应用和改进常见的SRE技术和流程以降低运维成本。 保持持续有效的关系 健康有效的关系需要不断的努力，本节简述了对我们而言效果非常好的策略。 投入时间共同努力 投入时间相互协作这种简单的行为有助于SRE和开发人员更有效的协作。我们建议SRE定期与开发人员当面沟通确保其运维的服务稳定性。SRE还可以定期与其他SRE团队沟通，这些团队运维的服务可以向本团队负责的服务提供流量或提供服务使用的通用基础架构。因为团队已经彼此了解并且设定了如何启动和管理升级的期望目标，这样，在故障或意见分歧期间，SRE团队可以自信且迅速的升级事件。 保持开放的沟通渠道 除了之前提到的团队日常沟通之外，我们还发现了一些更加正式的信息交换方法，这些方法在参与过程中十分有效。 SRE可以与产品领导进行季度“生产状态”谈话，帮助他们了解应该在何处投入资源以及SRE如何帮助他的产品或服务。类似的，开发人员可以定期向SRE团队提供“产品状态”，或者让SRE参与开发团队的执行演示。向SRE团队概述了开发团队在上季度所取得的成就（并让SRE了解他们自己的工作要如何实现）。还提供了产品未来几个季度的最新信息，以及让产品负责人了解SRE在哪些方面发挥了作用。 定期执行服务评估 作为服务的未来决策者，SRE和负责该服务的开发团队每年至少应该见面一次。也许很难更频繁的开会-例如，可能涉及洲际旅行。在会议期间，我们通常会分享未来12-18个月的路线图，并讨论新项目和发布会。 SRE团队有时会进行回顾讨论团队想要停止做什么，继续做什么以及开始做什么。项目可以出现在多个区域且这些意见都是有效的。最好的结果通常是全团队都参与的，所以需要积极促进这些会议。这些会议产生的细节可以推动重大的服务变更，因而被评为服务会议中最有用的会议。 当规则开始变化时要重新评估 如果之前协商的部分（参见379页的“设置基本规则”）开始回滚，开发人员和SRE都需要更改优先级以使服务恢复正常。我们发现，根据紧急程度，意味着可能发生以下任何一种情况： 团队指定的工程师必须放弃低优先级任务，专注于回滚。 两个团队都号称“可靠性黑客马拉松”，但通常团队的优先级是在黑客马拉松之上的。 停止功能开发，两个团队的多数成员都专注于解决回滚问题。 技术领导层确定产品的可靠性存在严重风险，团队要“全力以赴”的响应。 根据你的SLO和错误预算调整优先级 指定明确的SLO有助于团队安排工作优先级。如果服务存在丢失SLO或存在用完错误预算的风险，那么两个团队的高优先级工作应该是使服务恢复安全。他们可以通过战术措施（例如，超额配置以解决与流量相关的性能回滚）和更具战略性的软件修复（例如优化，缓存和优雅降级）来降级此类情况。 如果服务在SLO内且剩余错误预算充足，我们建议使用备用错误预算来提高功能迭代速度，而不是在服务改进上花费过多的精力。 妥善处理错误 人总会犯错。和我们的事后文化一致，我们不会责怪某个人，而是专注于系统行为。你的情况可能和我们不一样，但以下策略也可以作为参考。 三思而后行 如果可能，请勿在疲惫或情绪高涨时进行后续对话。在高压力时，人们很容易误解书面交流如电子邮件中的语气。读者会记住这些词语让他们产生何种感受的，当你在异地进行通信时，通常应该进行视频聊天，这样你可以看面部表情，听到的词语语调也可以帮忙消除原本可能产生的歧义。 当面（或尽可能近的）解决问题 仅通过代码审查或文档交互很难让人集中注意力。当另一个团队的行为或决定与我们预期的不一致时，我们会和他们讨论并询问为何没有达到预期。 要乐观 要感谢别人积极主动的行为。做起来可能很简单-例如，在代码审查，设计审查和故障场景培训期间，我们要求工程师介绍出彩的内容。你可能注意到优秀的代码注释或感谢人们愿意花时间投入设计审核。 了解沟通的差异 不同的团队对如何传播信息有不同的预期，了解这些差异有助于加强团队的关系。 将SRE扩展到更大的环境 目前为止，我们讨论的场景涉及一个SRE团队，一个开发团队和一个服务。较大的公司，甚至是使用微服务模型的小公司，可能需要扩展部分或全部团队规模。 单个SRE团队支持多项服务 由于SRE需要专业技能并且是稀缺资源，因此Google通常将SRE与开发人员的比率保持在&amp;lt;10%。因此，一个SRE团队通常与其产品领域（PA）中的多个开发团队合作。 如果SRE的数量不足以支持需要面对的服务数，是，那么SRE团队可以将精力集中到一项服务，或者集中在开发人员较少的一些服务上。 根据我们的经验，如果这些服务具有以下特征，你可以将有限的SRE资源应用到多个服务中： 服务是单一产品的一部分。提供了用户体验的端到端所有权以及与用户的一致性。 服务建立在相似的技术栈上。可以最大限度的减少认知负担，有效的重用技术技能。 服务由同一开发团队或少数相关开发团队构建。这样可以最大限度的减少关联数量，便于商定优先级。 构建多个SRE团队环境 如果你的公司足够大，拥有多个SRE团队，或许还有多个产品，那么你需要选择SRE和产品组相关联的合适的架构。 在Google，我们支持复杂的开发人员组织。如图18-2所示，每个PA由多个产品组组成，每个产品组包含多个产品。SRE组织以层次结构的方式影响开发人员组织，每个级别都有共享的优先级和最佳实践。当一个组中的所有团队或PA中的所有组都共享相同或相似的特定业务目标，且每个产品组都有产品领导和SRE领导时，这个模型都是有效的。 图18-2. 大规模的开发者与SRE团队关系图（每个产品领域） 如果你的组织有多个SRE团队，你需要以某种方式对其进行分组。我们发现有两种主要的分组方式： 将团队分组到产品中，这样他们就不必与太多不同的开发团队协调。 将团队分组到技术栈中（例如，“存储”或“网络”）。 为了防止在开发人员重新开发的期间SRE团队的流失，我们建议根据技术而不是开发人员PA报告架构来组织SRE团队。例如，许多支持存储系统的团队都以相同的方式构建和运行。即使是来自开发组织的不同部分，将技术型产品组中的存储系统分组可能会更有意义。 使SRE团队结构适应不断变化的环境 如果你需要调整SRE团队的结构来响应不断变化的PA需求，那么我们建议你根据服务需求以及工程和运维负载来创建，拆分（切分），合并和解散SRE团队。每个SRE团队都应该有一个清晰的章程来反映他们的服务，技术和运维。当一个SRE团队拥有太多服务时，我们宁愿将现有团队分成多个团队来传递企业文化并发展现有领导层，而不是从头开始建立新的团队。类似这种的变化不可避免会对现有团队造成破坏，因此我们建议你仅在必要时对团队进行重组。 运行有凝聚力的分布式SRE团队 如果你需要确保全天候保持业务连续性，并且拥有全球性的服务，那么可以通过在全球范围内建立你的SRE团队来提供均匀覆盖。如果你拥有多个全球分布的团队，我们建议根据邻接以及服务和共享技术的相似性来协调团队。独立的团队通常效率较低，且容易受到团队外部重组的影响-我们只有在业务明确需要他们并且考虑了其他所有选项后才会建立这样的团队。 许多公司没有足够的全球覆盖资源，但即使你只是在建筑物之间分布（不考虑洲际），创建和维护两个地方的团队也是有必要的。 通过创建、维护组织标准来推动规划和执行以及培养和维护共享的团队文化十分重要。为此，可以定期让整个团队聚在一起-例如，每12-18个月举办一次全员参与的峰会。 有时，对团队的个人而言，拥有某些特定职责是没有意义的-例如，从备份中执行定期测试还原或实施跨公司技术任务。在团队分布式站点间平衡这些责任时，请记住以下策略： 将个人职责分配给单个站点，但要定期轮换（例如，每年）。 分担各站点之间的责任，积极努力的平衡参与度和工作量。 不要常年将责任锁定在某个站点。我们发现这种配置的成本最终会超过收益。虽然这个站点可以很好的履行职责，但会培养“我们与他们”的心态，有碍知识的分享，并给业务带来连续性的风险。 所有这些策略都需要站点之间维持战术和策略沟通。 关系结束 SRE参与不一定是无限期的。SRE通过有影响力的工程工作提供价值，如果工作不再具有影响力（即，SRE参与的价值消失），或者大部分工作不再在工程（或运维）层面，你可能需要重新审视当前参与的SRE。一般而言，独立的SRE团队倾向从过度辛劳的团队转变成更有趣的工程工作团队。 在团队级别，如果SRE不再提供足够的业务价值来抵偿成本的话，你可能会归还服务。例如： 如果服务已经优化到不再需要SRE持续参与的水平 服务的重要性或相关性已经降低 如果服务已达到使用寿命 以下案例研究展示了两个Google SRE参与模式的结束方式。第一个结果基本上是积极的结果，而另一个的结果则比较微妙。 案例研究1：Ares Google的Abuse SRE和CommonAbuse Tool（CAT）团队为大多数Google产品提供了反滥用保护，并与面向客户的产品合作以确保用户安全。Abuse SRE团队应用工程工作来降低CAT的运维负担，以便开发人员能够直接支持其用户。这些用户是Google运维CAT所捍卫的资源，他们对CAT的功效及其对问题或新威胁的响应时间有着很高的预期。 有效的反滥用战斗需要保持持续的关注，能快速的适应变化，面对新的威胁和攻击时具有灵活性。通常SRE的目标是可靠性和有计划的功能开发，这些要求是与之冲突的。CAT团队通常需要快速开发并为受到攻击的资源部署新的保护措施。但是，Abuse SRE推迟了所要求的的变更，针对每个变更都要求对整个生产系统的影响进行更深入的分析。团队和审查之间协商的时间限制加剧了这种紧张局势。 为了改善这种状况，Abuse SRE和CAT领导层开展了一个持续全年度的项目，在CAT内部建立了一个专门的基础设施团队。新成立的“Ares”团队有权统一Google资源的反滥用基础设施。该团队由CAT工程师组成，他们拥有生产基础知识和构建运行大型服务的经验。团队启动了一项交换计划，将生产管理知识从Abuse SRE转移到CAT基础设施团队成员。 Abuse SRE团队告诉Ares团队，在生产中启动新服务最简单的方法（当你已经运行大型分布式服务时）是最小化服务所带来的额外认知负荷。为减少这种认知负荷，系统应尽可能是同构的。一起部署和管理生产服务集合意味着可以共享相同的发布结构，容量规划，访问存储的子服务等。根据这一建议，Ares重新设计了整个反滥用堆栈，应用模块化概念转向了微服务模型。他们还构建了一个新层，为开发人员提供抽象化，这样就不必担心监控，日志记录和存储等较低级别的生产细节。 现在，Ares团队开始管理新的反滥用基础设施，看上去更像是CAT的SRE团队。同时，Abuse SRE专注于整个反滥用基础设施的生产部署和高效的日常运维。 Ares工程师和AbuseSRE之间的协作带来了以下改进： 现在，Ares团队开始管理新的防滥用基础设施，看上去更像是CAT的SRE团队。同时，Abuse SRE专注于整个防滥用基础设施的生产部署和高效的日常运维。 Ares工程师和Abuse SRE之间的协作带来了以下改进： 由于CAT团队现在拥有“内部”生产专家，他们本身也是反滥用战斗的专家，Abuse SRE不再需要审查新的功能变更。大大缩短了新功能的开发时间。与此同时，由于新的基础设施抽象了生产管理细节，CAT团队的开发人员的开发速度也有了提高。 由于大多数请求不需要更改基础架构，因此Abuse SRE团队对CAT团队提出的新需求也少了很多。又因为基础设施很少需要更改，该团队对新功能影响的评估也比之前简单。当需要更改基础架构时，Abuse SRE只需要清楚对基础架构的影响，而不用了解具体的功能。 由于现在产品集成相当于功能发布，所以需要与反滥用基础架构集成的产品有更快更加可预测的转变时间。 在该项目结束时，Abuse SRE不再直接支持CAT，而是专注于底层基础设施。这并没有影响CAT的可靠性，也没有使CAT团队承担额外的运维工作；相反，这加快了CAT的整体发展速度。 目前，Ares通过大量Google资源来保护用户。自团队成立以来，SRE和产品开发合作一起就基础设施如何在生产中发挥作用进行决策。正是由于Ares的努力才使得这样的伙伴关系成为可能，Ares创造了一种共同的使命感。 案例研究2：数据分析通道 有时维持SRE运维关系的成本高于SRE提供的价值。这种情况下，通过解散SRE团队来结束这种关系是可行的 。 注1：Google HR在这类转换中为员工提供新机会 随着时间的推移这种关系的价值在减小，但很难确定终止合作的时间点。Google的两个支持重点收入数据分析通道的团队就面临这一挑战。在经过十年的合作之后，确定分离的方法是十分重要的。回想起来，我们能够确定团队互动的几种模式，这些模式是我们需要重新考虑SRE团队和产品团队间关系的重要指标。 数据挖掘 在衰退的前三年，所有相关方都认识到他们的主要数据分析通道正在遇到扩展的限制。当时，开发团队决定规划新系统，并让少数工程师专门投入此项工作。随着此项工作的融合合并，有必要为现有系统开发大型，复杂或有风险的特性来支持新系统的工作。随着时间的推移，产生了两个重要的影响： 对新项目采用了非正式规则：如果项目的复杂度或修改现有系统以适应项目涉及到的风险太高，那么最好在新系统中进行规划。 随着资源转向开发新系统，即使对现有系统进行相对保守的变更也变得十分困难。但此时对现有系统的使用量仍在快速增加。 沟通失败 在保持现有系统正常运行的同时设计，构建，启动替换系统对任何工程团队而言都是一项挑战。压力自然的落在同时关注着新、旧系统的人，以及需要做出优先级决策的团队身上。当团队在组织结构上是分离的，这些困难可能更加复杂-例如，一个专注于维护和运维现有系统的SRE团队和一个致力于下一代系统的开发团队。 在整个周期中，为了维护和保持团队间良好的工作关系，定期，开放和合作的沟通十分重要。在这个例子中，沟通不畅导致了团队间工作关系的不和谐。 解散 花费了一段时间才意识到SRE和开发团队完全脱节是不可取的。最终，最简单的解决方案是消除组织障碍，让开发团队完全把控新旧系统的优先级工作。在旧系统完全淘汰之前，预计两个系统将同时存在18-24个月。 将SRE和产品开发功能整合到一个团队中可以使高层管理人员最大限度的响应他们的问责领域。同时，团队可以决定如何平衡运维需求和速度。虽然解散两个SRE团队并不是件愉快的事，但这样做解决了在何处投入精力的问题。 尽管开发团队不可避免会有额外的运维负担，但是重新调整旧系统的所有权给对服务更了解的人员有助于更快的解决运维问题。该团队可以更深入的了解故障的潜在原因，能更高效的排查故障和解决问题。但是，开发团队在短期内接手所支持服务的运维工作时，不可避免会产生一些负面影响。SRE团队的最后工作是尽可能的分享运维知识，帮助开发团队顺利承担这项工作。 如果工作关系更健康-团队合作可以有效的解决问题-SRE能在短期内将生产工作交付给开发团队。在系统重新稳定并强健能够满足预期的增长需求后，SRE通常会重新承担系统运维的责任。SRE和开发团队要主动直接解决问题并找出需要重置的工作内容。SRE的一部分工作是在面对不断变化的业务需求时帮助开发进行优化开发，寻找解决挑战性问题的解决方案。 结论 SRE团队参与的模式会改变服务生命周期的各个阶段。本章对每个阶段都提供了具体建议。Google和纽约时报SRE团队的例子表明，有效管理参与度和指定出色的技术设计决策同样重要。有时SRE的参与应该达到一个自然的终止点。Ares和数据分析通道团队的案例研究提供了如何实现这点的示例，以及如何很好的结束参与关系。 在谈及SRE和产品开发团队之间建立有效关系的最佳实践时，关键在于定期和开放式沟通共享目标和方向。你可以通过多种方式扩展SRE团队，但这些关系管理原则应该始终如一。为了保持SRE参与的长期成功，协调团队目标，理解彼此的目标与捍卫SLO同样重要。</summary></entry><entry><title type="html">第十七章 从过载中识别和恢复</title><link href="http://localhost:4000/sre/2020/01/17/%E4%BB%8E%E8%BF%87%E8%BD%BD%E4%B8%AD%E8%AF%86%E5%88%AB%E5%92%8C%E6%81%A2%E5%A4%8D/" rel="alternate" type="text/html" title="第十七章 从过载中识别和恢复" /><published>2020-01-17T00:00:00+08:00</published><updated>2020-01-17T00:00:00+08:00</updated><id>http://localhost:4000/sre/2020/01/17/%E4%BB%8E%E8%BF%87%E8%BD%BD%E4%B8%AD%E8%AF%86%E5%88%AB%E5%92%8C%E6%81%A2%E5%A4%8D</id><content type="html" xml:base="http://localhost:4000/sre/2020/01/17/%E4%BB%8E%E8%BF%87%E8%BD%BD%E4%B8%AD%E8%AF%86%E5%88%AB%E5%92%8C%E6%81%A2%E5%A4%8D/">&lt;p&gt;当SRE团队顺利运行时，团队成员应该感觉他们可以轻松地处理所有工作。他们应该能够处理工单，并且还有时间处理长期项目，以便将来更容易地管理服务。&lt;/p&gt;

&lt;p&gt;但有时现实情况会妨碍团队的工作目标，比如，成员长期病假或转移到新的团队。组织为SRE制定了新的生产范围计划，对服务或更大系统的更改带来了新的技术挑战。随着工作量的增加，团队成员开始工作更长时间来处理工单和紧急警报，以至于减少了花在工程工作上的时间。整个团队开始感到压力并沮丧，因为他们努力工作却没有取得进步。反过来，压力会导致人们犯更多的错误，影响可靠性最终影响最终用户。简而言之，该团队失去了管理日常工作和有效管理服务的能力。&lt;/p&gt;

&lt;p&gt;因此，团队需要找到摆脱这种过载状态的方法。他们需要重新平衡工作量，以便团队成员可以专注于必要的工程工作。运维负载（或运维工作负载）是一个术语，描述的是使系统和服务以最佳性能运行的持续维护工作。有三种不同类型的运维负载：紧急警报、工单和日常运维任务。紧急警报通常需要立即关注，与紧急问题相关的工单可能会有紧迫的截止日期。报警和紧急工单都会中断SRE的工程工作来支持团队的运维工作。出于这个原因，我们将它们称为中断。SRE（Site Reliability Engineering）的第29章讨论了管理团队在维护复杂系统的运行状态时处理自然中断的技术。当运维负载超过团队管理能力时，团队最终将处于运维过载状态（也称为工作超负荷）。当团队无法在关键优先事项方面取得进展时，团队处于运营超负荷状态，因为紧急问题不断取代项目工作。除了降低团队的优先级和服务改进之外，过载还会增加工程师出错的可能性。&lt;/p&gt;

&lt;p&gt;运维过载的阈值因团队而异，Google SRE团队将工作量限制在工程师工作时间的50%。从长远来看，成功的SRE团队必须有信心他们将能够完成所需的工程项目，以减少他们所管理服务的运维负担。&lt;/p&gt;

&lt;p&gt;本章描述了Google的团队如何从一个以运维过载为特征的困难局面发展到管理良好的工作负载。两个案例研究显示了运维过载对团队健康的不利影响，以及团队如何改变他们的日常任务，以便可以专注于长期有影响力的项目。在案例研究1中，当身处于一个不断缩小的团队中的成员无法跟上工作负载时，便会导致过载。在案例研究2中，团队遭受他们所认为的过载——这是一种与运维过载具有相同效果的状态，但最初是对实际工作负荷的误解。&lt;/p&gt;

&lt;p&gt;虽然案例研究突出了两个Google SRE团队的具体行为，但“减轻过载的策略”一节第366页提供了适用于任何公司或组织辨别和减轻过载的实践。因此，本章应该对过载团队的管理者或任何关注过载的SRE团队有用。&lt;/p&gt;

&lt;h2 id=&quot;从负载到过载&quot;&gt;从负载到过载&lt;/h2&gt;

&lt;p&gt;无论其起源如何，过载都是一种可能削弱生产力的职业压力。如果不加以控制，可能会导致严重的疾病。对于SRE团队而言，运维负载通常是认知上困难任务的组合（如调试内存泄漏或分段故障）和一些需要频繁环境切换的小任务（通过配额请求，启动二进制分发等）。&lt;/p&gt;

&lt;p&gt;当团队没有足够的时间来处理所有这些任务时，通常会发生工作超负荷——当分配给团队的任务数量无法在每个任务的给定截止日期内完成时，这是客观现实。感知过载更为主观，并且当团队中的个人觉得他们有太多工作时就会发生。这通常发生在短期内有多次组织或工作变更时，但团队几乎没有机会与领导层就变更进行沟通。&lt;/p&gt;

&lt;p&gt;当你值班时，你永远不会清楚会出现什么问题，或者你的工作量是什么。一方面，看似单一的磁盘空间不足问题可能会导致对重复的垃圾收集工作进行深入调查。另一方面，20次以上的紧急报警风暴可能会成为监控不良的情况。当很难估计或预测你的工作量时，很容易成为认知偏差的受害者并误判工作量——例如，你可能会任务在你on-call期间工单队列太大而无法完成，即使你可以快速完成所有工单并且实际工作负载较低，你在第一次查看工单队列时也会感到超载。这种感知过载本身是一种影响工作方式和态度的心理因素，如果你没有以一种有很多工作的预想开始一天的工作，你将很可能潜心的按照你自己的方式完成工单序列。也许你整天都在工作，但并没有完成你的工作量（因此面临工作超负荷），但是这将比一开始就感觉不堪重负更有进步。&lt;/p&gt;

&lt;p&gt;累积很多工作中断可能会导致工作超载，但也并非如此。但是，当频繁的中断与外部压力因素配对时，大的工作量（甚至是小的工作量）很容易变成感知的过载。这种压力可能源于担心其他团队成员失望，工作安全感，工作相关或个人矛盾，疾病或健康相关问题，如缺乏睡眠或运动。如果你的工作没有得到适当的优先排序，那么每项任务都会显得同样紧迫，从而导致实际和感知过载。在实际的过载情况下，工单和警报的紧急程度可能导致团队成员工作到知道解决问题，即使这样做意味着持续的长时间工作。当一个团队面临被认为的过载时，重新确定优先级可以帮助减少紧急工作量，为他们创造空间，通过项目工作来解决过载源。&lt;/p&gt;

&lt;p&gt;在分析具体情况时，不一定要假设工作量本身需要更改，相反，我们建议首先量化团队所面临的工作，以及它如何（或没有）随时间变化。例如，你可以根据团队处理的故障单和紧急警报数量来衡量工作负载。如果你的工作量实际上没有随着时间的推移而发生变化，那么团队可能会感到超载仅仅是因为他们认为工作是压倒性的。可以通过要求每个成员列出他们面临的所有的工作任务来收集一次性快照，以更全面的了解团队当前的工作负载。然后看看你的团队面临的心理压力因素，例如组织变化或重新优化排序。完成研究后，就可以就改变工作量做出决定。&lt;/p&gt;

&lt;p&gt;第366页的“减轻过载的策略”更多的讨论了如何识别真是和感知的过载。首先，我们提出两个认可的团队案例研究，他们处于超负荷状态并采取措施缓解它。&lt;/p&gt;

&lt;h2 id=&quot;案例研究1当半数团队成员离开时工作超载&quot;&gt;案例研究1：当半数团队成员离开时工作超载&lt;/h2&gt;

&lt;h3 id=&quot;背景&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;Google的一个内部存储SRE团队负责多种服务的后端维护，包括Gmail，Google云端硬盘和Google网上论坛，以及许多其他内部或面向用户的服务。我们在2016年中期经历了一场危机，当时三分之二的团队成员，包括最高级工程师（经理），在相对较短的时间内因为完全不相干的原因而离职。这个时间显然导致了巨大的工作量管理问题：可用于处理日常工作和项目工作的SRE越来越少，导致团队过载。我们的工作也遇到了瓶颈，因为每个团队成员的专业知识都被划分到不同的生产领域。虽然增加新的团队成员和三名实习生可以改善我们的工作量，但增加这些工程师需要花费大量的时间和精力进行培训。&lt;/p&gt;

&lt;h3 id=&quot;问题陈述&quot;&gt;问题陈述&lt;/h3&gt;

&lt;p&gt;上述因素显著降低了团队生产力。我们的开始落后于项目工作，并且我们管理的许多服务相关的工单开始堆积。我们没有足够的时间来处理这个积压，因为我们的所有工作都被更高优先级的任务所消耗。过不了多久我们就无法完成所需要的所有重要且紧急的工作。与此同时，我们的团队很快将获得更多高优先级的工作。&lt;/p&gt;

&lt;p&gt;如果我们没有把一些工作从我们的主要版块上移开，那么我们只能放弃重要工作。然而，一旦我们开始放弃一些工作，我们就会遇到一些心理问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;放弃任何正在进行的工作，感觉就像我们刚刚浪费了我们努力的时间。大多数积压工作似乎要么至关重要，要么值得我们付出努力，所以只有无限期地推迟或取消项目。我们没有意识到我们正处于一种沉没成本谬论的控制之中。&lt;/li&gt;
  &lt;li&gt;努力实现流程自动化或修复工作负载的根本原因并不像立即处理高优先级故障那样重要。当这项工作被添加到已经庞大的堆积工作的顶部时，所有的工作都感到压力很大。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;我们决定做什么&quot;&gt;我们决定做什么&lt;/h3&gt;

&lt;p&gt;我们将团队成员聚集在一个房间中，并列出了团队的所有职责，包括积压项目、运维工作和工单。然后我们队每个列表项进行了分类，查看我们的每一项工作任务，这有助于我们确定并重新定义我们的实际优先级。然后，我们找到了最小化、切换或消除低优先级工作的方法。&lt;/p&gt;

&lt;h3 id=&quot;实现&quot;&gt;实现&lt;/h3&gt;

&lt;p&gt;我们将一些自动化低成本较低的工作自动化，可能这不会很多，但一旦部署，将大大降低运维负荷。&lt;/p&gt;

&lt;p&gt;我们还确定了可以实现自助服务的常见问题。编写客户所需的程序并不需要很长时间，并从队列中删除了一些重复的工作。&lt;/p&gt;

&lt;p&gt;我们合理地关闭了许多积压这的工单，这些工单中的大多数都是过时的、多余的，或者是紧急的（虽然他们声称是紧急的）。有些工单是监控那些不可操作的工作，所以我们修复了相关的监控。在某些情况下，我们积极解决不重要的问题。我们将这些问题放在一边处理更紧急的工单，但首先要记录我们的进度，以便在我们能够再次处理他们之前不会失去之前的环境。&lt;/p&gt;

&lt;p&gt;当有疑问时，我们放弃一项工作，但标记为第二阶段的分流。一旦我们的盘子（几乎）空了，我们将重新审视这个暂定列表，以决定恢复哪些任务。事实证明，这些任务几乎都不具有影响力或重要性，无法恢复。&lt;/p&gt;

&lt;p&gt;两天——一天的密集分流加上一天的记录流程和实施自动化——我们很小的团队解决了几个月的工单积压。然后我们可以处理剩余的几个故障，这些故障与生产中的活动问题有关。&lt;/p&gt;

&lt;h3 id=&quot;经验总结&quot;&gt;经验总结&lt;/h3&gt;

&lt;p&gt;我们的团队了解到识别和确认过载是解决问题的第一步。在我们帮助我们团队恢复健康状态之前，我们需要让每个人都进入同一个房间并重新评估积压工作。&lt;/p&gt;

&lt;p&gt;为了避免新的中断性任务积累，我们开始每两周对中断性任务进行一次分类。我们的技术负责人会定期检查任务队列，并评估团队是否有过载风险。我们决定每个团队成员应该有10张或更少的开放工单，以避免过载。如果团队领导同志团队成员的工单数超过10张，他们可以执行以下一项或多项组合：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;提醒团队关闭陈旧的工单。&lt;/li&gt;
  &lt;li&gt;与过载的团队成员同步并从他们那卸载工单。&lt;/li&gt;
  &lt;li&gt;提示各个团队成员解决他们的工单队列。&lt;/li&gt;
  &lt;li&gt;组织团队范围的一日工单修复工作。&lt;/li&gt;
  &lt;li&gt;分配工作以修复故障单来源或操作工作以减少将来的故障单。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;案例研究2组织和工作量变化后的感知过载&quot;&gt;案例研究2：组织和工作量变化后的感知过载&lt;/h2&gt;
&lt;h3 id=&quot;背景-1&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;本案例研究中的Google SRE团队分处两个地方，每个站点有六到七名随叫随到的工程师（有关团队规模的更多讨论，请参阅第11章站点可靠性工程)。虽然悉尼团队健康运作，但苏黎世团队在超负荷运转。&lt;/p&gt;

&lt;p&gt;在苏黎世团队进入超负荷之前，我们很稳定且满足。我们管理的服务数量相对稳定，每个服务都多种多样，维护度也很高。虽然我们所支持服务的SLO与其外部依赖的SLO不匹配，但这种不匹配并未引起任何问题。我们正在开展一些项目来改进我们管理的服务（例如，改善负载均衡）。&lt;/p&gt;

&lt;p&gt;同时致使苏黎世团队陷入过载的诱因是：我们开始在谷歌的基础架构中加入噪音更大、整合程度更低的新服务，技术主管和另一名团队成员也离开了我们团队，导致团队缺少两个人。额外工作量和知识流失的结合引发了更多问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对新服务的未调优监控和与迁移相关的监控导致每个班次增加了更多的页面。这种积累是渐进的，所以当它出现时我们没有注意到它的增加。&lt;/li&gt;
  &lt;li&gt;SRE对新服务感到相对无助，我们对它们的了解还不够，无法做出适当的反应，而且经常需要询问开发团队问题。虽然过载可能保证将服务交还给开发人员，但我们的团队从未返回过服务，所以我们并不认为这是一个可行的选择。&lt;/li&gt;
  &lt;li&gt;5人值班小组轮班缩短了我们通常花在业务工作上的时间。&lt;/li&gt;
  &lt;li&gt;新的故障单报警出现了问题，这种问题在最近的团队变更之前就存在了。我们过去只是简单地忽略了这些问题，但我们现在需要将被忽略的电子邮件报警移至故障单。项目规划并没有考虑到这一新的技术债务来源。&lt;/li&gt;
  &lt;li&gt;新的票据SLO要求我们在三天内处理票据，这意味着值班人员必须更快地处理在他们值班期间产生的票据。SLO旨在减少添加到我们（大部分被忽略的）积压工单中的票据数量，但这可能产生了更糟糕的副作用。现在，SREs觉得他们在轮班后无法得到他们所需要的休息，因为他们必须立即解决后续工作。对这些工单的优先考虑也意味着SREs没有足够的时间进行其它操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在此期间，我们团队被指派给一位新的经理，他同时管理另外两个团队。这位新上任的经理并不是值班轮值人员，因此没有直接感受到团队成员所面临的压力。当团队向经理解释情况时，没有任何改变。团队成员认为他们没有被听到，这让他们感到与管理团队的距离太远了。工单的超载持续了几个月，让团队成员变得脾气暴躁，直到一连串的不愉快情绪蔓延到整个团队。&lt;/p&gt;

&lt;h3 id=&quot;问题陈述-1&quot;&gt;问题陈述&lt;/h3&gt;

&lt;p&gt;在失去两个人并接受额外和各种各样的工作后，我们的团队感到超负荷。当我们试图将这种感觉传达给我们的直接经理时，经理不以为然。随着工作时间的延长，人们开始精疲力竭，生产力正在下降，任务增加的速度开始快于团队解决问题的速度。感知到的过载现在变成了客观过载，使情况变得更糟。&lt;/p&gt;

&lt;p&gt;超负荷造成的情绪压力降低了士气，导致一些团队成员倦怠。当个人处理工作过度对身体的影响（疾病和低生产力）时，团队中的其他人不得不承担更多的工作，在每周的团队会议上分配的工作没有完成。&lt;/p&gt;

&lt;p&gt;然后我们开始假设我们不能依赖其他人来完成他们的工作，这削弱了团队内部的信任和可靠性。因此，我们对人际风险承担感到不安全，这是心理安全的一个重要因素（见第11章网站可靠性工程）。团队成员感觉不被其他团队成员接受和尊重，因此他们之间没有自由地相互协作。随着团队心理安全的减弱，协作停止，信息共享速度减慢，导致效率进一步低下。&lt;/p&gt;

&lt;p&gt;团队调查还显示，他们的心理安全受损——团队成员表示，他们并不觉得自己属于团队。他们不再关心他们的职业发展，团队晋升率也降到了历史最低点。&lt;/p&gt;

&lt;p&gt;当高层管理人员为我们分配了新的强制性全公司项目时，我们终于达到了一个突破点，在这一点上，我们重新与管理层就过载问题进行了对话。一系列的讨论表明，我们不愉快的情况不仅仅是工作太多的结果——我们对团队安全的看法使我们不再相互信任和合作。&lt;/p&gt;

&lt;h3 id=&quot;我们决定做什么-1&quot;&gt;我们决定做什么&lt;/h3&gt;

&lt;p&gt;上层管理人员为我们团队指派了一位新经理，他不是供职于三个团队。新经理采用参与式管理方式来改善团队的心理安全，以便我们再次合作。该方法使团队成员能够积极参与解决团队问题。整个团队，包括我们的直接经理，都参与了一系列简单的团建活动，以提高我们的团队效率（其中一些活动就像一起喝茶一样简单）。最终，我们能够起草一套目标：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;短期&lt;/code&gt;：缓解压力，提高心理安全，营造健康的工作氛围。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;中期&lt;/code&gt;：通过培训建立团队成员的信心；找到导致过载问题的根本原因。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;长期&lt;/code&gt;：解决正在发生的导致级联的问题。&lt;/p&gt;

&lt;p&gt;为了设定这些目标，我们首先必须在团队中达到某种基本的心理安全。随着士气的提高，我们开始分享知识、并在彼此想法的基础上找到让我们的工作负荷得到控制的方法。&lt;/p&gt;

&lt;h3 id=&quot;实现-1&quot;&gt;实现&lt;/h3&gt;

&lt;h4 id=&quot;短期行为&quot;&gt;短期行为&lt;/h4&gt;

&lt;p&gt;长期压力，无论是过度工作还是对团队安全的看法，都会降低生产力并影响人们的健康。因此，我们最重要的短期行动是减轻压力，提高信任和心理安全。一旦缓解了一些压力，团队成员就可以更清晰地思考并参与推动整个团队向前发展。在确定过载的一个月内，我们实施了以下措施：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;开始了一个非定期的圆桌会议来讨论问题。该团队释放了挫败感，并对可能导致超负荷的原因进行了头脑风暴。&lt;/li&gt;
  &lt;li&gt;找到更好的衡量负载的指标。我们决定改进我们原有的页数标准，我们自动给值班人员分配工单，即使在轮班结束后，值班人也要负责这些工单。我们的新指标衡量了一位值班人在轮班后处理工单所需的时间。&lt;/li&gt;
  &lt;li&gt;审核并删除垃圾邮件警报。我们审核了警报，并删除了那些不代表面向用户问题的警报。&lt;/li&gt;
  &lt;li&gt;屏蔽大量警报。这个团队故意不去寻找每一个警报的来源，而是专注于减轻压力，避免因为我们已经知道的问题而不断接到警报和提工单。我们使用了以下策略：&lt;br /&gt;
      ——已知的警报在被修复之前一直处于屏蔽状态。&lt;br /&gt;
      ——警报只能在有限的一段时间内被屏蔽（通常是一天，有时长达一周）。否则，他们可能会掩盖故障。&lt;br /&gt;
     ——几分钟内无法修复的警报被分配到一个跟踪工单上。&lt;/li&gt;
  &lt;li&gt;增加了一个专门针对单个团队的直接经理。让一个受人尊敬的团队成员成为新经理重新建立了对管理的信任。新经理可以将更多时间集中在团队及其成员上，而不是管理三个团队。&lt;/li&gt;
  &lt;li&gt;重新平衡团队。我们通过添加技术经验丰富的SREs来引入新的视角并减轻值班人员的压力，这些SREs对团队或组织没有先入为主的观念。找到合适的人并不是一件容易的事，但值得付出努力。&lt;/li&gt;
  &lt;li&gt;举办团体活动，如午餐和棋盘游戏。谈论与工作无关的话题，一起大笑，缓解团队的紧张局势，提高心理安全性。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;中期行为&quot;&gt;中期行为&lt;/h4&gt;

&lt;p&gt;单靠短期解决方案无法维持良好的氛围——例如，我们的短期策略之一就是在没有真正解决问题的情况下屏蔽报警。在三个月内，我们还采取了一下行动：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;值班期间尽可能减少运维工作（参见SRE第29章），以便团队可以专注于永久性修复和项目工作。&lt;/li&gt;
  &lt;li&gt;将一项服务的责任归还给其开发团队。&lt;/li&gt;
  &lt;li&gt;相互培训（和新的团队成员）。虽然培训需要投入时间和精力，但传播知识意味着所有团队成员（以及未来的雇员）可以在未来更快地排除故障并解决问题。培训同时提高了我们的信心，因为我们意识到我们实际上对服务有很多了解。当他们获得知识时，团队成员开始寻找管理服务的新方法，提高可靠性和减少过载。&lt;/li&gt;
  &lt;li&gt;从其他团队中引入SREs来安排我们的一些值班工作并参与培训。他们注意到了团队的压力，并提供了一些有价值的新视角。&lt;/li&gt;
  &lt;li&gt;在团队中重新扮演了两个开放的角色。&lt;/li&gt;
  &lt;li&gt;在报警屏蔽过期解决每个报警。我们在周会中讨论了没有采取任何操作的重复报警，这让我们调整了报警或修复了潜在的问题。虽然这些是重要的（和明显的）行为，我们只有在报警被屏蔽情况下才有足够的空间进行分析和采取行动而不是制造持续的噪音。&lt;/li&gt;
  &lt;li&gt;有组织的聆听活动。管理层（包括跳级经理和团队领导）有意识地倾听团队的痛点并找到一个团队驱动的解决方案。&lt;/li&gt;
  &lt;li&gt;增加视角。希望不是一种策略，但它确实有助于提升团队士气。随着新成员加入on-call，转变为更清晰的优先事项，以及结束产生报警的项目，团队的情绪得到了改善。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;长期行为&quot;&gt;长期行为&lt;/h4&gt;

&lt;p&gt;为了保持我们新发现的稳定，我们目前正在将我们的SLO与其服务后端的SLO保持一致，并努力使服务更加统一。统一具有双重好处：它降低了SRE的心理负荷，并使编写可以跨服务使用的自动化变得更加容易。我们还回顾了已经存在了很长时间的服务，并将它们更新到当前的生产标准。例如，一些服务在负载下运行很差，这些年来显著增加。某些服务更需要根据其后端服务策略的更改进行更新。其它服务几年来一直没有更新。&lt;/p&gt;

&lt;h3 id=&quot;成效&quot;&gt;成效&lt;/h3&gt;

&lt;p&gt;我们在第一次头脑风暴会议后的几个月，结果开始浮出水面：on-call轮班期间变得更安静了，我们的团队成功地快速有效地处理了一个棘手的时间。不久，新的团队成员加入。当我们在圆桌会议上讨论心理安全时，新成员说他们无法想象团队会有这样的问题。事实上，他们认为我们的团队是一个温暖而安全的工作场所。在最初的升级后大约一年，最初的超负荷几乎没有，一项匿名调查显示，团队成员现在觉得这个团队是高效和安全的。&lt;/p&gt;

&lt;h3 id=&quot;经验总结-1&quot;&gt;经验总结&lt;/h3&gt;

&lt;p&gt;工作场所的变化会对团队中的人产生心理影响——毕竟，你的队友不是机器。你需要关注团队的压力水平这样人们就会开始互相信任，一起工作；否则，团队可能会进入导致压力的过载中恶性循环，从而阻止你应对过载。&lt;/p&gt;

&lt;p&gt;事实上，感知过载是过载，并且对团队的影响与其他因素造成的工作过载一样大。在我们的案例中，我们在悉尼的姐妹团队没有遇到同样的问题，与前几年相比，我们解决的报警数量并没有太大的变化。相反，失去两名团队成员，感知过载增加，工单增加以及新的3天的工单让团队感觉超负荷了。最终，客观和感知超载之间的区别并不重要：一些团队成员的管制过载会很快导致整个团队的超负荷。&lt;/p&gt;

&lt;h2 id=&quot;减轻过载的策略&quot;&gt;减轻过载的策略&lt;/h2&gt;

&lt;p&gt;外部视角有时可以很容易地识别团队何时超负荷。同样，回顾一下应该采取什么行动也很容易。但当你正在体验它时，你将如何识别过载？当你陷入过载困境时，通往健康、友好和快乐的工作氛围的道路很难想象。本节介绍了识别和减轻团队过载的实践。&lt;/p&gt;

&lt;h3 id=&quot;识别过载的症状&quot;&gt;识别过载的症状&lt;/h3&gt;

&lt;p&gt;如果你知道过载的症状，很容易识别出一个超负荷的团队：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;团队士气降低：&lt;/strong&gt;&lt;br /&gt;
过载可能表现为咆哮和抱怨。相关主题（工作条件、工作满意度、项目、同事和经理）的调查通常反映团队士气，并在团队超负荷时产生更多负面结果。与团队领导定期积极的聆听会议可以解决你不了解的问题。积极倾听的一个基本要素是不经过判断就倾听。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;团队成员长时间工作，或生病时工作：&lt;/strong&gt;&lt;br /&gt;
没有补偿的加班可能是心理压力源。领导者应该梳理一个好榜样：生病时待在家里。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;更频繁的疾病：&lt;/strong&gt;&lt;br /&gt;
过度工作的团队成员往往会经常沮丧和生病&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;不健康的任务队列：&lt;/strong&gt;&lt;br /&gt;
我们建议定期查看团队的任务队列，已查看积压的工单，处理哪些问题以及可以延迟或删除那些任务。如果团队错过最后期限，或者紧急事件阻止你定期执行此审核，那么团队很可能会比他们所能处理的更快地累积中断。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;不平衡的指标：&lt;/strong&gt;&lt;br /&gt;
    一些关键的指标可能表明你的团队过载
    * 长时间关闭某个问题
    * 长时间花费在艰难进行的工作上
    * 大量的时间来关闭来自于调用会话的问题&lt;/p&gt;

&lt;p&gt;团队应该共同决定使用哪些措施。没有一种适合所有人的方法；每个团队的超负荷都会以不同的方式放映出来。作为经理，在不了解每个人的工作量和工作习惯的情况下，不要对团队施加措施。如果坚持使用特定措施，团队成员可能会觉得你不理解工作。例如，如果你按照修复问题所需的天数来评估负载，那么一个人可能会整整一天解决问题，而另一个人可能会在几天内将工作分配到其他工作中。&lt;/p&gt;

&lt;h3 id=&quot;减少团队压力维持团队健康状态&quot;&gt;减少团队压力维持团队健康状态&lt;/h3&gt;

&lt;p&gt;阅读完标准后，你可能会认为你的团队已经超负荷了。不要绝望！本节提供了一个让你的团队恢复健康状态的方法。&lt;/p&gt;

&lt;p&gt;通常，给团队成员更多的控制和权力可以减少感知到的压力。虽然有压力的情况下求助于微管理，但重要的是要让团队处于循环状态中，并将优先级放在一起，以提高绩效和工作满意度。这个模型假设一个团队成员之间有着健康的人际关系之中。&lt;/p&gt;

&lt;h4 id=&quot;识别并减轻心理压力源&quot;&gt;识别并减轻心理压力源&lt;/h4&gt;

&lt;p&gt;当要调整一个超负载的团队时，最重要的是团队成员需要重建心理安全。团队和每个成员都是息息相关的。&lt;/p&gt;

&lt;p&gt;你可以从识别每个人和整个团队的心理压力源开始。实际哪些因素影响团队的压力？你无法控制团队成员是否患有重大疾病，但你可以控制团队面临压力的大小（如案例研究1中所示）或屏蔽报警（如案例研究2）。&lt;/p&gt;

&lt;p&gt;与你的合作的产品开发人员团队沟通，让他们知道你的团队的压力。他们或许可以伸出援助之手，甚至接管整个项目。&lt;/p&gt;

&lt;p&gt;当你的团队成员相互依赖并达到一定程度的心理安全（这样他们能够承担人际风险）时，你可以让个别成员承担更多的责任，学习其他领域的专业知识，并将专业人员物尽其用，从而提高他们的自信心，使他们能够承担风险的重任。&lt;/p&gt;

&lt;p&gt;决策应该是透明的，如果可能的话，应该是民主的。每个团队成员都应该对面对的情况有一种控制感。例如，案例研究2中的头脑风暴会议帮助团队识别和讨论问题。&lt;/p&gt;

&lt;h4 id=&quot;在四分之一的范围内优先处理和分类&quot;&gt;在四分之一的范围内优先处理和分类&lt;/h4&gt;

&lt;p&gt;健康的团队会首先处理重要的问题并对问题进行分类。案例研究1为这个观点提供了一个很好的例子：团队坐在一起并审查他们积压的问题。审查帮助他们意识到他们超载了。他们重新确定了工作优先级后，并完成了可以迅速减少负载的任务。案例研究2中的团队现在每个季度末召开会议，共同规划现有和未来工作并确定其优先顺序。&lt;/p&gt;

&lt;p&gt;如果可能，我们建议SRE在其日历上安排&lt;code class=&quot;highlighter-rouge&quot;&gt;无中断时间&lt;/code&gt;（没有on-call），这样他们就有时间处理技术深度上很困难的任务，如开发自动化和调查中断你的根本原因。在案例研究2中，当外部团队给予on-call一些解脱时，团队成员则有宝贵的时间专注于他们的项目。&lt;/p&gt;

&lt;p&gt;如果绝对必要，放弃一些工作内容：在案例研究2中，团队通过将此职责交还给开发团队，放弃了对其中一项服务的on-call支持。&lt;/p&gt;

&lt;h4 id=&quot;在未来保护自己&quot;&gt;在未来保护自己&lt;/h4&gt;

&lt;p&gt;我们强烈建议制定指标来评估团队的工作量。定期查看指标，确保他们正在衡量正确的事情。&lt;/p&gt;

&lt;p&gt;一旦你的团队出现过载，你可以通过采取措施监控或解决潜在问题来防止过载进一步恶化。例如，案例研究1中的团队现在维护一个轻量级的分类流程，以检测不断增加的积压任务。案例研究2中的团队目前正在制定一项长期计划，以协调后端和服务SLO。&lt;/p&gt;

&lt;p&gt;当你的团队处于超负荷状态时，优先考虑工程工作，即使你没有超负荷工作，也会比重复工作更重要，在将来你会获得利益。&lt;/p&gt;

&lt;p&gt;最后，团队中的每个人都应对预警信号负责（请参见第366也的“识别过载症状”），以指示可能出现的过载情况。如果管理人员认为团队正在走向过载，他们应该坐下来与团队成员交谈。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;在完美的世界中，SRE团队始终能够使用我们的第一本书中描述的策略来管理中断。但我们只是人类，我们的团队没有达到那个理想状态。本章研究了过载情况下如何建立团队健康的方法，并讨论了如何在它发生时检测和响应。&lt;/p&gt;

&lt;p&gt;特别实在运营工作方面，过度的中断很容易导致团队从正常工作负载滑落到过载。频繁的中断可能导致过载，过载会对健康和生产力产生负面影响。超载会给团队成员带来心理社会压力因素，进一步影响工作，导致自我强制循环。&lt;/p&gt;

&lt;p&gt;感知过载是一种特殊的过载形式，无法通过劳动量或操作量来衡量。很难确定和消除。为了使团队的工作量保持平衡，持续监控（感知的或为感知的）过载非常重要。为了更好地为用户服务并做好工作，你需要首先尊重自己和团队。在日常工作中保持健康的平衡对于帮助你和你的团队实现这一目标有很大帮助。&lt;/p&gt;</content><author><name>ZX</name></author><category term="《SRE-Google运维实践》" /><summary type="html">当SRE团队顺利运行时，团队成员应该感觉他们可以轻松地处理所有工作。他们应该能够处理工单，并且还有时间处理长期项目，以便将来更容易地管理服务。 但有时现实情况会妨碍团队的工作目标，比如，成员长期病假或转移到新的团队。组织为SRE制定了新的生产范围计划，对服务或更大系统的更改带来了新的技术挑战。随着工作量的增加，团队成员开始工作更长时间来处理工单和紧急警报，以至于减少了花在工程工作上的时间。整个团队开始感到压力并沮丧，因为他们努力工作却没有取得进步。反过来，压力会导致人们犯更多的错误，影响可靠性最终影响最终用户。简而言之，该团队失去了管理日常工作和有效管理服务的能力。 因此，团队需要找到摆脱这种过载状态的方法。他们需要重新平衡工作量，以便团队成员可以专注于必要的工程工作。运维负载（或运维工作负载）是一个术语，描述的是使系统和服务以最佳性能运行的持续维护工作。有三种不同类型的运维负载：紧急警报、工单和日常运维任务。紧急警报通常需要立即关注，与紧急问题相关的工单可能会有紧迫的截止日期。报警和紧急工单都会中断SRE的工程工作来支持团队的运维工作。出于这个原因，我们将它们称为中断。SRE（Site Reliability Engineering）的第29章讨论了管理团队在维护复杂系统的运行状态时处理自然中断的技术。当运维负载超过团队管理能力时，团队最终将处于运维过载状态（也称为工作超负荷）。当团队无法在关键优先事项方面取得进展时，团队处于运营超负荷状态，因为紧急问题不断取代项目工作。除了降低团队的优先级和服务改进之外，过载还会增加工程师出错的可能性。 运维过载的阈值因团队而异，Google SRE团队将工作量限制在工程师工作时间的50%。从长远来看，成功的SRE团队必须有信心他们将能够完成所需的工程项目，以减少他们所管理服务的运维负担。 本章描述了Google的团队如何从一个以运维过载为特征的困难局面发展到管理良好的工作负载。两个案例研究显示了运维过载对团队健康的不利影响，以及团队如何改变他们的日常任务，以便可以专注于长期有影响力的项目。在案例研究1中，当身处于一个不断缩小的团队中的成员无法跟上工作负载时，便会导致过载。在案例研究2中，团队遭受他们所认为的过载——这是一种与运维过载具有相同效果的状态，但最初是对实际工作负荷的误解。 虽然案例研究突出了两个Google SRE团队的具体行为，但“减轻过载的策略”一节第366页提供了适用于任何公司或组织辨别和减轻过载的实践。因此，本章应该对过载团队的管理者或任何关注过载的SRE团队有用。 从负载到过载 无论其起源如何，过载都是一种可能削弱生产力的职业压力。如果不加以控制，可能会导致严重的疾病。对于SRE团队而言，运维负载通常是认知上困难任务的组合（如调试内存泄漏或分段故障）和一些需要频繁环境切换的小任务（通过配额请求，启动二进制分发等）。 当团队没有足够的时间来处理所有这些任务时，通常会发生工作超负荷——当分配给团队的任务数量无法在每个任务的给定截止日期内完成时，这是客观现实。感知过载更为主观，并且当团队中的个人觉得他们有太多工作时就会发生。这通常发生在短期内有多次组织或工作变更时，但团队几乎没有机会与领导层就变更进行沟通。 当你值班时，你永远不会清楚会出现什么问题，或者你的工作量是什么。一方面，看似单一的磁盘空间不足问题可能会导致对重复的垃圾收集工作进行深入调查。另一方面，20次以上的紧急报警风暴可能会成为监控不良的情况。当很难估计或预测你的工作量时，很容易成为认知偏差的受害者并误判工作量——例如，你可能会任务在你on-call期间工单队列太大而无法完成，即使你可以快速完成所有工单并且实际工作负载较低，你在第一次查看工单队列时也会感到超载。这种感知过载本身是一种影响工作方式和态度的心理因素，如果你没有以一种有很多工作的预想开始一天的工作，你将很可能潜心的按照你自己的方式完成工单序列。也许你整天都在工作，但并没有完成你的工作量（因此面临工作超负荷），但是这将比一开始就感觉不堪重负更有进步。 累积很多工作中断可能会导致工作超载，但也并非如此。但是，当频繁的中断与外部压力因素配对时，大的工作量（甚至是小的工作量）很容易变成感知的过载。这种压力可能源于担心其他团队成员失望，工作安全感，工作相关或个人矛盾，疾病或健康相关问题，如缺乏睡眠或运动。如果你的工作没有得到适当的优先排序，那么每项任务都会显得同样紧迫，从而导致实际和感知过载。在实际的过载情况下，工单和警报的紧急程度可能导致团队成员工作到知道解决问题，即使这样做意味着持续的长时间工作。当一个团队面临被认为的过载时，重新确定优先级可以帮助减少紧急工作量，为他们创造空间，通过项目工作来解决过载源。 在分析具体情况时，不一定要假设工作量本身需要更改，相反，我们建议首先量化团队所面临的工作，以及它如何（或没有）随时间变化。例如，你可以根据团队处理的故障单和紧急警报数量来衡量工作负载。如果你的工作量实际上没有随着时间的推移而发生变化，那么团队可能会感到超载仅仅是因为他们认为工作是压倒性的。可以通过要求每个成员列出他们面临的所有的工作任务来收集一次性快照，以更全面的了解团队当前的工作负载。然后看看你的团队面临的心理压力因素，例如组织变化或重新优化排序。完成研究后，就可以就改变工作量做出决定。 第366页的“减轻过载的策略”更多的讨论了如何识别真是和感知的过载。首先，我们提出两个认可的团队案例研究，他们处于超负荷状态并采取措施缓解它。 案例研究1：当半数团队成员离开时工作超载 背景 Google的一个内部存储SRE团队负责多种服务的后端维护，包括Gmail，Google云端硬盘和Google网上论坛，以及许多其他内部或面向用户的服务。我们在2016年中期经历了一场危机，当时三分之二的团队成员，包括最高级工程师（经理），在相对较短的时间内因为完全不相干的原因而离职。这个时间显然导致了巨大的工作量管理问题：可用于处理日常工作和项目工作的SRE越来越少，导致团队过载。我们的工作也遇到了瓶颈，因为每个团队成员的专业知识都被划分到不同的生产领域。虽然增加新的团队成员和三名实习生可以改善我们的工作量，但增加这些工程师需要花费大量的时间和精力进行培训。 问题陈述 上述因素显著降低了团队生产力。我们的开始落后于项目工作，并且我们管理的许多服务相关的工单开始堆积。我们没有足够的时间来处理这个积压，因为我们的所有工作都被更高优先级的任务所消耗。过不了多久我们就无法完成所需要的所有重要且紧急的工作。与此同时，我们的团队很快将获得更多高优先级的工作。 如果我们没有把一些工作从我们的主要版块上移开，那么我们只能放弃重要工作。然而，一旦我们开始放弃一些工作，我们就会遇到一些心理问题： 放弃任何正在进行的工作，感觉就像我们刚刚浪费了我们努力的时间。大多数积压工作似乎要么至关重要，要么值得我们付出努力，所以只有无限期地推迟或取消项目。我们没有意识到我们正处于一种沉没成本谬论的控制之中。 努力实现流程自动化或修复工作负载的根本原因并不像立即处理高优先级故障那样重要。当这项工作被添加到已经庞大的堆积工作的顶部时，所有的工作都感到压力很大。 我们决定做什么 我们将团队成员聚集在一个房间中，并列出了团队的所有职责，包括积压项目、运维工作和工单。然后我们队每个列表项进行了分类，查看我们的每一项工作任务，这有助于我们确定并重新定义我们的实际优先级。然后，我们找到了最小化、切换或消除低优先级工作的方法。 实现 我们将一些自动化低成本较低的工作自动化，可能这不会很多，但一旦部署，将大大降低运维负荷。 我们还确定了可以实现自助服务的常见问题。编写客户所需的程序并不需要很长时间，并从队列中删除了一些重复的工作。 我们合理地关闭了许多积压这的工单，这些工单中的大多数都是过时的、多余的，或者是紧急的（虽然他们声称是紧急的）。有些工单是监控那些不可操作的工作，所以我们修复了相关的监控。在某些情况下，我们积极解决不重要的问题。我们将这些问题放在一边处理更紧急的工单，但首先要记录我们的进度，以便在我们能够再次处理他们之前不会失去之前的环境。 当有疑问时，我们放弃一项工作，但标记为第二阶段的分流。一旦我们的盘子（几乎）空了，我们将重新审视这个暂定列表，以决定恢复哪些任务。事实证明，这些任务几乎都不具有影响力或重要性，无法恢复。 两天——一天的密集分流加上一天的记录流程和实施自动化——我们很小的团队解决了几个月的工单积压。然后我们可以处理剩余的几个故障，这些故障与生产中的活动问题有关。 经验总结 我们的团队了解到识别和确认过载是解决问题的第一步。在我们帮助我们团队恢复健康状态之前，我们需要让每个人都进入同一个房间并重新评估积压工作。 为了避免新的中断性任务积累，我们开始每两周对中断性任务进行一次分类。我们的技术负责人会定期检查任务队列，并评估团队是否有过载风险。我们决定每个团队成员应该有10张或更少的开放工单，以避免过载。如果团队领导同志团队成员的工单数超过10张，他们可以执行以下一项或多项组合： 提醒团队关闭陈旧的工单。 与过载的团队成员同步并从他们那卸载工单。 提示各个团队成员解决他们的工单队列。 组织团队范围的一日工单修复工作。 分配工作以修复故障单来源或操作工作以减少将来的故障单。 案例研究2：组织和工作量变化后的感知过载 背景 本案例研究中的Google SRE团队分处两个地方，每个站点有六到七名随叫随到的工程师（有关团队规模的更多讨论，请参阅第11章站点可靠性工程)。虽然悉尼团队健康运作，但苏黎世团队在超负荷运转。 在苏黎世团队进入超负荷之前，我们很稳定且满足。我们管理的服务数量相对稳定，每个服务都多种多样，维护度也很高。虽然我们所支持服务的SLO与其外部依赖的SLO不匹配，但这种不匹配并未引起任何问题。我们正在开展一些项目来改进我们管理的服务（例如，改善负载均衡）。 同时致使苏黎世团队陷入过载的诱因是：我们开始在谷歌的基础架构中加入噪音更大、整合程度更低的新服务，技术主管和另一名团队成员也离开了我们团队，导致团队缺少两个人。额外工作量和知识流失的结合引发了更多问题： 对新服务的未调优监控和与迁移相关的监控导致每个班次增加了更多的页面。这种积累是渐进的，所以当它出现时我们没有注意到它的增加。 SRE对新服务感到相对无助，我们对它们的了解还不够，无法做出适当的反应，而且经常需要询问开发团队问题。虽然过载可能保证将服务交还给开发人员，但我们的团队从未返回过服务，所以我们并不认为这是一个可行的选择。 5人值班小组轮班缩短了我们通常花在业务工作上的时间。 新的故障单报警出现了问题，这种问题在最近的团队变更之前就存在了。我们过去只是简单地忽略了这些问题，但我们现在需要将被忽略的电子邮件报警移至故障单。项目规划并没有考虑到这一新的技术债务来源。 新的票据SLO要求我们在三天内处理票据，这意味着值班人员必须更快地处理在他们值班期间产生的票据。SLO旨在减少添加到我们（大部分被忽略的）积压工单中的票据数量，但这可能产生了更糟糕的副作用。现在，SREs觉得他们在轮班后无法得到他们所需要的休息，因为他们必须立即解决后续工作。对这些工单的优先考虑也意味着SREs没有足够的时间进行其它操作。 在此期间，我们团队被指派给一位新的经理，他同时管理另外两个团队。这位新上任的经理并不是值班轮值人员，因此没有直接感受到团队成员所面临的压力。当团队向经理解释情况时，没有任何改变。团队成员认为他们没有被听到，这让他们感到与管理团队的距离太远了。工单的超载持续了几个月，让团队成员变得脾气暴躁，直到一连串的不愉快情绪蔓延到整个团队。 问题陈述 在失去两个人并接受额外和各种各样的工作后，我们的团队感到超负荷。当我们试图将这种感觉传达给我们的直接经理时，经理不以为然。随着工作时间的延长，人们开始精疲力竭，生产力正在下降，任务增加的速度开始快于团队解决问题的速度。感知到的过载现在变成了客观过载，使情况变得更糟。 超负荷造成的情绪压力降低了士气，导致一些团队成员倦怠。当个人处理工作过度对身体的影响（疾病和低生产力）时，团队中的其他人不得不承担更多的工作，在每周的团队会议上分配的工作没有完成。 然后我们开始假设我们不能依赖其他人来完成他们的工作，这削弱了团队内部的信任和可靠性。因此，我们对人际风险承担感到不安全，这是心理安全的一个重要因素（见第11章网站可靠性工程）。团队成员感觉不被其他团队成员接受和尊重，因此他们之间没有自由地相互协作。随着团队心理安全的减弱，协作停止，信息共享速度减慢，导致效率进一步低下。 团队调查还显示，他们的心理安全受损——团队成员表示，他们并不觉得自己属于团队。他们不再关心他们的职业发展，团队晋升率也降到了历史最低点。 当高层管理人员为我们分配了新的强制性全公司项目时，我们终于达到了一个突破点，在这一点上，我们重新与管理层就过载问题进行了对话。一系列的讨论表明，我们不愉快的情况不仅仅是工作太多的结果——我们对团队安全的看法使我们不再相互信任和合作。 我们决定做什么 上层管理人员为我们团队指派了一位新经理，他不是供职于三个团队。新经理采用参与式管理方式来改善团队的心理安全，以便我们再次合作。该方法使团队成员能够积极参与解决团队问题。整个团队，包括我们的直接经理，都参与了一系列简单的团建活动，以提高我们的团队效率（其中一些活动就像一起喝茶一样简单）。最终，我们能够起草一套目标： 短期：缓解压力，提高心理安全，营造健康的工作氛围。 中期：通过培训建立团队成员的信心；找到导致过载问题的根本原因。 长期：解决正在发生的导致级联的问题。 为了设定这些目标，我们首先必须在团队中达到某种基本的心理安全。随着士气的提高，我们开始分享知识、并在彼此想法的基础上找到让我们的工作负荷得到控制的方法。 实现 短期行为 长期压力，无论是过度工作还是对团队安全的看法，都会降低生产力并影响人们的健康。因此，我们最重要的短期行动是减轻压力，提高信任和心理安全。一旦缓解了一些压力，团队成员就可以更清晰地思考并参与推动整个团队向前发展。在确定过载的一个月内，我们实施了以下措施： 开始了一个非定期的圆桌会议来讨论问题。该团队释放了挫败感，并对可能导致超负荷的原因进行了头脑风暴。 找到更好的衡量负载的指标。我们决定改进我们原有的页数标准，我们自动给值班人员分配工单，即使在轮班结束后，值班人也要负责这些工单。我们的新指标衡量了一位值班人在轮班后处理工单所需的时间。 审核并删除垃圾邮件警报。我们审核了警报，并删除了那些不代表面向用户问题的警报。 屏蔽大量警报。这个团队故意不去寻找每一个警报的来源，而是专注于减轻压力，避免因为我们已经知道的问题而不断接到警报和提工单。我们使用了以下策略： ——已知的警报在被修复之前一直处于屏蔽状态。 ——警报只能在有限的一段时间内被屏蔽（通常是一天，有时长达一周）。否则，他们可能会掩盖故障。 ——几分钟内无法修复的警报被分配到一个跟踪工单上。 增加了一个专门针对单个团队的直接经理。让一个受人尊敬的团队成员成为新经理重新建立了对管理的信任。新经理可以将更多时间集中在团队及其成员上，而不是管理三个团队。 重新平衡团队。我们通过添加技术经验丰富的SREs来引入新的视角并减轻值班人员的压力，这些SREs对团队或组织没有先入为主的观念。找到合适的人并不是一件容易的事，但值得付出努力。 举办团体活动，如午餐和棋盘游戏。谈论与工作无关的话题，一起大笑，缓解团队的紧张局势，提高心理安全性。 中期行为 单靠短期解决方案无法维持良好的氛围——例如，我们的短期策略之一就是在没有真正解决问题的情况下屏蔽报警。在三个月内，我们还采取了一下行动： 值班期间尽可能减少运维工作（参见SRE第29章），以便团队可以专注于永久性修复和项目工作。 将一项服务的责任归还给其开发团队。 相互培训（和新的团队成员）。虽然培训需要投入时间和精力，但传播知识意味着所有团队成员（以及未来的雇员）可以在未来更快地排除故障并解决问题。培训同时提高了我们的信心，因为我们意识到我们实际上对服务有很多了解。当他们获得知识时，团队成员开始寻找管理服务的新方法，提高可靠性和减少过载。 从其他团队中引入SREs来安排我们的一些值班工作并参与培训。他们注意到了团队的压力，并提供了一些有价值的新视角。 在团队中重新扮演了两个开放的角色。 在报警屏蔽过期解决每个报警。我们在周会中讨论了没有采取任何操作的重复报警，这让我们调整了报警或修复了潜在的问题。虽然这些是重要的（和明显的）行为，我们只有在报警被屏蔽情况下才有足够的空间进行分析和采取行动而不是制造持续的噪音。 有组织的聆听活动。管理层（包括跳级经理和团队领导）有意识地倾听团队的痛点并找到一个团队驱动的解决方案。 增加视角。希望不是一种策略，但它确实有助于提升团队士气。随着新成员加入on-call，转变为更清晰的优先事项，以及结束产生报警的项目，团队的情绪得到了改善。 长期行为 为了保持我们新发现的稳定，我们目前正在将我们的SLO与其服务后端的SLO保持一致，并努力使服务更加统一。统一具有双重好处：它降低了SRE的心理负荷，并使编写可以跨服务使用的自动化变得更加容易。我们还回顾了已经存在了很长时间的服务，并将它们更新到当前的生产标准。例如，一些服务在负载下运行很差，这些年来显著增加。某些服务更需要根据其后端服务策略的更改进行更新。其它服务几年来一直没有更新。 成效 我们在第一次头脑风暴会议后的几个月，结果开始浮出水面：on-call轮班期间变得更安静了，我们的团队成功地快速有效地处理了一个棘手的时间。不久，新的团队成员加入。当我们在圆桌会议上讨论心理安全时，新成员说他们无法想象团队会有这样的问题。事实上，他们认为我们的团队是一个温暖而安全的工作场所。在最初的升级后大约一年，最初的超负荷几乎没有，一项匿名调查显示，团队成员现在觉得这个团队是高效和安全的。 经验总结 工作场所的变化会对团队中的人产生心理影响——毕竟，你的队友不是机器。你需要关注团队的压力水平这样人们就会开始互相信任，一起工作；否则，团队可能会进入导致压力的过载中恶性循环，从而阻止你应对过载。 事实上，感知过载是过载，并且对团队的影响与其他因素造成的工作过载一样大。在我们的案例中，我们在悉尼的姐妹团队没有遇到同样的问题，与前几年相比，我们解决的报警数量并没有太大的变化。相反，失去两名团队成员，感知过载增加，工单增加以及新的3天的工单让团队感觉超负荷了。最终，客观和感知超载之间的区别并不重要：一些团队成员的管制过载会很快导致整个团队的超负荷。 减轻过载的策略 外部视角有时可以很容易地识别团队何时超负荷。同样，回顾一下应该采取什么行动也很容易。但当你正在体验它时，你将如何识别过载？当你陷入过载困境时，通往健康、友好和快乐的工作氛围的道路很难想象。本节介绍了识别和减轻团队过载的实践。 识别过载的症状 如果你知道过载的症状，很容易识别出一个超负荷的团队： 团队士气降低： 过载可能表现为咆哮和抱怨。相关主题（工作条件、工作满意度、项目、同事和经理）的调查通常反映团队士气，并在团队超负荷时产生更多负面结果。与团队领导定期积极的聆听会议可以解决你不了解的问题。积极倾听的一个基本要素是不经过判断就倾听。 团队成员长时间工作，或生病时工作： 没有补偿的加班可能是心理压力源。领导者应该梳理一个好榜样：生病时待在家里。 更频繁的疾病： 过度工作的团队成员往往会经常沮丧和生病 不健康的任务队列： 我们建议定期查看团队的任务队列，已查看积压的工单，处理哪些问题以及可以延迟或删除那些任务。如果团队错过最后期限，或者紧急事件阻止你定期执行此审核，那么团队很可能会比他们所能处理的更快地累积中断。 不平衡的指标： 一些关键的指标可能表明你的团队过载 * 长时间关闭某个问题 * 长时间花费在艰难进行的工作上 * 大量的时间来关闭来自于调用会话的问题 团队应该共同决定使用哪些措施。没有一种适合所有人的方法；每个团队的超负荷都会以不同的方式放映出来。作为经理，在不了解每个人的工作量和工作习惯的情况下，不要对团队施加措施。如果坚持使用特定措施，团队成员可能会觉得你不理解工作。例如，如果你按照修复问题所需的天数来评估负载，那么一个人可能会整整一天解决问题，而另一个人可能会在几天内将工作分配到其他工作中。 减少团队压力维持团队健康状态 阅读完标准后，你可能会认为你的团队已经超负荷了。不要绝望！本节提供了一个让你的团队恢复健康状态的方法。 通常，给团队成员更多的控制和权力可以减少感知到的压力。虽然有压力的情况下求助于微管理，但重要的是要让团队处于循环状态中，并将优先级放在一起，以提高绩效和工作满意度。这个模型假设一个团队成员之间有着健康的人际关系之中。 识别并减轻心理压力源 当要调整一个超负载的团队时，最重要的是团队成员需要重建心理安全。团队和每个成员都是息息相关的。 你可以从识别每个人和整个团队的心理压力源开始。实际哪些因素影响团队的压力？你无法控制团队成员是否患有重大疾病，但你可以控制团队面临压力的大小（如案例研究1中所示）或屏蔽报警（如案例研究2）。 与你的合作的产品开发人员团队沟通，让他们知道你的团队的压力。他们或许可以伸出援助之手，甚至接管整个项目。 当你的团队成员相互依赖并达到一定程度的心理安全（这样他们能够承担人际风险）时，你可以让个别成员承担更多的责任，学习其他领域的专业知识，并将专业人员物尽其用，从而提高他们的自信心，使他们能够承担风险的重任。 决策应该是透明的，如果可能的话，应该是民主的。每个团队成员都应该对面对的情况有一种控制感。例如，案例研究2中的头脑风暴会议帮助团队识别和讨论问题。 在四分之一的范围内优先处理和分类 健康的团队会首先处理重要的问题并对问题进行分类。案例研究1为这个观点提供了一个很好的例子：团队坐在一起并审查他们积压的问题。审查帮助他们意识到他们超载了。他们重新确定了工作优先级后，并完成了可以迅速减少负载的任务。案例研究2中的团队现在每个季度末召开会议，共同规划现有和未来工作并确定其优先顺序。 如果可能，我们建议SRE在其日历上安排无中断时间（没有on-call），这样他们就有时间处理技术深度上很困难的任务，如开发自动化和调查中断你的根本原因。在案例研究2中，当外部团队给予on-call一些解脱时，团队成员则有宝贵的时间专注于他们的项目。 如果绝对必要，放弃一些工作内容：在案例研究2中，团队通过将此职责交还给开发团队，放弃了对其中一项服务的on-call支持。 在未来保护自己 我们强烈建议制定指标来评估团队的工作量。定期查看指标，确保他们正在衡量正确的事情。 一旦你的团队出现过载，你可以通过采取措施监控或解决潜在问题来防止过载进一步恶化。例如，案例研究1中的团队现在维护一个轻量级的分类流程，以检测不断增加的积压任务。案例研究2中的团队目前正在制定一项长期计划，以协调后端和服务SLO。 当你的团队处于超负荷状态时，优先考虑工程工作，即使你没有超负荷工作，也会比重复工作更重要，在将来你会获得利益。 最后，团队中的每个人都应对预警信号负责（请参见第366也的“识别过载症状”），以指示可能出现的过载情况。如果管理人员认为团队正在走向过载，他们应该坐下来与团队成员交谈。 结论 在完美的世界中，SRE团队始终能够使用我们的第一本书中描述的策略来管理中断。但我们只是人类，我们的团队没有达到那个理想状态。本章研究了过载情况下如何建立团队健康的方法，并讨论了如何在它发生时检测和响应。 特别实在运营工作方面，过度的中断很容易导致团队从正常工作负载滑落到过载。频繁的中断可能导致过载，过载会对健康和生产力产生负面影响。超载会给团队成员带来心理社会压力因素，进一步影响工作，导致自我强制循环。 感知过载是一种特殊的过载形式，无法通过劳动量或操作量来衡量。很难确定和消除。为了使团队的工作量保持平衡，持续监控（感知的或为感知的）过载非常重要。为了更好地为用户服务并做好工作，你需要首先尊重自己和团队。在日常工作中保持健康的平衡对于帮助你和你的团队实现这一目标有很大帮助。</summary></entry><entry><title type="html">第十六章 灰度部署 (金丝雀部署)</title><link href="http://localhost:4000/sre/2020/01/16/%E7%81%B0%E5%BA%A6%E9%83%A8%E7%BD%B2/" rel="alternate" type="text/html" title="第十六章 灰度部署 (金丝雀部署)" /><published>2020-01-16T00:00:00+08:00</published><updated>2020-01-16T00:00:00+08:00</updated><id>http://localhost:4000/sre/2020/01/16/%E7%81%B0%E5%BA%A6%E9%83%A8%E7%BD%B2</id><content type="html" xml:base="http://localhost:4000/sre/2020/01/16/%E7%81%B0%E5%BA%A6%E9%83%A8%E7%BD%B2/">&lt;blockquote&gt;
  &lt;p&gt;发布工程是一个术语，用来描述从存储库中获取代码发布到生产环境中，之间相关的全部过程和所有组件。自动化发布可以帮助避免许多发布工程的传统缺陷: 重复性和手工任务的辛苦、手动流程的不一致性、无法了解上线的确切状态以及回滚困难。发布工程的自动化已经在其他文献中得到了很好的介绍——例如，关于持续集成和持续交付的书籍(CI/CD)。&lt;br /&gt;
  我们将灰度发布定义为：对服务进行部分且有时间限制的变更部署，并同时进行评估。该评估将帮助我们决定是否继续上线。变更的服务部分是&lt;code class=&quot;highlighter-rouge&quot;&gt;the canary&lt;/code&gt;，服务的其余部分是&lt;code class=&quot;highlighter-rouge&quot;&gt;the control&lt;/code&gt;。支持这种方法的逻辑是，灰度发布通常在线上进行小流量发布，或者影响比&lt;code class=&quot;highlighter-rouge&quot;&gt;the control&lt;/code&gt;部分少得多的用户上。灰度发布是一个有效的A/B测试过程。&lt;br /&gt;
  我们将首先介绍发布工程的基础知识，以及通过自动化发布来建立共享词汇的益处。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!-- more --&gt;
&lt;h2 id=&quot;发布工程原理&quot;&gt;发布工程原理&lt;/h2&gt;
&lt;p&gt;发布工程的基本原理如下:&lt;/p&gt;
&lt;h5 id=&quot;可再生构建&quot;&gt;可再生构建&lt;/h5&gt;
&lt;p&gt;构建系统应该能够接受构建输入(源代码、资产等)并生成相同结果。与上周相同的输入(构建代码)应该在本周产生相同的输出。&lt;/p&gt;
&lt;h5 id=&quot;自动化构建&quot;&gt;自动化构建&lt;/h5&gt;
&lt;p&gt;一旦代码上传之后，能够自动化生成构建组件并将其上传到存储系统。&lt;/p&gt;
&lt;h5 id=&quot;自动化测试&quot;&gt;自动化测试&lt;/h5&gt;
&lt;p&gt;一旦自动构建系统构建了组件，某种类型的测试套件应该确保它们正常工作。&lt;/p&gt;
&lt;h5 id=&quot;自动化部署&quot;&gt;自动化部署&lt;/h5&gt;
&lt;p&gt;部署应该由计算机执行，而不是人。&lt;/p&gt;
&lt;h5 id=&quot;小型部署&quot;&gt;小型部署&lt;/h5&gt;
&lt;p&gt;构建系统应该支持小的、自包含的更改。&lt;/p&gt;

&lt;p&gt;这些原则为运维人员带来直接收益:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;通过消除手工和重复的任务来减轻工程师的操作负担。&lt;/li&gt;
  &lt;li&gt;强制同行评审和版本控制，因为自动化通常是基于代码的。&lt;/li&gt;
  &lt;li&gt;建立一致的、可重复的、自动化的流程，从而减少错误。&lt;/li&gt;
  &lt;li&gt;添加对发布管道的监控，通过解决以下问题进行测量和持续改进:
    &lt;ul&gt;
      &lt;li&gt;–发布版本需要多长时间生产环境才生效?&lt;/li&gt;
      &lt;li&gt;–发布成功的频率是多少?一个成功的版本是一个没有严重缺陷或SLO违规的、客户可用的版本。&lt;/li&gt;
      &lt;li&gt;–可以做哪些更改来尽早的捕获管道中的缺陷?&lt;/li&gt;
      &lt;li&gt;–哪些步骤可以并行化或进一步优化?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CI/CD与发布自动化相结合可以持续改进开发周期，如图16-1所示。当发布自动化时，你可以更频繁地发布。对于变更率很高的软件来说，更频繁地发布意味着在任何给定的发布工件中捆绑更少的更改。而更小的、自包含的发布工件使得在出现bug时回滚任何给定的发布工件变得成本更低、更容易。更快的发布节奏意味着可以更快地修复bug。
&lt;img src=&quot;/blog/something/images/SRE/16-1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;平衡发布速度和可靠性&quot;&gt;平衡发布速度和可靠性&lt;/h2&gt;

&lt;p&gt;快速发布(以下称为&lt;code class=&quot;highlighter-rouge&quot;&gt;发布&lt;/code&gt;)和可靠性常常被视为相反的目标。企业希望以100%的可靠性尽快发布新特性和产品改进!然而这个目标是不可能实现的(因为100%从来不是可靠性的正确目标;参见第2章)，但可以在满足特定产品的特定可靠性目标的同时，尽可能快地进行交付。&lt;/p&gt;

&lt;p&gt;实现这个目标的第一步是了解发布对软件可靠性的影响。在谷歌的经验,大多数事件都是由二进制或配置推送导致的(见附录C)。许多类型的软件更改都可能导致系统故障 - 例如，底层组件的行为更改，依赖关系（例如API）的更改，或DNS等配置更改。&lt;/p&gt;

&lt;p&gt;尽管对软件进行变更存在固有的风险，但是这些变更(bug修复、安全补丁和新特性)对业务的成功是必需的。你可以使用SLOs和错误预算的概念来衡量发布新版本对可靠性的影响，而不是提倡反对变更。你的目标应该是在满足用户期望的可靠性目标的同时尽快发布软件。下一节将讨论如何使用canary流程来实现这些目标。&lt;/p&gt;

&lt;h3 id=&quot;分离变更频率不同的组件&quot;&gt;分离变更频率不同的组件&lt;/h3&gt;

&lt;p&gt;服务由具有不同变更频率的多个组件组成:二进制文件或代码、基础环境(如JVM、内核/OS)、库、服务配置或标志、特性/测试配置和用户配置。如果只有一种发布变更的方法，那么这些组件单独变更会比较困难。&lt;/p&gt;

&lt;p&gt;特性标志或测试框架(如Gertrude、Feature和PlanOut)允许你将特性启动从二进制版本中分离出来。如果二进制版本包含多个特性，你可以通过更改测试配置一次启用一个特性。这样，就没有必要将这些小的变更集合为一个大的变更，或者为每个特性执行单独的版本。更重要的是，如果只有一些新特性的行为不像预期的那样，你可以选择性地禁用这些特性，直到下一个构建/发布周期可以部署新的二进制文件为止。&lt;/p&gt;

&lt;p&gt;你可以将特性标志/试验原则应用于服务的任何类型的更改，而不仅仅是软件版本。&lt;/p&gt;

&lt;h2 id=&quot;canarying是什么&quot;&gt;Canarying是什么？&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Canarying&lt;/code&gt;一词是指将金丝雀带入煤矿以确定该矿是否对人类安全的做法。 由于鸟类比人类更小，呼吸更快，因此它们被危险气体毒害的速度比人类更快。&lt;/p&gt;

&lt;p&gt;即使你的发布管道是完全自动化的，在真正的流量到达服务之前，你依然无法检测到所有与发布相关的缺陷。当一个发布版本准备好部署到生产环境中时，你的测试策略应该充分保证该版本是安全的，并且按预期工作。然而，测试环境与生产环境并不是100%相同的，并且测试不可能会涵盖100％的场景。依然会存在一些会影响生产缺陷。如果一个版本立即部署到系统的全部地方，那么可能存在的缺陷亦将到达系统的全部地方。&lt;/p&gt;

&lt;p&gt;如果你能够快速地检测和解决缺陷，则可以接受此方案。但是，更安全的选择是:首先使用灰度发布向新版本导入一些生产流量。灰度发布允许部署管道在尽可能少地影响你的服务的前提下，更快地检测出问题。&lt;/p&gt;

&lt;h2 id=&quot;发布工程和灰度发布&quot;&gt;发布工程和灰度发布&lt;/h2&gt;

&lt;p&gt;在部署系统的新版本或其关键组件(如配置或数据)时，我们将变更(通常未公开给真实输入的更改，如面向用户的流量、或用户提供的批处理数据)打包。变更会带来新的特性和功能，但也存在部署之后出现问题的风险。我们的目标是通过测试一小部分流量来降低风险，以确保没有任何不良影响。我们将在本章后面讨论评估过程。&lt;/p&gt;

&lt;p&gt;灰度过程还让我们对变更充满信心，因为我们将其暴露给越来越大的流量。为变更引入实际生产流量还使我们能够识别在单元测试或负载测试等测试框架中可能不可见的问题，这些问题通常更为人为。&lt;/p&gt;

&lt;p&gt;我们将使用一个实际的示例来检查灰度过程及其评估，同时避免深入研究统计数据。相反，我们关注点是整个过程和典型的实际考虑。我们使用App Engine上的一个简单应用程序来说明发布的各个方面。&lt;/p&gt;

&lt;h3 id=&quot;灰度发布流程的需求&quot;&gt;灰度发布流程的需求&lt;/h3&gt;

&lt;p&gt;针对特定服务的灰度发布需要特定功能：
将变更通过灰度发布部署到服务全部子集的方法。      &lt;br /&gt;
一个评估过程，用来评估变更是&lt;code class=&quot;highlighter-rouge&quot;&gt;好&lt;/code&gt;还是&lt;code class=&quot;highlighter-rouge&quot;&gt;坏&lt;/code&gt;。
将评估集成到发布过程中。&lt;/p&gt;

&lt;p&gt;最后，当灰度检测到有问题的发布版本，并在没有误报的情况下识别出好的发布版本时，灰度发布展示了它的价值。&lt;/p&gt;

&lt;h3 id=&quot;我们的示例环境&quot;&gt;我们的示例环境&lt;/h3&gt;

&lt;p&gt;我们将使用一个简单的前端web服务应用程序来演示一些灰度发布的概念。该应用程序提供了一个基于http的API，消费者可以使用它来操作各种数据(如产品价格等简单信息)。示例应用程序有一些可调参数，我们可以使用这些参数来模拟各种生产环境，由灰度发布流程进行评估。例如，可以让应用程序为20%的请求返回错误，或者规定5%的请求至少需要两秒钟。&lt;/p&gt;

&lt;p&gt;我们使用部署在谷歌应用程序引擎上的应用程序来演示灰度发布流程，这些原则同样适用于其他环境。虽然示例应用程序是经过设计的，但是在实际场景中，类似的应用程序与我们的示例可以共享灰度发展中使用的指标。&lt;/p&gt;

&lt;p&gt;我们的示例服务有两个可能的版本:当前版本和候选版本。当前版本是当前部署在生产环境中的版本，而候选版本是新构建的版本。使用这两个版本来说明发布概念，以及如何实现灰度发布以使发布过程更安全。&lt;/p&gt;

&lt;h2 id=&quot;回滚部署与简单的canary部署比较&quot;&gt;回滚部署与简单的Canary部署比较&lt;/h2&gt;

&lt;p&gt;我们将在发生中断时根据错误预算节省和一般影响，来对没有灰度发布的部署流程和灰度发布流程进行比较。我们的部署过程以开发环境为基础。一旦我们感觉代码在开发环境中正常工作，我们就将该版本部署到生产环境中。&lt;/p&gt;

&lt;p&gt;在部署之后不久，监视开始报高错误率(参见图16-2，在图16-2中，为了模拟示例服务中的缺陷，对示例应用程序进行配置以使20％的请求失败)。对于示例，假设部署流程不支持回滚到以前已知的配置正常的版本时。修复这些错误的最佳选择就只有在生产版本中查找缺陷，对其进行补救，并在停机期间重新部署一个新版本。这种做法肯定会延长错误对用户的影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/16-2.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图 16-2 部署之后错误率增加 &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;为了改进这个初始部署过程，我们可以在使用灰度发布来减少推送错误代码所造成的影响。 我们需要一种方法来在小部分生产环境中运行候选版本，而不是一次性部署到生产环境。 然后将一小部分流量发送到该生产环境（the canary金丝雀）并将其与其他部分（the control 主控）进行比较。 使用此方法，我们可以在所有生产受到影响之前发现候选版本中的缺陷。&lt;/p&gt;

&lt;p&gt;我们在示例应用程序中的进行简单灰度发布，在应用程序的特定版本之间分配流量。 您可以使用App Engine或其他任何方法来分割流量（例如负载均衡器上的后端权重，代理配置或循环DNS记录）。&lt;/p&gt;

&lt;p&gt;图16-3显示了当我们使用灰度发布，变更的影响会大大降低;事实上，这些错误几乎不可见!这提出了一个有趣的问题:与总体流量趋势相比，灰度发布的流量趋势很难看到和跟踪。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/16-3.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图 16-3 部署之后错误率增canary部署错误率； 因为进行canary部署的只是系统的一小部分，因此总体错误率降低 &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;为了更清楚地了解需要在合理范围内跟踪的错误，我们可以通过App Engine应用程序版本查看关键指标(HTTP响应代码)，如图16-4所示。当我们查看每个版本的分解趋势图时，我们可以清楚地看到新版本引入的错误。我们还可以从图16-4中观察到当前版本提供的错误非常少。&lt;/p&gt;

&lt;p&gt;现在，我们可以根据应用程序版本的HTTP错误率对部署进行调优。如果灰度发布的错误率大于全部系统的错误率，这表明canary部署是&lt;code class=&quot;highlighter-rouge&quot;&gt;糟糕的&lt;/code&gt;。我们应该暂停并回滚部署，或者联系他人来帮助解决问题。如果错误率相似，我们可以正常地进行部署。在图16-4中，我们的canary部署显然很糟糕，我们应该回滚它。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/16-4.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图 16-4 应用程序HTTP响应码； 新版本产生多数错误、当前版本产生小数错误（图中显示10%的log） &lt;/center&gt;&lt;/p&gt;

&lt;h2 id=&quot;canary实施&quot;&gt;Canary实施&lt;/h2&gt;

&lt;p&gt;现在我们已经看到了一个相当简单的canary部署实现，接下来让我们更深入地了解成功的canary流程所需的参数。&lt;/p&gt;

&lt;h3 id=&quot;最小化slos和错误预算的风险&quot;&gt;最小化SLOs和错误预算的风险&lt;/h3&gt;

&lt;p&gt;第2章讨论了SLOs如何反映设计服务可用性的业务需求。这些需求也可以通过canary实现。canary进程的风险仅仅是我们错误预算的一小部分，它受到时间和canary规模大小的限制。&lt;/p&gt;

&lt;p&gt;全局部署会很快将SLO置于危险之中。如果实例中为系统全面部署候选版本，我们将面临20%的请求失败的风险。如果我们使用5%的canary规模，我们将为5%的流量提供20%错误，导致1%的总体错误率(如图16-3所示)。这个策略允许我们保留我们的错误预算—预算的影响与暴露于缺陷的流量的数量成正比。我们可以假设，对于全局部署和灰度部署，检测和回滚花费的时间差不多，但是当我们将灰度发布集成到部署过程中时，我们会以更低的成本获得有关新版本的有价值信息。&lt;/p&gt;

&lt;p&gt;这是一个假设负载均匀的极简模型。它还假设我们可以将整个错误预算用于灰度发布。这里我们只考虑新版本引入的不可用性，而不是实际可用性。我们的模型还假设新版本具有100%的失败率，这是最坏的情况。而进行灰度的部分不会导致线上系统100%不可用。我们还允许在灰度部署期间，整个系统的可用性低于SLO。&lt;/p&gt;

&lt;p&gt;这个模型有明显的缺陷，但它是一个可靠的起点，你可以根据业务需求进行调整。我们建议使用最简单的模型来满足你的技术和业务目标。根据我们的经验，专注于使模型在技术上尽可能正确，常常会导致在建模上的过度投资。对于具有高复杂性的服务，过于复杂的模型可能导致持续的模型调优，而没有真正的好处。&lt;/p&gt;

&lt;h3 id=&quot;选择灰度规模和持续时间&quot;&gt;选择灰度规模和持续时间&lt;/h3&gt;

&lt;p&gt;选择合适的灰度持续时间，需要考虑发布频率。 如果需要每天发布，那么在一次只运行一个灰度的情况下，无法使灰度保持一周,如果每周部署一次，就可以执行较长的灰度发布。 如果持续部署（例如，一天20次），灰度的持续时间必须明显缩短。 在一些说明里，虽然可以同时运行多个灰度，但这样做会增加大量精力来跟踪系统状态。 在任何情况下，需要快速推断系统状态时，同时运行多个灰度会成为问题。如果灰度重叠，同时运行多个灰度也会增加信号污染的风险。我们强烈建议一次只运行一个灰度。&lt;/p&gt;

&lt;p&gt;对于基本的评估，不需要大规模的灰度来检测关键条件。然而，一个有代表性的灰度发布流程需要跨多个维度进行决策:&lt;/p&gt;

&lt;h2 id=&quot;规模和持续时间&quot;&gt;规模和持续时间&lt;/h2&gt;

&lt;p&gt;它的规模应够大，持续时间应够长，足以代表整个部署。仅在接收到少量查询后终止canary部署，对于以具有不同功能的不同查询为特征的系统来说，这无法提供有用的信号。处理率越高，获取代表性样本所需的时间就越少，以确保所观察到的行为实际上是由变更引起的，而不仅仅是随机因素。&lt;/p&gt;

&lt;p&gt;流量&lt;/p&gt;

&lt;p&gt;我们需要在系统上接收足够的流量，以确保它是一个具有代表性的示例，并且系统有机会对输入做出负面反应。通常，请求越均匀，所需要的流量就越少。&lt;/p&gt;

&lt;p&gt;时间点&lt;/p&gt;

&lt;p&gt;性能缺陷通常只在高负载下出现，因此在非高峰时间部署可能不会触发性能相关的缺陷。&lt;/p&gt;

&lt;p&gt;度量指标&lt;/p&gt;

&lt;p&gt;灰度的代表性与我们选择评估的指标密切相关(我们将在本章后面讨论)。我们可以快速评估诸如查询成功之类的琐碎指标，但是其他指标(如队列深度)可能需要更多的时间或较大规模的灰度来提供清晰的信号。&lt;/p&gt;

&lt;p&gt;但问题是，这些要求可能相互冲突。Canarying是一种平衡行为，它通过对最坏情况的冷静分析和系统过去的实际记录来实现。一旦您从过去的灰度中收集了指标，您就可以根据典型的canary评估失败率而不是假想的最坏情况来选择canary参数。&lt;/p&gt;

&lt;h3 id=&quot;选择和评估度量标准&quot;&gt;选择和评估度量标准&lt;/h3&gt;

&lt;p&gt;到目前为止，我们一直在研究成功率，这是评估灰度发布的一个非常清晰和明显的指标。但是直觉上，我们知道这个单一的指标对于有意义的canary流程来说是不够的。如果我们以10倍的延迟为所有请求提供服务，或者在这样做时使用10倍的内存，那么我们可能也会遇到问题。并不是所有的指标都适合评估灰度发布。哪些指标最适合评估灰度发布版本是好是坏?&lt;/p&gt;

&lt;h3 id=&quot;度量标准应指出问题&quot;&gt;度量标准应指出问题&lt;/h3&gt;

&lt;p&gt;首先，指标需要能够指出服务中的问题。这很棘手，因为构成&lt;code class=&quot;highlighter-rouge&quot;&gt;问题&lt;/code&gt;的并不总是客观的。我们可能会认为用户请求失败是有问题的。但是如果一个请求的响应时间增加了10%，或者系统内存增加了10%?，这该如何判断？我们通常建议使用sla作为开始考虑canary指标的地方。良好的服务质量指数往往与服务健康状况密切相关。如果已经使用SLIs来度量SLO是否符合，那么我们可以重用这些工作。&lt;/p&gt;

&lt;p&gt;几乎任何指标在极端情况下都可能出现问题，但是向灰度流程中添加太多的指标也会产生成本。我们需要为每个指标正确定义可接受行为。如果可接受行为定义过于严格，我们会得到大量的误报;也就是说，我们会认为灰度很糟糕，即使实际不是这样。相反，如果对可接受行为的定义过于宽松，我们更有可能忽略掉有问题的灰度部署。正确选择什么是可接受的行为可能会成本较大——既耗时又需要分析。然而，如果做得不好，错误的结果会完全误导你。此外，随着服务、其特性集和行为的发展，您需要定期重新评估期望。&lt;/p&gt;

&lt;p&gt;我们应该根据这些指标多大程度上能够表明系统中实际用户的体验来进行排名，选择排名靠前的几个指标(可能不超过12个)。太多的度量标准会带来递减的回报，并且在某种程度上，收益会被维护它们的成本所抵消，或者在发布过程中如果不维护它们，会对发布结果无法保证100%的信任。&lt;/p&gt;

&lt;p&gt;为了使这个指导原则更加具体，让我们回头再来看示例。它有许多我们可以评估的指标:CPU使用量、内存占用、HTTP返回码(2xx、3xx等等)、响应延迟、正确性等等。在这种情况下，我们最好的度量标准可能是HTTP返回码和响应延迟，因为它们的降级最接近于实际用户影响。在这个场景中，CPU使用率并没有那么有用:资源使用的增加不一定会影响服务，并且可能导致不稳定或嘈杂的canary进程。这会导致操作人员禁用或忽略canary进程，这会首先破坏使用canary进程的目的。对于前端服务，我们直观地知道，响应较慢或响应失败通常会真实反映服务中存在的问题。&lt;/p&gt;

&lt;p&gt;HTTP返回码包含一些有趣的复杂情况，例如状态码404，它告诉我们没有找到资源。这可能是因为用户获得了错误的URL(想象一下在一个流行的论坛上分享了一个错误的URL)，或者因为服务器错误地停止了对资源的服务。通常，我们可以通过排除canary评估中的400级状态码，并添加黑盒监控来测试特定URL的存在，从而解决此类问题。然后，我们可以将黑盒数据作为canary分析的一部分，以帮助将canary流程与奇怪的用户行为隔离开来。&lt;/p&gt;

&lt;p&gt;度量标准应该具有代表性和可归属性&lt;/p&gt;

&lt;p&gt;观察到的指标变化其来源，应该清楚地归因于正在进行的变更，并且不应该受到外部因素的影响。&lt;/p&gt;

&lt;p&gt;在一个大的系统中(例如，许多服务器或许多容器)，我们可能会有外部性——超过连接的机器、运行具有不同性能特征的不同内核的机器，或者网络中过载的机器。此时金丝雀部分和主系统部分之间的差异，既是我们所部署的两个基础设施之间的差异，也会是我们变更导致的差异。&lt;/p&gt;

&lt;p&gt;管理金丝雀是多种力量之间的平衡。增加金丝雀的规模是减少这个问题影响的方法(如前所述)。当我们的系统达到我们认为的合理的金丝雀规模时，我们需要考虑我们选择的指标是否会显示出很大的差异。&lt;/p&gt;

&lt;p&gt;我们还应该知道canary和control环境之间共享的失败域;坏金丝雀会对控制产生负面影响，而系统中的坏行为可能会导致我们错误地评估金丝雀。同样，确保您的度量标准是良好隔离的。考虑一个同时运行我们的应用程序和其他进程的系统。整个系统的CPU使用量的急剧增加会导致糟糕的度量，因为系统中的其他进程(数据库负载、日志轮转等)可能会导致这种增加。更好的度量标准是在处理请求时所花费的CPU时间。更好的度量标准是在服务进程实际计划在CPU上的时间窗口上为处理请求服务所花费的CPU时间。虽然与我们的进程相关的严重超额的机器显然是一个问题(监控应该捕捉到它!)，但它不是由我们正在进行的更改引起的，因此不应该将其标记为金丝雀部署失败。&lt;/p&gt;

&lt;p&gt;金丝雀也需要是可归属的;也就是说，您还应该能够将canary度量与SLIs联系起来。如果一个度量可以在不影响服务的情况下发生巨大变化，那么它不适合用来评估灰度发布。&lt;/p&gt;

&lt;h3 id=&quot;评估前评估后依然是有风险的&quot;&gt;评估前/评估后依然是有风险的&lt;/h3&gt;

&lt;p&gt;canary过程的前后是归因问题的延伸。在这个过程中，旧系统被新系统完全替代，你的canary评估将在一段时间内比较变更之前和之后的系统行为。你可以将此过程称为&lt;code class=&quot;highlighter-rouge&quot;&gt;时空中的canary部署&lt;/code&gt;，在此过程中，您通过分割时间来选择A/B组，而不是通过机器、cookie或其他方法来分割总体。由于时间是观察到的指标变化的最大来源之一，因此很难在评估之前/之后来判断性能是否下降。&lt;/p&gt;

&lt;p&gt;虽然canary部署可能导致降级，但原有系统本身也可能会降级。如果需要长时间运行canary部署，就会变得更加复杂。例如，如果在周一进行发布，可能会将工作日的行为与周末的行为进行比较，从而引入大量噪音。在该示例中，用户可能在周末以不同的方式访问该服务。从而在canary进程中引入噪音。&lt;/p&gt;

&lt;p&gt;评估前/后过程本身引入了一个问题，即大而短的错误率(由前/后评估引入)是否优于小而长的错误率(由一个小金丝雀引入)。如果新版本完全被破坏，我们能多快地检测和恢复? 大规模的金丝雀之前/之后可以更快地检测到问题，但恢复的总体时间可能仍然相当长，与较小的金丝雀类似。在此期间，用户会一直受到影响。&lt;/p&gt;

&lt;h3 id=&quot;使用渐进的灰度会更好&quot;&gt;使用渐进的灰度会更好&lt;/h3&gt;

&lt;p&gt;选择的度量标准即使不符合我们理想中的属性，但仍然很有价值。我们可以通过使用更细微的灰度过程来介绍这些指标。&lt;/p&gt;

&lt;p&gt;我们可以使用包含多个阶段的canary来反映我们对度量的推理能力，而不是简单地评估单个canary阶段。在第一阶段，我们对这个版本没有信心或不了解。因此，我们希望使用一个小的阶段，以尽量减少负面影响。在小型灰度中，我们更喜欢能够最清晰地显示问题的指标——应用程序崩溃、请求失败等等。一旦这一阶段成功地过去，下一阶段将增加灰度规模，从而增强我们分析变化影响的信心。&lt;/p&gt;

&lt;h2 id=&quot;依赖和隔离&quot;&gt;依赖和隔离&lt;/h2&gt;

&lt;p&gt;正在测试的系统不会在完全真空中运行。出于实际原因，灰度和主系统可以共享后端、前端、网络、数据存储和其他基础设施。甚至可能与客户端有非常不明显的交互。例如，假设一个客户端发送了两个连续的请求。第一个请求可以由灰度部分来处理。其响应可能会改变第二个请求的内容，第二个请求可能会落在主系统部分，从而改变主系统的行为。&lt;/p&gt;

&lt;p&gt;不完美的隔离会带来几个后果。最重要的是，我们需要知道，如果灰度过程的结果表明我们应该停止生产变更并调查情况，那么灰度并不一定是错误的。这一事实对于一般的canarying来说是正确的，但是在实践中，它经常由于隔离问题而导致被强制执行。&lt;/p&gt;

&lt;p&gt;此外，不完美的隔离意味着灰度部署的错误行为也会对原始系统产生负面影响。Canarying是A/B比较，A和B有可能同时改变;这可能会导致评估灰度变得混乱。还必须使用绝对度量，例如定义的SLOs，以确保系统正确运行。&lt;/p&gt;

&lt;h2 id=&quot;在非交互系统中进行canarying&quot;&gt;在非交互系统中进行Canarying&lt;/h2&gt;

&lt;p&gt;本章重点讨论了交互式请求/响应系统，它在许多方面是最简单和最常讨论的系统设计。其他系统，如异步处理管道，也同样重要，但有不同的canarying注意事项，我们将简要列举。有关数据处理管道的canarying的更多信息，请参见第13章。&lt;/p&gt;

&lt;p&gt;首先，canary的持续时间和部署本质上依赖于工作单元处理的持续时间。当涉及到交互系统时，我们忽略了这个因素，假设工作单元处理的时间不会超过几秒钟，这比canary的持续时间要短。非交互式系统中的工作单元处理(如呈现管道或视频编码)可能需要更长的时间。因此，确保canary持续时间至少跨越单个工作单元的持续时间。&lt;/p&gt;

&lt;p&gt;对于非交互式系统，隔离可能变得更加复杂。许多管道系统只有一个工作分配程序和一组使用应用程序代码的工作人员。在多阶段管道中，工作单元由工作人员处理，然后返回到池中，由同一工作人员或另一个工作人员执行下一阶段的处理。金丝雀分析有助于确保处理特定工作单元的工人总是从相同的工人池中提取——要么是金丝雀池，要么是控制池。否则，信号就会变得越来越混杂(有关理清信号的需要的更多信息，请参见349页的&lt;code class=&quot;highlighter-rouge&quot;&gt;监视数据的要求&lt;/code&gt;)。&lt;/p&gt;

&lt;p&gt;最后，度量标准的选择可能更加复杂。我们可能感兴趣的是端到端处理工作单元的时间(类似于交互系统中的延迟)，以及处理本身的质量(当然，这是完全特定于应用程序的)。&lt;/p&gt;

&lt;p&gt;考虑到这些警告，canarying的一般概念仍然是可行的，并且适用相同的高级原则。&lt;/p&gt;

&lt;h2 id=&quot;监控要求&quot;&gt;监控要求&lt;/h2&gt;

&lt;p&gt;在评估灰度部署时，您必须能够将部署了灰度的系统与未部署灰度的系统进行比较。通常，这需要在构造监视系统时多加注意—有效的比较非常简单，并且能够产生有意义的结果。&lt;/p&gt;

&lt;p&gt;考虑之前的例子，在5%的规模中进行灰度，错误率为20%。因为监视很可能将系统作为一个整体来观察，所以它只能检测到1%的总体错误率。根据系统的不同，这个信号可能与其他错误源无法区分(参见图16-3)。&lt;/p&gt;

&lt;p&gt;如果我们通过按照服务请求的对象来（金丝雀与主系统）分解指标，(参见图16-4)我们可以清楚地看到主系统与canary之间的错误率，这清楚地说明了全局部署将带来什么。在这里，我们看到，对整个服务的监控不足以分析灰度是否ok。在收集监视数据时，能够执行细粒度的分解非常重要，这些分解使得能够区分金丝雀和主系统的指标。&lt;/p&gt;

&lt;p&gt;收集指标的另一个难点是金丝雀的部署受到设计的时间限制。当度量指标在特定时期内进行聚合时，这可能会导致问题。考虑每小时的度量误差。我们可以通过对过去一小时的请求求和来计算这个度量。如果我们使用这个度量来评估我们的canary，我们可能会遇到问题，如下面的时间表所述:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;某些事件会导致一些错误发生。&lt;/li&gt;
  &lt;li&gt;一只金丝雀被部署在5%的人口中;金丝雀的持续时间是30分钟。&lt;/li&gt;
  &lt;li&gt;canary系统开始监视每小时的错误度量，以确定部署是好是坏。&lt;/li&gt;
  &lt;li&gt;部署被检测为错误，因为每小时的错误度量与控制总体的每小时的错误显著不同。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;此场景是使用每小时计算一次的度量来评估仅30分钟长的部署的结果。因此，canary进程提供了一个非常模糊的信号。当使用度量来评估canary的成功时，确保度量的间隔与canary的持续时间相同或小于持续时间。&lt;/p&gt;

&lt;p&gt;相关概念&lt;/p&gt;

&lt;p&gt;通常，与客户的对话涉及到在生产中使用蓝/绿部署、人工负载生成和/或流量测试。这些概念类似于canarying，因此虽然它们不是严格意义上的金丝雀流程，但亦可使用。&lt;/p&gt;

&lt;h3 id=&quot;蓝绿部署&quot;&gt;蓝/绿部署&lt;/h3&gt;

&lt;p&gt;蓝/绿部署维护系统的两个实例：一个提供流量（绿色），另一个准备提供流量（蓝色）。 在蓝色环境中部署新版本后，将流量切换到其中。切换过程不需要停机，并且回滚只是简单逆转路由器而已。 一个缺点是该设置使用的资源是&lt;code class=&quot;highlighter-rouge&quot;&gt;传统&lt;/code&gt;部署的两倍。在该设置中，您正在有效地执行前/后金丝雀（前面已讨论过）。&lt;/p&gt;

&lt;p&gt;通过同时(而不是分开地)使用蓝/绿部署，您可以或多或少地将蓝色/绿色部署用作常规的金丝雀。在此策略中，您可以将canary部署到blue(备用)实例，并在绿色和蓝色环境之间缓慢地分配流量。您的评估和比较蓝色环境和绿色环境的指标都应该与流量控制相关。这种设置类似于A/B金丝雀，此时绿色环境是主系统，蓝色环境是金丝雀部署，金丝雀数量由发送到每个金丝雀的流量控制。&lt;/p&gt;

&lt;h3 id=&quot;人工负载生成&quot;&gt;人工负载生成&lt;/h3&gt;

&lt;p&gt;与其将实时用户流量暴露给canary部署，还不如在安全性方面犯点错误，使用人工负载。通常，您可以在多个部署阶段(QA、预生产，甚至在生产中)运行负载测试。虽然根据我们的定义，这些操作不符合canarying，但是它们仍然是找到缺陷的可行方法，但需要注意一些事项。&lt;/p&gt;

&lt;p&gt;使用人工负载进行测试可以很好地最大化代码覆盖率，但不能提供良好的状态覆盖率。在可变系统(具有缓存、cookie、请求关联等的系统)中人工模拟负载尤其困难。人工负载也可能无法准确地模拟真实系统中流量变化。有些问题可能只在无人工负载的情况下出现，从而导致覆盖率有所差距。&lt;/p&gt;

&lt;p&gt;人工负载在可变系统中也很难工作。例如，试图在计费系统上生成人工负载可能非常危险:系统可能开始向信用卡供应商发送呼叫，然后信用卡供应商将开始主动向客户收费。虽然我们可以避免测试危险的代码逻辑，但是在这些逻辑上缺乏测试会降低我们的测试覆盖率。&lt;/p&gt;

&lt;h3 id=&quot;流量测试&quot;&gt;流量测试&lt;/h3&gt;

&lt;p&gt;如果人工流量不具有代表性，我们可以复制流量并将其发送到生产系统和测试环境。这种技术被称为流量镜像。生产系统服务于实际流量并响应请求，canary部署服务于副本流量并丢弃响应。您甚至可以将canary响应与实际响应进行比较，并运行进一步的分析。&lt;/p&gt;

&lt;p&gt;这种策略可以提供有代表性的流量，但通常比更直接的canary流程更复杂。在有状态系统中，流量测试也不能充分识别风险;流量副本可能会在看似独立的部署之间引入意外的影响。例如，如果canary部署和生产系统共享一个缓存，人为导致的缓存命中率增加将使canary指标的性能度量无效。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;您可以使用许多工具和方法来自动化版本发布，并将canarying引入到发布管道中。没有一种测试方法是万能的，测试策略应该由系统的需求和行为决定。Canarying可以作为一种简单、健壮且易于集成的方法来补充测试。当您及早发现系统缺陷时，用户受到的影响最小。Canarying还可以为频繁发布提供信心，并提高开发速度。正如测试方法必须随着系统需求和设计而发展一样，canarying也必须如此。&lt;/p&gt;

&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;</content><author><name>ZX</name></author><category term="《SRE-Google运维实践》" /><summary type="html">发布工程是一个术语，用来描述从存储库中获取代码发布到生产环境中，之间相关的全部过程和所有组件。自动化发布可以帮助避免许多发布工程的传统缺陷: 重复性和手工任务的辛苦、手动流程的不一致性、无法了解上线的确切状态以及回滚困难。发布工程的自动化已经在其他文献中得到了很好的介绍——例如，关于持续集成和持续交付的书籍(CI/CD)。 我们将灰度发布定义为：对服务进行部分且有时间限制的变更部署，并同时进行评估。该评估将帮助我们决定是否继续上线。变更的服务部分是the canary，服务的其余部分是the control。支持这种方法的逻辑是，灰度发布通常在线上进行小流量发布，或者影响比the control部分少得多的用户上。灰度发布是一个有效的A/B测试过程。 我们将首先介绍发布工程的基础知识，以及通过自动化发布来建立共享词汇的益处。 发布工程原理 发布工程的基本原理如下: 可再生构建 构建系统应该能够接受构建输入(源代码、资产等)并生成相同结果。与上周相同的输入(构建代码)应该在本周产生相同的输出。 自动化构建 一旦代码上传之后，能够自动化生成构建组件并将其上传到存储系统。 自动化测试 一旦自动构建系统构建了组件，某种类型的测试套件应该确保它们正常工作。 自动化部署 部署应该由计算机执行，而不是人。 小型部署 构建系统应该支持小的、自包含的更改。 这些原则为运维人员带来直接收益: 通过消除手工和重复的任务来减轻工程师的操作负担。 强制同行评审和版本控制，因为自动化通常是基于代码的。 建立一致的、可重复的、自动化的流程，从而减少错误。 添加对发布管道的监控，通过解决以下问题进行测量和持续改进: –发布版本需要多长时间生产环境才生效? –发布成功的频率是多少?一个成功的版本是一个没有严重缺陷或SLO违规的、客户可用的版本。 –可以做哪些更改来尽早的捕获管道中的缺陷? –哪些步骤可以并行化或进一步优化? CI/CD与发布自动化相结合可以持续改进开发周期，如图16-1所示。当发布自动化时，你可以更频繁地发布。对于变更率很高的软件来说，更频繁地发布意味着在任何给定的发布工件中捆绑更少的更改。而更小的、自包含的发布工件使得在出现bug时回滚任何给定的发布工件变得成本更低、更容易。更快的发布节奏意味着可以更快地修复bug。 平衡发布速度和可靠性 快速发布(以下称为发布)和可靠性常常被视为相反的目标。企业希望以100%的可靠性尽快发布新特性和产品改进!然而这个目标是不可能实现的(因为100%从来不是可靠性的正确目标;参见第2章)，但可以在满足特定产品的特定可靠性目标的同时，尽可能快地进行交付。 实现这个目标的第一步是了解发布对软件可靠性的影响。在谷歌的经验,大多数事件都是由二进制或配置推送导致的(见附录C)。许多类型的软件更改都可能导致系统故障 - 例如，底层组件的行为更改，依赖关系（例如API）的更改，或DNS等配置更改。 尽管对软件进行变更存在固有的风险，但是这些变更(bug修复、安全补丁和新特性)对业务的成功是必需的。你可以使用SLOs和错误预算的概念来衡量发布新版本对可靠性的影响，而不是提倡反对变更。你的目标应该是在满足用户期望的可靠性目标的同时尽快发布软件。下一节将讨论如何使用canary流程来实现这些目标。 分离变更频率不同的组件 服务由具有不同变更频率的多个组件组成:二进制文件或代码、基础环境(如JVM、内核/OS)、库、服务配置或标志、特性/测试配置和用户配置。如果只有一种发布变更的方法，那么这些组件单独变更会比较困难。 特性标志或测试框架(如Gertrude、Feature和PlanOut)允许你将特性启动从二进制版本中分离出来。如果二进制版本包含多个特性，你可以通过更改测试配置一次启用一个特性。这样，就没有必要将这些小的变更集合为一个大的变更，或者为每个特性执行单独的版本。更重要的是，如果只有一些新特性的行为不像预期的那样，你可以选择性地禁用这些特性，直到下一个构建/发布周期可以部署新的二进制文件为止。 你可以将特性标志/试验原则应用于服务的任何类型的更改，而不仅仅是软件版本。 Canarying是什么？ Canarying一词是指将金丝雀带入煤矿以确定该矿是否对人类安全的做法。 由于鸟类比人类更小，呼吸更快，因此它们被危险气体毒害的速度比人类更快。 即使你的发布管道是完全自动化的，在真正的流量到达服务之前，你依然无法检测到所有与发布相关的缺陷。当一个发布版本准备好部署到生产环境中时，你的测试策略应该充分保证该版本是安全的，并且按预期工作。然而，测试环境与生产环境并不是100%相同的，并且测试不可能会涵盖100％的场景。依然会存在一些会影响生产缺陷。如果一个版本立即部署到系统的全部地方，那么可能存在的缺陷亦将到达系统的全部地方。 如果你能够快速地检测和解决缺陷，则可以接受此方案。但是，更安全的选择是:首先使用灰度发布向新版本导入一些生产流量。灰度发布允许部署管道在尽可能少地影响你的服务的前提下，更快地检测出问题。 发布工程和灰度发布 在部署系统的新版本或其关键组件(如配置或数据)时，我们将变更(通常未公开给真实输入的更改，如面向用户的流量、或用户提供的批处理数据)打包。变更会带来新的特性和功能，但也存在部署之后出现问题的风险。我们的目标是通过测试一小部分流量来降低风险，以确保没有任何不良影响。我们将在本章后面讨论评估过程。 灰度过程还让我们对变更充满信心，因为我们将其暴露给越来越大的流量。为变更引入实际生产流量还使我们能够识别在单元测试或负载测试等测试框架中可能不可见的问题，这些问题通常更为人为。 我们将使用一个实际的示例来检查灰度过程及其评估，同时避免深入研究统计数据。相反，我们关注点是整个过程和典型的实际考虑。我们使用App Engine上的一个简单应用程序来说明发布的各个方面。 灰度发布流程的需求 针对特定服务的灰度发布需要特定功能： 将变更通过灰度发布部署到服务全部子集的方法。 一个评估过程，用来评估变更是好还是坏。 将评估集成到发布过程中。 最后，当灰度检测到有问题的发布版本，并在没有误报的情况下识别出好的发布版本时，灰度发布展示了它的价值。 我们的示例环境 我们将使用一个简单的前端web服务应用程序来演示一些灰度发布的概念。该应用程序提供了一个基于http的API，消费者可以使用它来操作各种数据(如产品价格等简单信息)。示例应用程序有一些可调参数，我们可以使用这些参数来模拟各种生产环境，由灰度发布流程进行评估。例如，可以让应用程序为20%的请求返回错误，或者规定5%的请求至少需要两秒钟。 我们使用部署在谷歌应用程序引擎上的应用程序来演示灰度发布流程，这些原则同样适用于其他环境。虽然示例应用程序是经过设计的，但是在实际场景中，类似的应用程序与我们的示例可以共享灰度发展中使用的指标。 我们的示例服务有两个可能的版本:当前版本和候选版本。当前版本是当前部署在生产环境中的版本，而候选版本是新构建的版本。使用这两个版本来说明发布概念，以及如何实现灰度发布以使发布过程更安全。 回滚部署与简单的Canary部署比较 我们将在发生中断时根据错误预算节省和一般影响，来对没有灰度发布的部署流程和灰度发布流程进行比较。我们的部署过程以开发环境为基础。一旦我们感觉代码在开发环境中正常工作，我们就将该版本部署到生产环境中。 在部署之后不久，监视开始报高错误率(参见图16-2，在图16-2中，为了模拟示例服务中的缺陷，对示例应用程序进行配置以使20％的请求失败)。对于示例，假设部署流程不支持回滚到以前已知的配置正常的版本时。修复这些错误的最佳选择就只有在生产版本中查找缺陷，对其进行补救，并在停机期间重新部署一个新版本。这种做法肯定会延长错误对用户的影响。 图 16-2 部署之后错误率增加 为了改进这个初始部署过程，我们可以在使用灰度发布来减少推送错误代码所造成的影响。 我们需要一种方法来在小部分生产环境中运行候选版本，而不是一次性部署到生产环境。 然后将一小部分流量发送到该生产环境（the canary金丝雀）并将其与其他部分（the control 主控）进行比较。 使用此方法，我们可以在所有生产受到影响之前发现候选版本中的缺陷。 我们在示例应用程序中的进行简单灰度发布，在应用程序的特定版本之间分配流量。 您可以使用App Engine或其他任何方法来分割流量（例如负载均衡器上的后端权重，代理配置或循环DNS记录）。 图16-3显示了当我们使用灰度发布，变更的影响会大大降低;事实上，这些错误几乎不可见!这提出了一个有趣的问题:与总体流量趋势相比，灰度发布的流量趋势很难看到和跟踪。 图 16-3 部署之后错误率增canary部署错误率； 因为进行canary部署的只是系统的一小部分，因此总体错误率降低 为了更清楚地了解需要在合理范围内跟踪的错误，我们可以通过App Engine应用程序版本查看关键指标(HTTP响应代码)，如图16-4所示。当我们查看每个版本的分解趋势图时，我们可以清楚地看到新版本引入的错误。我们还可以从图16-4中观察到当前版本提供的错误非常少。 现在，我们可以根据应用程序版本的HTTP错误率对部署进行调优。如果灰度发布的错误率大于全部系统的错误率，这表明canary部署是糟糕的。我们应该暂停并回滚部署，或者联系他人来帮助解决问题。如果错误率相似，我们可以正常地进行部署。在图16-4中，我们的canary部署显然很糟糕，我们应该回滚它。 图 16-4 应用程序HTTP响应码； 新版本产生多数错误、当前版本产生小数错误（图中显示10%的log） Canary实施 现在我们已经看到了一个相当简单的canary部署实现，接下来让我们更深入地了解成功的canary流程所需的参数。 最小化SLOs和错误预算的风险 第2章讨论了SLOs如何反映设计服务可用性的业务需求。这些需求也可以通过canary实现。canary进程的风险仅仅是我们错误预算的一小部分，它受到时间和canary规模大小的限制。 全局部署会很快将SLO置于危险之中。如果实例中为系统全面部署候选版本，我们将面临20%的请求失败的风险。如果我们使用5%的canary规模，我们将为5%的流量提供20%错误，导致1%的总体错误率(如图16-3所示)。这个策略允许我们保留我们的错误预算—预算的影响与暴露于缺陷的流量的数量成正比。我们可以假设，对于全局部署和灰度部署，检测和回滚花费的时间差不多，但是当我们将灰度发布集成到部署过程中时，我们会以更低的成本获得有关新版本的有价值信息。 这是一个假设负载均匀的极简模型。它还假设我们可以将整个错误预算用于灰度发布。这里我们只考虑新版本引入的不可用性，而不是实际可用性。我们的模型还假设新版本具有100%的失败率，这是最坏的情况。而进行灰度的部分不会导致线上系统100%不可用。我们还允许在灰度部署期间，整个系统的可用性低于SLO。 这个模型有明显的缺陷，但它是一个可靠的起点，你可以根据业务需求进行调整。我们建议使用最简单的模型来满足你的技术和业务目标。根据我们的经验，专注于使模型在技术上尽可能正确，常常会导致在建模上的过度投资。对于具有高复杂性的服务，过于复杂的模型可能导致持续的模型调优，而没有真正的好处。 选择灰度规模和持续时间 选择合适的灰度持续时间，需要考虑发布频率。 如果需要每天发布，那么在一次只运行一个灰度的情况下，无法使灰度保持一周,如果每周部署一次，就可以执行较长的灰度发布。 如果持续部署（例如，一天20次），灰度的持续时间必须明显缩短。 在一些说明里，虽然可以同时运行多个灰度，但这样做会增加大量精力来跟踪系统状态。 在任何情况下，需要快速推断系统状态时，同时运行多个灰度会成为问题。如果灰度重叠，同时运行多个灰度也会增加信号污染的风险。我们强烈建议一次只运行一个灰度。 对于基本的评估，不需要大规模的灰度来检测关键条件。然而，一个有代表性的灰度发布流程需要跨多个维度进行决策: 规模和持续时间 它的规模应够大，持续时间应够长，足以代表整个部署。仅在接收到少量查询后终止canary部署，对于以具有不同功能的不同查询为特征的系统来说，这无法提供有用的信号。处理率越高，获取代表性样本所需的时间就越少，以确保所观察到的行为实际上是由变更引起的，而不仅仅是随机因素。 流量 我们需要在系统上接收足够的流量，以确保它是一个具有代表性的示例，并且系统有机会对输入做出负面反应。通常，请求越均匀，所需要的流量就越少。 时间点 性能缺陷通常只在高负载下出现，因此在非高峰时间部署可能不会触发性能相关的缺陷。 度量指标 灰度的代表性与我们选择评估的指标密切相关(我们将在本章后面讨论)。我们可以快速评估诸如查询成功之类的琐碎指标，但是其他指标(如队列深度)可能需要更多的时间或较大规模的灰度来提供清晰的信号。 但问题是，这些要求可能相互冲突。Canarying是一种平衡行为，它通过对最坏情况的冷静分析和系统过去的实际记录来实现。一旦您从过去的灰度中收集了指标，您就可以根据典型的canary评估失败率而不是假想的最坏情况来选择canary参数。 选择和评估度量标准 到目前为止，我们一直在研究成功率，这是评估灰度发布的一个非常清晰和明显的指标。但是直觉上，我们知道这个单一的指标对于有意义的canary流程来说是不够的。如果我们以10倍的延迟为所有请求提供服务，或者在这样做时使用10倍的内存，那么我们可能也会遇到问题。并不是所有的指标都适合评估灰度发布。哪些指标最适合评估灰度发布版本是好是坏? 度量标准应指出问题 首先，指标需要能够指出服务中的问题。这很棘手，因为构成问题的并不总是客观的。我们可能会认为用户请求失败是有问题的。但是如果一个请求的响应时间增加了10%，或者系统内存增加了10%?，这该如何判断？我们通常建议使用sla作为开始考虑canary指标的地方。良好的服务质量指数往往与服务健康状况密切相关。如果已经使用SLIs来度量SLO是否符合，那么我们可以重用这些工作。 几乎任何指标在极端情况下都可能出现问题，但是向灰度流程中添加太多的指标也会产生成本。我们需要为每个指标正确定义可接受行为。如果可接受行为定义过于严格，我们会得到大量的误报;也就是说，我们会认为灰度很糟糕，即使实际不是这样。相反，如果对可接受行为的定义过于宽松，我们更有可能忽略掉有问题的灰度部署。正确选择什么是可接受的行为可能会成本较大——既耗时又需要分析。然而，如果做得不好，错误的结果会完全误导你。此外，随着服务、其特性集和行为的发展，您需要定期重新评估期望。 我们应该根据这些指标多大程度上能够表明系统中实际用户的体验来进行排名，选择排名靠前的几个指标(可能不超过12个)。太多的度量标准会带来递减的回报，并且在某种程度上，收益会被维护它们的成本所抵消，或者在发布过程中如果不维护它们，会对发布结果无法保证100%的信任。 为了使这个指导原则更加具体，让我们回头再来看示例。它有许多我们可以评估的指标:CPU使用量、内存占用、HTTP返回码(2xx、3xx等等)、响应延迟、正确性等等。在这种情况下，我们最好的度量标准可能是HTTP返回码和响应延迟，因为它们的降级最接近于实际用户影响。在这个场景中，CPU使用率并没有那么有用:资源使用的增加不一定会影响服务，并且可能导致不稳定或嘈杂的canary进程。这会导致操作人员禁用或忽略canary进程，这会首先破坏使用canary进程的目的。对于前端服务，我们直观地知道，响应较慢或响应失败通常会真实反映服务中存在的问题。 HTTP返回码包含一些有趣的复杂情况，例如状态码404，它告诉我们没有找到资源。这可能是因为用户获得了错误的URL(想象一下在一个流行的论坛上分享了一个错误的URL)，或者因为服务器错误地停止了对资源的服务。通常，我们可以通过排除canary评估中的400级状态码，并添加黑盒监控来测试特定URL的存在，从而解决此类问题。然后，我们可以将黑盒数据作为canary分析的一部分，以帮助将canary流程与奇怪的用户行为隔离开来。 度量标准应该具有代表性和可归属性 观察到的指标变化其来源，应该清楚地归因于正在进行的变更，并且不应该受到外部因素的影响。 在一个大的系统中(例如，许多服务器或许多容器)，我们可能会有外部性——超过连接的机器、运行具有不同性能特征的不同内核的机器，或者网络中过载的机器。此时金丝雀部分和主系统部分之间的差异，既是我们所部署的两个基础设施之间的差异，也会是我们变更导致的差异。 管理金丝雀是多种力量之间的平衡。增加金丝雀的规模是减少这个问题影响的方法(如前所述)。当我们的系统达到我们认为的合理的金丝雀规模时，我们需要考虑我们选择的指标是否会显示出很大的差异。 我们还应该知道canary和control环境之间共享的失败域;坏金丝雀会对控制产生负面影响，而系统中的坏行为可能会导致我们错误地评估金丝雀。同样，确保您的度量标准是良好隔离的。考虑一个同时运行我们的应用程序和其他进程的系统。整个系统的CPU使用量的急剧增加会导致糟糕的度量，因为系统中的其他进程(数据库负载、日志轮转等)可能会导致这种增加。更好的度量标准是在处理请求时所花费的CPU时间。更好的度量标准是在服务进程实际计划在CPU上的时间窗口上为处理请求服务所花费的CPU时间。虽然与我们的进程相关的严重超额的机器显然是一个问题(监控应该捕捉到它!)，但它不是由我们正在进行的更改引起的，因此不应该将其标记为金丝雀部署失败。 金丝雀也需要是可归属的;也就是说，您还应该能够将canary度量与SLIs联系起来。如果一个度量可以在不影响服务的情况下发生巨大变化，那么它不适合用来评估灰度发布。 评估前/评估后依然是有风险的 canary过程的前后是归因问题的延伸。在这个过程中，旧系统被新系统完全替代，你的canary评估将在一段时间内比较变更之前和之后的系统行为。你可以将此过程称为时空中的canary部署，在此过程中，您通过分割时间来选择A/B组，而不是通过机器、cookie或其他方法来分割总体。由于时间是观察到的指标变化的最大来源之一，因此很难在评估之前/之后来判断性能是否下降。 虽然canary部署可能导致降级，但原有系统本身也可能会降级。如果需要长时间运行canary部署，就会变得更加复杂。例如，如果在周一进行发布，可能会将工作日的行为与周末的行为进行比较，从而引入大量噪音。在该示例中，用户可能在周末以不同的方式访问该服务。从而在canary进程中引入噪音。 评估前/后过程本身引入了一个问题，即大而短的错误率(由前/后评估引入)是否优于小而长的错误率(由一个小金丝雀引入)。如果新版本完全被破坏，我们能多快地检测和恢复? 大规模的金丝雀之前/之后可以更快地检测到问题，但恢复的总体时间可能仍然相当长，与较小的金丝雀类似。在此期间，用户会一直受到影响。 使用渐进的灰度会更好 选择的度量标准即使不符合我们理想中的属性，但仍然很有价值。我们可以通过使用更细微的灰度过程来介绍这些指标。 我们可以使用包含多个阶段的canary来反映我们对度量的推理能力，而不是简单地评估单个canary阶段。在第一阶段，我们对这个版本没有信心或不了解。因此，我们希望使用一个小的阶段，以尽量减少负面影响。在小型灰度中，我们更喜欢能够最清晰地显示问题的指标——应用程序崩溃、请求失败等等。一旦这一阶段成功地过去，下一阶段将增加灰度规模，从而增强我们分析变化影响的信心。 依赖和隔离 正在测试的系统不会在完全真空中运行。出于实际原因，灰度和主系统可以共享后端、前端、网络、数据存储和其他基础设施。甚至可能与客户端有非常不明显的交互。例如，假设一个客户端发送了两个连续的请求。第一个请求可以由灰度部分来处理。其响应可能会改变第二个请求的内容，第二个请求可能会落在主系统部分，从而改变主系统的行为。 不完美的隔离会带来几个后果。最重要的是，我们需要知道，如果灰度过程的结果表明我们应该停止生产变更并调查情况，那么灰度并不一定是错误的。这一事实对于一般的canarying来说是正确的，但是在实践中，它经常由于隔离问题而导致被强制执行。 此外，不完美的隔离意味着灰度部署的错误行为也会对原始系统产生负面影响。Canarying是A/B比较，A和B有可能同时改变;这可能会导致评估灰度变得混乱。还必须使用绝对度量，例如定义的SLOs，以确保系统正确运行。 在非交互系统中进行Canarying 本章重点讨论了交互式请求/响应系统，它在许多方面是最简单和最常讨论的系统设计。其他系统，如异步处理管道，也同样重要，但有不同的canarying注意事项，我们将简要列举。有关数据处理管道的canarying的更多信息，请参见第13章。 首先，canary的持续时间和部署本质上依赖于工作单元处理的持续时间。当涉及到交互系统时，我们忽略了这个因素，假设工作单元处理的时间不会超过几秒钟，这比canary的持续时间要短。非交互式系统中的工作单元处理(如呈现管道或视频编码)可能需要更长的时间。因此，确保canary持续时间至少跨越单个工作单元的持续时间。 对于非交互式系统，隔离可能变得更加复杂。许多管道系统只有一个工作分配程序和一组使用应用程序代码的工作人员。在多阶段管道中，工作单元由工作人员处理，然后返回到池中，由同一工作人员或另一个工作人员执行下一阶段的处理。金丝雀分析有助于确保处理特定工作单元的工人总是从相同的工人池中提取——要么是金丝雀池，要么是控制池。否则，信号就会变得越来越混杂(有关理清信号的需要的更多信息，请参见349页的监视数据的要求)。 最后，度量标准的选择可能更加复杂。我们可能感兴趣的是端到端处理工作单元的时间(类似于交互系统中的延迟)，以及处理本身的质量(当然，这是完全特定于应用程序的)。 考虑到这些警告，canarying的一般概念仍然是可行的，并且适用相同的高级原则。 监控要求 在评估灰度部署时，您必须能够将部署了灰度的系统与未部署灰度的系统进行比较。通常，这需要在构造监视系统时多加注意—有效的比较非常简单，并且能够产生有意义的结果。 考虑之前的例子，在5%的规模中进行灰度，错误率为20%。因为监视很可能将系统作为一个整体来观察，所以它只能检测到1%的总体错误率。根据系统的不同，这个信号可能与其他错误源无法区分(参见图16-3)。 如果我们通过按照服务请求的对象来（金丝雀与主系统）分解指标，(参见图16-4)我们可以清楚地看到主系统与canary之间的错误率，这清楚地说明了全局部署将带来什么。在这里，我们看到，对整个服务的监控不足以分析灰度是否ok。在收集监视数据时，能够执行细粒度的分解非常重要，这些分解使得能够区分金丝雀和主系统的指标。 收集指标的另一个难点是金丝雀的部署受到设计的时间限制。当度量指标在特定时期内进行聚合时，这可能会导致问题。考虑每小时的度量误差。我们可以通过对过去一小时的请求求和来计算这个度量。如果我们使用这个度量来评估我们的canary，我们可能会遇到问题，如下面的时间表所述: 某些事件会导致一些错误发生。 一只金丝雀被部署在5%的人口中;金丝雀的持续时间是30分钟。 canary系统开始监视每小时的错误度量，以确定部署是好是坏。 部署被检测为错误，因为每小时的错误度量与控制总体的每小时的错误显著不同。 此场景是使用每小时计算一次的度量来评估仅30分钟长的部署的结果。因此，canary进程提供了一个非常模糊的信号。当使用度量来评估canary的成功时，确保度量的间隔与canary的持续时间相同或小于持续时间。 相关概念 通常，与客户的对话涉及到在生产中使用蓝/绿部署、人工负载生成和/或流量测试。这些概念类似于canarying，因此虽然它们不是严格意义上的金丝雀流程，但亦可使用。 蓝/绿部署 蓝/绿部署维护系统的两个实例：一个提供流量（绿色），另一个准备提供流量（蓝色）。 在蓝色环境中部署新版本后，将流量切换到其中。切换过程不需要停机，并且回滚只是简单逆转路由器而已。 一个缺点是该设置使用的资源是传统部署的两倍。在该设置中，您正在有效地执行前/后金丝雀（前面已讨论过）。 通过同时(而不是分开地)使用蓝/绿部署，您可以或多或少地将蓝色/绿色部署用作常规的金丝雀。在此策略中，您可以将canary部署到blue(备用)实例，并在绿色和蓝色环境之间缓慢地分配流量。您的评估和比较蓝色环境和绿色环境的指标都应该与流量控制相关。这种设置类似于A/B金丝雀，此时绿色环境是主系统，蓝色环境是金丝雀部署，金丝雀数量由发送到每个金丝雀的流量控制。 人工负载生成 与其将实时用户流量暴露给canary部署，还不如在安全性方面犯点错误，使用人工负载。通常，您可以在多个部署阶段(QA、预生产，甚至在生产中)运行负载测试。虽然根据我们的定义，这些操作不符合canarying，但是它们仍然是找到缺陷的可行方法，但需要注意一些事项。 使用人工负载进行测试可以很好地最大化代码覆盖率，但不能提供良好的状态覆盖率。在可变系统(具有缓存、cookie、请求关联等的系统)中人工模拟负载尤其困难。人工负载也可能无法准确地模拟真实系统中流量变化。有些问题可能只在无人工负载的情况下出现，从而导致覆盖率有所差距。 人工负载在可变系统中也很难工作。例如，试图在计费系统上生成人工负载可能非常危险:系统可能开始向信用卡供应商发送呼叫，然后信用卡供应商将开始主动向客户收费。虽然我们可以避免测试危险的代码逻辑，但是在这些逻辑上缺乏测试会降低我们的测试覆盖率。 流量测试 如果人工流量不具有代表性，我们可以复制流量并将其发送到生产系统和测试环境。这种技术被称为流量镜像。生产系统服务于实际流量并响应请求，canary部署服务于副本流量并丢弃响应。您甚至可以将canary响应与实际响应进行比较，并运行进一步的分析。 这种策略可以提供有代表性的流量，但通常比更直接的canary流程更复杂。在有状态系统中，流量测试也不能充分识别风险;流量副本可能会在看似独立的部署之间引入意外的影响。例如，如果canary部署和生产系统共享一个缓存，人为导致的缓存命中率增加将使canary指标的性能度量无效。 结论 您可以使用许多工具和方法来自动化版本发布，并将canarying引入到发布管道中。没有一种测试方法是万能的，测试策略应该由系统的需求和行为决定。Canarying可以作为一种简单、健壮且易于集成的方法来补充测试。当您及早发现系统缺陷时，用户受到的影响最小。Canarying还可以为频繁发布提供信心，并提高开发速度。正如测试方法必须随着系统需求和设计而发展一样，canarying也必须如此。 前言</summary></entry><entry><title type="html">第十五章 配置细节</title><link href="http://localhost:4000/sre/2020/01/15/%E9%85%8D%E7%BD%AE%E7%BB%86%E8%8A%82/" rel="alternate" type="text/html" title="第十五章 配置细节" /><published>2020-01-15T00:00:00+08:00</published><updated>2020-01-15T00:00:00+08:00</updated><id>http://localhost:4000/sre/2020/01/15/%E9%85%8D%E7%BD%AE%E7%BB%86%E8%8A%82</id><content type="html" xml:base="http://localhost:4000/sre/2020/01/15/%E9%85%8D%E7%BD%AE%E7%BB%86%E8%8A%82/">&lt;p&gt;管理生产系统是SRE为组织提供价值的众多方式之一。在生产中配置和运行应用程序,需要深入了解这些系统如何组合在一起以及如何工作。当出现问题时，随时响应的工程师需要确切知道配置的位置以及如何更改配置。如果团队或组织未花精力去解决与配置相关的问题，则此责任可能成为负担。&lt;/p&gt;

&lt;p&gt;本书详细介绍了琐事的主题（见第6章）。如果您的SRE团队承担了大量与配置相关的工作负担，我们希望实现本章中介绍的一些想法可以帮助您节省部分更改配置所花费的时间。&lt;/p&gt;

&lt;h2 id=&quot;配置带来的琐事&quot;&gt;配置带来的琐事&lt;/h2&gt;

&lt;p&gt;在项目生命周期的开始阶段，配置通常相对轻量且简单。您可能有一些数据格式的文件，如INI，JSON，YAML或XML。管理这些文件几乎不需要辛劳。应用程序、服务器和变体的数量随着时间的推移而增加，配置可能变得非常复杂和冗长。例如，一开始可以通过单个配置文件来进行“配置更改”，但现在必须更新多个位置的配置文件。阅读这样的配置也很困难，因为重要的差异被无关且重复细节所淹没。这种与配置相关的琐事是重复的琐事：管理跨系统配置的无技术含量的任务。这种工作不仅限于大型组织和庞大的系统 –对于具有许多独立配置组件的微服务架构而言，这种情况尤为常见。&lt;/p&gt;

&lt;p&gt;工程师通常通过构建自动化或配置框架来应对重复工作。它们旨在消除配置系统中的重复性，并使配置更易于理解和维护。重复利用软件工程中的技术，这种方法通常使用“配置语言” .Google SRE创建了许多配置语言，旨在减少我们最大和最复杂的生产系统的辛劳。&lt;/p&gt;

&lt;p&gt;不幸的是，这种策略并不能根除配置导致的琐事。将你从大量的个人配置中解脱出来，该项目（及其配置资料库）以新的速度增长。不可避免地，你遇到了复杂的琐事：处理复杂自动化中出现的、有时是不受欢迎的挑战性行为和令人沮丧的任务。该琐事通常在较大的组织（10多名工程师）和一直增长的混合系统中出现。你越早解决就越好;  配置文件的大小和复杂性只会随着时间的推移而增长。&lt;/p&gt;

&lt;h2 id=&quot;减少配置导致的琐事&quot;&gt;减少配置导致的琐事&lt;/h2&gt;

&lt;p&gt;如果项目充斥着与配置相关的工作，您可以采取一些基本策略来改善这种情况。&lt;/p&gt;

&lt;p&gt;在极少数情况下，如果您的应用程序是自定义构建的，您可以选择完全删除配置。在处理配置的某些方面时，应用程序可能天然地就比配置语言更好：让应用程序使用默认值是有意义的，因为它可以访问有关机器的信息或者动态地改变某些值，或者可以根据负载进行扩展。&lt;/p&gt;

&lt;p&gt;如果配置不可删除，并且重复琐事正在成为问题，请考虑自动化以减少配置文件中的重复性。可能需要集成新的配置语言，或者需要改进或替换现有的配置文件。接下来，第317页的“配置系统的关键属性和缺陷”一节提供了有关选择或设计系统的一些指导。&lt;/p&gt;

&lt;p&gt;如果选择新的配置框架，则需要将配置语言与需要配置的应用程序集成。“集成现有应用程序：Kubernetes。（第322页）使用Kubernetes作为现有应用程序示例，要集成的应用程序和“集成自定义应用程序（内部软件）”（第326页）提供了一些更常规的建议。这些部分使用Jsonnet（作为代表进行说明）演示一些示例。&lt;/p&gt;

&lt;p&gt;一旦有适当的配置系统 - 不管是否是现有解决方案，还是选择新的配置语言进行实施 。 “有效运行配置系统”（第329页）中的最佳实践，“何时评估配置”（第331页）和“防止滥用配置”（第331页）都有助于优化设置，无论使用哪种语言。采用这些流程和工具有助于最大限度地降低复杂程度。&lt;/p&gt;

&lt;h2 id=&quot;配置系统的关键属性和缺陷&quot;&gt;配置系统的关键属性和缺陷&lt;/h2&gt;

&lt;p&gt;第14章概述了任何配置系统的一些关键属性。除了理想中的通用要求（如轻量级，易学，简单和富有表现力）之外，高效的配置系统必须：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;通过配置工具对配置文件进行管理（线程，调试器，格式化程序，IDE集成等）可以支持配置合法性检查，（增强）工程师信心和（提高）工作效率&lt;/li&gt;
  &lt;li&gt;提供回滚配置和一般可重复性的密封评估。&lt;/li&gt;
  &lt;li&gt;单独的配置和数据，以便于分析配置和一系列配置界面。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;普遍而言，人们不觉得这些属性是至关重要的，并且达到目前理解的程度已经是一个征程。（以至于）在此过程中，Google也发明了几种缺乏这些关键属性的配置系统。但这不仅止存在于我们之中，虽然流行的配置系统种类繁多，但你很难找到一个不会违反以下任意一条的系统。&lt;/p&gt;

&lt;h3 id=&quot;缺陷一未能将配置视为编程语言问题&quot;&gt;缺陷一：未能将配置视为编程语言问题&lt;/h3&gt;

&lt;p&gt;如果你不是有意设计一门语言，那么最终得到的“语言”很可能不是一门好语言。&lt;/p&gt;

&lt;p&gt;虽然配置语言描述数据而不是行为，但它们仍然具有编程语言的其他特征。如果我们的配置策略以仅使用数据格式为目标开始，那么编程语言功能往往会渗透到后门。该格式不是仅保留数据语言，而是一种深奥而复杂的编程语言。&lt;/p&gt;

&lt;p&gt;例如，某些系统将count属性添加到正在配置的虚拟机（VM）的架构中。此属性不是VM本身的属性，而是表示需要多个属性。虽然有用，但这是编程语言的一个特性，而不是数据格式，因为它需要外部编译器或解释器。经典编程语言方法将使用工件外部的逻辑（例如for循环或列表理解）来根据需要生成更多VM。&lt;/p&gt;

&lt;p&gt;另一个例子是一种配置语言，它产生字符串插值规则而不是支持通用表达式。这些字符串似乎只是“数据”，尽管它们实际上可以包含复杂的代码，包括数据结构操作，校验和，base64编码等。&lt;/p&gt;

&lt;p&gt;流行的YAML+Jinja解决方案也有缺点。简单的纯数据格式（如XML，JSON，YAML和文本格式的协议缓冲区）是纯数据用例的绝佳选择。同样，文本模板引擎（如Jinja2或Go模板）非常适合HTML模板化。但是，当使用配置语言时，人类和工具难以维护和分析。在这些情况下，该缺陷将导致出现复杂的、深奥不适合工具的“语言”。&lt;/p&gt;

&lt;h3 id=&quot;缺陷二设计意外或特殊语言功能&quot;&gt;缺陷二：设计意外或特殊语言功能&lt;/h3&gt;

&lt;p&gt;在大规模操作系统中，SRE通常会觉察到配置可用性问题。新语言不具备良好的工具支持（IDE支持，良好的连接），如果开发语言具有未公开的、或深奥的语义特性，那么开发自定义工具则很痛苦。&lt;/p&gt;

&lt;p&gt;随着时间的推移，将特殊编程语言功能添加到简单的配置格式可能会拥有一个功能完整的解决方案，但是临时语言更复杂，并且通常比其他经过设计的等价语言更不使用。这其中还会带来开发陷阱和特性风险，因为设计者无法提前考虑功能之间的相互作用。&lt;/p&gt;

&lt;p&gt;如果不希望配置系统变得足够复杂，而是简单的编程结构就能解决的话，最好在初始设计阶段考虑好这些要求。&lt;/p&gt;

&lt;h3 id=&quot;缺陷三构建太多特定领域的优化&quot;&gt;缺陷三：构建太多特定领域的优化&lt;/h3&gt;

&lt;p&gt;对于新的特定领域的解决方案，用户群越小则其出现的的时间就会越长, 因为其需要积累足够的用户来证明构建工具的合理性。工程师不愿意花时间理解该语言，因为它在该领域之外几乎没有适用性。像Stack Overflow这样的学习资源基本不可用。&lt;/p&gt;

&lt;h3 id=&quot;缺陷四混淆配置评估与副作用&quot;&gt;缺陷四：混淆“配置评估”与“副作用”&lt;/h3&gt;

&lt;p&gt;副作用包括在配置运行期间更改外部系统或咨询带外数据源（DNS、VM ID、最新构建版本）。&lt;/p&gt;

&lt;p&gt;允许这些副作用的系统会破坏密封性，影响配置与数据分离。在极端情况下，如果不花钱保留云资源，就无法调试配置。为了分离配置和数据，首先评估配置，然后将结果数据提供给用户进行分析，然后才考虑副作用。&lt;/p&gt;

&lt;h3 id=&quot;缺陷五使用现有的通用脚本语言如pythonruby或lua&quot;&gt;缺陷五：使用现有的通用脚本语言，如Python、Ruby或Lua&lt;/h3&gt;

&lt;p&gt;这似乎是避免前四个陷阱的一种微不足道的方法，但使用通用脚本语言的实现是重量级的和/或需要侵入式沙盒来确保密封性。由于通用语言可以访问本地系统，基于安全性考虑也可能需要沙盒。&lt;/p&gt;

&lt;p&gt;此外，无法保证维护配置人员熟悉所有语言。&lt;/p&gt;

&lt;p&gt;为了避免这些陷阱，开发了用于配置的可重用特定语言（DSL），例如HOCON、Flabbergast、Dhall和Jsonnet。我们建议使用现有的DSL进行配置。即使DSL看起来太强大，无法满足你的需求，可能需要在某些时候使用附加功能，并且始终可以使用内部样式指南来限制语言的功能。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h4 id=&quot;-jsonnet的简介-&quot;&gt;&lt;center&gt; Jsonnet的简介 &lt;/center&gt;&lt;/h4&gt;

  &lt;p&gt;Jsonnet是一个密封的开源DSL，可以用作库或命令行工具为任何应用程序提供配置。在Google内外都广泛使用。&lt;/p&gt;

  &lt;p&gt;这种语言对程序员来说很熟悉：它使用类似Python的语法、面向对象和功能构造。它是JSON的扩展，这意味着JSON文件只是一个输出自身的Jsonnet程序。在使用引号和逗号时，Jsonnet比JSON更方便，并支持注释。更重要的是，它增加了计算结构。&lt;/p&gt;

  &lt;p&gt;你不需要特别熟悉Jsonnet语法来完成本章的其余部分，只需花一些时间阅读在线教程就可以入门。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Google或我们的读者群中没有主流配置语言，但我们需要选择语言方便我们提供示例。本章使用Jsonnet来展示我们在第14章中所提供建议的示例。&lt;/p&gt;

  &lt;p&gt;如果你尚未使用特定配置语言并且想要使用Jsonnet，则可以直接应用本章中的示例。我们会尽力让你尽可能轻松地从代码示例中抽象出基础原理。&lt;/p&gt;

  &lt;p&gt;此外，一些示例探索了你可能希望在编程书中找到的概念（如图灵完整性）。我们只在必要时深入研究，以解释在生产中真正困扰我们的微妙之处。在大多数复杂的系统中 - 当然还有配置方面 - 故障处于边缘。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;集成配置语言&quot;&gt;集成配置语言&lt;/h2&gt;

&lt;p&gt;本节使用Jsonnet讨论如何将配置语言与你需要配置的应用程序集成，相同的技术也适用其他配置语言。&lt;/p&gt;

&lt;h3 id=&quot;以特定格式生成配置&quot;&gt;以特定格式生成配置&lt;/h3&gt;

&lt;p&gt;配置语言可以以正确的格式本机输出。例如，Jsonnet输出JSON，它与许多应用程序兼容。对于扩展JSON的语言的消费者，JSON也是足够的，例如JavaScript、YAML或HashiCorp的配置语言。如果这是你面对的情况，则无需进行其他任何集成工作。&lt;/p&gt;

&lt;p&gt;对于本机不支持的其他配置格式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;你需要找到一种在配置语言中表示配置数据的方法。这并不难，因为配置值（如图、列表、字符串和其他原始值）是通用的，并且可用于所有语言。&lt;/li&gt;
  &lt;li&gt;一旦用配置语言表示了这些数据，就可以使用该语言的结构来减少重复（减少工作量）。&lt;/li&gt;
  &lt;li&gt;你需要为必要的输出格式编写（或重用）序列化函数。例如，Jsonnet标准库具有从其内部类似JSON的表示中输出INI和XML的功能。如果配置数据无法在配置语言中表示（例如，Bash脚本），你可以使用基本的字符串模板技术作为最后手段。可以在http://bit.ly/2La0zDe找到使用示例。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;推动多种应用&quot;&gt;推动多种应用&lt;/h3&gt;

&lt;p&gt;一旦可以从配置语言驱动任意现有应用程序，你就可以从同一配置中定位多个应用程序。如果你的应用程序使用不同的配置格式，则需要做一些转换工作。一旦能够以一定的格式生成配置，你就可以轻松统一、同步和消除整个配置文件库中的重复。鉴于JSON和基于JSON格式的普及，甚至可能不必生成不同的格式 - 例如，如果使用部署体系结构，使用GCP部署管理器，AWS CloudFormation或Terraform作为基础架构，以及Kubernetes作为容器，则情况确实如此。&lt;/p&gt;

&lt;p&gt;此时，你可以：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从单个Jsonnet评估中输出Nginx Web服务器配置和Terraform防火墙配置，该评估仅定义端口一次。&lt;/li&gt;
  &lt;li&gt;从相同文件配置监控仪表盘，保留策略和警报通知管道。&lt;/li&gt;
  &lt;li&gt;通过将初始化命令从一个列表移动到另一个列表，管理VM启动脚本和磁盘映像构建脚本之间的性能权衡。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在将不同的配置统一到之后，会有很多机会来优化和抽象配置。配置甚至可以嵌套 - 例如，Cassandra配置可以嵌入其基础架构的DeploymentManager配置内或Kubernetes ConfigMap内。一个优秀的配置语言可以处理任何笨拙的字符串引用，通常这个操作自然而简单。&lt;/p&gt;

&lt;p&gt;为了便于为各种应用程序编写许多不同的文件，Jsonnet有一种模式，配置执行产生一个JSON对象，将文件名映射到文件内容（根据需要进行格式化）。可以在其他配置语言中模拟此功能，方法是在字符串之间产生映射，并使用后续处理步骤或脚本来编写文件。&lt;/p&gt;

&lt;h2 id=&quot;集成现有应用程序kubernetes&quot;&gt;集成现有应用程序：Kubernetes&lt;/h2&gt;

&lt;p&gt;Kubernetes提出了一个有趣的案例研究，原因如下：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;运行在Kubernetes上的作业需要配置文件，并且配置可能会很复杂。&lt;/li&gt;
  &lt;li&gt;Kubernetes没有附带绑定的配置语言（甚至没有专门的配置语言）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于最简单的结构，Kubernetes用户只需使用YAML即可。对于具有较大的基础结构，Kubernetes用户可以使用Jsonnet等语言扩展其工作流程，以其作为该规模所需的抽象工具。&lt;/p&gt;

&lt;h3 id=&quot;kubernetes提供什么&quot;&gt;Kubernetes提供什么&lt;/h3&gt;

&lt;p&gt;Kubernetes是一个开源系统，用于在一组机器上编排容器化工作负载。它的API允许你自己管理容器和许多重要的细节，例如容器之间的通信、集群内外的通信、负载平衡、存储、渐进式部署和自动扩展。每个配置项都用一个JSON对象表示，该对象可以通过API进行管理。命令行工具kubectl允许从磁盘读取这些对象并将它们发送到API。&lt;/p&gt;

&lt;p&gt;在磁盘上，JSON对象实际上被编码为YAML流，YAML易于读取，并可以通过常用库轻松转换为JSON。开箱即用的用户体验包括编写代表Kubernetes对象的YAML文件并运行kubectl以将它们部署到集群。&lt;/p&gt;

&lt;p&gt;要了解配置Kubernetes的最佳实践，请参阅有关该主题的Kubernetes文档。&lt;/p&gt;

&lt;h3 id=&quot;kubernetes配置示例&quot;&gt;Kubernetes配置示例&lt;/h3&gt;

&lt;p&gt;YAML是Kubernetes配置的用户界面，它提供了一些简单的功能，如注释，并且具有大多数人中所意的简洁的原始JSON语法。然而，YAML在抽象方面不尽如人意：它只提供锚点，这在实践中很少有用，而且Kubernetes不支持。&lt;/p&gt;

&lt;p&gt;假设你要使用不同的命名空间、标签和其他微小差异，将Kubernetes对配置文件复制四次。遵循基础结构不变的最佳实践，可以存储所有四个文件的配置，复制配置的相同处。以下代码片段提供了其中一个文件（为简洁起见，我们省略了其他三个文件）：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# example1.yaml
apiVersion: v1
kind: Service
metadata:
     labels:
        app: guestbook
        tier: frontend
     name: frontend
     namespace: prod
spec:
    externalTrafficPolicy: Cluster
    ports:
    - port: 80
       protocol: TCP
       targetPort: 80
    selector:
       app: guestbook
       tier: frontend
    sessionAffinity: None
    type: NodePort
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;此格式难以阅读和维护，因为重要的差异被模糊了。&lt;/p&gt;

&lt;h3 id=&quot;集成配置语言-1&quot;&gt;集成配置语言&lt;/h3&gt;

&lt;p&gt;如第315页上的“配置引发的操作”中所述，管理大量YAML文件可能会花费大量时间。配置语言可以帮助简化此任务。最直接的方法是从Jsonnet的每次执行中发出一个Kubernetes对象，然后将生成的JSON直接传递给kubectl，kubectl处理JSON，就好像它是YAML一样。或者，您可以发出YAML流（一系列此类对象或单个kubectl列表对象，或让Jsonnet从同一配置发出多个文件。有关进一步的讨论，请参阅Jsonnet网站）。&lt;/p&gt;

&lt;p&gt;开发人员应该意识到，通常，YAML允许您编写JSON中无法表达的配置（因此，Jsonnet无法生成）。YAML配置可以包含异常的IEEE浮点值，如NaN，或者包含非字符串字段的对象，如数组、其他对象或null。实际上，这些功能很少使用并且Kubernetes不允许使用它们，因为配置在发送到API时必须进行JSON编码。&lt;/p&gt;

&lt;p&gt;以下代码段显示了我们的示例Kubernetes配置在Jsonnet中的样子：&lt;/p&gt;

&lt;p&gt;请注意以下事项：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// templates.libsonnet
{
    MyTemplate:: {
          local service = self,
          tier:: error 'Needs tier',
          apiVersion: 'v1',
          kind: 'Service',
          local selector_labels = { app: 'guestbook', tier:service.tier },
          metadata: {
                labels: selector_labels,
                name: 'guestbook-' + service.tier,
                namespace: 'default',
           },
           spec: {
                externalTrafficPolicy: 'Cluster',
                ports: [{
                    port: 80,
                    protocol: 'TCP',
                    targetPort: 80,
                }],
            selector: selector_labels,
            sessionAffinity: 'None',
            type: 'NodePort',
        },
    },
}
// example1.jsonnet
local templates = import 'templates.libsonnet';
templates.MyTemplate {
    tier: 'frontend',
}
// example2.jsonnet
local templates = import 'templates.libsonnet';
templates.MyTemplate {
    tier: 'backend',
    metadata+: {
        namespace: 'prod',
    },
}
// example3.jsonnet
local templates = import 'templates.libsonnet';
templates.MyTemplate {
    tier: 'frontend',
    metadata+: {
        namespace: 'prod',
        labels+: { foo: 'bar' },
},
}
// example4.jsonnet
local templates = import 'templates.libsonnet';
templates.MyTemplate {
    tier: 'backend',
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;注意以下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;我们通过四次实例化抽象来表达所有四种变体，但你也可以使用功能抽象。&lt;/li&gt;
  &lt;li&gt;虽然我们为每个实例使用单独的Jsonnet文件，但你也可以将它们合并到一个文件中。&lt;/li&gt;
  &lt;li&gt;在抽象模板中，空间命名为默认值，并且必须被覆盖。&lt;/li&gt;
  &lt;li&gt;乍一看，Jsonnet略显冗长，但随着模板实例化数量的增加而降低了工作量。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在MyTemplate中，local关键字定义了一个变量服务，该服务初始化为self（对最近的封闭对象的引用）。这允许您从嵌套对象中引用对象，其中self被重新定义。&lt;/p&gt;

&lt;p&gt;tier字段有两个冒号（而不是常规的JSON单冒号），并且在生成的JSON中隐藏（不输出）。否则，Kubernetes将拒绝tier为无法识别的字段。隐藏字段仍然可以被覆盖和引用 - 在本例中为service.tier。&lt;/p&gt;

&lt;p&gt;模板本身不能使用，因为引用service.tier会触发错误构造，这会引发给定文本的运行时错误。为避免错误，模板的每个实例都会使用其他表达式覆盖tier字段。换句话说，这种模式表达类似于纯虚拟/抽象方法的东西。&lt;/p&gt;

&lt;p&gt;使用抽象函数意味着配置只能参数化。相反，模板允许您覆盖父项中的任何字段。如第14章所述，虽然简洁性应该是您设计的基础，但简单易行的能力非常重要。模板覆盖提供了一个有用的避开方式，可以更改通常被认为太低级别的特定细节。例如：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;templates.MyTemplate {
    tier: 'frontend',
    spec+: {
        sessionAffinity: 'ClientIP',
    },
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这是将现有模板转换为Jsonnet的典型工作流程：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将其中一个YAML格式转换为JSON。&lt;/li&gt;
  &lt;li&gt;通过Jsonnet格式化程序运行生成的JSON。&lt;/li&gt;
  &lt;li&gt;手动添加Jsonnet构造以抽象和实例化代码（如示例中所示）。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;该示例显示了如何在保留不同的某些字段的同时删除重复内容。随着差异越来越微妙（例如，字符串只是略有不同）或表达具有挑战性（例如，配置具有结构差异，如阵列中的附加元素，或者应用于阵列的所有元素的相同差异），使用配置语言变得更加引人注目。&lt;/p&gt;

&lt;p&gt;通常，抽象不同配置的共性可以促进关注点的分离，并且与编程语言中的模块化具有相同的好处。您可以针对许多不同的用例利用抽象功能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;单个团队可能需要创建几乎（但不完全）相同的多个配置版本。例如，在跨不同环境（prod/stage/dev/test）管理部署，调整不同体系结构上的部署或调整时区不同地区的能力。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;组织可能拥有一个基础架构团队，负责维护可重用组件-API服务框架、缓存服务器或MapReduces。对于每个组件，基础结构团队可以维护一个模板，该模板定义大规模运行该组件所需的Kubernetes对象。每个应用程序团队都可以实例化该模板以添加其应用程序的详细信息。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;集成自定义应用程序内部软件&quot;&gt;集成自定义应用程序（内部软件）&lt;/h2&gt;

&lt;p&gt;如果你的基础架构使用任何自定义应用程序（即内部开发的软件，而不是现成的解决方案），那么可以将这些应用程序设计为与可重用的配置语言共存。用于编写配置文件或与生成的配置数据交互时（例如，出于调试目的或与其他工具集成时），本节中的建议应改善整体用户配置体验。它们还应简化应用程序的设计并将配置与数据分开。&lt;/p&gt;

&lt;p&gt;处理自定义应用程序的通用策略应该是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;让配置语言处理它的设计目的:语言问题的方面。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;让应用程序处理所有其他功能。
以下最佳实践包括使用Jsonnet的示例，但相同的建议也适用于其他语言：&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;使用单个纯数据文件，然后让配置语言使用import将配置拆分为文件。这意味着配置语言实现只需要发出（并且应用程序只需要使用）单个文件。此外，由于应用程序可以以不同方式组合文件，因此该策略明确且清晰地描述了如何组合文件以形成应用程序配置。&lt;/li&gt;
  &lt;li&gt;使用对象表示命名实体的集合，其中字段包含对象名称，值包含实体的其余部分。避免使用每个元素都有名称字段的对象数组。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  Bad JSON:
      [
          { &quot;name&quot;: &quot;cat&quot;, ... },
          { &quot;name&quot;: &quot;dog&quot;, ... }
      ]
  Good JSON:
      {
           &quot;cat&quot;: { ... },
           &quot;dog&quot;: { ... }
   }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;该策略使得集合（和单个动物）更容易扩展，并且您可以通过名称引用实体（例如，animals.cat）而不是引用索引（例如，动物[0]）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;避免在顶级按类型对实体进行分组。构造JSON，以便将逻辑相关的配置分组到同一子树中。这允许抽象（在配置语言级别）遵循功能边界。
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  Bad JSON:
      {
          &quot;pots&quot;: { &quot;pot1&quot;: { ... },&quot;pot2&quot;: { ... } },
          &quot;lids&quot;: { &quot;lid1&quot;: { ... }, &quot;lid2&quot;:{ ... } }
      }
  Good JSON:
      {
          &quot;pot_assembly1&quot;: { &quot;pot&quot;: { ... },&quot;lid&quot;: { ... } },
          &quot;pot_assembly2&quot;: { &quot;pot&quot;: { ... },&quot;lid&quot;: { ... } }
      }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;在配置语言级别，此策略支持以下抽象：&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  local kitchen = import 'kitchen.libsonnet';
  {
  pot_assembly1: kitchen.CrockPot,
  pot_assembly2: kitchen.SaucePan { pot+: { color: 'red' }},
  }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;保持数据一直简单:：
    &lt;ul&gt;
      &lt;li&gt;–避免在数据表示中嵌入语言功能（如“陷阱1：无法将配置识别为编程语言问题”（第317页）中所述）。这些类型的抽象将只会产生混淆，因为它们会强制用户决定是使用数据表示形式还是配置语言中的抽象功能。&lt;/li&gt;
      &lt;li&gt;–不要担心过于冗长的数据表示。减少冗长的解决方案会带来复杂性，并且这个问题可以使用配置语言管理。&lt;/li&gt;
      &lt;li&gt;–避免在应用程序中解释自定义字符串插值语法，例如字符串中的条件或占位符引用。有时解释是不可避免的 - 例如，当您需要描述在生成配置的纯数据版本（报警，处理程序等）之后执行的操作时。但除此之外，让配置语言尽可能多地完成语言级别的工作。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如前所述，如果您可以完全删除配置，那么这样做始终是您的最佳选择。虽然配置语言可以通过使用具有默认值的模板来隐藏底层模型的复杂性，但生成的配置数据并不是完全隐藏的 - 它可以由工具处理、由人检查或加载到配置数据库中。出于同样的原因，不要依赖配置语言来修复模型本身中底层modelfix中不一致的命名、复数或错误。如果您无法修复模型中的不一致性，最好在语言级别使用它们以避免更多的不一致。&lt;/p&gt;

&lt;p&gt;根据我们的经验，配置更改往往会在系统中随着时间的推移成为导致停机的根本原因（请参阅附录C中的停机的主要原因列表）。验证配置更改是保持可靠性的关键步骤。我们建议在配置执行后立即验证生成的配置数据。单独的语法验证（即，检查JSON是否可解析）将不会发现许多错误。在通用模式验证之后，检查特定于应用程序域的属性 - 例如，是否存在必填字段、是否存在引用的文件名，以及提供的值是否在允许的范围内。&lt;/p&gt;

&lt;p&gt;您可以使用JSONschema验证Jsonnet的JSON。对于使用协议缓冲区的应用程序，您可以从Jsonnet轻松生成这些缓冲区的规范JSON格式，协议缓冲区实现将在反序列化期间进行验证。&lt;/p&gt;

&lt;p&gt;无论您决定如何验证，都不要忽略无法识别的字段名称，因为它们可能表示配置语言级别的拼写错误。Jsonnet可以使用::语法屏蔽不应输出的字段。在precommit hook中执行相同的验证也是一个好主意。&lt;/p&gt;

&lt;h2 id=&quot;有效地运行配置系统&quot;&gt;有效地运行配置系统&lt;/h2&gt;

&lt;p&gt;在以任何语言实现“配置为代码”时，我们建议遵循通常有助于软件工程的规程和流程。&lt;/p&gt;

&lt;h3 id=&quot;版本&quot;&gt;版本&lt;/h3&gt;

&lt;p&gt;配置语言通常会触发工程师编写模板库和实用程序函数。通常，一个团队维护这些库，但许多其他团队可能会使用它们。当您需要对库进行重大更改时，您有两种选择：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;提交所有客户端代码的全局更新，重构代码以使其仍然有效（这可能在组织上不可行）。&lt;/li&gt;
  &lt;li&gt;使用版本库，以便不同的消费者可以使用不同的版本并独立迁移。选择使用弃用版本的消费者将无法获得新版本的好处，并将产生技术债务 - 有一天，他们将不得不重构他们的代码以使用新库。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;大多数语言，包括Jsonnet，都没有为版本控制提供任何特定的支持; 相反，你可以轻松使用目录。有关Jsonnet中的实际示例，请参阅ksonnet-lib存储库，其中版本是导入路径的第一个组件：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    local k = import 'ksonnet.beta.2/k.libsonnet';
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;源控制&quot;&gt;源控制&lt;/h3&gt;

&lt;p&gt;第14章主张保留配置更改的历史记录（包括谁创建它们）并确保回滚简单可靠。检查配置到源代码控制中可以带来所有这些功能，还可以编写查看配置更改的代码。&lt;/p&gt;

&lt;h3 id=&quot;工具&quot;&gt;工具&lt;/h3&gt;

&lt;p&gt;考虑如何强制执行样式和lint配置，并调查是否有一个编辑器插件将这些工具集成到您的工作流程中。您的目标是在所有作者之间保持一致的风格、提高可读性并检测错误。有些编辑器支持可以为您运行格式化程序和其他外部工具的写后hook.。您还可以使用预先挂钩来运行相同的工具，以确保签入的配置具有高质量。&lt;/p&gt;

&lt;h3 id=&quot;测试&quot;&gt;测试&lt;/h3&gt;

&lt;p&gt;我们建议对上游模板库实施单元测试。确保库在实例化时生成预期的具体配置。与之对应的，为了便于维护，函数库也应该包括单元测试&lt;/p&gt;

&lt;p&gt;在Jsonnet中，你可以将测试编写为Jsonnet文件：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;导入要测试的库。&lt;/li&gt;
  &lt;li&gt;应用库&lt;/li&gt;
  &lt;li&gt;使用assert语句或标准库assertEqual函数来验证其输出。后者在其错误消息中显示所有不匹配的值。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以下示例为测试joinName函数和MyTemplate：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// utils_test.jsonnet
local utils = import 'utils.libsonnet';
std.assertEqual(utils.joinName(['foo', 'bar']),'foo-bar') &amp;amp;&amp;amp;
std.assertEqual(utils.MyTemplate { tier: 'frontend' }, {... })
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;对于较大的测试套件，你可以使用Jsonnet社区成员开发的更全面的单元测试框架。你可以用此框架以结构化方式定义和运行测试套件-例如，报告所有失败测试的集合，而不是在第一个失败的断点中中止执行。&lt;/p&gt;

&lt;h2 id=&quot;何时评估配置&quot;&gt;何时评估配置&lt;/h2&gt;

&lt;p&gt;我们的关键属性包括封闭性;也就是说，无论它们在何时何地执行，相同的配置语言必须生成相同的配置数据。如第14章所述，如果系统依赖于其密封环境之外可以改变的资源，则系统可能很难或无法回滚。通常，封闭性意味着Jsonnet代码始终可以与它所代表的扩展JSON互换。因此，你可以在任何时间从Jsonnet生成JSON。&lt;/p&gt;

&lt;p&gt;我们建议在版本控制中存储配置。你可以在注册之前验证配置。此外，应用程序在需要JSON数据时可以评估配置。同样，你可以在构建时进行评估。你可以根据用例的具体情况对每个选项进行评估优化。&lt;/p&gt;

&lt;h3 id=&quot;初期检查json&quot;&gt;初期：检查JSON&lt;/h3&gt;

&lt;p&gt;你可以在检查版本控制之前从Jsonnet代码生成JSON。典型的工作流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;修改Jsonnet文件。&lt;/li&gt;
  &lt;li&gt;运行Jsonnet命令行工具（可能包装在脚本中）以重新生成JSON文件。&lt;/li&gt;
  &lt;li&gt;勾选预先提交确保Jsonnet代码和JSON输出始终一致。&lt;/li&gt;
  &lt;li&gt;将所有内容打包成拉取请求以进行代码审查。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;优点&quot;&gt;优点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;审阅者可以检查具体的更改 - 例如，重构不应该影响生成的JSON。&lt;/li&gt;
  &lt;li&gt;可以在生成和抽象级别上跨不同版本检查多个作者的行注释。同样利于对变更的审核。&lt;/li&gt;
  &lt;li&gt;在运行时你无需运行Jsonnet，这样可以降低复杂性、二进制大小和风险。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;缺点&quot;&gt;缺点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;生成的JSON不一定是可读的 - 例如，如果它嵌入了长字符串。&lt;/li&gt;
  &lt;li&gt;由于其他原因，JSON可能不适合检查版本控制 - 例如，如果它太大或包含隐私。&lt;/li&gt;
  &lt;li&gt;如果单个Jsonnet文件的许多并发编辑同时合并到单个JSON文件，则可能会出现合并冲突。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;中期构建时评估&quot;&gt;中期：构建时评估&lt;/h3&gt;

&lt;p&gt;你可以通过在构建时运行Jsonnet命令行实用程序并将生成的JSON嵌入到发布工件中（例如，作为tarball）来避免将JSON检入源控件。应用程序代码只是在初始化时从磁盘读取JSON文件。如果你使用的是Bazel，则可以使用Jsonnet Bazel规则轻松实现此目的。在谷歌，我们通常使用这种方法，该方法有如下优点。&lt;/p&gt;

&lt;h4 id=&quot;优点-1&quot;&gt;优点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;你可以控制运行时的复杂性、二进制大小和风险，而无需在每个拉取请求中重建JSON文件。&lt;/li&gt;
  &lt;li&gt;原始Jsonnet代码与生成的JSON之间不存在去同步的风险。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;缺点-1&quot;&gt;缺点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;构建更复杂。&lt;/li&gt;
  &lt;li&gt;在代码审查期间评估具体变化更加困难。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;后期在运行时评估&quot;&gt;后期：在运行时评估&lt;/h3&gt;

&lt;p&gt;链接Jsonnet库允许应用程序本身随时解释配置，产生的JSON配置的内存中表示。&lt;/p&gt;

&lt;h4 id=&quot;优点-2&quot;&gt;优点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;它更简单，不需要事先评估。&lt;/li&gt;
  &lt;li&gt;可以在执行期间评估用户提供的Jsonnet代码。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;缺点-2&quot;&gt;缺点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;任何链接库都会增加覆盖范围和风险。&lt;/li&gt;
  &lt;li&gt;可能会在运行时发现配置错误，为时已晚。&lt;/li&gt;
  &lt;li&gt;如果Jsonnet代码不稳定，则必须特别小心。（我们在第333页的“防止滥用配置”中讨论了原因）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;按照我们的运行示例，如果你正在生成Kubernetes对象，何时应该运行Jsonnet？&lt;/p&gt;

&lt;p&gt;答案取决于你的具体实施。如果你正在构建类似ksonnet（从本地文件系统运行Jsonnet代码的客户端命令行工具），最简单的解决方案是将Jsonnet库链接到该工具并评估正在进行的Jsonnet。这样做是安全的，因为代码在作者自己的机器上运行。&lt;/p&gt;

&lt;p&gt;Box.com的基础架构使用Git将配置更改推送到生产环境。为了避免在服务器上执行Jsonnet，Git会对保存在存储库中的生成的JSON进行操作。对于像Helm或Spinnaker这样的部署管理守护程序，唯一的选择是在运行时评估服务器上的Jsonnet（下一节中将介绍注意事项）。&lt;/p&gt;

&lt;h2 id=&quot;防止滥用配置&quot;&gt;防止滥用配置&lt;/h2&gt;

&lt;p&gt;与长时间运行的服务不同，配置执行应该随着配置生成快速终止。然而，由于错误或恶意攻击，配置可能会占用任意数量的CPU时间或内存。为了说明原因，请考虑以下非终止Jsonnet程序：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    local f(x) = f(x +1); f(0)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;使用无界内存的程序与之类似：&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    local f(x) = f(x +[1]); f([])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;你可以使用对象而不是函数或其他配置语言编写等效示例。&lt;/p&gt;

&lt;p&gt;可以尝试通过限制语言来避免过度消耗资源，以使其不再是图灵计算机完成的。但是，强制所有配置终止并不一定能防止过度消耗资源。编写一个耗费足够时间或内存的程序而实际是不终止的程序是很容易的。例如：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    local f(x) = if x== 0 then [] else [f(x - 1), f(x - 1)]; f(100)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;实际上，即使使用简单的配置格式（如XML和YAML），也存在此类程序。&lt;/p&gt;

&lt;p&gt;当然，这些情景的风险取决于具体情况。问题较少的情况，假设命令行工具使用Jsonnet构建Kubernetes对象，然后部署这些对象。在这种情况下，Jsonnet代码是可信的：很少产生非终止的事故，你可以使用Ctrl-C来缓解它们。很少会产生内存耗尽。另一个极端情况，使用类似Helm或Spinnaker这样的服务，它接受来自最终用户的任意配置代码并在请求处理程序中对其进行评估，你需要避免占用请求处理程序或耗尽内存的DOS攻击。&lt;/p&gt;

&lt;p&gt;如果在请求处理程序中评估不受信任的Jsonnet代码，则可以通过沙盒化Jsonnet执行来避免此类攻击。一个简单的策略是使用单独的进程和ulimit（或其非UNIX等价物）。通常，你需要fork到命令行可执行文件而不是链接Jsonnet库。因此，未在给定资源内完成的程序将执行失败并通知最终用户。为了进一步防御C++内存漏洞利用，你可以使用Jsonnet的本机Go实现。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;无论是使用Jsonnet、采用其他配置语言还是开发自己的配置语言，我们都希望你能够应用这些最佳实践来管理配置生产系统所需的复杂性和操作负载。&lt;/p&gt;

&lt;p&gt;至少，配置语言的关键属性是优秀的工具，封闭配置以及配置和数据的分离。&lt;/p&gt;

&lt;p&gt;你的系统可能不至于复杂到使用配置语言。过渡到像Jsonnet这样的特定于域的语言是一种在你的系统复杂度增加时可以考虑的策略。它会提供一致且结构良好的界面，让你的SRE团队有更多时间来处理其他重要项目。&lt;/p&gt;</content><author><name>ZX</name></author><category term="《SRE-Google运维实践》" /><summary type="html">管理生产系统是SRE为组织提供价值的众多方式之一。在生产中配置和运行应用程序,需要深入了解这些系统如何组合在一起以及如何工作。当出现问题时，随时响应的工程师需要确切知道配置的位置以及如何更改配置。如果团队或组织未花精力去解决与配置相关的问题，则此责任可能成为负担。 本书详细介绍了琐事的主题（见第6章）。如果您的SRE团队承担了大量与配置相关的工作负担，我们希望实现本章中介绍的一些想法可以帮助您节省部分更改配置所花费的时间。 配置带来的琐事 在项目生命周期的开始阶段，配置通常相对轻量且简单。您可能有一些数据格式的文件，如INI，JSON，YAML或XML。管理这些文件几乎不需要辛劳。应用程序、服务器和变体的数量随着时间的推移而增加，配置可能变得非常复杂和冗长。例如，一开始可以通过单个配置文件来进行“配置更改”，但现在必须更新多个位置的配置文件。阅读这样的配置也很困难，因为重要的差异被无关且重复细节所淹没。这种与配置相关的琐事是重复的琐事：管理跨系统配置的无技术含量的任务。这种工作不仅限于大型组织和庞大的系统 –对于具有许多独立配置组件的微服务架构而言，这种情况尤为常见。 工程师通常通过构建自动化或配置框架来应对重复工作。它们旨在消除配置系统中的重复性，并使配置更易于理解和维护。重复利用软件工程中的技术，这种方法通常使用“配置语言” .Google SRE创建了许多配置语言，旨在减少我们最大和最复杂的生产系统的辛劳。 不幸的是，这种策略并不能根除配置导致的琐事。将你从大量的个人配置中解脱出来，该项目（及其配置资料库）以新的速度增长。不可避免地，你遇到了复杂的琐事：处理复杂自动化中出现的、有时是不受欢迎的挑战性行为和令人沮丧的任务。该琐事通常在较大的组织（10多名工程师）和一直增长的混合系统中出现。你越早解决就越好; 配置文件的大小和复杂性只会随着时间的推移而增长。 减少配置导致的琐事 如果项目充斥着与配置相关的工作，您可以采取一些基本策略来改善这种情况。 在极少数情况下，如果您的应用程序是自定义构建的，您可以选择完全删除配置。在处理配置的某些方面时，应用程序可能天然地就比配置语言更好：让应用程序使用默认值是有意义的，因为它可以访问有关机器的信息或者动态地改变某些值，或者可以根据负载进行扩展。 如果配置不可删除，并且重复琐事正在成为问题，请考虑自动化以减少配置文件中的重复性。可能需要集成新的配置语言，或者需要改进或替换现有的配置文件。接下来，第317页的“配置系统的关键属性和缺陷”一节提供了有关选择或设计系统的一些指导。 如果选择新的配置框架，则需要将配置语言与需要配置的应用程序集成。“集成现有应用程序：Kubernetes。（第322页）使用Kubernetes作为现有应用程序示例，要集成的应用程序和“集成自定义应用程序（内部软件）”（第326页）提供了一些更常规的建议。这些部分使用Jsonnet（作为代表进行说明）演示一些示例。 一旦有适当的配置系统 - 不管是否是现有解决方案，还是选择新的配置语言进行实施 。 “有效运行配置系统”（第329页）中的最佳实践，“何时评估配置”（第331页）和“防止滥用配置”（第331页）都有助于优化设置，无论使用哪种语言。采用这些流程和工具有助于最大限度地降低复杂程度。 配置系统的关键属性和缺陷 第14章概述了任何配置系统的一些关键属性。除了理想中的通用要求（如轻量级，易学，简单和富有表现力）之外，高效的配置系统必须： 通过配置工具对配置文件进行管理（线程，调试器，格式化程序，IDE集成等）可以支持配置合法性检查，（增强）工程师信心和（提高）工作效率 提供回滚配置和一般可重复性的密封评估。 单独的配置和数据，以便于分析配置和一系列配置界面。 普遍而言，人们不觉得这些属性是至关重要的，并且达到目前理解的程度已经是一个征程。（以至于）在此过程中，Google也发明了几种缺乏这些关键属性的配置系统。但这不仅止存在于我们之中，虽然流行的配置系统种类繁多，但你很难找到一个不会违反以下任意一条的系统。 缺陷一：未能将配置视为编程语言问题 如果你不是有意设计一门语言，那么最终得到的“语言”很可能不是一门好语言。 虽然配置语言描述数据而不是行为，但它们仍然具有编程语言的其他特征。如果我们的配置策略以仅使用数据格式为目标开始，那么编程语言功能往往会渗透到后门。该格式不是仅保留数据语言，而是一种深奥而复杂的编程语言。 例如，某些系统将count属性添加到正在配置的虚拟机（VM）的架构中。此属性不是VM本身的属性，而是表示需要多个属性。虽然有用，但这是编程语言的一个特性，而不是数据格式，因为它需要外部编译器或解释器。经典编程语言方法将使用工件外部的逻辑（例如for循环或列表理解）来根据需要生成更多VM。 另一个例子是一种配置语言，它产生字符串插值规则而不是支持通用表达式。这些字符串似乎只是“数据”，尽管它们实际上可以包含复杂的代码，包括数据结构操作，校验和，base64编码等。 流行的YAML+Jinja解决方案也有缺点。简单的纯数据格式（如XML，JSON，YAML和文本格式的协议缓冲区）是纯数据用例的绝佳选择。同样，文本模板引擎（如Jinja2或Go模板）非常适合HTML模板化。但是，当使用配置语言时，人类和工具难以维护和分析。在这些情况下，该缺陷将导致出现复杂的、深奥不适合工具的“语言”。 缺陷二：设计意外或特殊语言功能 在大规模操作系统中，SRE通常会觉察到配置可用性问题。新语言不具备良好的工具支持（IDE支持，良好的连接），如果开发语言具有未公开的、或深奥的语义特性，那么开发自定义工具则很痛苦。 随着时间的推移，将特殊编程语言功能添加到简单的配置格式可能会拥有一个功能完整的解决方案，但是临时语言更复杂，并且通常比其他经过设计的等价语言更不使用。这其中还会带来开发陷阱和特性风险，因为设计者无法提前考虑功能之间的相互作用。 如果不希望配置系统变得足够复杂，而是简单的编程结构就能解决的话，最好在初始设计阶段考虑好这些要求。 缺陷三：构建太多特定领域的优化 对于新的特定领域的解决方案，用户群越小则其出现的的时间就会越长, 因为其需要积累足够的用户来证明构建工具的合理性。工程师不愿意花时间理解该语言，因为它在该领域之外几乎没有适用性。像Stack Overflow这样的学习资源基本不可用。 缺陷四：混淆“配置评估”与“副作用” 副作用包括在配置运行期间更改外部系统或咨询带外数据源（DNS、VM ID、最新构建版本）。 允许这些副作用的系统会破坏密封性，影响配置与数据分离。在极端情况下，如果不花钱保留云资源，就无法调试配置。为了分离配置和数据，首先评估配置，然后将结果数据提供给用户进行分析，然后才考虑副作用。 缺陷五：使用现有的通用脚本语言，如Python、Ruby或Lua 这似乎是避免前四个陷阱的一种微不足道的方法，但使用通用脚本语言的实现是重量级的和/或需要侵入式沙盒来确保密封性。由于通用语言可以访问本地系统，基于安全性考虑也可能需要沙盒。 此外，无法保证维护配置人员熟悉所有语言。 为了避免这些陷阱，开发了用于配置的可重用特定语言（DSL），例如HOCON、Flabbergast、Dhall和Jsonnet。我们建议使用现有的DSL进行配置。即使DSL看起来太强大，无法满足你的需求，可能需要在某些时候使用附加功能，并且始终可以使用内部样式指南来限制语言的功能。 Jsonnet的简介 Jsonnet是一个密封的开源DSL，可以用作库或命令行工具为任何应用程序提供配置。在Google内外都广泛使用。 这种语言对程序员来说很熟悉：它使用类似Python的语法、面向对象和功能构造。它是JSON的扩展，这意味着JSON文件只是一个输出自身的Jsonnet程序。在使用引号和逗号时，Jsonnet比JSON更方便，并支持注释。更重要的是，它增加了计算结构。 你不需要特别熟悉Jsonnet语法来完成本章的其余部分，只需花一些时间阅读在线教程就可以入门。 Google或我们的读者群中没有主流配置语言，但我们需要选择语言方便我们提供示例。本章使用Jsonnet来展示我们在第14章中所提供建议的示例。 如果你尚未使用特定配置语言并且想要使用Jsonnet，则可以直接应用本章中的示例。我们会尽力让你尽可能轻松地从代码示例中抽象出基础原理。 此外，一些示例探索了你可能希望在编程书中找到的概念（如图灵完整性）。我们只在必要时深入研究，以解释在生产中真正困扰我们的微妙之处。在大多数复杂的系统中 - 当然还有配置方面 - 故障处于边缘。 集成配置语言 本节使用Jsonnet讨论如何将配置语言与你需要配置的应用程序集成，相同的技术也适用其他配置语言。 以特定格式生成配置 配置语言可以以正确的格式本机输出。例如，Jsonnet输出JSON，它与许多应用程序兼容。对于扩展JSON的语言的消费者，JSON也是足够的，例如JavaScript、YAML或HashiCorp的配置语言。如果这是你面对的情况，则无需进行其他任何集成工作。 对于本机不支持的其他配置格式： 你需要找到一种在配置语言中表示配置数据的方法。这并不难，因为配置值（如图、列表、字符串和其他原始值）是通用的，并且可用于所有语言。 一旦用配置语言表示了这些数据，就可以使用该语言的结构来减少重复（减少工作量）。 你需要为必要的输出格式编写（或重用）序列化函数。例如，Jsonnet标准库具有从其内部类似JSON的表示中输出INI和XML的功能。如果配置数据无法在配置语言中表示（例如，Bash脚本），你可以使用基本的字符串模板技术作为最后手段。可以在http://bit.ly/2La0zDe找到使用示例。 推动多种应用 一旦可以从配置语言驱动任意现有应用程序，你就可以从同一配置中定位多个应用程序。如果你的应用程序使用不同的配置格式，则需要做一些转换工作。一旦能够以一定的格式生成配置，你就可以轻松统一、同步和消除整个配置文件库中的重复。鉴于JSON和基于JSON格式的普及，甚至可能不必生成不同的格式 - 例如，如果使用部署体系结构，使用GCP部署管理器，AWS CloudFormation或Terraform作为基础架构，以及Kubernetes作为容器，则情况确实如此。 此时，你可以： 从单个Jsonnet评估中输出Nginx Web服务器配置和Terraform防火墙配置，该评估仅定义端口一次。 从相同文件配置监控仪表盘，保留策略和警报通知管道。 通过将初始化命令从一个列表移动到另一个列表，管理VM启动脚本和磁盘映像构建脚本之间的性能权衡。 在将不同的配置统一到之后，会有很多机会来优化和抽象配置。配置甚至可以嵌套 - 例如，Cassandra配置可以嵌入其基础架构的DeploymentManager配置内或Kubernetes ConfigMap内。一个优秀的配置语言可以处理任何笨拙的字符串引用，通常这个操作自然而简单。 为了便于为各种应用程序编写许多不同的文件，Jsonnet有一种模式，配置执行产生一个JSON对象，将文件名映射到文件内容（根据需要进行格式化）。可以在其他配置语言中模拟此功能，方法是在字符串之间产生映射，并使用后续处理步骤或脚本来编写文件。 集成现有应用程序：Kubernetes Kubernetes提出了一个有趣的案例研究，原因如下： 运行在Kubernetes上的作业需要配置文件，并且配置可能会很复杂。 Kubernetes没有附带绑定的配置语言（甚至没有专门的配置语言）。 对于最简单的结构，Kubernetes用户只需使用YAML即可。对于具有较大的基础结构，Kubernetes用户可以使用Jsonnet等语言扩展其工作流程，以其作为该规模所需的抽象工具。 Kubernetes提供什么 Kubernetes是一个开源系统，用于在一组机器上编排容器化工作负载。它的API允许你自己管理容器和许多重要的细节，例如容器之间的通信、集群内外的通信、负载平衡、存储、渐进式部署和自动扩展。每个配置项都用一个JSON对象表示，该对象可以通过API进行管理。命令行工具kubectl允许从磁盘读取这些对象并将它们发送到API。 在磁盘上，JSON对象实际上被编码为YAML流，YAML易于读取，并可以通过常用库轻松转换为JSON。开箱即用的用户体验包括编写代表Kubernetes对象的YAML文件并运行kubectl以将它们部署到集群。 要了解配置Kubernetes的最佳实践，请参阅有关该主题的Kubernetes文档。 Kubernetes配置示例 YAML是Kubernetes配置的用户界面，它提供了一些简单的功能，如注释，并且具有大多数人中所意的简洁的原始JSON语法。然而，YAML在抽象方面不尽如人意：它只提供锚点，这在实践中很少有用，而且Kubernetes不支持。 假设你要使用不同的命名空间、标签和其他微小差异，将Kubernetes对配置文件复制四次。遵循基础结构不变的最佳实践，可以存储所有四个文件的配置，复制配置的相同处。以下代码片段提供了其中一个文件（为简洁起见，我们省略了其他三个文件）： # example1.yaml apiVersion: v1 kind: Service metadata: labels: app: guestbook tier: frontend name: frontend namespace: prod spec: externalTrafficPolicy: Cluster ports: - port: 80 protocol: TCP targetPort: 80 selector: app: guestbook tier: frontend sessionAffinity: None type: NodePort 此格式难以阅读和维护，因为重要的差异被模糊了。 集成配置语言 如第315页上的“配置引发的操作”中所述，管理大量YAML文件可能会花费大量时间。配置语言可以帮助简化此任务。最直接的方法是从Jsonnet的每次执行中发出一个Kubernetes对象，然后将生成的JSON直接传递给kubectl，kubectl处理JSON，就好像它是YAML一样。或者，您可以发出YAML流（一系列此类对象或单个kubectl列表对象，或让Jsonnet从同一配置发出多个文件。有关进一步的讨论，请参阅Jsonnet网站）。 开发人员应该意识到，通常，YAML允许您编写JSON中无法表达的配置（因此，Jsonnet无法生成）。YAML配置可以包含异常的IEEE浮点值，如NaN，或者包含非字符串字段的对象，如数组、其他对象或null。实际上，这些功能很少使用并且Kubernetes不允许使用它们，因为配置在发送到API时必须进行JSON编码。 以下代码段显示了我们的示例Kubernetes配置在Jsonnet中的样子： 请注意以下事项： // templates.libsonnet { MyTemplate:: { local service = self, tier:: error 'Needs tier', apiVersion: 'v1', kind: 'Service', local selector_labels = { app: 'guestbook', tier:service.tier }, metadata: { labels: selector_labels, name: 'guestbook-' + service.tier, namespace: 'default', }, spec: { externalTrafficPolicy: 'Cluster', ports: [{ port: 80, protocol: 'TCP', targetPort: 80, }], selector: selector_labels, sessionAffinity: 'None', type: 'NodePort', }, }, } // example1.jsonnet local templates = import 'templates.libsonnet'; templates.MyTemplate { tier: 'frontend', } // example2.jsonnet local templates = import 'templates.libsonnet'; templates.MyTemplate { tier: 'backend', metadata+: { namespace: 'prod', }, } // example3.jsonnet local templates = import 'templates.libsonnet'; templates.MyTemplate { tier: 'frontend', metadata+: { namespace: 'prod', labels+: { foo: 'bar' }, }, } // example4.jsonnet local templates = import 'templates.libsonnet'; templates.MyTemplate { tier: 'backend', } 注意以下几点： 我们通过四次实例化抽象来表达所有四种变体，但你也可以使用功能抽象。 虽然我们为每个实例使用单独的Jsonnet文件，但你也可以将它们合并到一个文件中。 在抽象模板中，空间命名为默认值，并且必须被覆盖。 乍一看，Jsonnet略显冗长，但随着模板实例化数量的增加而降低了工作量。 在MyTemplate中，local关键字定义了一个变量服务，该服务初始化为self（对最近的封闭对象的引用）。这允许您从嵌套对象中引用对象，其中self被重新定义。 tier字段有两个冒号（而不是常规的JSON单冒号），并且在生成的JSON中隐藏（不输出）。否则，Kubernetes将拒绝tier为无法识别的字段。隐藏字段仍然可以被覆盖和引用 - 在本例中为service.tier。 模板本身不能使用，因为引用service.tier会触发错误构造，这会引发给定文本的运行时错误。为避免错误，模板的每个实例都会使用其他表达式覆盖tier字段。换句话说，这种模式表达类似于纯虚拟/抽象方法的东西。 使用抽象函数意味着配置只能参数化。相反，模板允许您覆盖父项中的任何字段。如第14章所述，虽然简洁性应该是您设计的基础，但简单易行的能力非常重要。模板覆盖提供了一个有用的避开方式，可以更改通常被认为太低级别的特定细节。例如： templates.MyTemplate { tier: 'frontend', spec+: { sessionAffinity: 'ClientIP', }, } 这是将现有模板转换为Jsonnet的典型工作流程： 将其中一个YAML格式转换为JSON。 通过Jsonnet格式化程序运行生成的JSON。 手动添加Jsonnet构造以抽象和实例化代码（如示例中所示）。 该示例显示了如何在保留不同的某些字段的同时删除重复内容。随着差异越来越微妙（例如，字符串只是略有不同）或表达具有挑战性（例如，配置具有结构差异，如阵列中的附加元素，或者应用于阵列的所有元素的相同差异），使用配置语言变得更加引人注目。 通常，抽象不同配置的共性可以促进关注点的分离，并且与编程语言中的模块化具有相同的好处。您可以针对许多不同的用例利用抽象功能： 单个团队可能需要创建几乎（但不完全）相同的多个配置版本。例如，在跨不同环境（prod/stage/dev/test）管理部署，调整不同体系结构上的部署或调整时区不同地区的能力。 组织可能拥有一个基础架构团队，负责维护可重用组件-API服务框架、缓存服务器或MapReduces。对于每个组件，基础结构团队可以维护一个模板，该模板定义大规模运行该组件所需的Kubernetes对象。每个应用程序团队都可以实例化该模板以添加其应用程序的详细信息。 集成自定义应用程序（内部软件） 如果你的基础架构使用任何自定义应用程序（即内部开发的软件，而不是现成的解决方案），那么可以将这些应用程序设计为与可重用的配置语言共存。用于编写配置文件或与生成的配置数据交互时（例如，出于调试目的或与其他工具集成时），本节中的建议应改善整体用户配置体验。它们还应简化应用程序的设计并将配置与数据分开。 处理自定义应用程序的通用策略应该是： 让配置语言处理它的设计目的:语言问题的方面。 让应用程序处理所有其他功能。 以下最佳实践包括使用Jsonnet的示例，但相同的建议也适用于其他语言： 使用单个纯数据文件，然后让配置语言使用import将配置拆分为文件。这意味着配置语言实现只需要发出（并且应用程序只需要使用）单个文件。此外，由于应用程序可以以不同方式组合文件，因此该策略明确且清晰地描述了如何组合文件以形成应用程序配置。 使用对象表示命名实体的集合，其中字段包含对象名称，值包含实体的其余部分。避免使用每个元素都有名称字段的对象数组。 Bad JSON: [ { &quot;name&quot;: &quot;cat&quot;, ... }, { &quot;name&quot;: &quot;dog&quot;, ... } ] Good JSON: { &quot;cat&quot;: { ... }, &quot;dog&quot;: { ... } } 该策略使得集合（和单个动物）更容易扩展，并且您可以通过名称引用实体（例如，animals.cat）而不是引用索引（例如，动物[0]）。 避免在顶级按类型对实体进行分组。构造JSON，以便将逻辑相关的配置分组到同一子树中。这允许抽象（在配置语言级别）遵循功能边界。 Bad JSON: { &quot;pots&quot;: { &quot;pot1&quot;: { ... },&quot;pot2&quot;: { ... } }, &quot;lids&quot;: { &quot;lid1&quot;: { ... }, &quot;lid2&quot;:{ ... } } } Good JSON: { &quot;pot_assembly1&quot;: { &quot;pot&quot;: { ... },&quot;lid&quot;: { ... } }, &quot;pot_assembly2&quot;: { &quot;pot&quot;: { ... },&quot;lid&quot;: { ... } } } 在配置语言级别，此策略支持以下抽象： local kitchen = import 'kitchen.libsonnet'; { pot_assembly1: kitchen.CrockPot, pot_assembly2: kitchen.SaucePan { pot+: { color: 'red' }}, } 保持数据一直简单:： –避免在数据表示中嵌入语言功能（如“陷阱1：无法将配置识别为编程语言问题”（第317页）中所述）。这些类型的抽象将只会产生混淆，因为它们会强制用户决定是使用数据表示形式还是配置语言中的抽象功能。 –不要担心过于冗长的数据表示。减少冗长的解决方案会带来复杂性，并且这个问题可以使用配置语言管理。 –避免在应用程序中解释自定义字符串插值语法，例如字符串中的条件或占位符引用。有时解释是不可避免的 - 例如，当您需要描述在生成配置的纯数据版本（报警，处理程序等）之后执行的操作时。但除此之外，让配置语言尽可能多地完成语言级别的工作。 如前所述，如果您可以完全删除配置，那么这样做始终是您的最佳选择。虽然配置语言可以通过使用具有默认值的模板来隐藏底层模型的复杂性，但生成的配置数据并不是完全隐藏的 - 它可以由工具处理、由人检查或加载到配置数据库中。出于同样的原因，不要依赖配置语言来修复模型本身中底层modelfix中不一致的命名、复数或错误。如果您无法修复模型中的不一致性，最好在语言级别使用它们以避免更多的不一致。 根据我们的经验，配置更改往往会在系统中随着时间的推移成为导致停机的根本原因（请参阅附录C中的停机的主要原因列表）。验证配置更改是保持可靠性的关键步骤。我们建议在配置执行后立即验证生成的配置数据。单独的语法验证（即，检查JSON是否可解析）将不会发现许多错误。在通用模式验证之后，检查特定于应用程序域的属性 - 例如，是否存在必填字段、是否存在引用的文件名，以及提供的值是否在允许的范围内。 您可以使用JSONschema验证Jsonnet的JSON。对于使用协议缓冲区的应用程序，您可以从Jsonnet轻松生成这些缓冲区的规范JSON格式，协议缓冲区实现将在反序列化期间进行验证。 无论您决定如何验证，都不要忽略无法识别的字段名称，因为它们可能表示配置语言级别的拼写错误。Jsonnet可以使用::语法屏蔽不应输出的字段。在precommit hook中执行相同的验证也是一个好主意。 有效地运行配置系统 在以任何语言实现“配置为代码”时，我们建议遵循通常有助于软件工程的规程和流程。 版本 配置语言通常会触发工程师编写模板库和实用程序函数。通常，一个团队维护这些库，但许多其他团队可能会使用它们。当您需要对库进行重大更改时，您有两种选择： 提交所有客户端代码的全局更新，重构代码以使其仍然有效（这可能在组织上不可行）。 使用版本库，以便不同的消费者可以使用不同的版本并独立迁移。选择使用弃用版本的消费者将无法获得新版本的好处，并将产生技术债务 - 有一天，他们将不得不重构他们的代码以使用新库。 大多数语言，包括Jsonnet，都没有为版本控制提供任何特定的支持; 相反，你可以轻松使用目录。有关Jsonnet中的实际示例，请参阅ksonnet-lib存储库，其中版本是导入路径的第一个组件： local k = import 'ksonnet.beta.2/k.libsonnet'; 源控制 第14章主张保留配置更改的历史记录（包括谁创建它们）并确保回滚简单可靠。检查配置到源代码控制中可以带来所有这些功能，还可以编写查看配置更改的代码。 工具 考虑如何强制执行样式和lint配置，并调查是否有一个编辑器插件将这些工具集成到您的工作流程中。您的目标是在所有作者之间保持一致的风格、提高可读性并检测错误。有些编辑器支持可以为您运行格式化程序和其他外部工具的写后hook.。您还可以使用预先挂钩来运行相同的工具，以确保签入的配置具有高质量。 测试 我们建议对上游模板库实施单元测试。确保库在实例化时生成预期的具体配置。与之对应的，为了便于维护，函数库也应该包括单元测试 在Jsonnet中，你可以将测试编写为Jsonnet文件： 导入要测试的库。 应用库 使用assert语句或标准库assertEqual函数来验证其输出。后者在其错误消息中显示所有不匹配的值。 以下示例为测试joinName函数和MyTemplate： // utils_test.jsonnet local utils = import 'utils.libsonnet'; std.assertEqual(utils.joinName(['foo', 'bar']),'foo-bar') &amp;amp;&amp;amp; std.assertEqual(utils.MyTemplate { tier: 'frontend' }, {... }) 对于较大的测试套件，你可以使用Jsonnet社区成员开发的更全面的单元测试框架。你可以用此框架以结构化方式定义和运行测试套件-例如，报告所有失败测试的集合，而不是在第一个失败的断点中中止执行。 何时评估配置 我们的关键属性包括封闭性;也就是说，无论它们在何时何地执行，相同的配置语言必须生成相同的配置数据。如第14章所述，如果系统依赖于其密封环境之外可以改变的资源，则系统可能很难或无法回滚。通常，封闭性意味着Jsonnet代码始终可以与它所代表的扩展JSON互换。因此，你可以在任何时间从Jsonnet生成JSON。 我们建议在版本控制中存储配置。你可以在注册之前验证配置。此外，应用程序在需要JSON数据时可以评估配置。同样，你可以在构建时进行评估。你可以根据用例的具体情况对每个选项进行评估优化。 初期：检查JSON 你可以在检查版本控制之前从Jsonnet代码生成JSON。典型的工作流程如下： 修改Jsonnet文件。 运行Jsonnet命令行工具（可能包装在脚本中）以重新生成JSON文件。 勾选预先提交确保Jsonnet代码和JSON输出始终一致。 将所有内容打包成拉取请求以进行代码审查。 优点 审阅者可以检查具体的更改 - 例如，重构不应该影响生成的JSON。 可以在生成和抽象级别上跨不同版本检查多个作者的行注释。同样利于对变更的审核。 在运行时你无需运行Jsonnet，这样可以降低复杂性、二进制大小和风险。 缺点 生成的JSON不一定是可读的 - 例如，如果它嵌入了长字符串。 由于其他原因，JSON可能不适合检查版本控制 - 例如，如果它太大或包含隐私。 如果单个Jsonnet文件的许多并发编辑同时合并到单个JSON文件，则可能会出现合并冲突。 中期：构建时评估 你可以通过在构建时运行Jsonnet命令行实用程序并将生成的JSON嵌入到发布工件中（例如，作为tarball）来避免将JSON检入源控件。应用程序代码只是在初始化时从磁盘读取JSON文件。如果你使用的是Bazel，则可以使用Jsonnet Bazel规则轻松实现此目的。在谷歌，我们通常使用这种方法，该方法有如下优点。 优点 你可以控制运行时的复杂性、二进制大小和风险，而无需在每个拉取请求中重建JSON文件。 原始Jsonnet代码与生成的JSON之间不存在去同步的风险。 缺点 构建更复杂。 在代码审查期间评估具体变化更加困难。 后期：在运行时评估 链接Jsonnet库允许应用程序本身随时解释配置，产生的JSON配置的内存中表示。 优点 它更简单，不需要事先评估。 可以在执行期间评估用户提供的Jsonnet代码。 缺点 任何链接库都会增加覆盖范围和风险。 可能会在运行时发现配置错误，为时已晚。 如果Jsonnet代码不稳定，则必须特别小心。（我们在第333页的“防止滥用配置”中讨论了原因） 按照我们的运行示例，如果你正在生成Kubernetes对象，何时应该运行Jsonnet？ 答案取决于你的具体实施。如果你正在构建类似ksonnet（从本地文件系统运行Jsonnet代码的客户端命令行工具），最简单的解决方案是将Jsonnet库链接到该工具并评估正在进行的Jsonnet。这样做是安全的，因为代码在作者自己的机器上运行。 Box.com的基础架构使用Git将配置更改推送到生产环境。为了避免在服务器上执行Jsonnet，Git会对保存在存储库中的生成的JSON进行操作。对于像Helm或Spinnaker这样的部署管理守护程序，唯一的选择是在运行时评估服务器上的Jsonnet（下一节中将介绍注意事项）。 防止滥用配置 与长时间运行的服务不同，配置执行应该随着配置生成快速终止。然而，由于错误或恶意攻击，配置可能会占用任意数量的CPU时间或内存。为了说明原因，请考虑以下非终止Jsonnet程序： local f(x) = f(x +1); f(0) 使用无界内存的程序与之类似： local f(x) = f(x +[1]); f([]) 你可以使用对象而不是函数或其他配置语言编写等效示例。 可以尝试通过限制语言来避免过度消耗资源，以使其不再是图灵计算机完成的。但是，强制所有配置终止并不一定能防止过度消耗资源。编写一个耗费足够时间或内存的程序而实际是不终止的程序是很容易的。例如： local f(x) = if x== 0 then [] else [f(x - 1), f(x - 1)]; f(100) 实际上，即使使用简单的配置格式（如XML和YAML），也存在此类程序。 当然，这些情景的风险取决于具体情况。问题较少的情况，假设命令行工具使用Jsonnet构建Kubernetes对象，然后部署这些对象。在这种情况下，Jsonnet代码是可信的：很少产生非终止的事故，你可以使用Ctrl-C来缓解它们。很少会产生内存耗尽。另一个极端情况，使用类似Helm或Spinnaker这样的服务，它接受来自最终用户的任意配置代码并在请求处理程序中对其进行评估，你需要避免占用请求处理程序或耗尽内存的DOS攻击。 如果在请求处理程序中评估不受信任的Jsonnet代码，则可以通过沙盒化Jsonnet执行来避免此类攻击。一个简单的策略是使用单独的进程和ulimit（或其非UNIX等价物）。通常，你需要fork到命令行可执行文件而不是链接Jsonnet库。因此，未在给定资源内完成的程序将执行失败并通知最终用户。为了进一步防御C++内存漏洞利用，你可以使用Jsonnet的本机Go实现。 结论 无论是使用Jsonnet、采用其他配置语言还是开发自己的配置语言，我们都希望你能够应用这些最佳实践来管理配置生产系统所需的复杂性和操作负载。 至少，配置语言的关键属性是优秀的工具，封闭配置以及配置和数据的分离。 你的系统可能不至于复杂到使用配置语言。过渡到像Jsonnet这样的特定于域的语言是一种在你的系统复杂度增加时可以考虑的策略。它会提供一致且结构良好的界面，让你的SRE团队有更多时间来处理其他重要项目。</summary></entry><entry><title type="html">第十四章 系统配置最佳实践</title><link href="http://localhost:4000/sre/2020/01/14/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/" rel="alternate" type="text/html" title="第十四章 系统配置最佳实践" /><published>2020-01-14T00:00:00+08:00</published><updated>2020-01-14T00:00:00+08:00</updated><id>http://localhost:4000/sre/2020/01/14/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5</id><content type="html" xml:base="http://localhost:4000/sre/2020/01/14/%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/">&lt;p&gt;系统配置是SRE经常要面对的问题。这是一项繁琐的工作，有时还会让人沮丧，特别是当工程师不熟悉系统，或是系统配置目标不够清晰时这种情况更为明显。系统配置常见的场景如下：在系统初始阶段的配置设计，出现事故时的紧急配置设计。&lt;/p&gt;

&lt;p&gt;本章基于经验和策略，以基础架构系统工程师的角度来进行系统配置，从而达到“安全和可持续”的目标。&lt;/p&gt;

&lt;h2 id=&quot;什么是配置&quot;&gt;什么是配置？&lt;/h2&gt;
&lt;p&gt;系统并不是永恒不变的。不断变化的业务需求、基础架构的需求和其他因素都会导致系统发生变化。当需要对系统快速迭代时（这个过程是昂贵和冗长的，不仅仅包含系统的重构、部署和代码的更改，系统配置的更新也是重要的一部分。由此，我们需要提供一种低开销的和人机界面的方式进行系统配置。SRE会利用此系统进行系统部署、性能调整和事件响应期间的配置变更。&lt;/p&gt;

&lt;p&gt;我们将系统分为三个关键组件：
. 应用程序
. 数据集
. 系统配置&lt;/p&gt;

&lt;p&gt;实际上，我们是无法将以上三个部分清楚的区分。例如，许多系统使用编程语言进行配置。同样，数据集可能包含代码，例如存储SQL的过程，这些代码已经构成了“应用程序”。&lt;/p&gt;

&lt;p&gt;而良好的配置界面可以完成快速、可信和可测试的配置更改。减少错误的发生，降低工程师的学习曲线。&lt;/p&gt;

&lt;h3 id=&quot;配置的可靠性&quot;&gt;配置的可靠性&lt;/h3&gt;

&lt;p&gt;系统最终由人来进行管理和配置。系统配置人机界面的质量会影响团队运行该系统的能力和可靠性。精心设计的配置界面对使用者的影响类似于代码质量对系统可维护性的影响。&lt;/p&gt;

&lt;p&gt;但在一些方面，配置往往与代码有不同的意义。通过代码更改系统功能是一个冗长且复杂的过程，涉及的范围往往是小增量的更改、代码审查和测试。相比之下，更改单个配置选项可能会对功能产生重大影响。例如，一个错误的防火墙配置规则可能会将自己锁到系统之外。而且，配置通常存在于未经测试（甚至是不可测试）的环境中。&lt;/p&gt;

&lt;p&gt;而且，系统配置更改可能需要工程师处于很大的压力下。在故障期间，可以简单安全地调整配置是必不可少的过程。举个航空的例子，早期，飞机的控制界面和指示灯混乱导致了许多安全事故。研究表明，无论飞行员技能或经验如何，操作故障都是频繁的。所以，可靠的配置是至关重要的。&lt;/p&gt;

&lt;h3 id=&quot;原理和机制&quot;&gt;原理和机制&lt;/h3&gt;

&lt;p&gt;在设计新软件或使用现有软件组装新系统时我们需要讨论配置：如何配置它？配置如何加载？我们将配置设为两部分：配置理论和配置机制。&lt;/p&gt;

&lt;p&gt;配置理论适用于完全独立于所选语言和其他机制的配置方面。我们对原理的讨论包括如何构造配置，如何实现抽象，以及如何无缝地支持不同的用例。&lt;/p&gt;

&lt;p&gt;我们对配置机制讨论涵盖了语言设计，部署策略以及与其他系统的交互等方面。本章重点关注机制，部分原因是语言选择已经在整个行业中进行了广泛的讨论。此外，一些特定的组织可能已经具有强大特色化的要求，例如预先存在的配置基础架构，因此配置机制不容易推广。Jsonnet的以下章节给出Jsonnet现有软件中配置机制的案例——特别是语言设计方面的。&lt;/p&gt;

&lt;p&gt;分别讨论理论和机制使我们能够更清楚地进行配置。实际上，如果配置需要大量难以理解的用户输入，那么配置语言（无论是XML还是Lua）等实现的细节也无关紧要。相反，如果必须将它们输入到非常麻烦的界面中，即使最简单的配置输入也会导致问题。比如旧的Linux内核配置的过程是——必须通过一系列命令进行配置设置每个参数。为了进行最简单的校正，用户必须从头开始配置过程。&lt;/p&gt;

&lt;h3 id=&quot;配置理论&quot;&gt;配置理论&lt;/h3&gt;
&lt;p&gt;本节讨论内容基于完整配置实现，因此下文一些观点是对所有配置实现的概况。&lt;/p&gt;

&lt;p&gt;在以下理论观点中，我们的理想配置是不需要任何配置。在理想场景下，新系统部署前，能根据部署信息、负载或其他配置自动生成正确配置。当然，这些实际都不太可能实现。需要指出的是，这个想法指出了配置的目标：避免复杂、多样的配置，向简单化努力。&lt;/p&gt;

&lt;p&gt;历史上，NASA的核心系统提供了大量的控制操作（相当于配置），这需要对操作者进行高强度的训练才能掌握。图14-1，展现了NASA的一名操作者，通过复杂的操作排列进行飞行器控制。在现代工业中，这种培训已不再可行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/14-1.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图14-1 NASA航天器控制中心的控制面板，说明了配置复杂性 &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;尽管这些理想的配置可以减少对操作员的训练，但也让操作员对问题的深入理解降低。然而，随着系统复杂性增加，操作员对系统的认知理解却越来越重要。&lt;/p&gt;

&lt;p&gt;当我们把这些原则应用到Google的系统时，目标是让内部用户使用简单、全面和低成本。&lt;/p&gt;

&lt;h3 id=&quot;与用户交互的配置问题&quot;&gt;与用户交互的配置问题&lt;/h3&gt;

&lt;p&gt;无论你的配置是什么，如何配置，最终都体现在与计算机交互的一个界面，来询问用户接下来如何操作，让用户来选择。无论是XML编辑，还是GUI向导，这种模型都适用。&lt;/p&gt;

&lt;p&gt;在现代软件系统中，我们可以从两个不同的角度来看待这个模型：&lt;/p&gt;

&lt;h4 id=&quot;以基础设施为主&quot;&gt;以基础设施为主：&lt;/h4&gt;

&lt;p&gt;提供尽可能多的配置。这样做使用户能够根据他们的确切需求调整系统。配置越多越好，因为系统可以调整到完美。&lt;/p&gt;

&lt;h4 id=&quot;以用户为主&quot;&gt;以用户为主：&lt;/h4&gt;

&lt;p&gt;首先会询问用户一部分关于基础设施的问题，之后才能回归到实际业务上。这样的配置，越少越好，因为回答问题是很繁琐、麻烦的事情。&lt;/p&gt;

&lt;p&gt;在最初的理论模型中，我们推崇以用户为中心的理念。&lt;/p&gt;

&lt;p&gt;这样的软件设计脱离了实际。以用户为中心的配置，要求你的软件设计需要真正考虑到用户的需求，专注于用户，这就需要对用户的需求进行深入挖掘。相比而言，以基础设施为中心的配置，需要你为用户提供丰富的配置，来达到系统操作的目的。这些模型互相不冲突，但调试他们比较困难。在配置中，选项可枚举是比较好的，而不是设计出一个极其通用的软件，真正做到“开箱即用”。&lt;/p&gt;

&lt;p&gt;实际中，可以通过各种方式（后续章节会介绍）来删除一些配置，让系统的配置从以基础设施为主，向以用户为主进行转变。&lt;/p&gt;

&lt;h3 id=&quot;交互性问题更应接近用户目标&quot;&gt;交互性问题更应接近用户目标&lt;/h3&gt;

&lt;p&gt;当我们以用户为中心进行配置时，提出的交互式问题，需要确保用户能够准确理解。我们可以思考用户输入的本质：一方面，针对用户的每一项提问，要有更少的配置选项；另一方面，用户又想了解系统如何实现他们的需求，这就需要更多的选项。&lt;/p&gt;

&lt;p&gt;让我们以沏茶的过程来比喻如何配置的过程。在配置项比较少的情况下，用户可以要求“热绿茶”，并能基本满足用户需求。相反，配置项很多的情况下，用户可以要求：水量、水温、茶叶品牌、茶叶分量、浸泡时间、茶杯类型。为了获取接近完美的茶，而使用更多配置项，坚持这些细节所付出的成本和代价，可能太大。&lt;/p&gt;

&lt;p&gt;这个比喻对用户和配置系统开发人员都很有帮助。当用户确定操作步骤时，系统应按照他们要求进行。但是当用户只清楚自己目标时，我们的系统可以改进其中的配置步骤，最终实现用户目标即可。因此，预先了解用户目标是很有必要的。&lt;/p&gt;

&lt;p&gt;此理论在实际应用中发挥的价值，以任务调度系统来补充说明。假如你需要运行一个分析进程，通过Kubernetes或Mesos可以实现你的目标，而不需要你花费很长时间去配置细节参数，比如选择哪台物理机运行等。&lt;/p&gt;

&lt;h3 id=&quot;配置的必选项和可选项&quot;&gt;配置的必选项和可选项&lt;/h3&gt;

&lt;p&gt;配置分为两类：必选项和可选项。必选项的配置回答的问题针对核心功能。例如谁为一项手术收费。可选项一般不代表核心功能，但配置这些选项可以提高功能的质量——例如，设置一些工作进程。&lt;/p&gt;

&lt;p&gt;为了保持以用户为中心并确保易用性，你的系统应尽量减少必选配置的数量。这不是一件容易的事，但这很重要。虽然人们可能会争辩说，增加一个或两个小步骤只会增加很少的成本，但工程师的生活往往是一个无穷无尽的单独步骤链。这些小步骤的减少可以显着提高工作效率。&lt;/p&gt;

&lt;p&gt;最初的一组必选配置通常包括您在设计系统时考虑的问题。减少必选项的最简单方法是将它们转换为可选项，这意味着这些默认配置可以安全有效地应用于大多数（如果不是全部）用户。例如，我们可以简单地执行运行，而不是要求用户定义执行是否应该运行。&lt;/p&gt;

&lt;p&gt;虽然默认值通常是保存在代码中的静态值，但并非必须如此。它可以基于系统的其他属性动态确定。利用动态确定可以进一步简化配置。&lt;/p&gt;

&lt;p&gt;对于上下文，请参考以下动态默认示例。计算密集型系统通常可以通过配置控制使用多少计算线程。它的动态缺省配置了与系统（或容器）具有执行核数一样多的线程。在这种情况下，单个静态默认值没有用。动态默认值意味着我们不要求用户给定平台上部署的正确线程数。同样，单独部署在容器中的Java二进制文件可以根据容器中的可用内存自动调整其堆限制。这是两个常见的动态默认值示例。如果您需要限制资源使用，则对能够覆盖配置中的动态默认值非常有用。&lt;/p&gt;

&lt;p&gt;使用动态默认值可能不适用于所有人。随着时间的推移，用户可能更喜欢不同的方法并要求更好地控制动态默认值。如果很多用户反映动态配置有问题，一般来说这表示你的动态配置逻辑可能不再符合当前用户群的要求。需要考虑实施改进，使您的动态默认值无需额外的配置即可运行。如果只有一小部分用户不满意，他们最好手动设置配置选项。更复杂的系统会增加用户的工作量（例如，增加了文档的阅读难度）。&lt;/p&gt;

&lt;p&gt;在为可选项选择默认选项时，无论您选择静态还是动态默认值，请仔细考虑您选择的影响。经验表明，大多数用户会使用默认值，因此默认值的配置既是机会也是责任。你可以巧妙地向人们推进正确的方向，但指定错误的默认值会造成很大的伤害。例如，考虑配置默认值及其在计算机科学之外的影响。器官默认捐献的国家的器官捐献都比例明显高于器官默认不捐献的国家。简单地选择特定的默认值会对整个系统中的医疗选择产生深远的影响。&lt;/p&gt;

&lt;p&gt;一些可选项在没有明确用例的情况下开始。您可能想要完全删除这些问题。大量可选项可能会使用户感到困惑，因此您应该仅在真正需要的情况下添加配置选项。最后，如果您的配置恰好使用了继承的概念，那么能够恢复配置中任何可选项的默认值是很有用的。&lt;/p&gt;

&lt;h3 id=&quot;避免简单&quot;&gt;避免简单&lt;/h3&gt;

&lt;p&gt;到目前为止，我们已经讨论过将系统配置简化为最简单的形式。但是，配置系统也可能需要考虑高级用户。回到我们的茶类比，如果我们真的需要在特定时间内浸泡茶怎么办？&lt;/p&gt;

&lt;p&gt;适应高级用户的一种策略是找到常规用户和高级用户所需要的最低公分母，并将此复杂性作为默认值。缺点是这个决定会影响每个人; 即使是最简单的用例现在也需要以低级别的角度来考虑。&lt;/p&gt;

&lt;p&gt;通过根据默认行为的可选覆盖考虑配置，用户配置“绿茶”，然后添加“将茶浸泡五分钟。”在此模型中，默认配置仍然是高级别并且接近用户的目标，但用户可以微调低级别配置。这种方法并不新颖。我们可以用高级编程语言（如C ++或Java）做类比，程序员能够将代码中的机器（或VM）指令包含在以高级语言编写的代码中。在某些消费者软件中，我们看到具有高级选项的屏幕可以提供比典型视图更精细的控制。&lt;/p&gt;

&lt;p&gt;优化整个配置的总时间是有用的。不仅要考虑配置本身的行为，还要考虑用户在提供许多选项时可能遇到的决策困难，在纠正错误配置所需的时间，由于信心较低而导致的修改配置速度较慢等等。在考虑配置设计备选方案时，如果能够更轻松地支持最常见的用例，则可以选择以较少但难度较大的步骤完成复杂配置的选项。&lt;/p&gt;

&lt;p&gt;如果您发现超过一小部分用户需要复杂配置，则可能错误地识别了常见用例。如果是这样，请重新审视系统的初始产品假设并其他用户进行研究。&lt;/p&gt;

&lt;h2 id=&quot;配置机制&quot;&gt;配置机制&lt;/h2&gt;
&lt;p&gt;到目前为止，我们的讨论涵盖了配置哲学。本节将重点转移到用户如何与配置交互的机制。&lt;/p&gt;

&lt;h3 id=&quot;单独的配置和产生的数据&quot;&gt;单独的配置和产生的数据&lt;/h3&gt;

&lt;p&gt;存储配置的语言是一个不可避免的问题。您可以选择使用INI、YAML或XML文件中的纯数据。或者，配置可以存储在更高级语言中，以允许更灵活的配置。&lt;/p&gt;

&lt;p&gt;从根本上说，向用户提出的所有问题都可以归结为静态信息）。这显然对“应该使用多少线程”等问题的静态回答）“但是，即使”每一个请求都应该使用什么功能？“也只是功能的静态引用。&lt;/p&gt;

&lt;p&gt;要回到配置是代码还是数据这个古老的问题，我们的经验表明，代码和数据都有，但将两者分离是最优的。系统基础结构应该对纯静态数据进行操作，这些数据可以是协议缓冲区、YAML或JSON等格式。这种选择并不意味着用户需要与纯数据进行实际交互。用户可以与生成此数据的高级接口进行交互。然而，这种数据格式可以被API使用，从而允许系统和自动化的进一步堆叠。&lt;/p&gt;

&lt;p&gt;这个高级接口几乎可以是任何东西。它可以是一种高级语言，如基于Python的域特定语言（DSL）、Lua或专用构建语言，如Jsonnet（我们将在第15章中详细讨论）。我们可以把这样的接口看作一个编译，类似于我们如何对待C++代码。高级接口也可能根本不是语言其配置由web UI消化。&lt;/p&gt;

&lt;p&gt;从有意与静态数据表示分离的配置UI开始，意味着系统具有部署的灵活性。不同的组织可能具有不同的文化规范或产品需求（例如使用公司内的特定语言或需要将配置外部化到最终用户），并且这种通用的系统可以适用于支持不同的配置需求。毫不费力地支持多种语言。参见图14-2。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/something/images/SRE/14-2.jpg&quot; alt=&quot;&quot; /&gt; &lt;center&gt;
图14-2。配置流具有单独的配置界面和配置数据基础结构。请注意，Web UI通常还会显示当前配置，从而使关系成为双向关系。 &lt;/center&gt;&lt;/p&gt;

&lt;p&gt;这种分离对于用户来说是完全不可见的。用户的共同路径可能是在配置语言中编辑文件，而所有其他的事情都发生在幕后。例如，一旦用户向系统提交更改，新存储的配置就自动编译成原始数据&lt;/p&gt;

&lt;p&gt;静态配置数据一旦获得，也可以在数据分析中使用。例如，如果生成的配置数据是JSON格式的，那么可以将其加载到PostgreSQL中，并用数据库查询进行分析。作为基础架构所有者，您可以快速且容易地查询正在使用哪些配置参数以及由谁使用这些配置参数。此查询对于识别您可以删除的特性或测量bugy选项的影响非常有用。&lt;/p&gt;

&lt;p&gt;当使用最终的配置数据时，您会发现存储有关配置如何被摄取的元数据也很有用。例如，如果您知道数据来自Jsonnet中的配置文件，或者您在将数据编译成数据之前已经拥有了原始数据的完整路径，那么您可以跟踪配置作者。&lt;/p&gt;

&lt;p&gt;配置语言是静态数据也是可以接受的。例如，您的基础结构和接口都可能使用普通JSON。但是，要避免接口使用的数据格式和内部使用的数据格式之间的紧密耦合。例如，您可以在内部使用包含配置所消耗的数据结构的数据结构。内部数据结构还可能包含完全特定于实现的数据，这些数据永远不需要在系统外部出现。&lt;/p&gt;

&lt;h3 id=&quot;工具的重要性&quot;&gt;工具的重要性&lt;/h3&gt;

&lt;p&gt;工具可以区分混乱的噩梦和可持续的可伸缩的系统，但在设计配置系统时经常会被忽略。本节讨论优化配置系统应该有的关键工具。&lt;/p&gt;

&lt;h4 id=&quot;语义验证&quot;&gt;语义验证&lt;/h4&gt;

&lt;p&gt;虽然大多数语言提供现成的语法验证，但不要忽视语义验证。即使您的配置在语法上有效，它是否可能做有用的事情？或者用户是否引用了一个不存在的目录（由于打字错误），或者需要比实际数据库多一千倍的RAM（因为单位不是用户所期望的）？&lt;/p&gt;

&lt;p&gt;尽可能验证配置在语义上是否有意义，有助于防止中断并降低运营成本。对于每个可能的错误配置，我们应该问自己，在用户提交配置时是否可以阻止它，而不是在提交更改之后。&lt;/p&gt;

&lt;h4 id=&quot;配置语法&quot;&gt;配置语法&lt;/h4&gt;

&lt;p&gt;虽然能够确保配置满足用户需求，但消除机械障碍也很重要。从语法角度来看，配置语言应该具备一下特点：&lt;/p&gt;

&lt;h5 id=&quot;在编辑器中高亮显示语法在公司内使用&quot;&gt;在编辑器中高亮显示语法（在公司内使用）&lt;/h5&gt;

&lt;p&gt;通常，您已经通过重用现有语言解决了这个问题。但是，特定语言可能具有额外的语法方式，从特定的方面突出显示 。&lt;/p&gt;

&lt;h5 id=&quot;短绒&quot;&gt;短绒&lt;/h5&gt;

&lt;p&gt;使用linter来识别语言使用中的常见不一致。 Pylint是一种流行的语言示例。&lt;/p&gt;

&lt;h5 id=&quot;自动语法格式化&quot;&gt;自动语法格式化&lt;/h5&gt;

&lt;p&gt;内置标准化可最大限度地减少关于格式化的讨论，并在贡献者切换项目时减少认知负荷。标准格式化还可以实现更轻松的自动编辑，这在大型组织中很有用。现有语言中的autoformatters示例包括clang-format和autopep8。&lt;/p&gt;

&lt;p&gt;这些工具使用户能够轻松地编写和编辑配置并确保其语法正确。在面向空白的配置中进行正确的缩进会产生很大的优势。&lt;/p&gt;

&lt;h4 id=&quot;权限和变更跟踪&quot;&gt;权限和变更跟踪&lt;/h4&gt;

&lt;p&gt;由于配置可能会影响公司和机构的关键系统，因此确保良好的用户隔离以及了解系统中发生的变化非常重要。如第10章所述，有效的死后文化可以避免责怪个人。但是，它既可以在事件期间进行，也可以在进行事后调查时知道谁更改了配置，并了解配置更改如何影响系统。无论事故是由于事故还是恶意行为都是如此。&lt;/p&gt;

&lt;p&gt;系统的每个配置代码段都应具有明确的所有者。例如，如果使用配置文件，则其目录可能由单个生产组拥有。如果目录中的文件只能有一个所有者，则跟踪谁进行更改会更容易。&lt;/p&gt;

&lt;p&gt;版本控制配置，无论其执行方式如何，都允许您及时返回以查看在任何给定时间点配置的内容。将配置文件检入版本控制系统（如Subversion或Git）是当今常见的做法，但这种做法对于Web UI或远程API提取的配置同样重要。您可能还希望在配置和正在配置的软件之间实现更紧密的耦合。通过这样做，您可以避免无意中配置软件中尚不可用或不再支持的功能。&lt;/p&gt;

&lt;p&gt;在相关的说明中，将配置和生成的应用程序的更改记录到系统是有用的（有时是必需的）。提交新版本配置的简单操作并不总是意味着直接应用配置（稍后将详细介绍）。如果在事件响应期间怀疑系统配置更改是罪魁祸首，则能够快速确定进行更改的完整配置编辑集非常有用。这样可以实现可靠的回滚，并能够通知其配置受到影响的各方。&lt;/p&gt;

&lt;h4 id=&quot;安全配置变更申请&quot;&gt;安全配置变更申请&lt;/h4&gt;

&lt;p&gt;如前所述，配置是对系统功能进行大量更改的简单方法，但它通常不经过单元测试甚至不易测试。由于我们希望避免可靠性事件，因此我们应该检查配置更改的安全应用是什么。&lt;/p&gt;

&lt;p&gt;要使配置更改安全，它必须具有三个主要属性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;逐步部署，避免全有或全无变化的能力&lt;/li&gt;
  &lt;li&gt;如果证明存在风险，则可以回滚更改&lt;/li&gt;
  &lt;li&gt;如果更改导致失控，则自动回滚（或至少是停止进度的能力）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;部署新配置时，避免全局一次性推送非常重要。相反，逐步推出新配置 - 这样做可以让您在导致100％中断之前检测问题并中止有问题的推送。这就是Kubernetes等工具使用滚动更新策略更新软件或配置而不是一次更新每个集群的原因之一。（有关相关讨论，请参阅第16章。）&lt;/p&gt;

&lt;p&gt;回滚能力对于减少故障持续时间非常重要。回滚有问题的配置可以比临时修复程序更快地缓解故障-对修补程序改进的内在信心肯定较低。&lt;/p&gt;

&lt;p&gt;为了能够向前滚动和回滚配置，它必须是密封的。需要可在其密封环境之外进行更改的外部资源的配置可能很难回滚。例如，存储在引用网络文件系统上的数据的版本控制系统中的配置不是密封的。&lt;/p&gt;

&lt;p&gt;最后但同样重要的是，在处理可能导致操作员控制突然丧失的变更时系统应特别小心。在桌面系统上，如果用户未确认更改，屏幕分辨率更改通常会提示倒计时并重置。这是因为不正确的显示器设置可能会阻止用户恢复更改。同样，系统管理员通常会意外地将自己防火墙移出他们当前正在设置的系统。&lt;/p&gt;

&lt;p&gt;这些原则并非配置所独有，适用于更改已部署系统的其他方法，例如升级二进制文件或推送新数据集。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;

&lt;p&gt;琐碎的配置更改可能会以极大的方式影响生产系统，因此我们需要刻意设计配置以减轻这些风险。配置设计包含API和UI设计的各个方面，应该是有目的的，而不仅仅是系统实现的副作用。将配置分为哲学和机制有助于我们在设计内部系统时获得清晰度，并使我们能够正确地进行讨论。&lt;/p&gt;

&lt;p&gt;应用这些建议需要时间和勤勉。有关我们如何在实践中应用这些原则的示例，请参阅有关Canary Analysis Service的ACM Queue文章。在设计这个实用的内部系统时，我们花了大约一个月的时间来尝试减少强制性问题并为可选问题找到合适的答案。我们的努力创造了一个简单的配置系统。因为它易于使用，所以它在内部被广泛采用。我们已经看不到用户支持的需求 - 因为用户可以轻松了解系统，他们可以放心地进行更改。当然，我们还没有完全消除错误配置和用户支持，我们也没有想到。&lt;/p&gt;</content><author><name>ZX</name></author><category term="《SRE-Google运维实践》" /><summary type="html">系统配置是SRE经常要面对的问题。这是一项繁琐的工作，有时还会让人沮丧，特别是当工程师不熟悉系统，或是系统配置目标不够清晰时这种情况更为明显。系统配置常见的场景如下：在系统初始阶段的配置设计，出现事故时的紧急配置设计。 本章基于经验和策略，以基础架构系统工程师的角度来进行系统配置，从而达到“安全和可持续”的目标。 什么是配置？ 系统并不是永恒不变的。不断变化的业务需求、基础架构的需求和其他因素都会导致系统发生变化。当需要对系统快速迭代时（这个过程是昂贵和冗长的，不仅仅包含系统的重构、部署和代码的更改，系统配置的更新也是重要的一部分。由此，我们需要提供一种低开销的和人机界面的方式进行系统配置。SRE会利用此系统进行系统部署、性能调整和事件响应期间的配置变更。 我们将系统分为三个关键组件： . 应用程序 . 数据集 . 系统配置 实际上，我们是无法将以上三个部分清楚的区分。例如，许多系统使用编程语言进行配置。同样，数据集可能包含代码，例如存储SQL的过程，这些代码已经构成了“应用程序”。 而良好的配置界面可以完成快速、可信和可测试的配置更改。减少错误的发生，降低工程师的学习曲线。 配置的可靠性 系统最终由人来进行管理和配置。系统配置人机界面的质量会影响团队运行该系统的能力和可靠性。精心设计的配置界面对使用者的影响类似于代码质量对系统可维护性的影响。 但在一些方面，配置往往与代码有不同的意义。通过代码更改系统功能是一个冗长且复杂的过程，涉及的范围往往是小增量的更改、代码审查和测试。相比之下，更改单个配置选项可能会对功能产生重大影响。例如，一个错误的防火墙配置规则可能会将自己锁到系统之外。而且，配置通常存在于未经测试（甚至是不可测试）的环境中。 而且，系统配置更改可能需要工程师处于很大的压力下。在故障期间，可以简单安全地调整配置是必不可少的过程。举个航空的例子，早期，飞机的控制界面和指示灯混乱导致了许多安全事故。研究表明，无论飞行员技能或经验如何，操作故障都是频繁的。所以，可靠的配置是至关重要的。 原理和机制 在设计新软件或使用现有软件组装新系统时我们需要讨论配置：如何配置它？配置如何加载？我们将配置设为两部分：配置理论和配置机制。 配置理论适用于完全独立于所选语言和其他机制的配置方面。我们对原理的讨论包括如何构造配置，如何实现抽象，以及如何无缝地支持不同的用例。 我们对配置机制讨论涵盖了语言设计，部署策略以及与其他系统的交互等方面。本章重点关注机制，部分原因是语言选择已经在整个行业中进行了广泛的讨论。此外，一些特定的组织可能已经具有强大特色化的要求，例如预先存在的配置基础架构，因此配置机制不容易推广。Jsonnet的以下章节给出Jsonnet现有软件中配置机制的案例——特别是语言设计方面的。 分别讨论理论和机制使我们能够更清楚地进行配置。实际上，如果配置需要大量难以理解的用户输入，那么配置语言（无论是XML还是Lua）等实现的细节也无关紧要。相反，如果必须将它们输入到非常麻烦的界面中，即使最简单的配置输入也会导致问题。比如旧的Linux内核配置的过程是——必须通过一系列命令进行配置设置每个参数。为了进行最简单的校正，用户必须从头开始配置过程。 配置理论 本节讨论内容基于完整配置实现，因此下文一些观点是对所有配置实现的概况。 在以下理论观点中，我们的理想配置是不需要任何配置。在理想场景下，新系统部署前，能根据部署信息、负载或其他配置自动生成正确配置。当然，这些实际都不太可能实现。需要指出的是，这个想法指出了配置的目标：避免复杂、多样的配置，向简单化努力。 历史上，NASA的核心系统提供了大量的控制操作（相当于配置），这需要对操作者进行高强度的训练才能掌握。图14-1，展现了NASA的一名操作者，通过复杂的操作排列进行飞行器控制。在现代工业中，这种培训已不再可行。 图14-1 NASA航天器控制中心的控制面板，说明了配置复杂性 尽管这些理想的配置可以减少对操作员的训练，但也让操作员对问题的深入理解降低。然而，随着系统复杂性增加，操作员对系统的认知理解却越来越重要。 当我们把这些原则应用到Google的系统时，目标是让内部用户使用简单、全面和低成本。 与用户交互的配置问题 无论你的配置是什么，如何配置，最终都体现在与计算机交互的一个界面，来询问用户接下来如何操作，让用户来选择。无论是XML编辑，还是GUI向导，这种模型都适用。 在现代软件系统中，我们可以从两个不同的角度来看待这个模型： 以基础设施为主： 提供尽可能多的配置。这样做使用户能够根据他们的确切需求调整系统。配置越多越好，因为系统可以调整到完美。 以用户为主： 首先会询问用户一部分关于基础设施的问题，之后才能回归到实际业务上。这样的配置，越少越好，因为回答问题是很繁琐、麻烦的事情。 在最初的理论模型中，我们推崇以用户为中心的理念。 这样的软件设计脱离了实际。以用户为中心的配置，要求你的软件设计需要真正考虑到用户的需求，专注于用户，这就需要对用户的需求进行深入挖掘。相比而言，以基础设施为中心的配置，需要你为用户提供丰富的配置，来达到系统操作的目的。这些模型互相不冲突，但调试他们比较困难。在配置中，选项可枚举是比较好的，而不是设计出一个极其通用的软件，真正做到“开箱即用”。 实际中，可以通过各种方式（后续章节会介绍）来删除一些配置，让系统的配置从以基础设施为主，向以用户为主进行转变。 交互性问题更应接近用户目标 当我们以用户为中心进行配置时，提出的交互式问题，需要确保用户能够准确理解。我们可以思考用户输入的本质：一方面，针对用户的每一项提问，要有更少的配置选项；另一方面，用户又想了解系统如何实现他们的需求，这就需要更多的选项。 让我们以沏茶的过程来比喻如何配置的过程。在配置项比较少的情况下，用户可以要求“热绿茶”，并能基本满足用户需求。相反，配置项很多的情况下，用户可以要求：水量、水温、茶叶品牌、茶叶分量、浸泡时间、茶杯类型。为了获取接近完美的茶，而使用更多配置项，坚持这些细节所付出的成本和代价，可能太大。 这个比喻对用户和配置系统开发人员都很有帮助。当用户确定操作步骤时，系统应按照他们要求进行。但是当用户只清楚自己目标时，我们的系统可以改进其中的配置步骤，最终实现用户目标即可。因此，预先了解用户目标是很有必要的。 此理论在实际应用中发挥的价值，以任务调度系统来补充说明。假如你需要运行一个分析进程，通过Kubernetes或Mesos可以实现你的目标，而不需要你花费很长时间去配置细节参数，比如选择哪台物理机运行等。 配置的必选项和可选项 配置分为两类：必选项和可选项。必选项的配置回答的问题针对核心功能。例如谁为一项手术收费。可选项一般不代表核心功能，但配置这些选项可以提高功能的质量——例如，设置一些工作进程。 为了保持以用户为中心并确保易用性，你的系统应尽量减少必选配置的数量。这不是一件容易的事，但这很重要。虽然人们可能会争辩说，增加一个或两个小步骤只会增加很少的成本，但工程师的生活往往是一个无穷无尽的单独步骤链。这些小步骤的减少可以显着提高工作效率。 最初的一组必选配置通常包括您在设计系统时考虑的问题。减少必选项的最简单方法是将它们转换为可选项，这意味着这些默认配置可以安全有效地应用于大多数（如果不是全部）用户。例如，我们可以简单地执行运行，而不是要求用户定义执行是否应该运行。 虽然默认值通常是保存在代码中的静态值，但并非必须如此。它可以基于系统的其他属性动态确定。利用动态确定可以进一步简化配置。 对于上下文，请参考以下动态默认示例。计算密集型系统通常可以通过配置控制使用多少计算线程。它的动态缺省配置了与系统（或容器）具有执行核数一样多的线程。在这种情况下，单个静态默认值没有用。动态默认值意味着我们不要求用户给定平台上部署的正确线程数。同样，单独部署在容器中的Java二进制文件可以根据容器中的可用内存自动调整其堆限制。这是两个常见的动态默认值示例。如果您需要限制资源使用，则对能够覆盖配置中的动态默认值非常有用。 使用动态默认值可能不适用于所有人。随着时间的推移，用户可能更喜欢不同的方法并要求更好地控制动态默认值。如果很多用户反映动态配置有问题，一般来说这表示你的动态配置逻辑可能不再符合当前用户群的要求。需要考虑实施改进，使您的动态默认值无需额外的配置即可运行。如果只有一小部分用户不满意，他们最好手动设置配置选项。更复杂的系统会增加用户的工作量（例如，增加了文档的阅读难度）。 在为可选项选择默认选项时，无论您选择静态还是动态默认值，请仔细考虑您选择的影响。经验表明，大多数用户会使用默认值，因此默认值的配置既是机会也是责任。你可以巧妙地向人们推进正确的方向，但指定错误的默认值会造成很大的伤害。例如，考虑配置默认值及其在计算机科学之外的影响。器官默认捐献的国家的器官捐献都比例明显高于器官默认不捐献的国家。简单地选择特定的默认值会对整个系统中的医疗选择产生深远的影响。 一些可选项在没有明确用例的情况下开始。您可能想要完全删除这些问题。大量可选项可能会使用户感到困惑，因此您应该仅在真正需要的情况下添加配置选项。最后，如果您的配置恰好使用了继承的概念，那么能够恢复配置中任何可选项的默认值是很有用的。 避免简单 到目前为止，我们已经讨论过将系统配置简化为最简单的形式。但是，配置系统也可能需要考虑高级用户。回到我们的茶类比，如果我们真的需要在特定时间内浸泡茶怎么办？ 适应高级用户的一种策略是找到常规用户和高级用户所需要的最低公分母，并将此复杂性作为默认值。缺点是这个决定会影响每个人; 即使是最简单的用例现在也需要以低级别的角度来考虑。 通过根据默认行为的可选覆盖考虑配置，用户配置“绿茶”，然后添加“将茶浸泡五分钟。”在此模型中，默认配置仍然是高级别并且接近用户的目标，但用户可以微调低级别配置。这种方法并不新颖。我们可以用高级编程语言（如C ++或Java）做类比，程序员能够将代码中的机器（或VM）指令包含在以高级语言编写的代码中。在某些消费者软件中，我们看到具有高级选项的屏幕可以提供比典型视图更精细的控制。 优化整个配置的总时间是有用的。不仅要考虑配置本身的行为，还要考虑用户在提供许多选项时可能遇到的决策困难，在纠正错误配置所需的时间，由于信心较低而导致的修改配置速度较慢等等。在考虑配置设计备选方案时，如果能够更轻松地支持最常见的用例，则可以选择以较少但难度较大的步骤完成复杂配置的选项。 如果您发现超过一小部分用户需要复杂配置，则可能错误地识别了常见用例。如果是这样，请重新审视系统的初始产品假设并其他用户进行研究。 配置机制 到目前为止，我们的讨论涵盖了配置哲学。本节将重点转移到用户如何与配置交互的机制。 单独的配置和产生的数据 存储配置的语言是一个不可避免的问题。您可以选择使用INI、YAML或XML文件中的纯数据。或者，配置可以存储在更高级语言中，以允许更灵活的配置。 从根本上说，向用户提出的所有问题都可以归结为静态信息）。这显然对“应该使用多少线程”等问题的静态回答）“但是，即使”每一个请求都应该使用什么功能？“也只是功能的静态引用。 要回到配置是代码还是数据这个古老的问题，我们的经验表明，代码和数据都有，但将两者分离是最优的。系统基础结构应该对纯静态数据进行操作，这些数据可以是协议缓冲区、YAML或JSON等格式。这种选择并不意味着用户需要与纯数据进行实际交互。用户可以与生成此数据的高级接口进行交互。然而，这种数据格式可以被API使用，从而允许系统和自动化的进一步堆叠。 这个高级接口几乎可以是任何东西。它可以是一种高级语言，如基于Python的域特定语言（DSL）、Lua或专用构建语言，如Jsonnet（我们将在第15章中详细讨论）。我们可以把这样的接口看作一个编译，类似于我们如何对待C++代码。高级接口也可能根本不是语言其配置由web UI消化。 从有意与静态数据表示分离的配置UI开始，意味着系统具有部署的灵活性。不同的组织可能具有不同的文化规范或产品需求（例如使用公司内的特定语言或需要将配置外部化到最终用户），并且这种通用的系统可以适用于支持不同的配置需求。毫不费力地支持多种语言。参见图14-2。 图14-2。配置流具有单独的配置界面和配置数据基础结构。请注意，Web UI通常还会显示当前配置，从而使关系成为双向关系。 这种分离对于用户来说是完全不可见的。用户的共同路径可能是在配置语言中编辑文件，而所有其他的事情都发生在幕后。例如，一旦用户向系统提交更改，新存储的配置就自动编译成原始数据 静态配置数据一旦获得，也可以在数据分析中使用。例如，如果生成的配置数据是JSON格式的，那么可以将其加载到PostgreSQL中，并用数据库查询进行分析。作为基础架构所有者，您可以快速且容易地查询正在使用哪些配置参数以及由谁使用这些配置参数。此查询对于识别您可以删除的特性或测量bugy选项的影响非常有用。 当使用最终的配置数据时，您会发现存储有关配置如何被摄取的元数据也很有用。例如，如果您知道数据来自Jsonnet中的配置文件，或者您在将数据编译成数据之前已经拥有了原始数据的完整路径，那么您可以跟踪配置作者。 配置语言是静态数据也是可以接受的。例如，您的基础结构和接口都可能使用普通JSON。但是，要避免接口使用的数据格式和内部使用的数据格式之间的紧密耦合。例如，您可以在内部使用包含配置所消耗的数据结构的数据结构。内部数据结构还可能包含完全特定于实现的数据，这些数据永远不需要在系统外部出现。 工具的重要性 工具可以区分混乱的噩梦和可持续的可伸缩的系统，但在设计配置系统时经常会被忽略。本节讨论优化配置系统应该有的关键工具。 语义验证 虽然大多数语言提供现成的语法验证，但不要忽视语义验证。即使您的配置在语法上有效，它是否可能做有用的事情？或者用户是否引用了一个不存在的目录（由于打字错误），或者需要比实际数据库多一千倍的RAM（因为单位不是用户所期望的）？ 尽可能验证配置在语义上是否有意义，有助于防止中断并降低运营成本。对于每个可能的错误配置，我们应该问自己，在用户提交配置时是否可以阻止它，而不是在提交更改之后。 配置语法 虽然能够确保配置满足用户需求，但消除机械障碍也很重要。从语法角度来看，配置语言应该具备一下特点： 在编辑器中高亮显示语法（在公司内使用） 通常，您已经通过重用现有语言解决了这个问题。但是，特定语言可能具有额外的语法方式，从特定的方面突出显示 。 短绒 使用linter来识别语言使用中的常见不一致。 Pylint是一种流行的语言示例。 自动语法格式化 内置标准化可最大限度地减少关于格式化的讨论，并在贡献者切换项目时减少认知负荷。标准格式化还可以实现更轻松的自动编辑，这在大型组织中很有用。现有语言中的autoformatters示例包括clang-format和autopep8。 这些工具使用户能够轻松地编写和编辑配置并确保其语法正确。在面向空白的配置中进行正确的缩进会产生很大的优势。 权限和变更跟踪 由于配置可能会影响公司和机构的关键系统，因此确保良好的用户隔离以及了解系统中发生的变化非常重要。如第10章所述，有效的死后文化可以避免责怪个人。但是，它既可以在事件期间进行，也可以在进行事后调查时知道谁更改了配置，并了解配置更改如何影响系统。无论事故是由于事故还是恶意行为都是如此。 系统的每个配置代码段都应具有明确的所有者。例如，如果使用配置文件，则其目录可能由单个生产组拥有。如果目录中的文件只能有一个所有者，则跟踪谁进行更改会更容易。 版本控制配置，无论其执行方式如何，都允许您及时返回以查看在任何给定时间点配置的内容。将配置文件检入版本控制系统（如Subversion或Git）是当今常见的做法，但这种做法对于Web UI或远程API提取的配置同样重要。您可能还希望在配置和正在配置的软件之间实现更紧密的耦合。通过这样做，您可以避免无意中配置软件中尚不可用或不再支持的功能。 在相关的说明中，将配置和生成的应用程序的更改记录到系统是有用的（有时是必需的）。提交新版本配置的简单操作并不总是意味着直接应用配置（稍后将详细介绍）。如果在事件响应期间怀疑系统配置更改是罪魁祸首，则能够快速确定进行更改的完整配置编辑集非常有用。这样可以实现可靠的回滚，并能够通知其配置受到影响的各方。 安全配置变更申请 如前所述，配置是对系统功能进行大量更改的简单方法，但它通常不经过单元测试甚至不易测试。由于我们希望避免可靠性事件，因此我们应该检查配置更改的安全应用是什么。 要使配置更改安全，它必须具有三个主要属性： 逐步部署，避免全有或全无变化的能力 如果证明存在风险，则可以回滚更改 如果更改导致失控，则自动回滚（或至少是停止进度的能力） 部署新配置时，避免全局一次性推送非常重要。相反，逐步推出新配置 - 这样做可以让您在导致100％中断之前检测问题并中止有问题的推送。这就是Kubernetes等工具使用滚动更新策略更新软件或配置而不是一次更新每个集群的原因之一。（有关相关讨论，请参阅第16章。） 回滚能力对于减少故障持续时间非常重要。回滚有问题的配置可以比临时修复程序更快地缓解故障-对修补程序改进的内在信心肯定较低。 为了能够向前滚动和回滚配置，它必须是密封的。需要可在其密封环境之外进行更改的外部资源的配置可能很难回滚。例如，存储在引用网络文件系统上的数据的版本控制系统中的配置不是密封的。 最后但同样重要的是，在处理可能导致操作员控制突然丧失的变更时系统应特别小心。在桌面系统上，如果用户未确认更改，屏幕分辨率更改通常会提示倒计时并重置。这是因为不正确的显示器设置可能会阻止用户恢复更改。同样，系统管理员通常会意外地将自己防火墙移出他们当前正在设置的系统。 这些原则并非配置所独有，适用于更改已部署系统的其他方法，例如升级二进制文件或推送新数据集。 结论 琐碎的配置更改可能会以极大的方式影响生产系统，因此我们需要刻意设计配置以减轻这些风险。配置设计包含API和UI设计的各个方面，应该是有目的的，而不仅仅是系统实现的副作用。将配置分为哲学和机制有助于我们在设计内部系统时获得清晰度，并使我们能够正确地进行讨论。 应用这些建议需要时间和勤勉。有关我们如何在实践中应用这些原则的示例，请参阅有关Canary Analysis Service的ACM Queue文章。在设计这个实用的内部系统时，我们花了大约一个月的时间来尝试减少强制性问题并为可选问题找到合适的答案。我们的努力创造了一个简单的配置系统。因为它易于使用，所以它在内部被广泛采用。我们已经看不到用户支持的需求 - 因为用户可以轻松了解系统，他们可以放心地进行更改。当然，我们还没有完全消除错误配置和用户支持，我们也没有想到。</summary></entry></feed>